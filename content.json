{"meta":{"title":"JJW-STORY","subtitle":null,"description":null,"author":"JJW","url":"https://jjw-story.github.io","root":"/"},"pages":[{"title":"","date":"2019-07-06T09:23:47.544Z","updated":"2019-07-06T09:23:47.544Z","comments":true,"path":"about/index.html","permalink":"https://jjw-story.github.io/about/index.html","excerpt":"","text":"关于我北京车和家信息技术有限公司~~开发工程师 关于工作城市：北京 关于学习每天都走在学习的大路上 关于座右铭 The Harder You Work, The Luckier You Will Be. (越努力，越幸运) 关于爱好杂乱无章 联系我 Home: JJW-STORE.GITHUB.IO Blog: JJW-STORE.GITHUB.IO Email: CHINAGOLDWJ@163.COM GitHub: JJW-STORE WeiBo: JJWStrive"}],"posts":[{"title":"Docker入门","slug":"Docker入门","date":"2020-04-20T13:05:38.000Z","updated":"2020-04-25T11:30:02.998Z","comments":true,"path":"2020/04/20/Docker入门/","link":"","permalink":"https://jjw-story.github.io/2020/04/20/Docker入门/","excerpt":"","text":"Docker入门容器技术介绍原始方式的应用程序部署有以下不足： 部署非常慢（需要找机房，安装操作系统及各种环境等） 成本非常高（有些应用程序占用的资源非常少，但是我们还是要部署一个机器，成本很高） 资源浪费（应用程序使用资源很少，导致我们的机器很多资源都在空置，造成浪费） 难于迁移和扩展（我们迁移应用的时候需要重新找机器安装各种环境，扩展同理，也需要我们准备各种环境，有的时候可以通过扩展机器配置来完成，但这样也很麻烦） 虚拟化技术出现以后： 一个物理机可以部署多个APP，每个APP可以运行在单独的一个VM中，虚拟化的优点： 资源池：一个物理机的资源分配到了不同的虚拟机中，可以节约资源 很容易扩展：在扩展的时候我们可以通过添加物理机或加虚拟机的方式来实现 虚拟化的局限性： 每个虚拟机都是一个完整的操作系统，需要给其分配资源，当虚拟机数量增多时，操作系统本身消耗的资源势必增多 容器技术解决了什么问题： 对软件和其依赖的标准化自动化打包和发布 能实现应用之间的相互隔离，类似于上述虚拟化技术的隔离，但是它的隔离没有虚拟化技术隔离的那么好 容器可以共享同一个OS（实现多个应用程序运行在一个OS上） 可以运行在很多主流的操作系统上 容器是APP层面的隔离，虚拟化是物理资源层面的隔离，我们也可以将虚拟化技术与容器技术结合使用，既对物理机器划分为不同的VM，每个VM上运行多个容器 Docker介绍Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从 Apache2.0 协议开源。 Docker 可以让开发者打包他们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。 容器是完全使用沙箱机制，相互之间不会有任何接口（类似 iPhone 的 app），更重要的是容器性能开销极低。 Docker的优点Docker 是一个用于开发，交付和运行应用程序的开放平台。Docker 使您能够将应用程序与基础架构分开，从而可以快速交付软件。借助 Docker，您可以与管理应用程序相同的方式来管理基础架构。通过利用 Docker 的方法来快速交付，测试和部署代码，您可以大大减少编写代码和在生产环境中运行代码之间的延迟。 1、快速，一致地交付您的应用程序 Docker 允许开发人员使用您提供的应用程序或服务的本地容器在标准化环境中工作，从而简化了开发的生命周期。 容器非常适合持续集成和持续交付（CI / CD）工作流程，请考虑以下示例方案： 您的开发人员在本地编写代码，并使用 Docker 容器与同事共享他们的工作。他们使用 Docker 将其应用程序推送到测试环境中，并执行自动或手动测试。当开发人员发现错误时，他们可以在开发环境中对其进行修复，然后将其重新部署到测试环境中，以进行测试和验证。测试完成后，将修补程序推送给生产环境，就像将更新的镜像推送到生产环境一样简单。 2、响应式部署和扩展 Docker 是基于容器的平台，允许高度可移植的工作负载。Docker 容器可以在开发人员的本机上，数据中心的物理或虚拟机上，云服务上或混合环境中运行。 Docker 的可移植性和轻量级的特性，还可以使您轻松地完成动态管理的工作负担，并根据业务需求指示，实时扩展或拆除应用程序和服务。 3、在同一硬件上运行更多工作负载 Docker 轻巧快速。它为基于虚拟机管理程序的虚拟机提供了可行、经济、高效的替代方案，因此您可以利用更多的计算能力来实现业务目标。Docker 非常适合于高密度环境以及中小型部署，而您可以用更少的资源做更多的事情。 Docker架构和底层技术实现docker的前生LXCLXC为Linux Container的简写。可以提供轻量级的虚拟化，以便隔离进程和资源，而且不需要提供指令解释机制以及全虚拟化的其他复杂性。相当于C++中的NameSpace。容器有效地将由单个操作系统管理的资源划分到孤立的组中，以更好地在孤立的组之间平衡有冲突的资源使用需求。与传统虚拟化技术相比，它的优势在于： 与宿主机使用同一个内核，性能损耗小； 不需要指令级模拟； 不需要即时(Just-in-time)编译； 容器可以在CPU核心的本地运行指令，不需要任何专门的解释机制； 避免了准虚拟化和系统调用替换中的复杂性； 轻量级隔离，在隔离的同时还提供共享机制，以实现容器与宿主机的资源共享。 总结：Linux Container是一种轻量级的虚拟化的手段。Linux Container提供了在单一可控主机节点上支持多个相互隔离的server container同时执行的机制。Linux Container有点像chroot，提供了一个拥有自己进程和网络空间的虚拟环境，但又有别于虚拟机，因为lxc是一种操作系统层次上的资源的虚拟化。 docker并不是LXC替代品，docker底层使用了LXC来实现，LXC将linux进程沙盒化，使得进程之间相互隔离，并且能够控制各进程的资源分配。 Docker架构Docker架构可以分为三个部分 Docker Client：这个就是我们平时操作Docker的主要入口，我们输入各种命令都是通过Client来操作的，客户端可以与Docker在同一个服务 Docker Host：是我们启动了docker的机器，也就是Docker所在的服务器，这上面主要有两个重要的概念，Containers（镜像）和images（容器） Image镜像：docker镜像就是一个只读模板，比如，一个镜像可以包含一个完整的centos，里面仅安装apache或用户的其他应用，镜像可以用来创建docker容器，另外docker提供了一个很简单的机制来创建镜像或者更新现有的镜像，用户甚至可以直接从其他人那里下载一个已经做好的镜像来直接使用。 Image是文件和meta data的集合，Linux分为内核空间和用户空间，内核空间就是Linux Kernel，也称为bootfs，用户空间其实就是基于此内核空间我们创建了各种Linux的发行版本，比如Ubuntu，CentOS，Debian等，这些其实就是一个Image，被称为Base Image，在此基础上，我们可以创建更高一级的Image，Base Image是不包含Liunx内核的，所以我们这些不同的Image可以共享Linux内核，也就是bootfs。我们可以在此Base Image上安装各种不同的软件，然后就形成了新的Image，个人理解Image就是基于内核安装各种不同的软件，然后形成不同的镜像，成为Image。所以Image是可以分层的，我们可以在每一层添加和删除文件，形成新的Image。 Image的获取有两种方式，1.我们的Docker Image，可以通过手动创建Dockerfile，然后根据它的语法来写入指令，实现自己的Dockerfile。2.Pull from Registry，其实就是类似于GitHub，我们通过Pull命令来此远程仓库拉取公开的各种Dockerfile，一般是通过Docker Hub来拉取，它是一个官方的仓库，我们可以去此仓库找到我们需要的Dockerfile，下载到本地，来创建我们的专用的Docker容器。 container容器：docker利用容器来运行应用，容器是从镜像创建的运行实例，它可以被启动，开始、停止、删除、每个容器都是互相隔离的，保证安全的平台，可以把容器看做是要给简易版的linux环境（包括root用户权限、镜像空间、用户空间和网络空间等）和运行再其中的应用程序。 × container是通过image创建的。container是在image之上建立的一个container layer（可读写），image是一个只读的东西，container要去运行程序或者安装软件，所以它是可写的。container和image类似与我们Java中类和实例的关系，container就是实例，image是负责app的存储和分发的，Container负责运行App。 Registry：是一个存储容器镜像的仓库。而容器镜像是在容器被创建时，被加载用来初始化容器的文件架构与目录。它可以理解为我们的GitHUb，仓库是集中存储镜像文件的，registry是仓库主从服务器，实际上参考注册服务器上存放着多个仓库，每个仓库中又包含了多个镜像，每个镜像有不同的标签（tag），仓库分为两种，公有参考，和私有仓库，最大的公开仓库是docker Hub，存放了数量庞大的镜像供用户下周，国内的docker pool，这里仓库的概念与Git类似，registry可以理解为github这样的托管服务 底层技术支持 Namespace docker是通过namespace实现资源隔离，它可以实现六项资源的隔离， UTS：主机与域名 IPS：信号量和消息队列和共享内容 PID：进程编号 NETWORK：网络设备、网络栈、端口等 MOUNT：挂载点，既文件系统 USER：用户和用户组 Control Group CGroup它是用来做资源限制的，主要有四大功能： 资源限制：可以对任务使用的资源总额进行限制 优先级分配：通过分配的cpu时间片数量以及磁盘IO带宽大小，实际上相当于控制了任务运行优先级 资源统计：可以统计系统的资源使用量，如cpu时长，内存用量等 任务控制：cgroup可以对任务执行挂起、恢复等操作 Union file systems Container和image的分层，Docker的存储驱动的实现是基于Union File System，简称UnionFS，他是一种为Linux 、FreeBSD 和NetBSD 操作系统设计的，把其他文件系统联合到一个联合挂载点的文件系统服务。它用到了一个重要的资源管理技术,叫写时复制。写时复制（copy-on-write），也叫隐式共享，是一种对可修改资源实现高效复制的资源管理技术。对于一个重复资源，若不修改，则无需立刻创建一个新的资源，该资源可以被共享使用。当发生修改的时候，才会创建新资源。这会大大减少对于未修改资源复制的消耗。Docker正式基于此去创建images和containers 入门使用及基本命令Image操作 查询当前所有的image：docker image ls 或者 docker images 删除image：docker image rm ‘Image ID’ 或者 docker rmi ‘Image ID’， ‘Image ID‘是通过ls命令查出的，有时候我们一个Dockerfile被build成了多个image，这时我们不能直接删除，可以加 -f 参数来强制删除，示例： 12345678910111213141516171819202122# 1.查看所有的imagejw@jjw-PC:~$ docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEjjw-story/hello-docker-c latest 73404f3002a9 47 minutes ago 756kBjjw-story/hello-docker-copy latest f982998b02d3 49 minutes ago 682Bjjw-story/hello-docker latest ad1e583a2447 51 minutes ago 682B# 第一种删除方案# 2.删除失败jjw@jjw-PC:~$ docker image rm f982998b02d3Error response from daemon: conflict: unable to delete f982998b02d3 (must be forced) - image is being used by stopped container 88443ef588b1# 3.强制删除jjw@jjw-PC:~$ docker image rm -f f982998b02d3Untagged: jjw-story/hello-docker-copy:latestDeleted: sha256:f982998b02d382876511b156632c77d795a8155103e4a7e2c4d67703a16be89c# 4.查看结果jjw@jjw-PC:~$ docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEjjw-story/hello-docker-c latest 73404f3002a9 About an hour ago 756kBjjw-story/hello-docker latest ad1e583a2447 About an hour ago 682B 如上示例，COMMAND 列展示的其实是我们在 Dockerfile CMD项 指定的命令 Container操作 创建container即实例化Image：docker run ‘Image tag’，image tag就是我们使用Dockerfile构建image时指定的tag 交互式运行container，及后台运行不自动关闭，以便我们可以再次container中进行一些操作：douker run -it ‘Image tag’，如下示例： 12jjw@jjw-PC:~$ docker run jjw-story/hello-docker-chello docker 查看当前所有正在运行的container：docker container ls，如下示例： 查看所有的container，包括历史运行的：docker container ls -a 或者 docker ps -a，如下示例： 1234jjw@jjw-PC:~$ docker container ls -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES979454ee2253 jjw-story/hello-docker-c &quot;/hello&quot; 4 minutes ago Exited (0) 4 minutes ago sweet_davinciad4051fc47ed jjw-story/hello-docker &quot;java /HelloWorld&quot; 4 minutes ago Created clever_goodall 上述查询结果中，COMMAND 展示的就是我们在编写Dockerfile时制定的 CMD 所对应的命令内容 删除container： docker container rm ‘Container ID’ 或者直接 docker rm ‘Container ID’ 效果是一样的，默认删除的就是container，Container ID是通用 container ls 命令查询出来的，这里的ID我们也可以只写ID的前几位，只要能区分出唯一即可，例如： 12345678910jw@jjw-PC:~$ docker container ls -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESd4d452d8cf2c jjw-story/hello-docker-c &quot;/hello&quot; 3 minutes ago Exited (0) 3 minutes ago competent_varahamihira6f40251fb684 jjw-story/hello-docker-c &quot;/hello&quot; 4 minutes ago Exited (0) 4 minutes ago jovial_keldyshjw@jjw-PC:~$ docker container rm 6f6fjjw@jjw-PC:~$ docker container ls -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESd4d452d8cf2c jjw-story/hello-docker-c &quot;/hello&quot; 5 minutes ago Exited (0) 5 minutes ago competent_varahamihira 查看当前所有的container，并只显示id：docker container ls -aq，此命令会显示标题。去除标题：docker container ls -a | awk {‘print$1’} 基于上述命令删除所有的container：docker rm $(docker container ls -aq) 查看所有已经退出的容器：docker container ls -f “status=exited”, 只列出ID：docker container ls -f “status=exited” -q 删除所有已退出的容器：docker rm $(docker container ls -f “status=exited” -q)","categories":[{"name":"Docker","slug":"Docker","permalink":"https://jjw-story.github.io/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://jjw-story.github.io/tags/Docker/"},{"name":"入门","slug":"入门","permalink":"https://jjw-story.github.io/tags/入门/"}],"author":"JJW"},{"title":"分布式消息队列","slug":"分布式消息队列","date":"2020-04-05T04:11:21.000Z","updated":"2020-04-05T11:28:25.175Z","comments":true,"path":"2020/04/05/分布式消息队列/","link":"","permalink":"https://jjw-story.github.io/2020/04/05/分布式消息队列/","excerpt":"","text":"MQ应用详解分布式消息队列的应用思考点 生产端的消息可靠性投递 就是有些业务场景我们需要消息是百分之百投递成功的，或者与我们的数据库一定是一个原子性的操作 消费端幂等 在生产端为了保证消息投递可靠的时候，可能会出现重复发送消息的情况，我们的消费端一定要做好消费的幂等，杜绝出现消息重复消费的情况 MQ的高可用 我们要保证MQ的节点在挂掉一个或多个，MQ还是可用的状态 MQ的低延迟 在流量非常大的时候，我们如何保证消息的低延迟 MQ的消息的可靠性 就是如果我们的消息落到了MQ中，如何保证消息肯定不会丢失，比如某个磁盘出现问题，还能使消息不丢失（一般都是使用分片、副本的概念解决） MQ消息的堆积能力 当消息量非常大，消费者消费速度跟不上的时候，我们的MQ能否堆积一个很大的消息量 扩展性等 主流的分布式消息队列目前业界主流的消息中间件有： ActiveMQ、RabbitMQ、RocketMQ、Kafka 如何进行技术选型 各个MQ的性能、优缺点、响应的业务场景、 集群架构模式，分布式、可扩展性、高可用、可维护性 综合成本问题，集群规模，人员成本（既看公司的技术栈，公司整体比较熟悉哪种MQ的使用等等的综合考虑） 未来的方向、规划、思考 JMS及其专业术语JMS（Java Message Service）规范，也就是Java消息服务，它定义了Java中访问消息中间件的接口的规范。在这里注意，JMS只是接口，并没有给予实现，实现JMS接口的消息中间件称为 “JMS Provider”，目前知名的开源 MOM （Message Oriented Middleware，也就是消息中间件）系统包括Apache的ActiveMQ、RocketMQ、Kafka，以及RabbitMQ，可以说他们都 “基本遵循” 或 “参考” JMS规范，都有自己的特点和优势 专业术语： JMS（Java Message Service）：实现JMS 接口的消息中间件； Provider（MessageProvider）：消息的生产者； Consumer（MessageConsumer）：消息的消费者； PTP（Point to Point）：即点对点的消息模型，这也是非常经典的模型； Pub / Sub（Publish/Subscribe）：，即发布/订阅的消息模型； Queue：队列目标，也就是我们常说的消息队列，一般都是会真正的进行物理存储； Topic：主题目标； ConnectionFactory：连接工厂，JMS 用它创建连接； Connection：JMS 客户端到JMS Provider 的连接； Destination：消息的目的地； Session：会话，一个发送或接收消息的线程（这里Session可以类比Mybatis的Session）； ActiveMQActiveMQ介绍ActiveMQ 是一个完全支持JMS1.1和J2EE 1.4规范的 JMS Provider实现，尽管JMS规范出台已经是很久的事情了，但是JMS在早些年的 “J2EE应用” 时期扮演着特殊的地位，可以说那个年代ActiveMQ在业界应用最广泛，当然如果现在想要有更强大的性能和海量数据处理能力，ActiveMQ还需要不断的升级版本，不断的提升性能和架构设计的重构。 就算现在我们 80% 以上的业务我们使用ActiveMQ已经足够满足需求，其丰富的API、多种集群构建模式使得他成为业界老牌消息中间件，在中小型企业中应用广泛！ 当然如果你想针对大规模、高并发应用服务做消息中间件技术选型，譬如淘宝、京东这种大型的电商网站，尤其是双11这种特殊时间，ActiveMQ可能就显得力不从心了 ActiveMQ消息投递模式 点对点：生产者向队列投递一条消息，只有一个消费者能够监听得到这条消息（PTP) 发布订阅：生产者向队列投递一条消息，所有监听该队列的消费者都能够监听得到这条消息（P/S) ActiveMQ各项指标衡量一个MOM，我们主要从三方面考虑即可，即服务性能、存储堆积能力、可扩展性。 服务性能：ActiveMQ的性能一般，在早期传统行业为王的时代还是比较流行的，但现如今面对高并发、大数据的业务场景，往往力不从心！ 数据存储：默认采用kahadb存储（索引文件形式存储），也可以使用高性能的google leveldb（内存数据库存储）， 或者可以使用MySql、Oracle进程消息存储（关系型数据库存储）。 集群架构：ActiveMQ 可以与zookeeper进行构建 主备集群模型，并且多套的主备模型直接可以采用Network的方式构建分布式集群。 ActiveMQ集群架构模式ActiveMQ最经典的两种集群架构模式，Master-Slave 、Network 集群模式 Master-Slave: 顾名思义，就是主从方式，当然这里要理解为主备的方式，也就是双机热备机制；Master Slave 背后的想法是，消息被复制到slave broker，因此即使master broker遇到了像硬件故障之类的错误，你也可以立即切换到slave broker而不丢失任何消息。 Master Slave是目前ActiveMQ推荐的高可靠性和容错的解决方案。 zookeeper的作用就是为了当绿色的主节点宕机时，进行及时切换到备份的灰色节点上去，使其进行主从角色的互换，用于实现高可用性的方案。 Master-Slave集群模型的缺点也显而易见，就是不能做到分布式的topic、queue，当消息量巨大时，我们的MQ集群压力过大，没办法满足分布式的需求 Network：这里可以理解为网络通信方式，也可以说叫Network of brokers。这种方式真正解决了分布式消息存储和故障转移、broker切换的问题。可以理解消息会进行均衡；从ActiveMQ1.1版本起，ActiveMQ支持networks of brokers。它支持分布式的queues和topics。一个broker会相同对待所有的订阅（subscription）：不管他们是来自本地的客户连接，还是来自远程broker，它都会递送有关的消息拷贝到每个订阅。远程broker得到这个消息拷贝后，会依次把它递送到其内部的本地连接上。（说白了就是部署多套MQ集群，以每个集群为单位进行通信，每个集群有自己的主从节点，有自己的zookeeper节点） Network集群模型的关键点： 这种方案需要两套或多套（Master-Slave）的集群模型才可以搞定，部署非常麻烦，需要两套或多套集群直接相互交叉配置，相互间能够感知到彼此的存在 Network虽然解决了分布式消息队列这个难题，但是还有很多潜在的问题，最典型的就是资源浪费问题，并且也可能达不到所预期的效果；通常采用Master-Slave模型是传统型互联网公司的首选，作为互联网公司往往会选择开箱即用的消息中间件，从运维、部署、使用各个方面都要优于ActiveMQ，当然ActiveMQ毕竟是 “老牌传统强Q”，Apache的顶级项目之一，目前正在进行新版本的重构（对于5.X版本）与落地。 RibbitMQRibbitMQ四种集群模式 主备模式warren（兔子窝）：经典的主备模式，正常情况由主节点提供服务，从节点只是备份数据，当主节点挂掉，从节点会代替主节点提供服务。与Active不同的是，主从实现不是通过zookeeper来实现的，它使用Haproxy实现的，Haproxy跟Nginx有点类似 远程模式早起版本提供的一种多活的模式，主要是服务异地的容灾，与上述ActiveMQ的NetWork模式非常类似，主要是在不同的地方部署不同的集群，可以提高容灾能力及处理性能，现在的版本已经不推荐使用 远距离通信和复制，可以实现多活的一种模式，简称Shovel模式，就是我们可以把消息进行不同的数据中心的复制工作，可以让跨地域的两个MQ集群互联，当其中的某一个集群处理消息处理不过来的时候，可以把消息转发到另外一个集群进行处理。集群之间的通信使用MQ的amqp协议来做通信的。此模式的配置非常麻烦，现在已经很少使用，只做了解就行。 镜像模式业界使用最为广泛的模型，非常经典的Mirror镜像模式，保证数据100%的不丢失，镜像模式其实就是数据的备份。可靠性非常高，因为数据发过来之后，它需要将数据同步到MQ镜像集群中所有的节点，所有节点都会对数据做备份存储，它的模型跟ES的很像，但是它的副本是在所有的节点上。但是缺点也很明显，就是每个节点都存储了所有的数据，如果我们要扩容的话只能增加所有节点的磁盘大小，而不能通过增加机器来实现 多活模型这种模式也是实现异地数据复制的主流模式，因为Shovel模式配置比较复杂，所以一般实现异地集群都是使用这种多活模型。这种模型需要依赖RabbitMQ的federation插件，可以实现持续可靠的AMQP数据通信，配置与应用很简单。 部署架构采用多中心模式，在两套或多套数据中心中各部署一套Rabbit集群，各中心的RabbitMQ服务除了为业务提供正常消息服务外，中心之间需要实现部分队列消息共享。集群可以是不同RibbitMQ版本的集群 RocketMQ概述RocketMQ是一款分布式、队列模型的消息中间件，由阿里巴巴自主研发的一款适用于高并发、高可靠性、海量数据场景的消息中间件。早期开源2.x版本名为MetaQ；15年迭代3.x版本，更名为RocketMQ，16年开始贡献到Apache，经过1年多的孵化，最终成为Apache顶级的开源项目，更新非常频繁，社区活跃度也非常高；RocketMQ参考借鉴了优秀的开源消息中间件Apache Kafka，其消息的路由、存储、集群划分都借鉴了Kafka优秀的设计思路，并结合自身的 “双十一” 场景进行了合理的扩展和API丰富。 优秀的能力与支持 支持集群模型、负载均衡、水平扩展能力 亿级别的消息堆积能力 采用零拷贝的原理、顺序写盘、随机读（索引文件） 丰富的API使用 代码优秀，底层通信框架采用Netty NIO框架 NameServer 代替 Zookeeper 强调集群无单点，可扩展，任意一点高可用，水平可扩展 消息失败重试机制、消息可查询 开源社区活跃度、是否足够成熟（经过双十一考验） 专业术语 Producer：消息生产者，负责产生消息，一般由业务系统负责产生消息。 Consumer：消息消费者，负责消费消息，一般是后台系统负责异步消费。 Push Consumer：Consumer的一种，需要向Consumer对象注册监听。 Pull Consumer：Consumer的一种，需要主动请求Broker拉取消息。 Producer Group：生产者集合，一般用于发送一类消息。 Consumer Group：消费者集合，一般用于接受一类消息进行消费。 Broker ： MQ消息服务（中转角色，用于消息存储与生产消费转发） 集群架构模型RocketMQ为我们提供了丰富的集群架构模型，包括单点模式、主从模式、双主模式、以及生产上使用最多的双主双从模式（或者说多主多从模式） Producer集群就是生产者集群（他们在同一个生产者组 Producer Group） Consumer集群就是消费者集群（他们在同一个消费者组 Consumer Group） NameServer集群作为超轻量级的配置中心，只做集群元数据存储和心跳工作，不必保障节点间数据强一致性，也就是说NameServer集群是一个多机热备的概念。 对于Broker而言，通常Master与Slave为一组服务，他们互为主从节点，通过NameServer与外部的Client端暴露统一的集群入口。Broker就是消息存储的核心MQ服务了。 RocketMQ作为国内顶级的消息中间件，其性能主要依赖于天然的分布式Topic/Queue，并且其内存与磁盘都会存储消息数据，借鉴了Kafka的 “空中接力” 概念，所谓 “空中接力” 就是指数据不一定要落地，RocketMQ提供了同步/异步双写、同步/异步复制的特性。在真正的生产环境中应该选择符合自己业务的配置。下面针对于RocketMQ的高性能及其瓶颈在这里加以说明： RocketMQ目前其主要瓶颈最终会落在IOPS上面，当高峰期来临的时候，磁盘读写能力是主要的性能瓶颈，为什么瓶颈在IOPS? 根本原因还是因为云环境导致的问题，云环境的SSD物理存储显然和自建机房SSD会有不小的差距，这一点我们无论是从数据库的磁盘性能、还是搜索服务（ElasticSearch）的磁盘性能，都能给出准确的瓶颈点，单机IOPS达到1万左右就是云存储SSD的性能瓶颈，这个也解释了 “木桶短板原理” 的效应，在真正的生产中，CPU的工作主要在等待IO操作，高并发下 CPU资源接近极限，但是IOPS还是达不到我们想要的效果。 与KAFKA对比既然RocketMQ有Kafka所有的优点，那么它两的区别在哪呢？ 消息投递实时性 Kafka使用短轮询方式，实时性取决于轮询间隔时间 RocketMQ使用长轮询，同Push方式实时性一致，消息的投递延时通常在几个毫秒。 严格的消息顺序 Kafka支持消息顺序，但是一台Broker宕机后，就会产生消息乱序 RocketMQ支持严格的消息顺序，在顺序消息场景下，一台Broker宕机后，发送消息会失败，但是不会乱序 namesrv VS zk kafka和rocketMq在协调节点选择上的差异，kafka通过zookeeper来进行协调，而rocketMq通过自身的namesrv进行协调。 kafka在具备选举功能，在Kafka里面，Master/Slave的选举，有2步：第1步，先通过ZK在所有机器中，选举出一个KafkaController；第2步，再由这个Controller，决定每个partition的Master是谁，Slave是谁。因为有了选举功能，所以kafka某个partition的master挂了，该partition对应的某个slave会升级为主对外提供服务。 rocketMQ不具备选举，Master/Slave的角色也是固定的。当一个Master挂了之后，你可以写到其他Master上，但不能让一个Slave切换成Master。那么rocketMq是如何实现高可用的呢，其实很简单，rocketMq的所有broker节点的角色都是一样，上面分配的topic和对应的queue的数量也是一样的，Mq只能保证当一个broker挂了，把原本写到这个broker的请求迁移到其他broker上面，而并不是这个broker对应的slave升级为主。 吞吐量 kafka在消息存储过程中会根据topic和partition的数量创建物理文件，也就是说我们创建一个topic并指定了3个partition，那么就会有3个物理文件目录，也就说说partition的数量和对应的物理文件是一一对应的。 rocketMq在消息存储方式就一个物流问题，也就说传说中的commitLog，rocketMq的queue的数量其实是在consumeQueue里面体现的，在真正存储消息的commitLog其实就只有一个物理文件。 kafka的多文件并发写入 VS rocketMq的单文件写入，性能差异kafka完胜可想而知。 kafka的大量文件存储会导致一个问题，也就说在partition特别多的时候，磁盘的访问会发生很大的瓶颈，毕竟单个文件看着是append操作，但是多个文件之间必然会导致磁盘的寻道。 在性能上Kafka是完胜的 KAFKA介绍Kafka是LinkedIn开源的分布式消息系统，目前归属于Apache顶级项目 主要特点是基于Pull的模式来处理消息消费，追求高吞吐量，一开始就是用于日志收集 0.8版本开始支持复制，不支持事务，对消息的重复、丢失、错误没有严格要求，适合产生大量数据的互联网服务的数据收集业务 特点 有分布式的特性，就是支持分区的概念，一个主题下可以有多个分区 有跨平台的特性，支持不同语言的客户端 堆积能力特别强，且并不影响消息的接收和发送 实时性非常强 高性能的原因（重点）顺序写就是顺序写盘，可以提高磁盘的利用率，就是一个一个的写，而不是随机写，这样会大大提高写的性能。 每个topic有不同的分区，而每个分区下包含若干个只能追加写的提交日志：新消息被追加到文件的最末端。最直接的证明就是Kafka源码中只调用了FileChannel.write(ByteBuffer)，而没有调用过带offset参数的write方法，说明它不会执行随机写操作。 Page Cache首先，Kafka重度依赖底层操作系统提供的PageCache功能。当上层有写操作时，操作系统只是将数据写入PageCache，同时标记Page属性为Dirty。当读操作发生时，先从PageCache中查找，如果发生缺页才进行磁盘调度，最终返回需要的数据。实际上PageCache是把尽可能多的空闲内存都当做了磁盘缓存来使用。同时如果有其他进程申请内存，回收PageCache的代价又很小，所以现代的OS都支持PageCache。 使用PageCache功能同时可以避免在JVM内部缓存数据，JVM为我们提供了强大的GC能力，同时也引入了一些问题不适用与Kafka的设计。 如果在Heap内管理缓存，JVM的GC线程会频繁扫描Heap空间，带来不必要的开销。如果Heap过大，执行一次Full GC对系统的可用性来说将是极大的挑战。 所有在在JVM内的对象都不免带有一个Object Overhead(千万不可小视)，内存的有效空间利用率会因此降低。 所有的In-Process Cache在OS中都有一份同样的PageCache。所以通过只在PageCache中做缓存至少可以提高一倍的缓存空间。 如果Kafka重启，所有的In-Process Cache都会失效，而OS管理的PageCache依然可以继续使用。 零拷贝首先介绍一下传统的网络I/O操作流程，大体上分为以下4步： OS从硬盘把数据读到内核区的PageCache。 用户进程把数据从内核区Copy到用户区。 然后用户进程再把数据写入到Socket，数据流入内核区的Socket Buffer上。 OS再把数据从Buffer中Copy到网卡的Buffer上，这样完成一次发送。 整个过程一共经历了四次拷贝，同一份数据在内核Buffer与用户Buffer之间重复拷贝，效率低下。其中2、3两步没有必要，完全可以直接在内核区完成数据拷贝。 零拷贝技术就是省略了第2、3步，不难看出，Kafka的设计初衷是尽一切努力在内存中完成数据交换，无论是对外作为一整个消息系统，或是内部同底层操作系统的交互。如果Producer和Consumer之间生产和消费进度上配合得当，完全可以实现数据交换零I/O。这也就是我为什么说Kafka使用“硬盘”并没有带来过多性能损失的原因。 主要特点 同时为发布和订阅提供高吞吐量。据了解，Kafka每秒可以生产约25万消息（50 MB），每秒处理55万消息（110 MB）。 可进行持久化操作。将消息持久化到磁盘，因此可用于批量消费，例如ETL，以及实时应用程序。通过将数据持久化到硬盘以及replication防止数据丢失。 分布式系统，易于向外扩展。所有的producer、broker和consumer都会有多个，均为分布式的。无需停机即可扩展机器。 消息被处理的状态是在consumer端维护，而不是由server端维护。当失败时能自动平衡。 支持online和offline的场景。 Kafka的架构Kafka的整体架构非常简单，是显式分布式架构，producer、broker（kafka）和consumer都可以有多个。Producer，consumer实现Kafka注册的接口，数据从producer发送到broker，broker承担一个中间缓存和分发的作用。broker分发注册到系统中的consumer。broker的作用类似于缓存，即活跃的数据和离线处理系统之间的缓存。客户端和服务器端的通信，是基于简单，高性能，且与编程语言无关的TCP协议。 基本概念 Topic：特指Kafka处理的消息源（feeds of messages）的不同分类。 Partition：Topic物理上的分组，一个topic可以分为多个partition，每个partition是一个有序的队列。partition中的每条消息都会被分配一个有序的id（offset）。 Message：消息，是通信的基本单位，每个producer可以向一个topic（主题）发布一些消息。 Producers：消息和数据生产者，向Kafka的一个topic发布消息的过程叫做producers。 Consumers：消息和数据消费者，订阅topics并处理其发布的消息的过程叫做consumers。 Broker：缓存代理，Kafka集群中的一台或多台服务器统称为broker。 发送消息的流程 Producer根据指定的partition方法（round-robin、hash等），将消息发布到指定topic的partition里面 kafka集群接收到Producer发过来的消息后，将其持久化到硬盘，并保留消息指定时长（可配置），而不关注消息是否被消费。 Consumer从kafka集群pull数据，并控制获取消息的offset kafka的优秀设计从kafka的吞吐量、负载均衡、消息拉取、扩展性来说一说kafka的优秀设计。 高吞吐高吞吐是kafka需要实现的核心目标之一，为此kafka做了以下一些设计： 内存访问：直接使用 linux 文件系统的cache，来高效缓存数据，对数据进行读取和写入。 数据磁盘持久化：消息不在内存中cache，直接写入到磁盘，充分利用磁盘的顺序读写性能。 zero-copy：减少IO操作步骤，采用linux Zero-Copy提高发送性能。传统的数据发送需要发送4次上下文切换，采用sendfile系统调用之后，数据直接在内核态交换，系统上下文切换减少为2次。根据测试结果，可以提高60%的数据发送性能。Zero-Copy详细的技术细节可以参考：https://www.ibm.com/developerworks/linux/library/j-zerocopy/ 对消息的处理：支持数据批量发送、支持数据压缩机制 主题分区：Topic划分为多个partition，提高生产/消费端处理消息的parallelism（并行度），数据在磁盘上存取代价为O(1)。kafka以topic来进行消息管理，每个topic包含多个part（ition），每个part对应一个逻辑log，有多个segment组成。每个segment中存储多条消息，消息id由其逻辑位置决定，即从消息id可直接定位到消息的存储位置，避免id到位置的额外映射。每个part在内存中对应一个index，记录每个segment中的第一条消息偏移。发布者发到某个topic的消息会被均匀的分布到多个part上（随机或根据用户指定的回调函数进行分布），broker收到发布消息往对应part的最后一个segment上添加该消息，当某个segment上的消息条数达到配置值或消息发布时间超过阈值时，segment上的消息会被flush到磁盘，只有flush到磁盘上的消息订阅者才能订阅到，segment达到一定的大小后将不会再往该segment写数据，broker会创建新的segment。 负载均衡 producer根据用户指定的算法，将消息发送到指定的partition 存在多个partiiton，每个partition有自己的replica，每个replica分布在不同的Broker节点上 多个partition需要选取出lead partition，lead partition负责读写，并由zookeeper负责fail over 通过zookeeper管理broker与consumer的动态加入与离开 消息的拉取 简化kafka设计（由于kafka broker会持久化数据，broker没有内存压力，因此，consumer非常适合采取pull的方式消费数据） consumer根据消费能力自主控制消息拉取速度 consumer根据自身情况自主选择消费模式，例如批量，重复消费，从尾端开始消费等 可扩展性当需要增加broker结点时，新增的broker会向zookeeper注册，而producer及consumer会根据注册在zookeeper上的watcher感知这些变化，并及时作出调整。 KAFKA应用场景 消息队列：比起大多数的消息系统来说，Kafka有更好的吞吐量，内置的分区，冗余及容错性，这让Kafka成为了一个很好的大规模消息处理应用的解决方案。消息系统一般吞吐量相对较低，但是需要更小的端到端延时，并常常依赖于Kafka提供的强大的持久性保障。在这个领域，Kafka足以媲美传统消息系统，如ActiveMQ或RabbitMQ。 行为跟踪：Kafka的另一个应用场景是跟踪用户浏览页面、搜索及其他行为，以发布-订阅的模式实时记录到对应的topic里。那么这些结果被订阅者拿到后，就可以做进一步的实时处理，或实时监控，或放到hadoop/离线数据仓库里处理。 元信息监控：作为操作记录的监控模块来使用，即汇集记录一些操作信息，可以理解为运维性质的数据监控吧。 日志收集：日志收集方面，其实开源产品有很多，包括Scribe、Apache Flume。很多人使用Kafka代替日志聚合（log aggregation）。日志聚合一般来说是从服务器上收集日志文件，然后放到一个集中的位置（文件服务器或HDFS）进行处理。然而Kafka忽略掉文件的细节，将其更清晰地抽象成一个个日志或事件的消息流。这就让Kafka处理过程延迟更低，更容易支持多数据源和分布式数据处理。比起以日志为中心的系统比如Scribe或者Flume来说，Kafka提供同样高效的性能和因为复制导致的更高的耐用性保证，以及更低的端到端延迟。 流处理：这个场景可能比较多，也很好理解。保存收集流数据，以提供之后对接的Storm或其他流式计算框架进行处理。很多用户会将那些从原始topic来的数据进行阶段性处理，汇总，扩充或者以其他的方式转换到新的topic下再继续后面的处理。例如一个文章推荐的处理流程，可能是先从RSS数据源中抓取文章的内容，然后将其丢入一个叫做“文章”的topic中；后续操作可能是需要对这个内容进行清理，比如回复正常数据或者删除重复数据，最后再将内容匹配的结果返还给用户。这就在一个独立的topic之外，产生了一系列的实时数据处理的流程。Strom和Samza是非常著名的实现这种类型数据转换的框架。 事件源：事件源是一种应用程序设计的方式，该方式的状态转移被记录为按时间顺序排序的记录序列。Kafka可以存储大量的日志数据，这使得它成为一个对这种方式的应用来说绝佳的后台。比如动态汇总（News feed） 持久性日志（commit log）：Kafka可以为一种外部的持久性日志的分布式系统提供服务。这种日志可以在节点间备份数据，并为故障节点数据回复提供一种重新同步的机制。Kafka中日志压缩功能为这种用法提供了条件。在这种用法中，Kafka类似于Apache BookKeeper项目。","categories":[{"name":"MQ","slug":"MQ","permalink":"https://jjw-story.github.io/categories/MQ/"}],"tags":[{"name":"MQ","slug":"MQ","permalink":"https://jjw-story.github.io/tags/MQ/"}],"author":"JJW"},{"title":"Shell","slug":"shell","date":"2020-03-22T09:58:31.000Z","updated":"2020-04-10T02:35:29.211Z","comments":true,"path":"2020/03/22/shell/","link":"","permalink":"https://jjw-story.github.io/2020/03/22/shell/","excerpt":"","text":"Shellshell介绍Shell 是一个用 C 语言编写的程序，它是用户使用 Linux 的桥梁。Shell 既是一种命令语言，又是一种程序设计语言Shell是命令解释器，用来解释用户对操作系统的操作，也就是将我们用户执行的命令，翻译给内核，内核根据命令执行的结果，将结果反馈给用户Shell 脚本（shell script），是一种为 shell 编写的脚本程序，业界所说的 shell 通常都是指 shell 脚本Shell有很多种，我们一般使用的都是 bash Linux的启动过程BLOS - MBR - BootLoader(grub) - kernel - systemd - 系统初始化 - shell BLOS：基本的输入输出系统，这个功能是在主板上的，通过BLOS来选择引导的介质，一般引导的介质有两种，一是早起使用到的光盘，二是硬盘。现在更多用的是网络的方式去引导 MBR：硬盘的主引导记录部分，硬盘是不是可以引导， 是通过这部分来确定的 BootLoader(grub)： 这里就是Linux的部分了，Linux的部分首先不是内核的工作引导，而是通过grub这样的一个软件来引导，grub我们在Linux中称为BootLoader，主要用来启动和引导内核的一个工具。我们可以简单理解为BootLoader是用来选择哪一个内核及选择指定内核版本的，选定后我们就要启动内核了 kernel：内核 systemd：Linux的一号进程，如果是CentOS7以下的版本，头号进程是 init 进程。在systemd中，系统初始化的过程一部分是通过配置文件完成的，一部分是通过shell完成的，init中，系统初始化过程都是通过shell完成的 Shell脚本的格式UNIX的哲学：一条命令只做一件事 为组合命令和多次执行，使用脚本文件来保存需要执行的命令 然后赋予该文件的执行权限（chmod u+rx filename） Shell脚本的作用就是将一系列的命令操作整合在一个文件里，然后再下次执行的时候可以直接执行此文件，而不需要我们一步一步的执行所有命令 一般我们都是使用bash的方式来执行我们的脚本文件，我们的shell脚本文件一般使用 .sh 作为文件的后缀 标准Shell脚本需要包含的元素 Sha-bang：就是每一个shell脚本文件的内容开头 以 #! 开头，是一个声明作用，如果我们使用 【bash 文件名.sh】 的方式来执行，那么此内容变不被识别，如果使用 【./文件名.sh】 的方式来执行，那么此文件头就表示告诉Linux系统，此文件需要使用 bash 脚本的，既告诉Linux，此文件是一个bash的脚本。下面是一般Sha-bang的内容： 1#!/bin/bash 命令：这里说的就是我们之前学习的那么多的Linux命令 “#” 开头的注释。在我们的shell脚本中，# 开头的行表示内容是注释 赋予文件可执行的权限。例如 chmod u+x aa.sh 执行命令的方式： bash ./filename.sh ./filename.sh source ./filename.sh .filename.sh 这里只需要注意：命令我们可以在一行中使用 ; 号隔开来写多个命令，但是一般我们是通过换行的方式来写多个命令","categories":[{"name":"Linux","slug":"Linux","permalink":"https://jjw-story.github.io/categories/Linux/"}],"tags":[{"name":"Shell","slug":"Shell","permalink":"https://jjw-story.github.io/tags/Shell/"}],"author":"JJW"},{"title":"逻辑卷管理","slug":"逻辑卷管理","date":"2020-03-15T07:37:55.000Z","updated":"2020-03-15T09:28:57.415Z","comments":true,"path":"2020/03/15/逻辑卷管理/","link":"","permalink":"https://jjw-story.github.io/2020/03/15/逻辑卷管理/","excerpt":"","text":"逻辑卷管理什么是逻辑卷许多Linux使用者安装操作系统时都会遇到这样的困境：如何精确评估和分配各个硬盘分区的容量，如果当初评估不准确，一旦系统分区不够用时可能不得不备份、删除相关数据，甚至被迫重新规划分区并重装操作系统，以满足应用系统的需要 LVM逻辑卷相当于在传统的硬盘的底层上面在叠一层，把上面的这一层也当做一个硬盘来对待，只是这个硬盘是一个虚拟的硬盘，RAID其实就是一个逻辑卷的应用，Linux中默认使用的就是根目录，逻辑卷去管理磁盘的 增加逻辑卷增加逻辑卷首先我们首先需要添加物理硬盘，然后对添加的物理硬盘做好分区，注意：这里可以添加多块硬盘，然后我们建立上层系统，将几块硬盘做一个整合，整合成一个物理卷，然后再上层查看磁盘状态的时候，我们发现这几个硬盘它是一个整体，只有一块硬盘，这样我们就可以通过上层的系统将这块硬盘划分成不同的逻辑卷（比如，给根目录划分挂载，给boot目录划分挂载，给usr划分挂载，将这些目录进行隔离开，这些隔离开的空间就称为逻辑卷） 下面是具体步骤： 12345678910111213141516171819202122232425262728293031323334# 1.将多块分区组成一个物理卷pvcreate /dev/sdb1 /dev/sdc1 /dev/sdd1# 注意这里可以使用简写，通配符pvcreate /dev/sd[b,c,d]1# 2.查看我们创建的物理卷，会发现我们添加的三块硬盘已经创建成了三个物理卷，但是他们的 VG 选项都是空的，VG选项表示他们属于哪个卷组，这里我们还没有对他们设置卷组pvs# 3.对物理卷设置卷组vgcreate vg1 /dev/sdb1 /dev/sdc1 /dev/sdd1-- 这里 vg1 表示卷组的名称# 4.创建成功后我们继续通过 pvs 命令查看，发现这三个分区的 VG 选项就有了值，是我们设置的vg1-- 注意一个分区只能属于一个卷组# 5.我们可以通过 vgs 命令来插件当前机器的卷组，来查看我们创建的卷组信息vgs-- 注意查询出来的 #LV 选项表述的就是此物理卷创建了几个逻辑卷，一般我们安装LINUX系统时，会默认创建一个逻辑卷，CENTOS，它里面会有两个逻辑卷，一般默认都是 / 和 boot 逻辑卷，我们先创建的物理卷这里会显示为0，表示还没有创建逻辑卷# 6.现在我们就可以创建逻辑卷了# 使用命令：lvcreate -L [逻辑卷大小] -n [逻辑卷名称] [物理卷名称]lvcreate -L 100M -n lv1 vg1# 7.现在通过lvs查看逻辑卷信息，我们发现里面已经有我们创建好的逻辑卷信息，然后通过vgs查看物理卷，发现vg1这个物理卷已经有了逻辑卷，既 #LV 选项值为1lvsvgs# 8.逻辑卷的使用，使用方法还是现将逻辑卷进行格式化，然后创建目录进行挂载# 8.1 创建文件夹mkdir /mnt/test# 8.2 格式化逻辑卷mkfs.xfs /dev/vg1/lv1# 8.3 mount挂载挂载成功后，此逻辑卷就可以正常使用 扩充逻辑卷很多时候当我们物理卷够用的情况下但是逻辑卷大小分配太小，我们可以直接从物理卷上扩充逻辑卷，有的情况是物理卷也太小，需要先扩充物理卷然后扩充逻辑卷，下面是扩充展示： 1234567891011121314151617181920212223242526# 1.扩充物理卷组首先添加磁盘，然后对新添加的磁盘进行分区，例如这里划分分区为 /dev/sde1# 2.将新的分区划分给需要扩充的物理卷组，下面命令 vg1 为物理卷组名称，后面是分区名称vgextend vg1 /dev/sde1# 3.使用pvs命令查看是否划分成功pvs# 4.使用vgs查看物理卷信息vgs-- 这里我们发现 vg1 物理卷的大小已经发生了变化，增大了我们新加入的磁盘分区大小# 5.扩充我们要扩充的逻辑卷, 下面命令 +10G 表示添加10G大小的空间给逻辑卷，后面是逻辑卷名称-- 注意：我们物理卷够用的时候，可以直接从这里开始扩充逻辑卷就好，不需要扩充物理卷lvextend -L +10G /dev/vg1/lv1# 6.使用lvs查看逻辑卷大小是否改变，这里发现已经被扩大lvs这里先不要着急，我们虽然看到逻辑卷已经被扩大，但是我们还没有告诉文件系统，文件系统还认为我们的大小没有变，这里需要告诉文件系统# 7.告诉文件系统xfs_growfs /dev/vg1/lv1# 8.使用 df -h 查看文件夹是否扩容成功df -h","categories":[{"name":"Linux","slug":"Linux","permalink":"https://jjw-story.github.io/categories/Linux/"}],"tags":[{"name":"command","slug":"command","permalink":"https://jjw-story.github.io/tags/command/"},{"name":"逻辑卷管理","slug":"逻辑卷管理","permalink":"https://jjw-story.github.io/tags/逻辑卷管理/"}],"author":"JJW"},{"title":"高效员工起航训练营","slug":"高效员工起航训练营","date":"2020-02-16T11:00:00.000Z","updated":"2020-02-18T03:37:47.358Z","comments":true,"path":"2020/02/16/高效员工起航训练营/","link":"","permalink":"https://jjw-story.github.io/2020/02/16/高效员工起航训练营/","excerpt":"","text":"高效员工起航训练营如何使执行效果达到预期（以终为始） 明确任务执行完成的目标，以任务实现达到的效果为目标，而不是以执行任务为目标 任务执行效果未达到预期，应以实际证据来支撑未达成目标的原因，而不是临时应付造原因 有效执行是第一有效的方案（积极主动） 接收到任务时，应该立即投入到执行中，不要拖拉，总在快要到交付时间的时候才开始，这样可以完成的记住任务所有的需求或要求，避免拖延执行而忘记某些需求点，导致目标实现效果不佳 即使在因为某些原因而不能立即执行，也应该将当时构思的方案及需求点记录下来，避免执行时丢失某些点 该吃吃该喝喝，该睡觉就好好睡，该玩就好好玩，拖延会造成在做任何事情都会顶着雷，并且随时会爆炸，导致每一种生活都受影响 如何在执行时获得有利帮助 及时汇报工作进展，当遇到个人无法解决的问题时，应及时向领导寻求帮助，使领导协调相应的资源及帮助，不要自己蒙头干，最后还完不成任务（重点：站会的目的，此处解释的淋漓尽致） 遇到问题一定要如实汇报，即使已解决的问题，也要即使汇报，汇报时要详细说明自己遇到的问题情况，并且如何解决的，可以汇报一些自己的收获，这是一种让领导认可你的方式 协调工作可以即使寻求领导帮助，自己协调完成也应该汇报给领导，得到领导的认可和指导 如何做到灵活执行 执行不是按照自己的意识就头脑发热立即开始执行，接到任务一定要分析任务，分析任务完成需要达到的目标，想清楚什么方式能达到最好的执行效果（重点：仔细分析，考虑到影响的结果及后期会产生的问题，全面考虑一下） 如何有效完成上司安排的日常任务（要事第一） 其实就是大石头，运用好的时间管理工具，任务要分清主次，紧急重要、紧急不重要、重要不紧急、不重要不紧急。 千万不要顾此失彼，重要的事情细心的办，分清主次，并且学会寻求帮助及遇到冲突及时反馈 如何明确有效倾听的内涵（知彼解己-同理心交流） 不要随意打断别人的话，保持眼神接触 在需要表达自己想法时，用请原谅来开头 及时察觉对方的情绪 重要内容记录笔记 社交行为风格与沟通技巧 与分析型人沟通:沟通时提供可靠的数据和信息，并且有条理的分析，尽量能有书面的提案，因为沟通者也需要时间思考和决定 与亲和型人沟通:有话好好说，有事好商量（发现我们组的人性格特性十分明显） 与干劲型人沟通:开门见山，态度真诚，少周旋，提供足够信息判断选择（与分析型不太好区分） 与表达型人沟通:这种类型人沟通时喜欢制造热烈与参与的气氛，乐于分享自己的梦想与激情，沟通喜欢激励、主动，比较关注他人对他的意见和看法。这这种类型人最好沟通，就是听他说，听他说，等他说的差不多了，然后你在绕回来直接问他最终的抉择 这一节有这些就够了（我非常确认我的领导们是什么样类型的） 如何与上司沟通？ 要有效的与领导沟通，需要我们仔细倾听，认真观察，理解上司的沟通风格，把握三个问题： 你的上司是倾听者还是阅读者？倾听者喜欢先听后度，阅读者喜欢先看到书面报告，再讨论 上司喜欢看详实材料和数据还是只看看概述？摸清楚之后，使用调整使用对应的策略 上司希望收到新消息的频率如何？了解上司是不是喜欢在某些特点点希望收到新消息，以及会不会不同的项目又不同的对待，摸清楚领导期望收到消息的频率，然后根据要求及时汇报 如何提高沟通效率 讨论期限要确切，避免尽快，或下周什么时候之类模糊的用语，给予确切的时间（重点注意） 坦陈自己能做到什么，做不到什么 要明确自己的目标 不明白就问，同时问清下次何时有机会沟通，因为之后可能还会想到其他问题（重点注意） 工作遇到问题，主动请教 遇到问题要正确面对，不要怕问，不懂的要及时请教别人，避免小问题拖成大问题 请教别人时需要注意： 确定请教对象，专业/专家，省时高效 选择合适的时间：不在别人忙碌时打扰别人 组织语言，确认重点：快速让别人清楚你要咨询什么 尽量一次问清楚：避免模棱相克和反复请教 请教问题时一定要礼貌客气：让别人感觉到你对他的尊重 这节是好东西，实际存在的问题（重点：一定要注意） 高效的与领导沟通 沟通前做好准备，沟通时做好确认（要准备好工作本身的相关资料，并且了解前因后果，这个是重点，遇到好几次了，一定要了解前因后果） 不能慌乱，实事求是。可以说目前是。。。情况，具体我会去核实一下 准备好方案，学会给领导做选择题（这个得慢慢来） 内容重点突出，直击要点，逻辑清晰（千万不要在自己都捋不清的情况下直接去找领导，这个也是重点） 先讲结论，再展开说明（这是一个技巧，要学习把握，重点） 注意沟通方式和态度，意见不一致不要发生激烈顶撞，先尊重和认可领导，在展开讨论 如何增加人脉建立的渠道 珍惜各种聚会及活动的机会，能增加个人曝光率 树立帮助观念这集不喜欢。。。 如何做好人脉的维护工作 有效打破规范（要注意礼仪礼貌，多听少说，尊重对方的想法和愿望，摸清楚对方的兴趣所在，意见不同的地方，要先肯定，再反问，后共识。要真诚赞美对方，发现对方的优点并赞美） 自己人脉圈内的人员要经常来往 如何与上级或同事保持良好的人际关系 如何与上级相处： 最大效率原则 最佳方式原则（开诚布公，表现自己的诚意） 最佳时机原则（选择合适的时间和地点） 及时性原则（及时与上级保持沟通，保证工作的时效性） 将心比心原则（站在领导角度替领导考虑） 尊敬原则（谦虚但不怯场） 道德原则（不说坏话） 特事特办原则（必要时可以越级） 与同事相处 三心两意（积极、知人、自信、主动、诚恳） 沟通合作只冲突处理 应对冲突的三个步骤 确定目标（是要坚持己见，还是满足对方，还是双赢） 选择策略 采取行动这里着重说采取策略： 坚持己见（运用的重点是要：1.坚定和明确立场。2.语气不可模棱两可。3.清晰果断表名自己的期望、观点。4.必要时说明不遵从的可能后果） 拖延回避（不表态、不退让、不采取行动）当局势不利于自己，对方比自己更着急，这样处理可以争取时间创造有利局面，并争取筹码 妥协退让（这里注意不要让对方感觉自己是经过长时间思考、放弃自己珍惜的事务后才做的决定。表明放弃自己的立场是为了想与对方维系长远关系、对方很重要等等） 寻求共赢（敞开心扉，齐心协力找最佳解决方式），双赢思想，这个不做赘述 如何确定问题根源理想工作八步法应该比这个更加详细","categories":[{"name":"高效员工起航训练营","slug":"高效员工起航训练营","permalink":"https://jjw-story.github.io/categories/高效员工起航训练营/"}],"tags":[{"name":"高效员工起航训练营","slug":"高效员工起航训练营","permalink":"https://jjw-story.github.io/tags/高效员工起航训练营/"}],"author":"JJW"},{"title":"Lamda","slug":"Lamda","date":"2019-12-29T08:57:11.000Z","updated":"2020-02-18T03:22:50.733Z","comments":true,"path":"2019/12/29/Lamda/","link":"","permalink":"https://jjw-story.github.io/2019/12/29/Lamda/","excerpt":"","text":"Lamda表达式基本语法函数式接口的应用函数式接口就是Java类型系统中的接口，是只包含一个接口方法的特殊接口，我们在定义函数式接口时，可以使用注解 @FunctionalInterface 来完成语义化的检测 以下是函数式接口的定义代码示例： 1234567891011121314151617181920212223242526272829303132// 定义函数式接口// 这里使用此注解来帮助我们实现一个正确的函数式接口@FunctionalInterfacepublic interface IUserCredential &#123; // 每一个函数式接口只能包含一个未实现的方法 String verifyUser(String username); // 这里注意，如果包含了两个就会报错，在编译期 // boolean test(); // 有一个特例，因为Java中的类都继承了Object，所以Object类中的方法可以写在这里不实现它 String toString(); // 注意：接口中可以包含实现的静态方法 static boolean verifyMessage(String msg) &#123; if (msg != null) &#123; return true; &#125; return false; &#125; // 1.8中可以在接口中定义默认的方法实现 default String getCredential(String username) &#123; // 模拟方法 if (&quot;admin&quot;.equals(username)) &#123; return &quot;admin + 系统管理员用户&quot;; &#125; else &#123; return &quot;commons + 普通会员用户&quot;; &#125; &#125;&#125; 以下是函数式接口的使用示例： 1234567891011121314151617181920212223// 首先是普通接口的调用实现// 1. 普通实现，直接初始化接口实现类IUserCredential ic = new UserCredentialImpl();System.out.println(ic.verifyUser(&quot;admin&quot;));// 2. 静态方法，直接调用String msg = &quot;hello world&quot;;IMessageFormat.verifyMessage(msg)// 3. 匿名内部类，实现接口的抽象方法IUserCredential ic2 = new IUserCredential() &#123; @Override public String verifyUser(String username) &#123; return &quot;admin&quot;.equals(username)?&quot;管理员&quot;:&quot;会员&quot;; &#125;&#125;;// 4. 使用Lamda的方式实现接口的抽象方法// 这里我们需要注意，Lamda是通过返回的接收对象确定它实现的是哪个接口的方法，所以当有多个函数式接口中都有相同的未实现方法参数列表时，我们是通过返回的接收对象来绑定实现的接口类型，，如此示例中，就是通过 IUserCredential ic3 这个返回的接收接口来类型推导，绑定实现的接口，所以不会有冲突的情况IUserCredential ic3 = (String username) -&gt; &#123; return &quot;admin&quot;.equals(username)?&quot;lbd管理员&quot;: &quot;lbd会员&quot;;&#125;; 以下是JDK8提供的常见的函数式接口 12345678910111213141516171819202122232425262728293031323334353637// 1. PredicatePredicate&lt;String&gt; pre = (String username) -&gt; &#123; return &quot;admin&quot;.equals(username);&#125;;System.out.println(pre.test(&quot;manager&quot;));// 2. ConsumerConsumer&lt;String&gt; con = (String message) -&gt; &#123; System.out.println(&quot;要发送的消息：&quot; + message); System.out.println(&quot;消息发送完成&quot;);&#125;;con.accept(&quot;hello 慕课网的学员们..&quot;);// 3. FunctionFunction&lt;String, Integer&gt; fun = (String gender) -&gt; &#123; return &quot;male&quot;.equals(gender)?1:0;&#125;;System.out.println(fun.apply(&quot;male&quot;));// 4. SupplierSupplier&lt;String&gt; sup = () -&gt; &#123; return UUID.randomUUID().toString();&#125;;System.out.println(sup.get());// 5. UnaryOperatorUnaryOperator&lt;String&gt; uo = (String img)-&gt; &#123; img += &quot;[100x200]&quot;; return img;&#125;;System.out.println(uo.apply(&quot;原图--&quot;));// 6. BinaryOperatorBinaryOperator&lt;Integer&gt; bo = (Integer i1, Integer i2) -&gt; &#123; return i1 &gt; i2? i1: i2;&#125;;System.out.println(bo.apply(12, 13)); java.util.function提供了大量的函数式接口，以上示例使用总结如下： Predicate 接收参数T对象，返回一个boolean类型结果 Consumer 接收参数T对象，没有返回值 Function 接收参数T对象，返回R对象 Supplier 不接受任何参数，直接通过get()获取指定类型的对象 UnaryOperator 接口参数T对象，执行业务处理后，返回更新后的T对象 BinaryOperator 接口接收两个T对象，执行业务处理后，返回一个T对象 lambda表达式的基本语法: 声明：就是和lambda表达式绑定的接口类型 参数：包含在一对圆括号中，和绑定的接口中的抽象方法中的参数个数及顺序一致 操作符：-&gt; 执行代码块：包含在一对大括号中，出现在操作符号的右侧 [接口声明] = (参数) -&gt; {执行代码块}; Lamda表达式的变量捕获首先我们查看原始代码风格中的变量捕获方式及存在的问题: 123456789101112131415161718192021222324252627public class App2 &#123; String s1 = &quot;全局变量&quot;; String s3 = &quot;全局变量s3&quot;; // 1. 匿名内部类型中对于变量的访问 public void testInnerClass() &#123; String s2 = &quot;局部变量&quot;; new Thread(new Runnable() &#123; String s3 = &quot;内部变量s3&quot;; @Override public void run() &#123; // 访问全局变量，这里用this访问到的是外部类中的全局变量s1，因为在内部类中并没有定义s1 System.out.println(this.s1); System.out.println(s1); System.out.println(s2); // 局部变量的访问，~不能对局部变量进行数据的修改[final] // s2 = &quot;hello&quot;; // 这里访问的就是内部类中定义的内部变量，因为就近原则，所以这里很多时候就会被初学者产生歧义 System.out.println(s3); System.out.println(this.s3); &#125; &#125;).start(); &#125; 我们再用lambda表达式变量捕获的方式来实现一遍： 12345678910111213141516171819202122232425public class App2 &#123; String s1 = &quot;全局变量&quot;; String s3 = &quot;全局变量s3&quot;; public void testLambda() &#123; String s2 = &quot;局部变量lambda&quot;; new Thread(() -&gt; &#123; String s3 = &quot;内部变量lambda&quot;; // 访问全局变量 System.out.println(this.s1);// this关键字，表示的就是所属方法所在类型的对象 // 访问局部变量 System.out.println(s2); // 这里不能进行数据修改，默认推导变量的修饰符：final，因为获取到的s2是在栈中的 s2 = &quot;hello&quot;; // 这里我们捕获到的变量就是外部定义的s3全局变量，这里就不会产生歧义 System.out.println(s3); // 这里获取到的s3变量是可以修改的，因为此外部的变量是存放在堆中的 s3 = &quot;labmda 内部变量直接修改&quot;; System.out.println(s3); &#125;).start(); &#125;&#125; 通过以上代码示例，我们就可以看出Lamda表达式对于变量捕获的影响 方法重载对于lmabda表达式的影响具体我们通过代码来查看： 12345678910111213141516171819202122232425262728293031323334353637383940414243public class App4 &#123; interface Param1 &#123; void outInfo(String info); &#125; interface Param2 &#123; void outInfo(String info); &#125; // 定义重载的方法 public void lambdaMethod(Param1 param) &#123; param.outInfo(&quot;hello param1 imooc!&quot;); &#125; public void lambdaMethod(Param2 param) &#123; param.outInfo(&quot;hello param2 imooc&quot;); &#125; // 这里我们通过匿名内部类来实现此重载方法，这样是没有任何问题的 public static void main(String[] args) &#123; App4 app = new App4(); app.lambdaMethod(new Param1() &#123; @Override public void outInfo(String info) &#123; System.out.println(info); &#125; &#125;); app.lambdaMethod(new Param2() &#123; @Override public void outInfo(String info) &#123; System.out.println(&quot;------&quot;); System.out.println(info); &#125; &#125;); // 这里我们通过lamda表达式来重载，发现是失败的， 会报错，因为它无法推导出具体要绑定的接口是哪个 // app.lambdaMethod( (String info) -&gt; &#123; // System.out.println(info); // &#125;); &#125;&#125; 以上示例说明，Lamda是存在类型推导的，lambda表达式存在类型检查-&gt; 自动推导lambda表达式的目标类型，具体推导流程如下 1234567lambdaMethod() -&gt; 方法 -&gt; 重载方法 -&gt; Param1 函数式接口 -&gt; Param2 函数式接口 调用方法-&gt; 传递Lambda表达式-&gt; 自动推导-&gt; -&gt; Param1 | Param2这里到了推导的最后一步，发现有两个接口满足此推导逻辑，导致产生了歧义，这样就出现了问题，导致无法编译 Lamda的方法引用的实现我们还是通过示例的代码来分析： 12345678910111213141516171819202122232425262728293031// 首次定义用于示例的实体类@Data@AllArgsConstructor@NoArgsConstructorclass Person &#123; private String name; // 姓名 private int age; // 年龄 // 这里使用lombox，有默认的构造方式 AllArgsConstructor // 静态方法 public static int compareByAge(Person p1, Person p2) &#123; return p1.getAge() - p2.getAge(); &#125; // 实例方法 public int compareByName(Person p1, Person p2) &#123; return p1.getName().hashCode() - p2.getName().hashCode(); &#125;&#125;// 静态方法调用Person::compareByAge// 实例方法调用Person pu = new Person();pu::compareByName// 构造方法引用：绑定函数式接口Person ip = Person::new; // 无参构造Person person = ip.initPerson(&quot;jerry&quot;, &quot;男&quot;, 22); // 有参构造 Stream常见操作API介绍Stream的获取 批量数据 -&gt; Stream对象 123456789101112131415161718192021222324// 多个数据Stream stream = Stream.of(&quot;admin&quot;, &quot;tom&quot;, &quot;damu&quot;);// 数组String [] strArrays = new String[] &#123;&quot;xueqi&quot;, &quot;biyao&quot;&#125;;Stream stream2 = Arrays.stream(strArrays);// 列表List&lt;String&gt; list = new ArrayList&lt;&gt;();list.add(&quot;少林&quot;);list.add(&quot;武当&quot;);Stream stream3 = list.stream();// 集合Set&lt;String&gt; set = new HashSet&lt;&gt;();set.add(&quot;武当长拳&quot;);set.add(&quot;青城剑法&quot;);Stream stream4 = set.stream();// MapMap&lt;String, Integer&gt; map = new HashMap&lt;&gt;();map.put(&quot;tom&quot;, 1000);map.put(&quot;jerry&quot;, 1200);Stream stream5 = map.entrySet().stream(); Stream对象对于基本数据类型的功能封装 注意，当前只支持 int / long / double 这三种数据类型 123IntStream.of(new int[] &#123;10, 20, 30&#125;).forEach(System.out::println);IntStream.range(1, 5).forEach(System.out::println); // 开区间IntStream.rangeClosed(1, 5).forEach(System.out::println); // 闭区间 Stream对象 –&gt; 转换得到指定的数据类型 注意：这里涉及到的都是终结操作，既每一个操作后stream流就被关闭了 123456789101112131415161718// 数组Object [] objx = stream.toArray(String[]::new);// 字符串String str = stream.collect(Collectors.joining()).toString();System.out.println(str);// 列表List&lt;String&gt; listx = (List&lt;String&gt;) stream.collect(Collectors.toList());System.out.println(listx);// 集合Set&lt;String&gt; setx = (Set&lt;String&gt;) stream.collect(Collectors.toSet());System.out.println(setx);// MapMap&lt;String, String&gt; mapx = (Map&lt;String, String&gt;) stream.collect(Collectors.toMap(x-&gt;x, y-&gt;&quot;value:&quot;+y));System.out.println(mapx); Stream常见API介绍 聚合操作 stream的处理流程 数据源 数据转换 获取结果 获取Stream对象 1234567891011121314* 1. 从集合或者数组中获取[**]* Collection.stream()，如accounts.stream()* Collection.parallelStream()* Arrays.stream(T t)* 2. BufferReader* BufferReader.lines()-&gt; stream()* 3. 静态工厂* java.util.stream.IntStream.range()..* java.nio.file.Files.walk()..* 4. 自定构建* java.util.Spliterator* 5. 更多的方式..* Random.ints()* Pattern.splitAsStream().. 中间操作API{intermediate} 操作结果是一个Stream，中间操作可以有一个或者多个连续的中间操作，需要注意的是，中间操作只记录操作方式，不做具体执行，直到结束操作发生时，才做数据的最终执行。 中间操作：就是业务逻辑处理。 中间操作过程：无状态：数据处理时，不受前置中间操作的影响，如下面所列操作： map/filter/peek/parallel/sequential/unordered 有状态：数据处理时，受到前置中间操作的影响，如下面所列操作： distinct/sorted/limit/skip 终结操作|结束操作{Terminal} 需要注意：一个Stream对象，只能有一个Terminal操作，这个操作一旦发生，就会真实处理数据，生成对应的处理结果。 终结操作：非短路操作：当前的Stream对象必须处理完集合中所有 数据，才能得到处理结果，如下面所列操作： forEach/forEachOrdered/toArray/reduce/collect/min/max/count/iterator 短路操作：当前的Stream对象在处理过程中，一旦满足某个条件，就可以得到结果。 anyMatch/allMatch/noneMatch/findFirst/findAny等 Short-circuiting，无限大的Stream-&gt; 有限大的Stream。 Stream常见的API操作 基本常用的操作支持 123456789101112131415161718192021// 定义一个集合数据List&lt;String&gt; accountList = new ArrayList&lt;&gt;();accountList.add(&quot;songjiang&quot;);accountList.add(&quot;lujunyi&quot;);accountList.add(&quot;wuyong&quot;);// 1.map() 中间操作，map()方法接收一个Functional接口accountList = accountList.stream().map(x-&gt;&quot;梁山好汉:&quot; + x).collect(Collectors.toList());// 2.filter() 添加过滤条件，过滤符合条件的用户accountList = accountList.stream().filter(x-&gt; x.length() &gt; 5).collect(Collectors.toList());// 3.forEach 增强型循环accountList.forEach(x-&gt; System.out.println(&quot;forEach-&gt;&quot; + x));// 4.peek() 中间操作，迭代数据完成数据的依次处理过程，这里只循环一次，但是能处理两件事情accountList.stream() .peek(x -&gt; System.out.println(&quot;peek 1: &quot; + x)) .peek(x -&gt; System.out.println(&quot;peek 2:&quot; + x)) .forEach(System.out::println); Stream中对于数字运算的支持 123456789101112131415161718192021222324252627282930// 定义一个数字集合List&lt;Integer&gt; intList = new ArrayList&lt;&gt;();intList.add(20);intList.add(19);intList.add(7);intList.add(12);intList.add(5);// 1.skip() 中间操作，有状态，跳过部分数据，示例跳过前三个数据intList.stream().skip(3).forEach(System.out::println);// 2.limit() 中间操作，有状态，限制输出数据量，示例跳过前三个数据，然后取跳过后的前两个数据intList.stream().skip(3).limit(2).forEach(System.out::println);// 3.distinct() 中间操作，有状态，剔除重复的数据intList.stream().distinct().forEach(System.out::println);// 4.sorted() 中间操作，有状态，排序// 5.max() 获取最大值Optional optional = intList.stream().max((x, y)-&gt; x-y);System.out.println(optional.get());// 6.min() 获取最小值Optional optional = intList.stream().min((x, y)-&gt; x-y);System.out.println(optional.get());// 7.reduce() 合并处理数据Optional optional2 = intList.stream().reduce((sum, x)-&gt; sum + x);System.out.println(optional2.get()); 补充 ParallelStreamParallelStream是一个并发多线程的Stream 使用示例： 12345678910111213141516171819202122Optional optional = list.parallelStream().max(Integer::compare);System.out.println(optional.get());// 整数列表，注意：下面示例是为了说明并行的Stream会出现线程安全问题List&lt;Integer&gt; lists = new ArrayList&lt;Integer&gt;();// 增加数据for (int i = 0; i &lt; 1000; i++)&#123; lists.add(i);&#125;// 串行StreamList&lt;Integer&gt; list2 = new ArrayList&lt;&gt;();lists.stream().forEach(x-&gt;list2.add(x));System.out.println(lists.size());System.out.println(list2.size());// 并行StreamList&lt;Integer&gt; list3 = new ArrayList&lt;&gt;();lists.parallelStream().forEach(x-&gt; list3.add(x));System.out.println(list3.size());//List&lt;Integer&gt; list4 = lists.parallelStream().collect(Collectors.toList());System.out.println(list4.size());","categories":[{"name":"Lamda","slug":"Lamda","permalink":"https://jjw-story.github.io/categories/Lamda/"}],"tags":[{"name":"Lamda","slug":"Lamda","permalink":"https://jjw-story.github.io/tags/Lamda/"}],"author":"JJW"},{"title":"内存与磁盘管理","slug":"内存与磁盘管理","date":"2019-11-10T06:22:53.000Z","updated":"2019-12-15T05:02:11.349Z","comments":true,"path":"2019/11/10/内存与磁盘管理/","link":"","permalink":"https://jjw-story.github.io/2019/11/10/内存与磁盘管理/","excerpt":"","text":"内存与磁盘管理内存查看命令free命令通过free命令可以查看当前内存的使用情况，使用方法： free [参数] 参数： -m 将数据按以MB为单位进行显示 -g 将数据按以GB为单位进行显示 注意我们一般不用 -g 参数，因为例如我们内存使用了1990M，但是-g会显示1g，将超出的都舍去了，所以会显示的不精准 下面是使用示例： 1234567891011121314151617181920# 1.直接查看[root@iZm5ehzqow4ijp2ya2g2drZ ~]# free total used free shared buffers cachedMem: 1019980 838124 181856 160 142184 337192-/+ buffers/cache: 358748 661232Swap: 0 0 0# 2.使用-m参数[root@iZm5ehzqow4ijp2ya2g2drZ ~]# free -m total used free shared buffers cachedMem: 996 818 177 0 138 329-/+ buffers/cache: 350 645Swap: 0 0 0# 3.使用-g参数[root@iZm5ehzqow4ijp2ya2g2drZ ~]# free -g total used free shared buffers cachedMem: 0 0 0 0 0 0-/+ buffers/cache: 0 0Swap: 0 0 0 以上查询结果我们需要注意的是，buffers/cache 项目查询的结果，有的时候我们查看内存发现我们 used 的内存已经非常大，free 的内存就剩一点点这个时候我们先不要着急去想办法加内存，我们首先查看 buffers/cache 下的内存有多少，如果这里显示的内存使用了很多，那么我们就不需要加内存，因为这里使用的内存是缓冲剂缓存使用的，这些都是可以被回收的内存，所以当内存真的撑不住的时候，会回收这一部分，当然，CentOS6没有查询出 available 的内容，如果可以看到这个的占用，这里是汇总的所有可释放的占用，我们可以直接查看这一块的占用，来判断需不需要加内存 还有要注意的就是Swap，它是交换分区的意思，它占用的并不是实际的内存，而是使用的磁盘空间，这里一般查看都是0，如果我们发现查询的时候这里的占用不是0，那么就真的该加内存了，这里就跟Windows中虚拟内存是一样的，指的是内存本身不够用了，我们需要将一些超出的使用转移到硬盘上，将硬盘的一些容量当做内存使用，但是磁盘的读写速度比内存慢十倍，所以一般我们看到交换分区被使用了，就该加内存了。这个交换分区大小一般默认为2G，可以手动指定。 如果我们不指定swap分区，既超出内存占用后不使用交换分区，那么系统会随机杀掉一些占用内存较大的进程，当然这样是不安全的，所以我们一般还是保留swap存在。还有一些Redies了，Memcache等内存数据库，它们不会使用swap分区，内存超出后就停止新增数据了 top命令top命令我们在进程管理中已经讲解完毕了，可以直接去进程管理章节查看 磁盘查看命令fdisk命令fdisk命令既可以查看磁盘的信息，又可以修改磁盘的分区，一般不要直接执行此命令进行分区，会有风险 使用方法： fdisk [参数] -l 查询磁盘信息，使用示例如下： 1234567891011[root@iZm5ehzqow4ijp2ya2g2drZ ~]# fdisk -lDisk /dev/vda: 42.9 GB, 42949672960 bytes255 heads, 63 sectors/track, 5221 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x0003a7b4 Device Boot Start End Blocks Id System/dev/vda1 * 1 5222 41940992 83 Linux Linux的磁盘都是用文件来表示的，磁盘文件所在的位置是:/dev目录下，vda表示是主机固有磁盘，我们有时候会见到很多 /dev/sda 的磁盘，这种表示的是可插拔的磁盘，类似于我们外接的移动硬盘等，磁盘一般表示都是 vda ~ vdb …这样按顺序往下排，同样挂载的硬盘也是，sda ~ sdb 等排列 上述命令查询出信息的第一行有磁盘总大小的表示方法，一种是以GB为单位，一种是换算为字节为单位，一般我们关注第一行的信息即可，还有就是最后的表格展示的项目，当我们有多快磁盘在机器中时，我们需要看到boot选项的 * 号在哪块磁盘上，* 号表示的就是我们系统启动的引导盘 我们可以直接进入 /dev 目录具体的查看硬盘的文件信息。如下示例： 12345[root@iZm5ehzqow4ijp2ya2g2drZ ~]# ls -l /dev/vd?brw-rw---- 1 root disk 252, 0 Sep 14 09:44 /dev/vda[root@iZm5ehzqow4ijp2ya2g2drZ ~]# ls -l /dev/vd??brw-rw---- 1 root disk 252, 1 Sep 14 09:44 /dev/vda1 如上查询，disk后跟的数字252表示磁盘的主设备号，第二个数字表示磁盘的从设备号，我们第二条命令查询出来的发现是 vda1，其中1表示这块磁盘的分区为1分区，如同我们Windows中一块磁盘可以划分为CDE几块不同的分区，Linux也有分区的概念，如果有多个分区，就是从 1 … n，这样的表示方法 df命令此命令也可以查询磁盘的具体大小，它可以作为fdsik命令的补充，因为fdisk命令只能查看到磁盘的大小，看不到磁盘具体挂载的目录以及目录的大小，这个时候我们就可以使用df命令来查看，一般我们会使用 -h 参数来具体查看，使用示例如下： 1234[root@iZm5ehzqow4ijp2ya2g2drZ ~]# df -hFilesystem Size Used Avail Use% Mounted on/dev/vda1 40G 2.5G 35G 7% /tmpfs 499M 0 499M 0% /dev/shm 如上我们就可以看到我们机器的分区挂载目录，以及此目录的大小，注意：此命令是我们最常用的 du命令上述命令都是直接查看磁盘大小的，我们还可以通过du命令查看具体文件夹的大小，但是注意，我们同样可以是用ls -l命令查看文件的大小，但是ls命令查询出的文件大小可能与du命令查出的文件大小是不一样的，这是因为，ls查询出的文件包含了文件占用的全部大小，而这全部大小可能包含了很多空洞文件，空洞文件表示的是可以理解为一块磁盘空间，我们只给空间头和尾加了标记，其他位置全部都是空的，这样的文件就叫做空洞文件，我们可以使用dd命令来创建空洞命令，这里不做详细解释 在查看文件的具体大小时我们可以使用此两种命令查看文件的具体大小，使用示例如下： 12345[root@iZm5ehzqow4ijp2ya2g2drZ balyu]# ls -lh SparrowNet-1.0-SNAPSHOT.jar -rw-r--r-- 1 root root 51M Oct 19 14:27 SparrowNet-1.0-SNAPSHOT.jar[root@iZm5ehzqow4ijp2ya2g2drZ balyu]# du -h SparrowNet-1.0-SNAPSHOT.jar 51M SparrowNet-1.0-SNAPSHOT.jar 以上两种命令所查出的文件大小是一样的，说明此文件中没有包含空洞文件 我们需要查看文件夹的大小时，我们就可以使用du命令，因为我们发现ls命令查看的文件夹大小并不包含文件夹中的内容，所以无法知道文件夹及其中内容的总大小，这时我们就可以使用 du -sh *命令，注意此命令是重点，要牢记，使用示例如下： 1234567891011121314151617181920# 首先使用 ls -lh 命令查看，这里只包含一级目录的大小，并没有包含子目录中文件的总大小[root@iZm5ehzqow4ijp2ya2g2drZ balyu]# ls -lhtotal 51Mdrwxrwxrwx 2 root root 4.0K Nov 15 01:02 datadrwxr-xr-x 2 root root 4.0K Nov 17 00:07 logsdrwxr-xr-x 2 root root 4.0K Oct 19 14:28 packagedrwxrwxrwx 5 root root 4.0K Sep 14 17:20 resources-rw-r--r-- 1 root root 51M Oct 19 14:27 SparrowNet-1.0-SNAPSHOT.jar# 使用 du 命令的 -sh 参数查询文件的总大小，包含了子目录中所有文件的大小[root@iZm5ehzqow4ijp2ya2g2drZ balyu]# du -sh84M .# 使用 du -sh * 命令分别查看一级目录中所有文件及子目录的总大小[root@iZm5ehzqow4ijp2ya2g2drZ balyu]# du -sh *60K data9.0M logs4.0K package24M resources51M SparrowNet-1.0-SNAPSHOT.jar 通过上述示例我们很容易能看出区别，所以此命令我们需要牢记 常见文件系统Linux支持多种文件系统，常见的有： ext4 xfs NTFS(需要安装额外转件) 目前比较流行的是前两种，CentOS7使用的xfs文件系统，之前的版本使用的都是ext4文件系统，这两个操作系统都是足够稳定的，NTFS文件系统Windows使用的文件系统，我们将这种格式的磁盘挂载到Linux系统上的时候，它会是只读状态，因为这种文件系统是有版权的，需要额外安装一个软件才能操作它 这里我们介绍最常用的ext4文件系统，它分为四个部分： 超级块 超级块副本 I节点(iNode) 数据块(datablock) 超级块是在文件系统最开始的部分的空间，它所存储的主要是磁盘的大小，磁盘中文件所占用的大小，包含了多少个文件，文件的总数，我们在使用df命令很快就能查看出文件的总数及大小，就是因为它查看的是超级块中的信息 超级块副本是超级块的备份，它不止有一份，当超级块出现故障的时候，可以在这里恢复 i节点记录的是每一个文件，它记录的是文件的大小，位置，创建时间，修改时间，文件的权限，编号等等信息，但是这里不包括文件的名称，注意：文件的名称是记录在自己文件的父目录的i节点中，当文件过多的时候，也会记录在父目录的数据块中 数据块就是记录的真实的文件数据，数据块是挂在i节点后的，我们只要能找到文件的i节点，就能找到文件的数据块，就可以通过挂的数据块的个数来知道文件的大小 所以我们使用ls查看文件的大小的时候，查看的是i节点里面文件的大小信息，而du统计的是i节点挂在的数据块的个数统计文件的大小信息，所以说du查看的是真实的文件大小 i节点和数据块操作我们首先观察cp和mv命令 12345678910111213141516171819202122232425# 首先我们创建一个文件并查看文件信息，发现它占用0k大小[root@iZm5ehzqow4ijp2ya2g2drZ test]# touch file1[root@iZm5ehzqow4ijp2ya2g2drZ test]# ls -litotal 01179654 -rw-r--r-- 1 root root 0 Dec 1 14:34 file1# 然后写入文件123字符，发现大小时4k[root@iZm5ehzqow4ijp2ya2g2drZ test]# echo &gt;file1 123[root@iZm5ehzqow4ijp2ya2g2drZ test]# ls -litotal 41179657 -rw-r--r-- 1 root root 4 Dec 1 14:34 file1# 然后copy这个文件，发现两个文件占用大小相同，复制的文件创建了一个新的i节点[root@iZm5ehzqow4ijp2ya2g2drZ test]# cp file1 file2[root@iZm5ehzqow4ijp2ya2g2drZ test]# ls -litotal 81179657 -rw-r--r-- 1 root root 4 Dec 1 14:34 file11179654 -rw-r--r-- 1 root root 4 Dec 1 14:35 file2# 然后我们移动file2到当前目录修改名称为file3，发现file2的节点没有发生变化，只是文件名称发生变化[root@iZm5ehzqow4ijp2ya2g2drZ test]# mv file2 file3[root@iZm5ehzqow4ijp2ya2g2drZ test]# ls -litotal 81179657 -rw-r--r-- 1 root root 4 Dec 1 14:34 file11179654 -rw-r--r-- 1 root root 4 Dec 1 14:35 file3 通过上述示例，我们发现，复制名称是创建了一个新的i节点及文件，而移动操作并不会创建新的i节点及数据块，只是修改了目中的文件的信息，比如上述文件名 注意：上述移动我们只是移动到当前目录下，所以只需要修改名称，这个过程是非常快的。如果我们将文件移动到此分区的其他目录，我们发现移动也非常快，通过原理我们知道，移动到其他目录，我们也并不需要创建新的i节点及数据块等，只需要将目录链接做修改即可。但是如果我们将文件移动到其他分区，这里因为发生了文件系统的变换，从一个文件系统移动到另一个文件系统，这里就需要在创建新的i节点和数据块，所以这个过程就比较慢了。 注意：一般我们创建文件，默认大小就是4K的大小，虽然上述示例我们只写入了三个数字，只占用102位，也就是12个字节，但是文件的大小还是4K，所以我们要创建很多小文件的时候，需要注意一下浪费空间，这个当然有办法解决，可以自行google 上述我们给文件写入数据使用的是echo命令，注意的是，如果我们使用vim来修改文件内容的话，文件的i节点及数据块都会发生变化，这里在CentOS6、7版本都是这样。如果i节点发生变化，那么此文件就已经不是原来的文件，这里主要是vim对于文件一致性的考虑，所以会有这样的操作机制，vim打开的文件实际是一个交换文件，具体可以自行google rm命令，其实也不是将文件直接删除，而是将i节点与数据块的链接给断开了，所以我们在删除文件的时候操作也是非常快，不管多大的文件 利用ext4和xfs文件系统的特性修改文件的权限我们之前知道原始的文件的权限就三种，rwx，原始修改文件权限的方式是一改全改，但是当我们有特殊的业务场景，比如我们需要一个文件，user1有读权限，user2有写权限，user3有执行权限，这个时候我们原始的设置权限的方式就不能满足我们的需求了，这个时候我们就可以利用ext4和xfs文件系统的特性来满足此需求，这两个文件系统支持了一个文件访问控制列表，叫facl的功能 getfacl命令我们可以使用getfacl命令来查看文件的控制访问列表，使用方法: getfacl 文件名，示例如下： 12345678910111213# 普通查看方式[root@iZm5ehzqow4ijp2ya2g2drZ test]# ll file1-rw-r--r-- 1 root root 4 Dec 1 14:34 file1[root@iZm5ehzqow4ijp2ya2g2drZ test]# lsfile1[root@iZm5ehzqow4ijp2ya2g2drZ test]# getfacl file1# file: file1# owner: root# group: rootuser::rw-group::r--other::r-- 这里我们使用faclget命令查看的文件控制访问列表跟我们使用ll查询出的信息一致，这是基本的一些控制信息，那我们怎么赋予指定用户或用户组的一些权限呢？使用setfacl命令 setfacl命令我们可以使用setfacl为指定的用户或用户组赋予权限，使用方法:setfacl -m u:用户名称:权限符号 文件名，具体使用示例如下： 123456# 设置[root@iZm5ehzqow4ijp2ya2g2drZ test]# setfacl -m u:user01:r file1# 查看文件权限[root@iZm5ehzqow4ijp2ya2g2drZ test]# ls -l file1-rw-r--r--+ 1 root root 4 Dec 1 14:34 file1 我们通过setfacl命令设置完权限之后，我们使用普通ll命令查看此文件权限的时候，发现权限列表中 -rw-r–r–+ 多了一个+号，这个+号表示除了我们标准权限之后，此文件还被设置了文件访问控制权限facl的权限，我们必须使用getfacl命令来查看，如下： 123456789[root@iZm5ehzqow4ijp2ya2g2drZ test]# getfacl file1# file: file1# owner: root# group: rootuser::rw-user:user01:r--group::r--mask::r--other::r-- 我们发现此文件user01用户有了读的权限，我们还可以给user02设置读和写的权限，设置示例如下： 12345678910111213141516[root@iZm5ehzqow4ijp2ya2g2drZ test]# setfacl -m u:user02:rw file1[root@iZm5ehzqow4ijp2ya2g2drZ test]# lltotal 4-rw-rw-r--+ 1 root root 4 Dec 1 14:34 file1[root@iZm5ehzqow4ijp2ya2g2drZ test]# getfacl file1# file: file1# owner: root# group: rootuser::rw-user:user01:r--user:user02:rw-group::r--mask::rw-other::r-- 如上我们就设置成功了，user02有了读写权限 我们还可以为指定的组赋予权限，使用的还是setfacl命令，使用方法：setfacl -m g:组名称:权限 文件名，使用示例如下： 1234567891011121314151617[root@iZm5ehzqow4ijp2ya2g2drZ test]# setfacl -m g:group01:x file1[root@iZm5ehzqow4ijp2ya2g2drZ test]# lltotal 4-rw-rwxr--+ 1 root root 4 Dec 1 14:34 file1[root@iZm5ehzqow4ijp2ya2g2drZ test]# getfacl file1# file: file1# owner: root# group: rootuser::rw-user:user01:r--user:user02:rw-group::r--group:group01:--xmask::rwxother::r-- 如上我们就为新建组group01分配了执行权限 收回权限我们只需要将setfacl命令参数中的 -m 修改为 -x，使用方法：setfacl -x u:用户名称 文件名，使用示例： 12345678910111213# 收回root@iZm5ehzqow4ijp2ya2g2drZ test]# setfacl -x u:user02 file1[root@iZm5ehzqow4ijp2ya2g2drZ test]# getfacl file1# file: file1# owner: root# group: rootuser::rw-user:user01:r--group::r--group:group01:--xmask::r-xother::r-- 注意：收回只能按照用户级别或者用户组级别，而不能收回单个权限编码，例如只收回某个用户的读权限，上述命令收回组权限使用用法与收回用户一样，直降u改为g即可，使用用法：setfacl -x g:用户组名称 文件名 这样我们就可以非常细粒度及灵活的设置文件的具体权限 磁盘分区和挂载这里我们不详细描述磁盘的分区和挂载，因为用的不会太多，即使使用可以网上自行百度一下，这里只列举一下步骤 首先第一种情况是需要分区的磁盘容量小于2T： 首先使用：fdisk 分区设备 命令，然后输入 m 查看帮助命令，这里我们输入 n 选择分区类型，一般我们都是将一个磁盘划分为一个主分区，所以这里再选择输入 p，这是会提示我们输入分区号及分区大小，选择完成后，我们就可以选择输入命令，选择是保存还是不保存删除刚才输入的分区信息，保存使用 w ，保存后，我们就可以使用 fdisk -l 查看我们刚才创建的分区了 注意:上述命令中分区设备示例： /dev/sdd 分好区后，路径是 /dev/sdd1 接下来使用：mkfs. 命令来格式化分区的文件系统类型，使用方法：mkfs.文件系统类型 分区位置，这里我们一般选择ext4文件系统，这样我们就给分区格式化好了磁盘格式 接下来:使用mkdir命令，创建一个目录 接下来：使用mount命令将刚刚分好区的磁盘挂载到此目录上，使用方法：mount 分区路径 目录 这样我们就可以使用mount来查看磁盘的挂载情况，发现我们新添加分好区的磁盘就挂载到了指定的目录上，这样我们操作此目录中的内容，最后就落在了我们挂载的磁盘上 第二种情况磁盘容量大有2T： 这时我们就不能使用fdisk命令来为磁盘分区了，我们需要使用parted命令来操作，同样我们可以对标fdisk来操作，使用help来查看具体使用，当然具体流程是一样的，只不过分区的命令不一样，其他流程及命令都一样 以上我们的操作都是保存在内存中的，如果我们的机器重启，配置就会丢失，如果我们需要固化下来，就需要修改一个配置文件，在此配置文件中进行指定挂载的配置，配置文件的位置：/etc/fstab, 配置说明： 磁盘分区 挂载目录 文件系统格式 default 0 0 示例： 1/dev/sdc1 /mnt/sdc1 ext4 default 0 0 将以上配置信息写入文件，就可以完成永久的挂载配置 创建交换分区swap是在硬盘中开辟的一块区域，之前我们介绍过，它的作用是临时的扩充内存的区域 新添加磁盘挂载为交换分区注意这种方式我们很少用，因为很少用新添加的磁盘作为内存使用。上面我们讲述了如何新添加磁盘然后分区、挂载，现在我们讲述如何新添加磁盘然后分区挂载为交换分区 查看交换分区大小使用free -m命令 首先我们对新添加的硬盘进行分区，命令与上述一样，首先使用：fdisk 分区设备 命令，然后我们输入 n 选择分区类型，然后输入 p 表示将一个磁盘划分为一个主分区，这是会提示我们输入分区号及分区大小，分区编号一般选择 1 ，从1开始，分区大小可以不选择，直接默认使用全部，选择完成后，我们 w 保存配置，这样我们就可以查看我们的分区了 如同使用正常的文件系统一样，我们将磁盘分区为交换分区，也需要对它进行格式化，格式化命令：mkswap 分区位置， 格式化命令使用示例： mkswap /dev/sdd1 格式化完成就需要对此分区进行挂载了，如果是文件系统使用的是mount命令，挂载为内存分区使用的是：swapon 分区位置，挂载命令使用示例：swapon /dev/sdd1 这样我们就对内存分区扩展完成，可以使用 free -m 命令查看了 如果我们想将此新挂载的swap分区关闭掉，使用命令：swapoff 分区位置，使用示例：swapoff /dev/sdd1，这是使用 free -m 命令再次查看，发现就已经被关闭掉了 使用文件挂载为交换分区上述我们是新添加了一块磁盘作为交换分区，但是一般很不常用，一般我们是在已有磁盘开辟一块空间，作为交换分区，挂载方式如下： 首先创建一个文件，文件创建未空洞文件形式，使用命令示例：dd if=/dev/zero bs=4M count=1024 of=/swapfile, 这里我们创建了一个每块为4M。一共1024块的大小的文件 下面我们需要格式化此文件，但是首先我们需要将此文件的权限处理好，负责可能会报关于权限的错误，所以这里首先：chmod 600 /swapfile 然后格式化此文件，使用命令：mkswap /swapfile 打开挂载此文件，使用命令：swapon /swapfile 这样我们就可以使用 free -m 命令来查看了 上述创建挂载方式跟我们普通磁盘文件系统挂载步骤差不多，所以一样都是保存在内存中的，如果我们的机器重启，配置就会丢失，如果我们需要固化下来，就需要修改一个配置文件，在此配置文件中进行指定挂载的配置，配置文件的位置：/etc/fstab 配置说明： 磁盘分区 挂载目录 文件系统格式 default 0 0 写入示例： 1234## 上述磁盘挂载配置/dev/sdc1 swap swap default 0 0## 上述文件挂载配置/swapfile swap swap default 0 0 将以上配置信息写入文件，就可以完成永久的挂载配置","categories":[{"name":"Linux","slug":"Linux","permalink":"https://jjw-story.github.io/categories/Linux/"}],"tags":[{"name":"command","slug":"command","permalink":"https://jjw-story.github.io/tags/command/"},{"name":"内存与磁盘管理","slug":"内存与磁盘管理","permalink":"https://jjw-story.github.io/tags/内存与磁盘管理/"}],"author":"JJW"},{"title":"Elasticsearch核心技术","slug":"Elasticsearch核心技术","date":"2019-10-20T08:17:09.000Z","updated":"2020-02-18T03:24:27.710Z","comments":true,"path":"2019/10/20/Elasticsearch核心技术/","link":"","permalink":"https://jjw-story.github.io/2019/10/20/Elasticsearch核心技术/","excerpt":"","text":"ElasticsearchElasticsearch简介Elasticsearch是分布式，高性能，高可用，可伸缩的全文检索和分析系统 什么是搜索，百度、谷歌等是我们接触到的最直接的搜索，还有垂直搜索（站内搜索），比如理想APP、OA了等等的搜索 如果用数据库做搜索有什么缺点？ （1、每次都搜索查找都需要对数据库中所有的记录进行扫描查找。2、不能将搜索词拆分，比如我搜索理想汽车但是却匹配搜索不出理想One。总的来说，效率会非常差） 什么是全文检索和lucene？（1、倒排索引的概念：传统数据库的检索，如果有几十万条数据，那么我们数据库检索就要扫描几十万次，而使用倒排索引，它可以把这几十万条数据拆分成单个的词或词语，可能会拆出来几百万条，但是我们在检索的时候，只要第一次匹配到检索的词语，就可以知道此词语在哪些文档中，并且在这些文档的什么位置，我们不必担心几十万的数据拆词后拆成几百万个词在极端情况下会需要检索到最后的几百万次才能检索到此词语，因为ES底层的算法及数据结构对此做了非常大的优化，所以我们并不需要担心。这里可以专门讲解一下倒排索引的数据结构。 2、lucene的概念：就是一些个jar包，里面包含了封装好的各种建立倒排索引，以及进行搜索的代码，包括各种算法。我们就用java开发的时候，引入lucene jar，然后基于lucene的api进行去进行开发就可以了。用lucene，我们就可以去将已有的数据建立索引，lucene会在本地磁盘上面，给我们组织索引的数据结构。另外的话，我们也可以用lucene提供的一些功能和api来针对磁盘上的索引数据进行搜索。 总之来讲：lucene非常优秀，以前玩过一个solr，也是建立在lucene上，ES同样也是，他们都是对lucene的封装） 什么是Elasticsearch？（我们说ES是基于lucene的封装，那他解决了什么问题呢？ 1、磁盘容量问题：基于磁盘容量的限制，比如我们有10TB的数据，如果我们使用10个1TB的计算机分别存储，数据散落在不同的机器上，那么每次查询我们都需要跟多台机器进行通信分别查询然后组织所有数据这个过程会非常麻烦。 这里我们就可以使用ES的集群来解决此问题，我们建立多个ES的节点，ES会自动维护数据并将数据均匀的分布在多个节点上，并且将搜索请求分布到各个节点上，然后把数据整体封装起来返回给调用方。 2、机器宕机的问题：我们的10个1TB的机器中有一个或多个挂掉，那么数据就会有丢失。这里ES会自动维护数据的冗余副本，可以保证如果一些机器宕机了，不会丢失任何的数据。 3、基于lucene的封装，提供了更多的高级功能，以便给我们提供更多的高级支持，使我们快速开发更复杂的应用，比如更复杂的查询，聚合查询分析等，地理位置的搜索等） 这就是Elasticsearch，以上已经将ES的分布式，高性能（ES的很多性能优化），高可用，可伸缩（可伸缩说的是集群扩容成本很低）的特性讲解了 Elastcsearch入门Elasticsearch功能 分布式的搜索引擎和数据分析引擎（1、搜索：百度，网站的站内搜索，IT系统的检索。 2、数据分析：电商网站，最近7天牙膏这种商品销量排名前10的商家有哪些；新闻网站，最近1个月访问量排名前3的新闻版块是哪些） 全文检索，结构化检索，数据分析等等（1、全文检索：类似模糊匹配。 2、结构化检索：精确匹配。 3、数据分析：统计分类总数，直方图了等等。还包括搜索纠错、数据分词等） 对海量数据进行近实时的处理（ES自动可以将海量数据分散到多台服务器上去存储和检索，分布式以后，就可以采用大量的服务器去存储和检索数据，自然而然就可以实现海量数据的处理了，在秒级别对数据进行搜索和分析） lucene，单机应用，只能在单台服务器上使用，最多只能处理单台服务器可以处理的数据量 Elasticsearch使用场景 维基百科，全文检索，高亮，搜索推荐 理想APP话题及帖子，对用户行为日志（点击、浏览、收藏、评论）数据分析，分析话题的热度，文章的反馈反响等 GitHub（开源代码管理），搜索上千亿行代码 淘宝京东商品检索 IT系统搜索（OA，CRM，ERP，等等），数据分析（ES热门的一个使用场景） Elasticsearch特点 可以作为一个大型分布式集群（数百台服务器）技术，处理PB级数据，服务大公司；也可以运行在单机上，服务小公司 Elasticsearch不是什么新技术，主要是将全文检索、数据分析以及分布式技术，合并在了一起，才形成了独一无二的ES；lucene（全文检索），商用的数据分析软件（也是有的），分布式数据库（mycat） 对用户而言，是开箱即用的，非常简单，作为中小型的应用，直接3分钟部署一下ES，就可以作为生产环境的系统来使用了，数据量不大，操作不是太复杂 数据库的功能面对很多领域是不够用的；特殊的功能，比如全文检索，同义词处理，相关度排名，复杂数据分析，海量数据的近实时处理；Elasticsearch作为传统数据库的一个补充，提供了数据库所不不能提供的很多功能 Elasticsearch核心概念通过上面的讲解我们知道lucene和elasticsearch之间的关系。 lucene：最先进、功能最强大的搜索库，直接基于lucene开发，非常复杂，api复杂（实现一些简单的功能，写大量的java代码），需要深入理解原理（各种索引结构） elasticsearch：基于lucene，隐藏复杂性，提供简单易用的restful api接口、java api接口（还有其他语言的api接口），lucene是单机的，ES有如下特点： 分布式的文档存储引擎 分布式的搜索引擎和分析引擎 分布式，支持PB级数据 开箱即用，优秀的默认参数，不需要任何额外设置，完全开源 关于elasticsearch的一个传说，有一个程序员失业了，陪着自己老婆去英国伦敦学习厨师课程。程序员在失业期间想给老婆写一个菜谱搜索引擎，觉得lucene实在太复杂了，就开发了一个封装了lucene的开源项目，compass。后来程序员找到了工作，是做分布式的高性能项目的，觉得compass不够，就写了elasticsearch，让lucene变成分布式的系统。 核心概念Near Realtime（NRT）：近实时，两个意思，1、从写入数据到数据可以被搜索到有一个小延迟（大概1秒）。 2、基于es执行搜索和分析可以达到秒级。一般说纯实时说的基本是毫秒级，秒或几十秒算是近实时。这里也遇到问题，比如我们搜索热词删除之后刷新快的话，数据还在。 Cluster：集群，包含多个节点，每个节点属于哪个集群是通过一个配置（集群名称，默认是elasticsearch）来决定的，对于中小型应用来说，刚开始一个集群就一个节点很正常 Node：节点，集群中的一个节点，节点也有一个名称（默认是随机分配的），节点名称很重要（在执行运维管理操作的时候），默认节点会去加入一个名称为“elasticsearch”的集群，如果直接启动一堆节点，那么它们会自动组成一个elasticsearch集群，当然一个节点也可以组成一个elasticsearch集群，一个局域网中的集群是通过集群的名称来分割的，节点也是通过集群名称匹配来加入集群的 Document&amp;field：文档，es中的最小数据单元，一个document可以是一条客户数据，一条商品分类数据，一条订单数据，通常用JSON数据结构表示，每个index下的type中，都可以去存储多个document。一个document里面有多个field，每个field就是一个数据字段。 Index：索引，包含一堆有相似结构的文档数据，比如可以有一个客户索引，商品分类索引，订单索引，索引有一个名称。一个index包含很多document，一个index就代表了一类类似的或者相同的document。比如说建立一个product index，商品索引，里面可能就存放了所有的商品数据，所有的商品document。 Type：类型，每个索引里都可以有一个或多个type，type是index中的一个逻辑数据分类，一个type下的document，都有相同的field，比如博客系统，有一个索引，可以定义用户数据type，博客数据type，评论数据type。（这里可以讲一下type已经不推荐使用了，它跟数据库表的区别，多个type类型的文档但是如果在同一个索引下，type的mapping既字段类型必须是一样的，现在还存在只是为了兼容） 注：以上三个类型可以现场打开kibana进行讲解分析一下 shard：单台机器无法存储大量数据，es可以将一个索引中的数据切分为多个shard，分布在多台服务器上存储。有了shard就可以横向扩展，存储更多数据，让搜索和分析等操作分布到多台服务器上去执行，提升吞吐量和性能。每个shard都是一个lucene index。 replica：任何一个服务器随时可能故障或宕机，此时shard可能就会丢失，因此可以为每个shard创建多个replica副本。replica可以在shard故障时提供备用服务，保证数据不丢失，多个replica还可以提升搜索操作的吞吐量和性能。primary shard（建立索引时一次设置，不能修改，默认5个），replica shard（随时修改数量，默认1个），默认每个索引10个shard，5个primary shard，5个replica shard，最小的高可用配置，是2台服务器。 注： 上述主分片和副本分片详细说明如下： 在ES中，index会被拆分成多个shard，每个shard会存放这个index一部分数据，这些shard会散落在多台服务器上面，shard其实叫primary shard，一般直接说shard，多个分片的好处主要有两个：1、横向扩展：比如说我们的数据量增大，现有的服务器已经无法承载，那我们就加机器，横向扩展，重新建立索引然后将数据重新索引导入就行。 2、数据分布在多个shard，多台服务器上，所有的操作，都会在多台服务器上并行分布式执行，提升吞吐量和性能 副本分片replice其实叫replice shard，它也是分片，并且跟主分片一样，一般简称为replice。上面讲过如果不使用ES，传统lucene多个机器，其中一个机器挂掉，那么搜索就会丢数据，ES能解决这个问题，就是通过副本分片来解决的，如果我们的集群中有一台机器宕机了，这个时候不会丢数据，因为还有一个replice，在另外一个节点上面，用户搜索的时候，还是可以搜索到的，请求直接被发送到replice上，这样数据就不会丢失。 总结分片好处： 1、高可用，一个shard宕机，数据不会丢，服务继续提供。 2、提升了搜索这类请求的吞吐量和性能 分片机制梳理： index包含多个shard 每个shard都是一个最小工作单元，承载部分数据，lucene实例，完整的建立索引和处理请求的能力 增减节点时，shard会自动在nodes中负载均衡 primary shard和replica shard，每个document肯定只存在于某一个primary shard以及其对应的replica shard中，不可能存在于多个primary shard replica shard是primary shard的副本，负责容错，以及承担读请求负载 primary shard的数量在创建索引的时候就固定了，replica shard的数量可以随时修改 primary shard的默认数量是5，replica默认是1，默认有10个shard，5个primary shard，5个replica shard primary shard不能和自己的replica shard放在同一个节点上（否则节点宕机，primary shard和副本都丢失，起不到容错的作用），但是可以和其他primary shard的replica shard放在同一个节点上 如果集群中某个节点宕掉了，那么此节点的主分片立刻失效，转移到其他存活的节点上的副本分片上，将其他节点的副本分片作为主节点。宕掉的节点重新启动后，其他节点会将数据同步到新起来的节点上，并且不是直接覆盖，而是只是将宕机的期间发生的新的数据变化的内容同步过来 注意（个人理解）：要保证服务器的高容错性，我们可以增加副本分片的数量，保证更多的机器有跟多的副本分片，容错性更高，当然，容错高是需要占用更多的磁盘空间。另外提升检索效率，可以适当增加主分片的个数，但是不要一味的高，各个集群机器之间的通信也非常耗费时间。 ES的特性透明隐藏性：ES将复杂的分布式机制，比如分片、副本、负载均衡等等全部隐藏了起来 扩容的透明性：两种方式，1、垂直扩容：直接扩展服务器的磁盘容量，但是这种方案的弊端就是，世界上最大的服务器磁盘容量也就只有10T。2、水平扩容：采购更多的服务，扩展到集群中。一般采取水平扩容的方式。 负载均衡：某个节点的分片或者数据量，及处理的请求量，明显比其他节点多，那么ES就会有负载均衡的特点，将压力分布到其他节点上 master节点：并不是必须存在，关键看集群的部署是那种方式，比如我们现在的项目，它就没有master节点，如果有的话，它的作用是：1、创建或删除索引。2、增加或删除节点 节点平等的分布式架构：1.节点对等，每个节点都能接收所有的请求。2、自动请求路由。3.响应收集。主要就是每一个节点接收到查询等的请求，都可以将每个节点上收集的数据汇总起来，由接收到的节点响应给用户 Elasticsearch基本使用集群状态既所有索引查看等API，待定是否讲解索引操作（PUT创建索引，DELETE删除操作）索引文档操作（增删改查，注意修改的时候，可以使用PUT直接替换，和使用POST修改），注意替换方式，必须带上所有的数据进行替换，修改可以只修改其中某一个字段，讲的时候可以演示一下PUT和POST的使用，注意，POST的使用最后要跟上”_update”在url上，DELETE演示直接使用ID删除就可以增加文档的时候，我们可以指定ID，也可以不指定ID，如果我们的数据是从SQL数据库中拉取过来，那么我们就使用数据中已有的ID，指定ID进行保存数据。如果我们的数据只是在ES库中存在，那么我们可以不指定ID，使用ES自带的主键生成策略，它使用一种GUID得算法生成主键，保证在分布式的系统中，同时插入数据生成的主键不会重复，不指定主键的插入数据需要使用POST，然后不指定主键即可，PUT式的插入数据需要指定主键 注意：ES全量替换是先将原来的数据删除，然后新添加进去，注意这里说的删除和我们主动的删除数据都是伪删除，只是给文档标记为了deleted的状态，并没有直接删除，它会在后面这种状态的数据多的时候或者其他情况下执行物理删除 注意：ES的并发控制是通过乐观锁CAS这种方式来控制的，它里面有_version这个字段，不过现在的版本已经改了，不是这个字段了。这个字段我们在对文档进行操作，不管是修改还是删除，都会给这个字段自动+1，即使我们是PUT形式覆盖数据，或者先删除数据，然后添加数据，ID一样，它的版本号都是存在并且直接++的，而不是重新从1开始（注意：主从同步时，只有版本号高的时候才同步数据，否则不同步） 注意：一般我们在修改数据的时候，还是尽量使用PUT式的全量替换，而不是使用POST式的部分替换，虽然POST修改只修改我们需要修改的字段，能够节省网络开销，但是其实我们内部的修改实现是和PUT是一样的，都是先删除在插入，而且POST式的修改，ES先把要修改的所有文档的内容找出来，然后将我们POST过来的数据中的部分字段内容替换，然后将原文档删除，插入此新的文档。所以我们发现虽然能节省网络开销，但是多了重新构建数据这一步，对于数据量很大的情况来说，还是会有损失效率，所以尽量使用PUT来修改。注意：如果我们是用的POST这种方式修改数据，我们内部也是有并发控制的，同样使用CAS，如果我们在拼装好新的数据后，发现_version已经不一样了，那么它内部会重新拉去doucment数据，然后重新拼装，然后再次CAS，一共可以重试五次，如果五次都失败了，则会抛弃此数据。 DSL语言演示讲解（Domain Specified Language）（注意一些高阶查询，聚合查询，可以查看视频中第八讲的笔记，这里讲了一点）Elasticsearch的分布式架构","categories":[{"name":"Linux","slug":"Linux","permalink":"https://jjw-story.github.io/categories/Linux/"}],"tags":[{"name":"Elasticsearch核心技术","slug":"Elasticsearch核心技术","permalink":"https://jjw-story.github.io/tags/Elasticsearch核心技术/"},{"name":"基础入门","slug":"基础入门","permalink":"https://jjw-story.github.io/tags/基础入门/"}],"author":"JJW"},{"title":"进程管理","slug":"进程管理","date":"2019-10-06T08:30:13.000Z","updated":"2019-11-02T09:51:14.163Z","comments":true,"path":"2019/10/06/进程管理/","link":"","permalink":"https://jjw-story.github.io/2019/10/06/进程管理/","excerpt":"","text":"进程管理进程可以理解为程序正在运行的过程，管理的内容主要包括程序什么时候启动，程序运行的整个生命周期需要多少资源，包括需要多少内存资源，运行是需要多少CPU资源，运行结束是需要自己结束还是被其他程序结束的，还有程序运行时我们需要让他结束应该怎么让它结束等等 进程的概念及进程查看进程是运行中的程序，从程序开始运行到终止的整个生命周期是可管理的 C程序的启动时从main函数开始的，包括Java等，终止的方式并不唯一，分为正常终止和异常终止： 正常终止也分为从main返回，调用exit等方式 异常终止分为调用abort、接收信号等。当程序获取不到资源比如内存、CPU资源等，会调用abort函数来终止程序 ps命令使用方法：ps [选项] 单独使用ps命令，它只能查看到当前终端既当前shell下面能够查看到的进程状态，并不是真的只有这些进程在运行，如下只查看到两条: 1234[root@iZm5ehzqow4ijp2ya2g2drZ etc]# ps PID TTY TIME CMD27267 pts/0 00:00:00 bash27342 pts/0 00:00:00 ps PID：表示进程在系统中运行的唯一表示，注意进程的名称是可以重复的，但是PID不能重复 TTY：表示执行当前进程的终端，那么当前执行是一个虚拟终端，所以叫 pts/0 TIME：程序的运行时间，此项不具有参考价值，可以不用关注 CMD：命令 ps选项说明 -e 查看所有的进程，这样我们查出来的会非常多，我们可以通过 more 命令来进行分页查看，具体使用为：ps -e | more，这里主要是通过管道符，将管道符左边的输出传递给more，示例如下： 123456789root@iZm5ehzqow4ijp2ya2g2drZ etc]# ps -e | more PID TTY TIME CMD 1 ? 00:00:00 init 2 ? 00:00:00 kthreadd 3 ? 00:00:00 migration/0 4 ? 00:00:01 ksoftirqd/0 5 ? 00:00:00 stopper/0 6 ? 00:00:02 watchdog/0 7 ? 00:01:35 events/0 注意我们看到的1号进程，此进程在CentOS6中叫init，在CentOS7中叫systemd -f 表示显示全格式，既对进程的信息显示更加完善，一般是结合-e选项来使用，ps -ef | more 123456UID PID PPID C STIME TTY TIME CMDroot 1 0 0 Sep14 ? 00:00:00 /sbin/initroot 2 0 0 Sep14 ? 00:00:00 [kthreadd]root 3 2 0 Sep14 ? 00:00:00 [migration/0]root 4 2 0 Sep14 ? 00:00:01 [ksoftirqd/0]root 5 2 0 Sep14 ? 00:00:00 [stopper/0] UID表示此进程是哪一个用户来启动的，但是注意，进程启动的用户是可以修改的，所以它的专业名称叫有效用户ID PPID是父进程，因为我们的程序在启动时都要集成它的父进程的一些信息下来，Linux的第一个进程是1号进程，既init进程 -L 查看更详细的进程情况，既可以查看到当前进程中包含了多少个线程，通过此选项我们可以查看到当前进程运行缓慢是不是因为并发太大及线程太多导致的，一般使用也是结合着-ef，具体：ps -eLf | more 123456UID PID PPID LWP C NLWP STIME TTY TIME CMDroot 1 0 1 0 1 Sep14 ? 00:00:00 /sbin/initroot 2 0 2 0 1 Sep14 ? 00:00:00 [kthreadd]root 3 2 3 0 1 Sep14 ? 00:00:00 [migration/0]root 4 2 4 0 1 Sep14 ? 00:00:01 [ksoftirqd/0]root 5 2 5 0 1 Sep14 ? 00:00:00 [stopper/0] LWP表示的既是线程数量 pstree命令pstree命令是将进程用树形表示出来，上述ps命令中，我们能查看到进程的父进程，在使用此命令时，我们可以看到一个树形结构的进程图，方便我们查看进程的依属关系，示例如下： 123456789root@iZm5ehzqow4ijp2ya2g2drZ etc]# pstree | moreinit-+-AliYunDun---17*[&#123;AliYunDun&#125;] |-AliYunDunUpdate---3*[&#123;AliYunDunUpdat&#125;] |-agetty |-aliyun-service---2*[&#123;aliyun-service&#125;] |-auditd---&#123;auditd&#125; |-crond |-dhclient |-java---28*[&#123;java&#125;] top命令top命令能显示系统的信息及进程信息，类似于Windows的任务管理器，也是一个日常非常实用的命令，可以不带参数，使用具体如下： 12345678910111213[root@iZm5ehzqow4ijp2ya2g2drZ etc]# toptop - 17:38:41 up 22 days, 7:54, 2 users, load average: 0.00, 0.00, 0.00Tasks: 78 total, 1 running, 77 sleeping, 0 stopped, 0 zombieCpu(s): 0.3%us, 0.3%sy, 0.0%ni, 99.3%id, 0.0%wa, 0.0%hi, 0.0%si, 0.0%stMem: 1019980k total, 732792k used, 287188k free, 138988k buffersSwap: 0k total, 0k used, 0k free, 230192k cached PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 1407 root 10 -10 121m 11m 9176 S 0.3 1.2 94:59.64 AliYunDun 27417 root 20 0 15012 1292 1004 R 0.3 0.1 0:00.01 top 1 root 20 0 19228 1508 1232 S 0.0 0.1 0:00.72 init 2 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kthreadd 3 root RT 0 0 0 0 S 0.0 0.0 0:00.00 migration/0 说明： top up 22 days： 当前系统上一次开机到现在运行的时长 users：当前系统有两个用户已经登录了 load average: 0.00, 0.00, 0.00： 平均负载，全都是0.00表示空负载，数值越大负载越高，都是1表示满负载运行，平均负载是一分钟进行一次汇总的结果，第一个数字是1分钟的数据，中间数据时5分钟的数据，最后一个是15分钟的统计数据，此数据是查看系统繁忙程度的指标数据 Tasks: 78 tota：系统中有多少个任务正在运行，这里系统将进程表示为任务 1 running, 77 sleeping, 0 stopped, 0 zombie：一个进程在运行中，77个在休眠状态中。。 Cpu(s): 0.3%us： 0.3%的资源用于用户状态的计算 0.3%sy： 进程的状态交互占用的资源 99.3%id：空闲的CPU资源 0.0%wa：磁盘IO占用的资源 Cpu(s)是说统计的是一个整体情况，如果我们是多核的，可以按下数字键1来分别查看每一个CPU的运行状况，再次按下数字1即可恢复成整体模式 123456789101112top - 17:54:45 up 1 min, 0 users, load average: 0.52, 0.58, 0.59Tasks: 4 total, 1 running, 3 sleeping, 0 stopped, 0 zombie%Cpu0 : 5.4 us, 8.0 sy, 0.0 ni, 84.0 id, 0.0 wa, 2.6 hi, 0.0 si, 0.0 st%Cpu1 : 2.0 us, 3.0 sy, 0.0 ni, 95.1 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu2 : 5.6 us, 10.8 sy, 0.0 ni, 83.6 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu3 : 3.0 us, 3.0 sy, 0.0 ni, 94.1 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu4 : 4.6 us, 3.0 sy, 0.0 ni, 92.4 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu5 : 2.3 us, 0.3 sy, 0.0 ni, 97.4 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu6 : 1.6 us, 2.0 sy, 0.0 ni, 96.4 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu7 : 1.6 us, 14.8 sy, 0.0 ni, 83.6 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 stKiB Mem : 16670136 total, 9322736 free, 7118048 used, 229352 buff/cacheKiB Swap: 15518328 total, 15430616 free, 87712 used. 9418356 avail Mem Mem： 1019980k total：总共有多少内存 732792k used：已经使用了的内存 287188k free：空闲的内存 138988k buffers：读写缓存使用的内存 Swap：交换分区，当内存不够用的时候，需要使用交换分区的内存 0k used：这里只需要关注此选项即可，因为在内存占用比较大的时候才会与系统进行交换分区内存，这里有占用说明程序占用内存很大了 进程信息： 这里的进程信息我们可以看到还显示了每个进程当前的CPU占用率，以及内存占用情况，默认是3秒已刷新，我们还可以修改刷新时间，使用按键s，即可输入你需要的刷新间隔时间，然后回车，注意单位是秒，这样既可以按照你输入的时间间隔来刷新 进程信息中PR表示进程的系统优先级，NI表示Nice值，可以理解为此进程占用了多少系统资源，%CPU表示进程占用的CPU资源百分比 参数说明 -p 使用-p参数然后指定进程id可以只查看指定id的进程信息，使用示例： 123456789[root@iZm5ehzqow4ijp2ya2g2drZ ~]# top -p 35top - 16:33:23 up 29 days, 6:49, 2 users, load average: 0.00, 0.00, 0.00Tasks: 1 total, 0 running, 1 sleeping, 0 stopped, 0 zombieCpu(s): 0.0%us, 0.0%sy, 0.0%ni,100.0%id, 0.0%wa, 0.0%hi, 0.0%si, 0.0%stMem: 1019980k total, 758240k used, 261740k free, 139084k buffersSwap: 0k total, 0k used, 0k free, 239196k cached PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 35 root 25 5 0 0 0 S 0.0 0.0 0:00.00 ksmd 进程的优先级调整进程的优先级我们可以通过查看进程的信息来具体查看，进程信息的NI选项就表示进程的优先级，NI的值在 -20 ~ 19 之间，值越小，优先级越高，抢占资源就越多，一般我们启动的程序默认的优先级是0 使用nice命令修改启动进程的优先级我们首先启动一个程序，查看它的进程信息如下： 1234567891011121314# 第一个终端启动此自定义进程[root@iZm5ehzqow4ijp2ya2g2drZ home]# ./test.sh2946# 重新打开一个终端，查看此进程的信息[root@iZm5ehzqow4ijp2ya2g2drZ ~]# top -p 2946top - 17:14:15 up 29 days, 7:29, 3 users, load average: 0.89, 0.85, 0.55Tasks: 1 total, 1 running, 0 sleeping, 0 stopped, 0 zombieCpu(s):100.0%us, 0.0%sy, 0.0%ni, 0.0%id, 0.0%wa, 0.0%hi, 0.0%si, 0.0%stMem: 1019980k total, 760396k used, 259584k free, 139088k buffersSwap: 0k total, 0k used, 0k free, 239332k cachedPID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 2946 root 20 0 103m 1332 1152 R 99.9 0.1 0:53.76 test.sh 我们看到此进程的NI值为0，CPU的占用率达到了100%，因为我们这个程序一直在循环执行中，然后我们停止此程序，然后使用nice命令指定优先级 nice命令使用方法：nice -n [优先级值] ./应用程序 使用示例： 1234567891011121314# 使用第一个终端启动自定义的应用程序并指定进程优先级为15[root@iZm5ehzqow4ijp2ya2g2drZ home]# nice -n 15 ./test.sh2953# 使用第二个终端查看此进程信息[root@iZm5ehzqow4ijp2ya2g2drZ ~]# top -p 2953top - 17:12:54 up 29 days, 7:28, 3 users, load average: 0.92, 0.84, 0.52Tasks: 1 total, 1 running, 0 sleeping, 0 stopped, 0 zombieCpu(s): 0.0%us, 0.0%sy,100.0%ni, 0.0%id, 0.0%wa, 0.0%hi, 0.0%si, 0.0%stMem: 1019980k total, 760396k used, 259584k free, 139088k buffersSwap: 0k total, 0k used, 0k free, 239332k cached PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 2953 root 35 15 103m 1332 1152 R 99.6 0.1 1:42.75 test.sh 通过更改程序的优先级来启动程序，我们发现更改后的此进程NI值就变成了我们设置的值，并且很明显的区别就是CPU占用率，我们将优先级值调大之后，CPU占用率在0.0% - 0.3%摆动，表示资源占用急剧下降，所以我们指定程序的优先级是很有效果的一个操作 使用renice命令修改进程的优先级nice命令有一个问题，我们一般程序在运行中不会终止，上述更改优先级需要将程序停止然后重新指定优先级后启动，这个问题怎么解决呢？ 使用renice命令就可以解决，可以在程序运行中直接修改，无需重启 使用方法：renice -n [优先级值] ./应用程序 使用示例： 1234567891011121314151617181920212223# 第一个终端启动此自定义进程[root@iZm5ehzqow4ijp2ya2g2drZ home]# ./test.sh2966# 使用第二个终端查看此进程的信息[root@iZm5ehzqow4ijp2ya2g2drZ ~]# top -p 2966...Cpu(s):100.0%us, 0.0%sy, 0.0%ni, 0.0%id, 0.0%wa, 0.0%hi, 0.0%si, 0.0%st PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 2966 root 20 0 103m 1332 1152 R 99.7 0.1 0:47.87 test.sh # 使用第三个终端使用renice修改此进程的优先级值为18[root@iZm5ehzqow4ijp2ya2g2drZ ~]# renice -n 18 29662966: old priority 0, new priority 18# 切换回第二个终端查看此进程信息，我们发现进程的优先级已经被修改，且程序并没有停止[root@iZm5ehzqow4ijp2ya2g2drZ ~]# top -p 2966...Cpu(s): 0.0%us, 0.0%sy,100.0%ni, 0.0%id, 0.0%wa, 0.0%hi, 0.0%si, 0.0%st PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 2966 root 38 18 103m 1332 1152 R 99.6 0.1 5:07.68 test.sh 进程的启动前台后台切换程序后台启动我们上述启动程序发现程序一直在终端显示，无法输入其他命令，此终端不能进行其他操作，这种启动的方式叫做前台启动，后台启动就是程序是后台运行的，不影响我们在终端进行操作 后台启动程序的方式是在启动程序命令后 加 &amp; ，使用示例： 123456789[root@iZm5ehzqow4ijp2ya2g2drZ home]# ./test.sh &amp;[3] 3019[root@iZm5ehzqow4ijp2ya2g2drZ home]# 3019lstest.sh[root@iZm5ehzqow4ijp2ya2g2drZ home]# top -p 3019... PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 3019 root 20 0 103m 1332 1152 R 49.9 0.1 0:14.74 test.sh 通过示例我们发现，启动程序后终端返回了程序的进程ID，然后我们就可以在此终端上进行任意其他操作 后台运行程序切换回前台运行有时候我们需要将后台运行的程序切换回前台运行，可以使用 jobs命令查询出所有的后台程序，然后根据后台运行编号使用fg命令切换回来，使用如下： 1234[root@iZm5ehzqow4ijp2ya2g2drZ home]# jobs[3]+ Running ./test.sh &amp;[root@iZm5ehzqow4ijp2ya2g2drZ home]# fg 3./test.sh 我们发现程序就恢复前台运行了，此时可以通过 CTRL + C 来终止此程序 前台运行程序切换到后台运行使用 CTRL + Z 可以将前台运行程序切换为后台运行，但是使用此命令切换到后台运行，程序就不是运行的状态了，而是一个暂停运行的状态，它保存在了内存中 使用示例： 12345# 首先前台启动进程，然后使用 CTRL + Z 将程序转为后台运行，并且提示你程序为Stopped状态，既停止运行的状态[root@iZm5ehzqow4ijp2ya2g2drZ home]# ./test.sh3043^Z[4]+ Stopped ./test.sh 上述示例我们发现程序进入后台运行但是是停止状态，我们需要让程序继续运行怎么办？使用jobs命令，然后使用 fg 将程序切换为前台运行或者使用 bg 将程序切换为后台运行 切换为前台运行我们上面已经有过示例了，现在我们示例切换为后台运行，完整示例如下： 12345678910111213# 前台运行程序然后切换为后台暂停运行[root@iZm5ehzqow4ijp2ya2g2drZ home]# ./test.sh3050^Z[5]+ Stopped ./test.sh# 将程序切换为后台运行[root@iZm5ehzqow4ijp2ya2g2drZ home]# jobs[5]+ Stopped ./test.sh[root@iZm5ehzqow4ijp2ya2g2drZ home]# bg 5[5]+ ./test.sh &amp;[root@iZm5ehzqow4ijp2ya2g2drZ home]# jobs[5] Running ./test.sh 上述后，我们发现程序就为后台运行了 进程的通信方式与信号进程之间的通信就是两个进程之间可以有一些消息进行交互，还有就是两个进程之间可以互相进行控制。进程通信有很多种的方式，比如管道，信号，这里我们主要学习信号 信号：终端用户通过快捷键或者命令来输入信号，通过信号的机制可以让程序停止运行，经常使用的有 CTRL + C、kill等 kill命令我们可以使用kill命令的 -l 参数来查看我们系统支持的所有信号，示例如下： 1234567891011121314[root@iZm5ehzqow4ijp2ya2g2drZ ~]# kill -l 1) SIGHUP 2) SIGINT 3) SIGQUIT 4) SIGILL 5) SIGTRAP 6) SIGABRT 7) SIGBUS 8) SIGFPE 9) SIGKILL 10) SIGUSR111) SIGSEGV 12) SIGUSR2 13) SIGPIPE 14) SIGALRM 15) SIGTERM16) SIGSTKFLT 17) SIGCHLD 18) SIGCONT 19) SIGSTOP 20) SIGTSTP21) SIGTTIN 22) SIGTTOU 23) SIGURG 24) SIGXCPU 25) SIGXFSZ26) SIGVTALRM 27) SIGPROF 28) SIGWINCH 29) SIGIO 30) SIGPWR31) SIGSYS 34) SIGRTMIN 35) SIGRTMIN+1 36) SIGRTMIN+2 37) SIGRTMIN+338) SIGRTMIN+4 39) SIGRTMIN+5 40) SIGRTMIN+6 41) SIGRTMIN+7 42) SIGRTMIN+843) SIGRTMIN+9 44) SIGRTMIN+10 45) SIGRTMIN+11 46) SIGRTMIN+12 47) SIGRTMIN+1348) SIGRTMIN+14 49) SIGRTMIN+15 50) SIGRTMAX-14 51) SIGRTMAX-13 52) SIGRTMAX-1253) SIGRTMAX-11 54) SIGRTMAX-10 55) SIGRTMAX-9 56) SIGRTMAX-8 57) SIGRTMAX-758) SIGRTMAX-6 59) SIGRTMAX-5 60) SIGRTMAX-4 61) SIGRTMAX-3 62) SIGRTMAX-263) SIGRTMAX-1 64) SIGRTMAX 以上就是我们系统中所有的信号，平时我们使用的CTRL + C对应的就是2号信号，SIGINT kill命令具体使用方法：kill [-信号编号] 进程ID 比如我们平时使用的更多的是 kill -9 9号命令，它是用于强制停止进程，直接杀掉，一般我们在生产中直接使用 kill 命令来结束程序，可以达到优雅下线的效果 守护进程很多时候我们希望我们有些进程在系统启动的时候就启动，或者有些我们在终端启动的进程在关闭终端之后还继续运行，Linux提供了实现这种需求的方法，就是使用守护进程，英文叫 daemon，就是精灵的意思，守护进程实现的就是我们不需要使用终端就可以把进程启动起来，另外启动的时候它的输出也会打印出来，并且这个程序使用的目录是根目录，避免占用其他一些移动硬盘的目录，导致此移动硬盘无法卸载的情况 nohup启动进程在讲守护进程之前我们先讲另外一个进程，叫nohup启动进程，以此来对比守护进程 nohup启动进程会使进程忽略掉 hangup 挂起信号，使用此进程我们可以实现守护进程的效果，比如关掉终端之后进程还可以继续运行，但它还是有一些不同，首先这里示例一下使用nohup进程的效果 123456789101112131415# 首先我们使用第一个终端然后运行 tail 进程[root@iZm5ehzqow4ijp2ya2g2drZ ~]# tail -1000f /balyu/logs/platformrun.log 2019-10-19 01:02:12.606 [http-nio-80-exec-16] INFO com.sparrow.portal.IndexController - access index...2019-10-19 01:18:06.548 [http-nio-80-exec-18] INFO com.sparrow.manage.monitor.AccessMonitor - 123.126.113.160...# 然后打开第二个终端查看此进程 这里是可以查看到的[root@iZm5ehzqow4ijp2ya2g2drZ ~]# ps -ef | grep tailroot 12218 12129 0 13:46 pts/2 00:00:00 tail -1000f /balyu/logs/platformrun.logroot 12237 12221 0 13:47 pts/3 00:00:00 grep tail# 然后第三步是直接关闭终端，不退出tail直接关闭终端窗口# 然后第四步我们继续到另一个终端查看此进程 -&gt; 发现tail进程也不存在了[root@iZm5ehzqow4ijp2ya2g2drZ ~]# ps -ef | grep tailroot 12241 12221 0 13:49 pts/3 00:00:00 grep tail 下面示例使用nohup来是进程在终端关闭后继续运行 12345678910111213# 第一步使用nohup启动tail进程，启动后提示将此进程的输出比如tail的查看内容输出放在了 nohup.out 文件下[root@iZm5ehzqow4ijp2ya2g2drZ ~]# nohup tail - 100f /balyu/logs/platformrun.log nohup: ignoring input and appending output to `nohup.out&apos;# 第二步启动另外一个终端查看此进程，这里我们查看到此进程的父进程是 pts/3[root@iZm5ehzqow4ijp2ya2g2drZ ~]# ps -ef | grep tailroot 12251 12221 0 13:54 pts/3 00:00:00 tail -100f /balyu/logs/platformrun.logroot 12270 12254 0 13:55 pts/2 00:00:00 grep tail# 第三步关闭此终端，然后使用另一个终端查看tail进程，我们发现进程还在存活，但是父进程变成了?，这是因为我们的进程在终端关闭之后此进程就成了孤儿进程，孤儿进程一定要被其它进程所收留，那么这里它就被 1 号进程所收留，这里显示了一个 ?，但其实是 1 号进程，init进程[root@iZm5ehzqow4ijp2ya2g2drZ ~]# ps -ef | grep tailroot 12251 1 0 13:54 ? 00:00:00 tail -100f /balyu/logs/platformrun.logroot 12272 12254 0 13:56 pts/2 00:00:00 grep tail 以上就是nohup的使用示例，这里我们发现虽然可以将进程一直运行，但是启动程序的时候还是要通过终端启动，还有一个特点就是我们的进程输出会放在我们执行命令的当前文件夹下的nohup.out文件，它会占用我们当前磁盘的空间，name我们可不可以像windows一样，设置开机自启动呢？并且有一个合理的日志文件或者输出内容的文件所在的位置呢？请看下面的内容 screen命令Screen是一款由GNU计划开发的用于命令行终端切换的自由软件。用户可以通过该软件同时连接多个本地或远程的命令行会话，并在其间自由切换。GNU Screen可以看作是窗口管理器的命令行界面版本。它提供了统一的管理多个会话的界面和相应的功能 在Screen环境下，所有的会话都独立的运行，并拥有各自的编号、输入、输出和窗口缓存。用户可以通过快捷键在不同的窗口下切换，并可以自由的重定向各个窗口的输入和输出 总的来说个人理解就是使用screen启动的程序我们在退出screen之后，程序还会继续运行，退出终端也会如此，所以直接将启动的程序作为了守护进程 使用方法： 使用 screen 命令直接进入screen环境 操作完成后或者启动程序完成后，使用 CTRL + A D，退出（detached）screen环境 我们可以使用 screen -ls 查看所有screen的会话 可以使用 screen -r sessionid 恢复会话，注意这里的sessionid是上述使用-ls查询出来的信息 注意：我们可以在screen模式下结束我们的进程，退出此环境使用 exit 退出此环境 以下是使用示例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859# 1.首先使用screen命令进入此环境[root@iZm5ehzqow4ijp2ya2g2drZ ~]# screen-bash: screen: command not found# 2.这里提示找不到这个命令，是因为我们没有安装，需要使用yum命令进行安装[root@iZm5ehzqow4ijp2ya2g2drZ ~]# yum install screenLoaded plugins: fastestmirrorSetting up Install Process...Installed: screen.x86_64 0:4.0.3-19.el6Complete!# 3.安装成功后再次使用此命令进入Screen环境，我们发现直接就进入了此环境，并没有任何提示和不一样的地方[root@iZm5ehzqow4ijp2ya2g2drZ ~]# screen[root@iZm5ehzqow4ijp2ya2g2drZ ~]# # 4.再此环境下执行命令，还是之前使用的tail命令来让它后台运行[root@iZm5ehzqow4ijp2ya2g2drZ ~]# tail -1000f /balyu/logs/platformrun.log 2019-10-26 00:15:58.351 [http-nio-80-exec-9] INFO com.sparrow.portal.IndexController - access index...2019-10-26 00:51:58.660 [http-nio-80-exec-7] ERROR org.apache.catalina.core.ContainerBase.[Tomcat].[localhost] - Exception Processing ErrorPage[errorCode=0, location=/error]org.apache.catalina.connector.ClientAbortException: java.io.IOException: Connection reset by peer# 5.使用另外一个客户端，查看此启动的进程，我们发现实可以查询到的[root@iZm5ehzqow4ijp2ya2g2drZ ~]# ps -ef | grep tailroot 20513 20484 0 12:02 pts/1 00:00:00 tail -1000f /balyu/logs/platformrun.logroot 20532 20516 0 12:04 pts/3 00:00:00 grep tail# 6.我们使用CTRL + A D退出screen环境，退出后发现终端并没有什么变化[root@iZm5ehzqow4ijp2ya2g2drZ ~]# screen[detached][root@iZm5ehzqow4ijp2ya2g2drZ ~]# # 7.我们再次用第二个客户端查看在screen环境中启动的tail进程发现是可以查询到的，即使将第一个终端直接关闭掉，也是可以查询到此进程[root@iZm5ehzqow4ijp2ya2g2drZ ~]# ps -ef | grep tailroot 20513 20484 0 12:02 pts/1 00:00:00 tail -1000f /balyu/logs/platformrun.logroot 20538 20516 0 12:09 pts/3 00:00:00 grep tail# 8.使用第二个终端查询当前系统上运行的screen环境， screen -ls 命令，查询发现启动的有一个，并且sessionid是20483 [root@iZm5ehzqow4ijp2ya2g2drZ ~]# screen -lsThere is a screen on: 20483.pts-0.iZm5ehzqow4ijp2ya2g2drZ (Detached)1 Socket in /var/run/screen/S-root.# 9.使用 screen -r sessionid恢复此screen环境，发现是恢复了的[root@iZm5ehzqow4ijp2ya2g2drZ ~]# screen -r 20483 at org.apache.catalina.core.ApplicationDispatcher.invoke(ApplicationDispatcher.java:726) at org.apache.catalina.core.ApplicationDispatcher.processRequest(ApplicationDispatcher.java:471) ... # 10.使用CTRL + C 退出此环境下前台运行的程序（tail 程序），然后使用exit退出screen环境... 这里不做演示# 11.再次使用screen -ls 查询运行的screen环境，发现已经查询不到了，因为我们已经退出了[root@iZm5ehzqow4ijp2ya2g2drZ ~]# screen -lsNo Sockets found in /var/run/screen/S-root. 系统日志这里只是一个补充说明，我们可以进入 /var/log 文件夹，这里有大量的日志文件，这些文件叫做系统日志，我们系统运行的状态都记录在这些文件中，重点关注以下文件就行： messages文件，系统的常规日志，也可以理解为当前系统运行实时产生的日志 dmesg文件，内核日志信息，内核日志一般在我们启动系统的时候启动内核所打印出来的日志，一般我们在系统启动时可能查看的不够详细，这样我们就可以直接查看此文件来详细查看内核启动运行的一些日志信息 secure文件，这个文件是我们系统的安全日志，此文件可以查看系统有没有产生一些安全的问题 cron文件，这个日志是我们系统执行计划任务，定时任务等产生的日志，查看这种任务的日志可以在此文件中查看 服务管理工具这里服务指的是提供常见功能的守护进程，是系统本身所提供的服务。服务管理工具说的是我们之前在网络管理和配置文件章节讲述过，有两种，CentOS7以前的版本是用的是service工具，之后默认使用的是systemctl工具，但是我们可以切换回service工具来管理 我们之前讲述过service的基本启动脚本在 /etc/init.d 文件夹中，这里有我们service管理工具所管理的所有服务，每个服务都有一个文件，此文件中便是服务的启动关闭重启等等的操作的命令脚本，这些脚本也可以我们自己来编写，就比如之前我们操作过的网卡服务，network文件中便有一堆关于操作网卡的脚本，每个操作我们可以理解为一个函数，函数中又具体的后台的逻辑。我们可以看到，service管理的服务脚本都很复杂。而systemctl管理工具基本的脚本在 /usr/lib/systemd/system 文件夹下，里面也是各种文件，文件所管理的就是服务，比如我们打开sshd.service文件，这个里面就是封装的sshd服务的一些操作脚本，我们明显可以看到这里的脚本比service管理的服务脚本要简单很多，这是因为脚本中具体的逻辑都已经有systemctl来管理了，不需要我们手动自己来写这些复杂的脚本，所有相对看着比较简单，我们在Linux系统的迭代中，会逐渐的将所有的service管理的服务都交给systenctl来管理。 之前我们说过service管理的服务都有级别，分为6个级别，这6个级别分别代表程序在哪个级别是启动的，在哪个级别的关闭的，我们可以通过service提供的chkconfig命令来查看及修改服务在各种级别运行的状态，而systemctl管理工具不是用过数字来代表启动级别了，而是直接通过英语单词来代表 systemctl管理工具怎么操作服务，我们列举一下常见的操作： start、stop、restart、reload、enable、disable、status 使用的方法就是：systemctl 操作命令 服务名称，例如：systemctl start sshd.service 具体有哪些服务呢？我们可以直接查看 /usr/lib/systemd/system 文件夹，里面的内容中有很多扩展名为 .service 和 .target 的文件，.service的文件就是我们管理的服务，我们就可以通过systemctl命令来操作这些服务，这些.target的文件，表示的就是服务表示的就是不同的级别，runleavel0.target 到 runleavel6.target 就表示我们之前描述的 0 - 6 的系统级别，我们可以通过命令 ls -l runleavel*.target 来查看这些文件的具体映射，这些查看出来的文件就映射到了具体的英文单词表示的级别 我们还可以通过 systemctl get-default 来查看我们当前系统的默认级别，字符级别还是图形界面级别。还可以通过 systemctl set-default 级别英文单词表示 来修改我们设置的默认级别，这样在下次启动系统的时候就切换了默认的级别，例如： systemctl set-default multy-user.target 就将默认的启动级别就切换成多用户的启动级别了，也就是字符界面级别 以上具体可以查看 网络管理和配置文件 章节","categories":[{"name":"Linux","slug":"Linux","permalink":"https://jjw-story.github.io/categories/Linux/"}],"tags":[{"name":"command","slug":"command","permalink":"https://jjw-story.github.io/tags/command/"},{"name":"进程管理","slug":"进程管理","permalink":"https://jjw-story.github.io/tags/进程管理/"}],"author":"JJW"},{"title":"网络故障排除命令","slug":"网络故障排除命令","date":"2019-09-03T12:02:04.000Z","updated":"2019-09-03T11:45:01.715Z","comments":true,"path":"2019/09/03/网络故障排除命令/","link":"","permalink":"https://jjw-story.github.io/2019/09/03/网络故障排除命令/","excerpt":"","text":"网络故障排查命令ping命令Linux系统的ping命令是常用的网络命令，它通常用来测试与目标主机的连通性 使用方法：ping [参数] 主机IP或域名 参数详解： -q 不显示任何传送封包的信息，只显示最后的结果 -n 只输出数值 -R 记录路由过程 -c count 总次数 -i 时间间隔 -t 存活数值：设置存活数值TTL的大小 使用示例： 123456789wangjia3@CHJ-20190520VPS:~$ ping -c 3 192.168.1.1PING 192.168.1.1 (192.168.1.1) 56(84) bytes of data.64 bytes from 192.168.1.1: icmp_seq=1 ttl=64 time=3.18 ms64 bytes from 192.168.1.1: icmp_seq=2 ttl=64 time=3.14 ms64 bytes from 192.168.1.1: icmp_seq=3 ttl=64 time=10.0 ms--- 192.168.1.1 ping statistics ---3 packets transmitted, 3 received, 0% packet loss, time 2002msrtt min/avg/max/mdev = 3.147/5.445/10.007/3.226 ms traceroute命令命令用于显示数据包到主机间的路径，traceroute指令让你追踪网络数据包的路由途径，预设数据包大小是40Bytes，用户可另行设置 使用方法：traceroute [参数] 主机IP或域名 参数详解： -m &lt;存活数值&gt; 设置检测数据包的最大存活数值TTL的大小 -n 直接使用IP地址而非主机名称 -v 详细显示指令的执行过程 -w &lt;超时秒数&gt; 设置等待远端主机回报的时间 12345678910traceroute to www.baidu.com (180.101.49.12), 30 hops max, 60 byte packets 1 * * * 2 11.219.5.13 (11.219.5.13) 6.841 ms 11.219.5.85 (11.219.5.85) 7.559 ms 11.219.4.85 (11.219.4.85) 6.439 ms 3 * * * 4 11.219.68.42 (11.219.68.42) 0.427 ms 0.436 ms 11.219.68.26 (11.219.68.26) 0.679 ms 5 103.41.143.69 (103.41.143.69) 1.187 ms 103.52.86.106 (103.52.86.106) 1.045 ms 103.52.86.138 (103.52.86.138) 0.956 ms 6 116.251.113.33 (116.251.113.33) 1.145 ms 116.251.113.37 (116.251.113.37) 1.447 ms 116.251.113.53 (116.251.113.53) 0.856 ms 7 150.138.130.121 (150.138.130.121) 1.377 ms 150.138.132.129 (150.138.132.129) 0.939 ms 150.138.130.133 (150.138.130.133) 1.184 ms 8 150.138.128.65 (150.138.128.65) 12.132 ms 150.138.128.173 (150.138.128.173) 17.526 ms 17.970 ms 9 202.97.46.49 (202.97.46.49) 22.672 ms 显示的访问此主机中间经过的路由，中间路由对应的IP地址及它的延时是多长时间等等，注意如果不支持traceroute方式追踪，会以 * * * 的方式展示出来 mtr命令在Linux中有一个更好的网络连通性判断工具，它可以结合ping nslookup tracert 来判断网络的相关特性,这个命令就是mtr 此命令要比上述traceroute命令展示的信息更加详细，所以使用的更多 使用方法：mtr [参数] [主机IP或域名] 参数详解： -r 已报告模式显示 使用示例： 123456789101112131415161718[root@iZm5ehzqow4ijp2ya2g2drZ ~]# mtr -r www.baidu.comHOST: iZm5ehzqow4ijp2ya2g2drZ Loss% Snt Last Avg Best Wrst StDev 1. ??? 100.0 10 0.0 0.0 0.0 0.0 0.0 2. 11.219.4.13 0.0% 10 2.3 4.5 1.6 12.9 3.7 3. ??? 100.0 10 0.0 0.0 0.0 0.0 0.0 4. 11.219.68.58 0.0% 10 0.4 1.8 0.4 12.5 3.8 5. 116.251.117.198 0.0% 10 0.7 0.8 0.7 1.1 0.2 6. 140.205.26.217 0.0% 10 1.2 1.5 1.2 3.0 0.5 7. 150.138.132.149 0.0% 10 1.6 1.5 1.4 1.6 0.1 8. 150.138.128.157 0.0% 10 18.6 20.8 18.6 27.0 3.5 9. 202.97.46.61 20.0% 10 24.5 23.1 22.9 24.5 0.6 10. 58.213.94.6 0.0% 10 18.2 18.4 18.0 20.4 0.7 11. 58.213.94.122 90.0% 10 24.1 24.1 24.1 24.1 0.0 12. 58.213.96.90 0.0% 10 21.4 21.6 21.2 23.7 0.7 13. ??? 100.0 10 0.0 0.0 0.0 0.0 0.0 14. ??? 100.0 10 0.0 0.0 0.0 0.0 0.0 15. ??? 100.0 10 0.0 0.0 0.0 0.0 0.0 16. 180.101.49.12 0.0% 10 18.0 18.0 17.9 18.0 0.0 注意此命令可以不带任何参数及IP单独使用，My traceroute 报告解释： 第一列:显示的是IP地址和本机域名，这点和tracert很像 第二列:snt:10 设置每秒发送数据包的数量，默认值是10 可以通过参数 -c来指定 第三列:是显示的每个对应IP的丢包率 第四列:显示的最近一次的返回时延 第五列:是平均值 这个应该是发送ping包的平均时延 第六列:是最好或者说时延最短的 第七列:是最差或者说时延最常的 第八列:是标准偏差 nslookup命令查看哪台DNS服务器进行的域名解析，并解析出域名对应的IP地址 使用方法：nslookup 域名 使用示例： 12345678910wangjia3@CHJ-20190520VPS:~$ nslookup www.baidu.comServer: 192.168.1.1Address: 192.168.1.1#53Non-authoritative answer:www.baidu.com canonical name = www.a.shifen.com.Name: www.a.shifen.comAddress: 61.135.169.121Name: www.a.shifen.comAddress: 61.135.169.125 以上查询第一行显示的是DNS服务器的地址，这里百度是有对应的别名的：www.baidu.com canonical name = www.a.shifen.com. 别名下有对应的两个地址 telnet命令telnet命令通常用来远程登录，它为用户提供了在本地计算机上完成远程主机工作的 能力。在终端使用者的电脑上使用telnet程序，用它连接到服务器。终端使用者可以在telnet程序中输入命令，这些命令会在服务器上运行，就像直接在服务器的控制台上输入一样。可以在本地就能控制服务器。要开始一个 telnet会话，必须输入用户名和密码来登录服务器。Telnet是常用的远程控制Web服务器的方法。 但是，telnet因为采用明文传送报文，安全性不好，很多Linux服务器都不开放telnet服务，而改用更安全的ssh方式了。但仍然有很多别的系统可能采用了telnet方式来提供远程登录，因此弄清楚telnet客户端的使用方式仍是很有必要的。 telnet命令还可做别的用途，比如确定远程服务的状态，比如确定远程服务器的某个端口是否能访问，这里我们说明的主要使用就是确认端口是否能够访问 畅通 使用方法：telnet [参数] 主机 端口 使用示例： 1234567891011121314# 端口可达wangjia3@CHJ-20190520VPS:~$ telnet www.baidu.com 80Trying 61.135.169.121...Connected to www.a.shifen.com.Escape character is &apos;^]&apos;.^]telnet&gt; quit# 端口不可达wangjia3@CHJ-20190520VPS:~$ telnet www.baidu.com 8900Trying 61.135.169.121...Trying 61.135.169.125...telnet: Unable to connect to remote host: Resource temporarily unavailable 注意我们需要通过 CTRl + 右侧方括号 来退出此查看，然后使用 CTRL + C 或者 quit命令，退出 telnet tcpdump命令很多时候我们的系统部署在Linux系统上面，在一些情况下定位问题就需要查看各个系统之间发送数据报文是否正常，下面我就简单讲解一下如何使用tcpdump抓包。tcpdump是Linux下面的一个开源的抓包工具，和Windows下面的wireshark抓包工具一样， 支持抓取指定网口、指定目的地址、指定源地址、指定端口、指定协议的数据。 用简单的话来定义tcpdump，就是：dump the traffic on a network，根据使用者的定义对网络上的数据包进行截获的包分析工具。 tcpdump可以将网络中传送的数据包的“头”完全截获下来提供分析。它支 持针对网络层、协议、主机、网络或端口的过滤，并提供and、or、not等逻辑语句来帮助你去掉无用的信息 使用说明： 监视所有网卡接口的数据包： tcpdump -i any 监视指定网络接口的数据包： tcpdump -i eth1 如果不指定网卡，默认tcpdump只会监视第一个网络接口，一般是eth0，下面的例子都没有指定网络接口 捕获所有网卡发往80端口的数据包，并且如果包含域名，将域名解析成IP，主要使用 -n 参数 tcpdump -i any -n port 80 监视指定主机收到的和发出的所有的数据包： tcpdump -i any -n host 210.27.48.1 监视指定主机和端口的数据包： tcpdump -i any -n port 23 and host 210.27.48.1 netstat命令Linux netstat命令用于显示网络状态，利用netstat指令可让你得知整个Linux系统的网络情况，查看服务的监听地址 使用方法：netstat [参数] 常用参数说明： -n 直接使用IP地址，而不通过域名服务器 -t 显示TCP传输协议的连线状况 -u 显示UDP传输协议的连线状况 -p 显示正在使用Socket的程序识别码和程序名称 -l 显示监控中的服务器的Socket -v 显示指令执行过程 使用示例： 12345[root@iZm5ehzqow4ijp2ya2g2drZ ~]# netstat -ntplActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program nametcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1260/sshdtcp 0 0 127.0.0.1:25 0.0.0.0:* LISTEN 1427/master ss命令ss是Socket Statistics的缩写。顾名思义，ss命令可以用来获取socket统计信息，它可以显示和netstat类似的内容。ss的优势在于它能够显示更多更详细的有关TCP和连接状态的信息，而且比netstat更快速更高效 当服务器的socket连接数量变得非常大时，无论是使用netstat命令还是直接cat /proc/net/tcp，执行速度都会很慢 ss快的秘诀在于，它利用到了TCP协议栈中tcp_diag。tcp_diag是一个用于分析统计的模块，可以获得Linux 内核中第一手的信息，这就确保了ss的快捷高效 使用方法：ss [参数] 常用参数说明： -n 直接使用IP地址，而不通过域名服务器 -t 显示TCP传输协议的连线状况 -u 显示UDP传输协议的连线状况 -p 显示正在使用Socket的程序识别码和程序名称 -l 显示监控中的服务器的Socket -m 显示套接字的内存使用信息 -p 显示使用套接字的进程 使用示例： 1234[root@iZm5ehzqow4ijp2ya2g2drZ ~]# ss -ntplState Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 128 *:22 *:* users:((&quot;sshd&quot;,1260,3))LISTEN 0 100 127.0.0.1:25 *:* users:((&quot;master&quot;,1427,12))","categories":[],"tags":[{"name":"command","slug":"command","permalink":"https://jjw-story.github.io/tags/command/"},{"name":"网络管理","slug":"网络管理","permalink":"https://jjw-story.github.io/tags/网络管理/"}]},{"title":"网络管理和配置文件","slug":"网络管理和配置文件","date":"2019-08-30T05:18:53.000Z","updated":"2019-11-02T09:50:48.312Z","comments":true,"path":"2019/08/30/网络管理和配置文件/","link":"","permalink":"https://jjw-story.github.io/2019/08/30/网络管理和配置文件/","excerpt":"","text":"网络服务管理概述当我们需要将网络的配置固化下来，既重启服务也能保持我们的配置状态，就需要修改Linux的配置文件，将配置文件中的配置修改后，就能将我们的配置固化下来 管理配置文件我们一般是使用一些管理程序，网络服务管理程序分为两种，分别是SysV和systemd，systemd是 CentOS 7.0 版本新添加的管理程序 配置文件一般是如下两类： 网卡配置文件：ifcfg-etho 注意：etho是根据网卡名称的不同不一样的，它会随着你的真实网卡名称变化， 主机名相关配置文件，控制网络常用参数：/etc/hosts 注意在CentOS7版本中，有两套服务管理的脚本，一套是 network (任何版本都支持)，一套是 NetworkManager，在工作当中我们一般只使用其中一套，不推荐两套都使用，可以使用以下命令查看当前机器是否支持使用 NetworkManager： 1systemctl list-unit-files NetworkManager.service 当我们想要关闭 network 服务管理只使用 NetworkManager 时就需要使用chkconfig命令来解决了，具体是 –level 参数 NetworkManager的作用： 一般应用于个人的主机，比如插入网线之后可以识别网卡的激活状态，自动进行网络的激活，或者比如我们连接到熟悉的无线网络连接当中，它会自动激活无线的连接。但是应用于服务器上这些功能都有些鸡肋，所以服务器上我们一般还是沿用network脚本 启用/禁用 NetworkManager 脚本命令： 12345# 启用systemctl disable NetworkManager禁用systemctl enable NetworkManager 配置文件说明网卡配置文件： 网卡配置文件在 /etc/sysconfig/network-scripts/目录下，在此目录下会有很多以 ifcfg 开头的文件，这些文件每一个对应着我们的一个网络接口，我们可以打开其中一个进行查看： 12345678910[root@iZm5ehzqow4ijp2ya2g2drZ /]# cd /etc/sysconfig/network-scripts/[root@iZm5ehzqow4ijp2ya2g2drZ network-scripts]# ls ifcfg-*ifcfg-eth0 ifcfg-lovim ifcfg-eth0NAME=ethoDEVICE=eth0BOOTPROTO=dhcpONBOOT=yes 网卡配置文件内容说明： 我们打开ifcfg-eth0文件，发现其中设置内容还是有一些的，基本格式都是前边是设置项，后面是设置值，这些设置有一些是它的关键设置，有些是IPV6它的初始化设置，我们只需要关注其中几项即可 BOOTPROTO=dhcp，表示我们的机器它的IP地址是动态分配的，我们可以把它的值修改为 none ，表示IP地址是静态分配的，静态分配具体配置将在下面专门描述 NAMR=etho，DEVICE=eth0，表示的是网卡的名称设置 ONBOOT=yes，表示网卡是否开机启用，如果是 yes 表示开机启用，如果是 no 表示开机不启用 网卡IP静态分配配置： 配置示例如下： 12345678910vim ifcfg-eth0NAME=ethoDEVICE=eth0BOOTPROTO=noneONBOOT=yesIPADDR=192.168.1.28NETMASK=255.255.255.0GATEWAY=192.168.1.1DNS1=114.114.114.114 注意：配置静态IP需要修改BOOTPROTO设置项，然后添加IP地址、子网掩码、网关、默认DNS的地址 设置完成需要使用命令来让它生效，使用命令有两种，分别如下，命令具体使用在后边分析描述： service network restart systemctl restart NetworkManager.service 如上操作完成之后，就可以使用命令 ipconfig etho 来查看IP及子网掩码配置是否生效，使用 route -n 查看网关是否配置生效，使用 nslookup 查看默认的DNS设置是否生效 chkconfigchkconfig命令主要用来更新（启动或停止）和查询系统服务的运行级信息。谨记chkconfig不是立即自动禁止或激活一个服务，它只是简单的改变了符号连接 使用方法：chkconfig 参数 系统服务 参数详解： –list 列出所有的系统服务及状态，使用示例如下： 12[root@iZm5ehzqow4ijp2ya2g2drZ ~]# chkconfig --list networknetwork 0:off 1:off 2:on 3:on 4:on 5:on 6:off 上述示例中，数字表示不同的级别，及不同的级别服务的运行情况，级别表示如下： 等级0表示：表示关机 等级1表示：单用户模式 等级2表示：无网络连接的多用户命令行模式 等级3表示：有网络连接的多用户命令行模式 等级4表示：不可用 等级5表示：带图形界面的多用户模式 等级6表示：重新启动 –level 指定读系统服务要在哪一个执行等级中开启或关毕，使用时需要指定等级 使用示例，将当前开启的服务全部关闭 2 3 4 5 等级都关闭： 1234[root@iZm5ehzqow4ijp2ya2g2drZ ~]# chkconfig --level 2345 network off[root@iZm5ehzqow4ijp2ya2g2drZ ~]# chkconfig --list networknetwork 0:off 1:off 2:off 3:off 4:off 5:off 6:off 注意：当我们在CentOS7及以上版本中如此操作时，就相当与关闭了 network 服务管理工具，改为使用 NetworkManager 查看网络状态service network status 命令 使用示例： 12345[root@iZm5ehzqow4ijp2ya2g2drZ ~]# service network statusConfigured devices:lo eth0Currently active devices:lo eth0 如上查询结果中，第一表示我们已配置的网卡设备，第二表示当前活跃的设备 还原网卡默认配置 service network restart 将我们使用ifconfig、route等命令自己配置的内容恢复到默认的状态 使用示例： 1234567[root@iZm5ehzqow4ijp2ya2g2drZ ~]# service network restartShutting down interface eth0: [ OK ]Shutting down loopback interface: [ OK ]Bringing up loopback interface: [ OK ]Bringing up interface eth0: Determining IP information for eth0... done. [ OK ] systemctl restart NetworkManager.service 如果在 CentOS7 及以上版本中开启了 NetworkManager 脚本，还可以使用此命令来还原配置 配置主机名称查看主机名称查看主机名称使用 hostname 命令，使用示例如下： 12wangjia3@CHJ-20190520VPS:~$ hostnameCHJ-20190520VPS 临时设置主机名称临时设置就是当前修改过来，但是主机重启之后还是恢复成默认的 使用命令：hostname 自定义主机名称 如下示例： 1234567wangjia3@CHJ-20190520VPS:~$ hostname CHJhostname: you must be root to change the host namewangjia3@CHJ-20190520VPS:~$ sudo hostname CHJ[sudo] password for wangjia3:wangjia3@CHJ-20190520VPS:~$ hostnameCHJ 永久修改主机名称使用命令：hostnamectl set-hostname 自定义主机名称 这样设置之后即使重启之后也会使用新的主机名，但是要注意，如果我们更改主机名之后，很多服务是要依赖主机名进行工作，这里我们必须一个配置文件中将新的主机名写在127.0.0.1的对应关系当中，如果不写可能会出现在启动系统的时候，在某个服务上卡住，在等待它超时，这个文件是 /etc/hosts，如下： 12345678910 2 # %WINDIR%\\System32\\drivers\\etc\\hosts. Modifications to this file will be overwritten. 3 127.0.0.1 localhost 4 127.0.1.1 CHJ-20190520VPS.localdomain CHJ-20190520VPS # 修改此行内容 5 6 # The following lines are desirable for IPv6 capable hosts 7 ::1 ip6-localhost ip6-loopback 8 fe00::0 ip6-localnet 9 ff00::0 ip6-mcastprefix10 ff02::1 ip6-allnodes11 ff02::2 ip6-allrouters","categories":[],"tags":[{"name":"command","slug":"command","permalink":"https://jjw-story.github.io/tags/command/"},{"name":"网络管理","slug":"网络管理","permalink":"https://jjw-story.github.io/tags/网络管理/"}]},{"title":"软件包管理器和内核升级","slug":"软件包管理器","date":"2019-08-25T03:17:20.000Z","updated":"2019-10-06T08:22:48.743Z","comments":true,"path":"2019/08/25/软件包管理器/","link":"","permalink":"https://jjw-story.github.io/2019/08/25/软件包管理器/","excerpt":"","text":"介绍包管理器是方便软件安装、卸载、解决软件依赖关系的重要工具 CentOS、RedHat使用yum包管理器，软件安装包格式为rpm Debian、Ubuntu使用apt包管理器，软件安装包格式为deb rpmrpm包格式： vim-common-7.4.10.5.el7.x86_64.rpm 分别对应着软件名称、软件版本、系统版本、平台，然后以.rpm作为结尾。注意系统版本 el7 表示支持7版本的Linux系统，x86_64表示64位的平台系统 rpm命令使用方法：rpm [参数] 常用参数： -a： 查询所有套件 -c： 只列出组态配置文件，本参数需配合”-l”参数使用 -d： 只列出文本文件，本参数需配合”-l”参数使用 -e&lt;软件包&gt;： 删除指定的软件 -f&lt;文件&gt;+： 查询拥有指定文件的套件 -i&lt;软件包&gt;： 安装指定的软件包 -l： 显示套件的文件列表 -p&lt;软件包&gt;+： 查询指定的RPM套件档 -q： 使用询问模式，当遇到任何问题时，rpm指令会先询问用户 查询安装的软件包使用示例： 123456789101112131415# 查询所有安装的软件包[root@iZm5ehzqow4ijp2ya2g2drZ ~]# rpm -qavim-common-7.4.629-5.el6_8.1.x86_64setup-2.8.14-23.el6.noarchtcpdump-4.0.0-11.20090921gitdf3cb4.2.el6.x86_64basesystem-10.0-4.el6.noarch...# 显示内容太多还可以分页显示，命令如下：rpm -qa | more使用管道符加 more 即可实现 more 命令的翻页效果# 查询是否安装指定的软件包：使用-q参数，后面跟上要查询的软件包名称[root@iZm5ehzqow4ijp2ya2g2drZ ~]# rpm -q vim-commonvim-common-7.4.629-5.el6_8.1.x86_64 安装软件包使用示例： 1234# 主要是使用 -i 参数[root@iZm5ehzqow4ijp2ya2g2drZ ~]# rpm -i vim-enhanced-7.4.160-5.el7.x86_64.rpm# 注意很多时候我们安装软件包的时候回安装失败，错误信息为安装此安装包需要依赖另一个软件，这时我们需要先安装依赖的软件包 卸载已安装的软件包使用示例： 1234567# 主要是使用 -e 参数[root@iZm5ehzqow4ijp2ya2g2drZ ~]# rpm -e vim-enhanced注意：在删除安装的软件包时不需要指定软件包的全限定名称，只需要指定名称即可# 删除多个软件包[root@iZm5ehzqow4ijp2ya2g2drZ ~]# rpm -e vim-enhanced vim—common使用空格分开继续追加软件即可 yumyum概述及配置yum包管理器或yum仓库，它的出现是为了解决 rpm 包存在的问题： 需要自己解决依赖关系 如果我们要使用光盘中的rpm包，需要将整个光盘挂载到Linux当中，甚至如果没有光盘需要将整个光盘的iso镜像下载回来，以及软件包来源不可靠 CentOS yum源地址： http://mirror.centos.org/centos/7/ 国内镜像： https://opsx.alibaba.com/mirror 使用国内镜像有两种配置方式，第一种，需要修改yum的配置文件，修改文件如下： /etc/yum.repos.d/CentOS-Base.repo 1234567[base]name=CentOS-$releaseverenabled=1failovermethod=prioritybaseurl=http://mirrors.cloud.aliyuncs.com/centos/$releasever/os/$basearch/gpgcheck=1gpgkey=http://mirrors.cloud.aliyuncs.com/centos/RPM-GPG-KEY-CentOS-6 base表示基础应用的包，baseurl表示基础应用的rpm包放在哪一个源路径下，gpgcheck检测yum源软件包有没有被人恶意修改，是否为最开始发布的软件包的内容，防止被添加入木马 第二种方式，备份我们系统中yum配置文件，然后至镜像网站查询对应的OS版本的配置文件下载的地址 wget 命令，执行此 wget 命令后，就将原来的配置文件覆盖掉，之后运行 yum makecache 命令，生成缓存，让软件包指向我们要指向的开源的镜像站 使用 yum makecache 命令，可以把之前的缓存清空，然后通过网络把新的版本的软件包，配置等下载回来，然后更新，注意更新的过程不要中断 yum命令安装软件包使用yum安装软件可以自动检测软件包的依赖，并将依赖也下载安装，使用示例如下： 123456789101112131415161718192021# 首先卸载 vim-enhanced 和 vim-common 这两个软件包[root@iZm5ehzqow4ijp2ya2g2drZ yum.repos.d]# rpm -e vim-enhanced[root@iZm5ehzqow4ijp2ya2g2drZ yum.repos.d]# rpm -e vim-common# 然后使用 yum install 命令安装 vim-enhanced 软件包# 安装时我们发现它自动检测的安装 vim-enhanced 包的依赖关系，并将两个软件包同时进行安装[root@iZm5ehzqow4ijp2ya2g2drZ yum.repos.d]# yum install vim-enhanced...Dependencies Resolved=============================================================================================================================================================================== Package Arch Version Repository Size===============================================================================================================================================================================Installing: vim-enhanced x86_64 2:7.4.629-5.el6_10.2 updates 1.0 MInstalling for dependencies: vim-common x86_64 2:7.4.629-5.el6_10.2 updates 6.7 MTransaction Summary===============================================================================================================================================================================Install 2 Package(s) 卸载软件包卸载软件包使用的是 yum remove 命令，使用如下： 123456789101112131415# 删除与 vim 相关的软件包[root@iZm5ehzqow4ijp2ya2g2drZ yum.repos.d]# yum remove vim# 会提示有哪些与vim相关的软件包Dependencies Resolved=============================================================================================================================================================================== Package Arch Version Repository Size===============================================================================================================================================================================Removing: vim-enhanced x86_64 2:7.4.629-5.el6_10.2 @updates 2.2 MTransaction Summary===============================================================================================================================================================================Remove 1 Package(s) 查看软件包可以使用 yum list 命令来查看我们已经安装了哪些软件包，使用如下： 1234567[root@iZm5ehzqow4ijp2ya2g2drZ yum.repos.d]# yum list...zvbi.i686 0.2.35-1.el6 epelzvbi.x86_64 0.2.35-1.el6 epelzvbi-devel.i686 0.2.35-1.el6 epelzvbi-devel.x86_64 0.2.35-1.el6 epelzvbi-fonts.noarch 0.2.35-1.el6 epel 还可以使用 yum list package1 查看指定的软件包的安装情况，使用如下: 12345[root@iZm5ehzqow4ijp2ya2g2drZ yum.repos.d]# yum list vim-commonLoaded plugins: fastestmirrorLoading mirror speeds from cached hostfileInstalled Packagesvim-common.x86_64 2:7.4.629-5.el6_10.2 @updates 升级软件包升级软件包是一个非常重要的命令，因为我们在生产环境中安装的软件可能多多少少会出现一些bug或安全漏洞，这就需要我们定期的给软件进行一定的升级，那么如何升级呢，我们就需要使用 yum update 软件包名 命令来升级指定的软件包，如果我们不加软件包名，就会对当前所有的安装的软件包进行升级，注意：并不是直接升级，是会有提示的 使用如下： 1234567891011121314151617181920212223242526272829303132333435363738# 检查所有需要升级的软件并选择是否升级Dependencies Resolved=============================================================================================================================================================================== Package Arch Version Repository Size===============================================================================================================================================================================Installing: kernel x86_64 2.6.32-754.18.2.el6 updates 32 MUpdating: binutils x86_64 2.20.51.0.2-5.48.el6_10.1 updates 2.8 M ca-certificates noarch 2018.2.22-65.1.el6 base 930 kTransaction Summary===============================================================================================================================================================================Install 1 Package(s)Upgrade 57 Package(s)Total download size: 113 MIs this ok [y/N]: # 这里提示有57个软件包需要进行升级，我们出入 y 之后，既开始升级# 升级指定的软件包[root@iZm5ehzqow4ijp2ya2g2drZ yum.repos.d]# yum update vim-filesystemDependencies Resolved=============================================================================================================================================================================== Package Arch Version Repository Size===============================================================================================================================================================================Updating: vim-filesystem x86_64 2:7.4.629-5.el6_10.2 updates 15 kTransaction Summary===============================================================================================================================================================================Upgrade 1 Package(s)Total download size: 15 kIs this ok [y/N]: 通过源代码编译安装软件包有些时候我们在安装或升级软件包时，发现官网并没有直接可以安装的软件包，既不可以通过 yum 命令直接安装，只提供了压缩源代码软件包，这时我们就需要自己来编译此源代码来进行安装 注意，此种情况比较少，且安装比较麻烦，如果 yum 或 rpm 可以直接安装的话，尽量不要通过此种方式 安装示例我们将通过安装一个 openresty 源代码包来作为示例，具体步骤如下： 下载源代码包 使用命令 wget https://openresty.org/download/openresty-1.15.8.1.tar.gz 1234567root@iZm5ehzqow4ijp2ya2g2drZ ~]# wget https://openresty.org/download/openresty-1.15.8.1.tar.gz--2019-09-07 17:03:16-- https://openresty.org/download/openresty-1.15.8.1.tar.gz...2019-09-07 17:03:17 (34.3 MB/s) - “openresty-1.15.8.1.tar.gz” saved [4904182/4904182][root@iZm5ehzqow4ijp2ya2g2drZ ~]# ll-rw-r--r-- 1 root root 4904182 May 17 05:34 openresty-1.15.8.1.tar.gz 解压此源代码包 tar -zxvf openresty-VENSION.tar.gz 123456[root@iZm5ehzqow4ijp2ya2g2drZ ~]# tar -zxvf openresty-1.15.8.1.tar.gz [root@iZm5ehzqow4ijp2ya2g2drZ ~]# ls -lhtotal 53Mdrwxrwxr-x 5 1000 1003 4.0K May 17 05:27 openresty-1.15.8.1-rw-r--r-- 1 root root 4.7M May 17 05:34 openresty-1.15.8.1.tar.gz 进入解压好的文件夹，然后进行编译源代码 123456789[root@iZm5ehzqow4ijp2ya2g2drZ openresty-1.15.8.1]# ls -lhtotal 108Kdrwxrwxr-x 46 1000 1003 4.0K May 17 05:27 bundle-rwxrwxr-x 1 1000 1003 52K May 17 05:27 configure-rw-rw-r-- 1 1000 1003 23K May 17 05:27 COPYRIGHTdrwxrwxr-x 2 1000 1003 4.0K May 17 05:27 patches-rw-rw-r-- 1 1000 1003 4.6K May 17 05:27 README.markdown-rw-rw-r-- 1 1000 1003 8.8K May 17 05:27 README-windows.txtdrwxrwxr-x 2 1000 1003 4.0K May 17 05:27 util 我们发现 configure 是一个绿色的文件，并且是一个可执行的文件，一般情况下我们下载下源代码编译好后，都是通过 make 和 make install 命令来安装源代码，所以在我们解压源代码后就进入目录看看是否有类似于此示例中 configure 这样的可执行文件，如果没有的话，可以阅读源码包中的README文件，来查看具体的安装编译方法 接下来就是执行此可执行文件，注意：一般在执行此可执行程序时，我们都会指定它的安装目录，使用 –prefix 参数执行即可，指定完目录之后就意味着之后安装程序全都是在这个指定的目录下 12345678[root@iZm5ehzqow4ijp2ya2g2drZ openresty-1.15.8.1]# ./configure --prefix=/usr/local/openresty==== Building LuaJIT 2.1.0-beta3 ====gmake -C srcgmake[1]: cc: Command not found...gmake: *** [default] Error 2ERROR: failed to run command: gmake TARGET_STRIP=@: CCDEBUG=-g XCFLAGS=&apos;-DLUAJIT_ENABLE_LUA52COMPAT -DLUAJIT_ENABLE_GC64&apos; CC=cc PREFIX=/usr/local/openresty/luajit 执行之后我们发现有报错信息，这时候我们就需要解决此报错，此报错说 cc 命令找不到，既没有安装 gcc 软件包，那我们使用 yum 命令安装即可 1234[root@iZm5ehzqow4ijp2ya2g2drZ openresty-1.15.8.1]# yum install gccLoaded plugins: fastestmirrorSetting up Install Process... 安装完成之后我们发现再次执行发现可以执行了，但是还是执行失败，失败报错缺少 PCRE 这个库，这时候我们还需要安装这个库 12345678910[root@iZm5ehzqow4ijp2ya2g2drZ openresty-1.15.8.1]# ./configure --prefix=/usr/local/openrestyplatform: linux (linux)cp -rp bundle/ build..../configure: error: the HTTP rewrite module requires the PCRE library.You can either disable the module by using --without-http_rewrite_moduleoption, or install the PCRE library into the system, or build the PCRE librarystatically from the source with nginx by using --with-pcre=&lt;path&gt; option.ERROR: failed to run command: sh ./configure --prefix=/usr/local/openresty/nginx \\... 通过 yum 安装 PCRE 这个库，安装示例： 1234[root@iZm5ehzqow4ijp2ya2g2drZ openresty-1.15.8.1]# yum install pcre-develLoaded plugins: fastestmirrorSetting up Install Process... 安装完成后再次执行此可执行文件，发现还是报错，说缺少 OpenSSL这个库： 12345678[root@iZm5ehzqow4ijp2ya2g2drZ openresty-1.15.8.1]# ./configure --prefix=/usr/local/openresty..../configure: error: SSL modules require the OpenSSL library.You can either do not enable the modules, or install the OpenSSL libraryinto the system, or build the OpenSSL library statically from the sourcewith nginx by using --with-openssl=&lt;path&gt; option.ERROR: failed to run command: sh ./configure --prefix=/usr/local/openresty/nginx \\... 通过 yum 安装 OpenSSL 这个库 12345[root@iZm5ehzqow4ijp2ya2g2drZ openresty-1.15.8.1]# yum install openssl-develLoaded plugins: fastestmirrorSetting up Install ProcessLoading mirror speeds from cached hostfile... 上述示例中：-devel表示的都是开发库 安装完成后再次执行此文件，发现终于可以执行成功了 12345678root@iZm5ehzqow4ijp2ya2g2drZ openresty-1.15.8.1]# ./configure --prefix=/usr/local/openrestyplatform: linux (linux)cp -rp bundle/ build...cd ../..Type the following commands to build and install: gmake gmake install 执行完成后我们发现终于给了提示，说可以使用 gmake 和 gmake install 进行编译安装此软件包 通常我们都是使用 make 和 make install 进行编译安装，这是提示使用 gmake 和 gmake install，gmake 和 gmake install 是方便我们跨平台的进行编译安装的命令，所以我们这里使用 gmake 和 gmake install 这两个命令进行编译安装，此两种命令都可以使用 编译 首先使用 gmake 编译此源码包，可以使用 -j2 参数进行指定使用两个cpu进行编译，效率会更快 1234567[root@iZm5ehzqow4ijp2ya2g2drZ openresty-1.15.8.1]# gmake -j2...gmake[2]: Leaving directory `/root/openresty-1.15.8.1/build/nginx-1.15.8&apos;gmake[1]: Leaving directory `/root/openresty-1.15.8.1/build/nginx-1.15.8&apos;[root@iZm5ehzqow4ijp2ya2g2drZ openresty-1.15.8.1]# lsbuild bundle configure COPYRIGHT Makefile patches README.markdown README-windows.txt util 编译完成之后，我们发现源代码目录文件中多了一个 build 文件夹，这里面就存放了编译之后的文件及配置文件 安装 使用 gmake install 命令，将 build 文件中的所有文件都安装到我们之前指定的目录中 注意还是在原来的目录中，不需要进去其他目录 12345[root@iZm5ehzqow4ijp2ya2g2drZ openresty-1.15.8.1]# gmake installcd /root/openresty-1.15.8.1/build/LuaJIT-2.1-20190507 &amp;&amp; gmake TARGET_STRIP=@: CCDEBUG=-g XCFLAGS=&apos;-std=gnu99 -DLUAJIT_ENABLE_LUA52COMPAT -DLUAJIT_ENABLE_GC64 -msse4.2&apos; CC=cc PREFIX=/usr/local/openresty/luajit...mkdir -p /usr/local/openresty/site/lualib /usr/local/openresty/site/pod /usr/local/openresty/site/manifestln -sf /usr/local/openresty/nginx/sbin/nginx /usr/local/openresty/bin/openresty 执行完成后，就已经安装完成了，可以查看我们之前的指定目录，查看安装后的文件内容 12345678910root@iZm5ehzqow4ijp2ya2g2drZ openresty-1.15.8.1]# ll /usr/local/openresty/total 272drwxr-xr-x 2 root root 4096 Sep 7 18:20 bin-rw-r--r-- 1 root root 22924 Sep 7 18:20 COPYRIGHTdrwxr-xr-x 6 root root 4096 Sep 7 18:20 luajitdrwxr-xr-x 6 root root 4096 Sep 7 18:20 lualibdrwxr-xr-x 6 root root 4096 Sep 7 18:20 nginxdrwxr-xr-x 47 root root 4096 Sep 7 18:20 pod-rw-r--r-- 1 root root 226376 Sep 7 18:20 resty.indexdrwxr-xr-x 5 root root 4096 Sep 7 18:20 site 只有再安装完成后，才可以看到此目录及文件，这样就完成了通过源代码安装软件啦 内核升级uname命令Linux uname命令用于显示系统信息，uname可显示电脑以及操作系统的相关信息 使用方式：uname [选项] 参数说明 -a 显示全部的信息 -m 显示电脑类型 -n 显示在网络上的主机名称 -r 显示操作系统的发行编号 -s 显示操作系统名称 -v 显示操作系统的版本 使用示例： 12[root@iZm5ehzqow4ijp2ya2g2drZ balyu]# uname -aLinux iZm5ehzqow4ijp2ya2g2drZ 2.6.32-696.16.1.el6.x86_64 #1 SMP Wed Nov 15 16:51:15 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux df命令Linux df命令用于显示目前在Linux系统上的文件系统的磁盘使用情况统计 使用方法： df [选项] 参数说明 -h -human-readable 使用人类可读的格式(预设值是不加这个选项的…) -t -type=TYPE 限制列出文件系统的 TYPE -i 输出显示inode信息而非块使用量 使用示例： 1234[root@iZm5ehzqow4ijp2ya2g2drZ boot]# df -hFilesystem Size Used Avail Use% Mounted on/dev/vda1 40G 2.4G 35G 7% /tmpfs 499M 0 499M 0% /dev/shm lscpu命令查看当前主机CPU状况的命令，使用示例： 123456789101112131415161718192021222324[root@iZm5ehzqow4ijp2ya2g2drZ balyu]# lscpuArchitecture: x86_64CPU op-mode(s): 32-bit, 64-bitByte Order: Little EndianCPU(s): 1On-line CPU(s) list: 0Thread(s) per core: 1Core(s) per socket: 1Socket(s): 1NUMA node(s): 1Vendor ID: GenuineIntelCPU family: 6Model: 85Model name: Intel(R) Xeon(R) Platinum 8163 CPU @ 2.50GHzStepping: 4CPU MHz: 2500.006BogoMIPS: 5000.01Hypervisor vendor: KVMVirtualization type: fullL1d cache: 32KL1i cache: 32KL2 cache: 1024KL3 cache: 33792KNUMA node0 CPU(s): 0 top命令类似于Windows的任务管理器，使用示例： 12345678910111213[root@iZm5ehzqow4ijp2ya2g2drZ balyu]# toptop - 15:03:02 up 7 days, 5:18, 2 users, load average: 0.00, 0.00, 0.00Tasks: 79 total, 1 running, 78 sleeping, 0 stopped, 0 zombieCpu(s): 0.3%us, 0.3%sy, 0.0%ni, 99.0%id, 0.3%wa, 0.0%hi, 0.0%si, 0.0%stMem: 1019980k total, 705416k used, 314564k free, 131904k buffersSwap: 0k total, 0k used, 0k free, 209692k cached PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 1407 root 10 -10 121m 11m 9176 S 0.3 1.2 30:52.20 AliYunDun 1 root 20 0 19228 1500 1232 S 0.0 0.1 0:00.71 init 2 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kthreadd 3 root RT 0 0 0 0 S 0.0 0.0 0:00.00 migration/0 4 root 20 0 0 0 0 S 0.0 0.0 0:00.62 ksoftirqd/0 可以看到能查询到CPU及内存等的使用状态，以及当前进程等 扩展软件仓库很多时候我们发现CentOS默认提供的软件仓库中并没有我们需要的软件，或者软件版本没有一些最新的，比如下面我们要说的内核，这时候我们就需要去别的仓库去找，所以这里我们介绍扩展软件仓库 一般比较流行的软件仓库是 epel 仓库，我们只需要通过命令来安装这个仓库即可，命令如下： 1yum install epel-release -y 升级内核以上我们已经知道了如何查看自己主机当前的内核版本，现在我们就可以对它进行升级了 使用yum命令升级第一种方式是指定内核的版本进行升级，我们可以去内核的官网查看我们需要升级的内核版本，然后使用yum命令进行升级，具体命令如下： 1yum install kernel-3.10.0 注意上面我们只使用 yum install kernel 命令，不指定具体的版本号的时候，yum就会去仓库寻找最新的 kernel 版本来进行安装 第二种方式是自动进行升级，它可以直接对我们所有安装的软件及内核进行版本检测，检测到有最新版本的话就会自动升级，具体使用如下： 1yum update 使用源代码编译方式安装升级 源代码编译的方式比较复杂，上面我们已经说过了，需要解决各种各样的依赖，以下是大神总结出来的所有的依赖： 12安装依赖包yum install gcc gcc-c++ make ncurses-devel openssl-devel elfutils-libelf-devel 接下来需要下载并解压缩内核软件包，下载地址：www.kernel.org，选择好我们要安装的内核版本并下载，然后解压缩就可以安装了 配置内核编译参数 配置内核编译参数和我们上述介绍的./configure不一样，需要进入到内核的软件包指定目录中，然后使用 make 命令来配置。具体如下： 12cd /usr/src/kernals/linux-5.1.1.0/make menuconfig | allyelsconfig | allnoconfig 上述介绍的 ./configure 是有很多的自动化配置在里面，但是我们在安装内核的时候，这些配置都需要我们自己手动来完成，所以这里需要使用 make – 命令来进行配置： make menuconfig 我们自己来根据弹出的菜单选项来进行配置 make allyelconfig 无脑设置，既有的功能全部都配置上 make allnoconfig 无脑设置，既什么功能都不配置，这样有可能会出现什么都不安装，导致安装后启动都启动不了 我们还可以使用当前的系统配置来进行配置，这里只需要将我们原先内核的配置文件拷贝到软件包的指定目录下，并且重命名为 .config 就可以使用原来内核的配置，这样就可以减少我们配置的复杂度，具体命令如下： 1cp /boot/config-kernelversion.platfrom /uer/src/kernels/linux-5.1.10/.config 注意上述命令示例中 kernelversion.platfrom 是需要替换成我们本地的文件，形式：config-2.6.32-696.16.1.el6.x86_64 编译 编译软件包与上述源代码编译一样，使用make命令直接编译即可，如下： 1make -j2 all 安装 安装与上述源代码安装不一样，多了一个步骤，我们在安装内核的时候需要先安装内核所支持的模块，然后再安装内核，具体命令如下： 123make modules_installmake install 这里我们就将内核安装升级完成了 grub配置文件升级完内核时我们需要设置启动引导软件来设置默认的内核，CentOS7使用的是gurb2版本，CentOS使用的是一版本，在一版本中，我们什么样的配置都需要自己手动去编辑，而且需要向设置网卡一样，记住每一项的功能，而二版本给我们提供了很多方便的工具，我们需要修改配置的时候只需要通过命令修改即可。所以grub2版本就不需要我们去背每一个设置项及内容了。 配置文件具体说明配置文件所在的位置：/boot/grub2/grub.cfg，由于grub2程序的特性，我们一般不要去直接编辑此文件，因为此文件可以说是一个内存级的配置文件，如果我们再通过一些其他的手段去修改了默认的配置，那么我们的的编辑就会丢失及消失 所以我们通常如果想要修改配置，会去修改：/etc/default/grub 这个文件，这个是一些基本的配置的配置文件，如果我们想修改更为详细的配置，我们可以去：/etc/grud.d/ 此文件目录下的一些其他的配置文件，此文件是从 00、01 … 等一直向后排序的 当我们修改完成后，通过命令：grub2-mkconfig-o /boot/gurb2/grub.cfg 就可以产生新的配置文件了 /etc/default/grub这个文件是修改默认的一些设置，这里面一般我们只需要关注两个配置项即可： GRUB_DEFAULT=saved GRUB_CMDLINE_LINUX=”rd.lvm.lv=centos/root rd.lvm.lv=centos/swap rhgb quiet biosde vname=0 net.ifnames=0” 修改默认启动引导内核当我们需要修改默认的启动引导内核，就需要依赖上述第一项，我们需要通过命令：grub2-editenv list 能查看到当前系统启动的引导内核是什么版本的， 然后我们需要通过命令：grub2 ^menu /boot/default/grub 来查看当前我们系统中安装了哪些内核版本及顺序，我们找到所有以 menuentry 开头的行，它后边包含的内容就是我们安装的内核版本信息，我们需要找到我们需要修改的内核的顺序，第一个从0开始，然后记录。然后我们通过命令：grub2-set-default 顺序编号 来设置我们默认的系统引导内核。 当修改完成后，我们再来通过 grub2-editenv list 命令查看当前系统启动引导内核时，发现就成为了我们设置的内核（saved_entry=顺序编号），这时我们重新启动电脑，发现重启后默认的启动内核就变成了我们所设置的内核 启动项配置上述描述中第二项就是我们需要关注的，修改网卡名称所要用到的一项，此项中我们经常需要修改的是两个项： 1GRUB_CMDLINE_LINUX=&quot;rd.lvm.lv=centos/root rd.lvm.lv=centos/swap rhgb quiet biosde vname=0 net.ifnames=0&quot; 上述中rhgb：此项表示引导的时候使用一个图形界面，我们看到启动时的进度条，也是当启动出现问题的将此项去掉已查看启动时更为详细的信息 上述中quiet：此项为静默模式，表示引导的时候只是打印一些必要的消息，当我们发现启动出现异常的时候，我们会将此项去掉，已打印更为全面的消息来定位问题","categories":[{"name":"Linux","slug":"Linux","permalink":"https://jjw-story.github.io/categories/Linux/"}],"tags":[{"name":"command","slug":"command","permalink":"https://jjw-story.github.io/tags/command/"},{"name":"软件包管理器和内核升级","slug":"软件包管理器和内核升级","permalink":"https://jjw-story.github.io/tags/软件包管理器和内核升级/"}],"author":"JJW"},{"title":"网络配置","slug":"网络配置","date":"2019-08-12T12:00:00.000Z","updated":"2019-08-20T12:06:13.128Z","comments":true,"path":"2019/08/12/网络配置/","link":"","permalink":"https://jjw-story.github.io/2019/08/12/网络配置/","excerpt":"","text":"网络配置命令设置网卡IP地址ifconfig命令我们可以使用ifconfig命令来设置网卡的ip地址，使用方法: ifconfig 接口 IP地址 [netmask 子网掩码] 使用示例： 123456789101112131415161718192021222324root@CHJ-20190520VPS:/# ifconfigeth3: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 172.31.34.113 netmask 255.255.255.240 broadcast 172.31.34.127 inet6 fe80::4c47:3429:b72c:5130 prefixlen 64 scopeid 0x0&lt;global&gt; ether 7e:15:d8:27:73:38 (Ethernet) ...# 修改iproot@CHJ-20190520VPS:/# ifconfig eth3 172.31.34.118root@CHJ-20190520VPS:/# ifconfigeth3: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 172.31.34.113 netmask 255.255.255.240 broadcast 172.31.34.127 inet6 fe80::4c47:3429:b72c:5130 prefixlen 64 scopeid 0x0&lt;global&gt; ether 7e:15:d8:27:73:38 (Ethernet) ...# 修改ip并指定子网掩码root@CHJ-20190520VPS:/# ifconfig eth3 172.31.34.118 netmask 255.255.255.0root@CHJ-20190520VPS:/# ifconfigeth3: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 172.31.34.118 netmask 255.255.255.0 broadcast 172.31.34.127 inet6 fe80::4c47:3429:b72c:5130 prefixlen 64 scopeid 0x0&lt;global&gt; ether 7e:15:d8:27:73:38 (Ethernet) ... 启动和关闭网卡启动和关闭网卡动作和我们Windows中的是一样的，这两个操作其实是在一些特殊情况来使用网卡操作的命令，一般是网卡的配置被改乱了，我们希望恢复到默认的配置，可能需要这两个命令，一般情况下我们是不需要使用这两个命令的 启动命令以下都分别对用两种工具包的命令，使用哪一种都可以 ifconfig 接口 up ifup 接口 关闭命令ipconfig 接口 down ifdown 接口 网关配置命令添加网关网段使用route add命令，使用方法： route add [-net | -host] 目的网络或主机 gw 网关ip route add [-net | -host] dev 网卡接口 route add -net 指定网段 netmask 子网掩码 eth0 route add -net 指定网段 netmask 子网掩码 gw 网关ip -net是指定网段，-host是指定ip 使用示例： 12345678910111213141516171819202122232425262728293031323334353637383940[root@iZm5ehzqow4ijp2ya2g2drZ etc]# routeKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface172.31.240.0 * 255.255.240.0 U 0 0 0 eth0link-local * 255.255.0.0 U 1002 0 0 eth0default 172.31.255.253 0.0.0.0 UG 0 0 0 eth0# 添加主机路由[root@iZm5ehzqow4ijp2ya2g2drZ etc]# route add -host 192.168.1.2 dev eth0[root@iZm5ehzqow4ijp2ya2g2drZ etc]# routeKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface192.168.1.2 * 255.255.255.255 UH 0 0 0 eth0172.31.240.0 * 255.255.240.0 U 0 0 0 eth0link-local * 255.255.0.0 U 1002 0 0 eth0default 172.31.255.253 0.0.0.0 UG 0 0 0 eth0# 添加网络路由 10.20.30.40 ~ 255.255.255.248[root@iZm5ehzqow4ijp2ya2g2drZ etc]# route add -net 10.20.30.40 netmask 255.255.255.248 eth0[root@iZm5ehzqow4ijp2ya2g2drZ etc]# routeKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface192.168.1.2 * 255.255.255.255 UH 0 0 0 eth010.20.30.40 * 255.255.255.248 U 0 0 0 eth0172.31.240.0 * 255.255.240.0 U 0 0 0 eth0link-local * 255.255.0.0 U 1002 0 0 eth0default 172.31.255.253 0.0.0.0 UG 0 0 0 eth0# 添加默认路由 default ~ 192.168.1.2[root@iZm5ehzqow4ijp2ya2g2drZ etc]# route add default gw 192.168.1.2[root@iZm5ehzqow4ijp2ya2g2drZ etc]# routeKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface192.168.1.2 * 255.255.255.255 UH 0 0 0 eth010.20.30.40 * 255.255.255.248 U 0 0 0 eth0172.31.240.0 * 255.255.240.0 U 0 0 0 eth0link-local * 255.255.0.0 U 1002 0 0 eth0default 192.168.1.2 0.0.0.0 UG 0 0 0 eth0default 172.31.255.253 0.0.0.0 UG 0 0 0 eth0 删除网关网段使用route del命令，使用方法： route del [-net | -host] 目的网络或主机 gw 网关ip route del [-net | -host] dev 网卡接口 route del -net 指定网段 netmask 子网掩码 eth0 route del -net 指定网段 netmask 子网掩码 gw 网关ip 使用示例： 123456789101112131415161718192021222324252627282930313233343536373839[root@iZm5ehzqow4ijp2ya2g2drZ etc]# routeKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface192.168.1.2 * 255.255.255.255 UH 0 0 0 eth010.20.30.40 * 255.255.255.248 U 0 0 0 eth0172.31.240.0 * 255.255.240.0 U 0 0 0 eth0link-local * 255.255.0.0 U 1002 0 0 eth0default 192.168.1.2 0.0.0.0 UG 0 0 0 eth0default 172.31.255.253 0.0.0.0 UG 0 0 0 eth0# 删除主机路由[root@iZm5ehzqow4ijp2ya2g2drZ etc]# route del -host 192.168.1.2 dev eth0[root@iZm5ehzqow4ijp2ya2g2drZ etc]# routeKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface10.20.30.40 * 255.255.255.248 U 0 0 0 eth0172.31.240.0 * 255.255.240.0 U 0 0 0 eth0link-local * 255.255.0.0 U 1002 0 0 eth0default 192.168.1.2 0.0.0.0 UG 0 0 0 eth0default 172.31.255.253 0.0.0.0 UG 0 0 0 eth0# 删除默认路由[root@iZm5ehzqow4ijp2ya2g2drZ etc]# route del -net default gw 192.168.1.2[root@iZm5ehzqow4ijp2ya2g2drZ etc]# routeKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface10.20.30.40 * 255.255.255.248 U 0 0 0 eth0172.31.240.0 * 255.255.240.0 U 0 0 0 eth0link-local * 255.255.0.0 U 1002 0 0 eth0default 172.31.255.253 0.0.0.0 UG 0 0 0 eth0# 删除网络路由[root@iZm5ehzqow4ijp2ya2g2drZ etc]# route del -net 10.20.30.40 netmask 255.255.255.248 eth0[root@iZm5ehzqow4ijp2ya2g2drZ etc]# routeKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface172.31.240.0 * 255.255.240.0 U 0 0 0 eth0link-local * 255.255.0.0 U 1002 0 0 eth0default 172.31.255.253 0.0.0.0 UG 0 0 0 eth0 修改网关地址如果我们要修改默认网关，需要先把网关删除，然后再进行添加 使用示例： 将 169.254.0.0 的默认网关修改为 192.168.1.2 1234567891011121314151617181920212223[root@iZm5ehzqow4ijp2ya2g2drZ etc]# route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface192.168.1.2 0.0.0.0 255.255.255.255 UH 0 0 0 eth0172.31.240.0 0.0.0.0 255.255.240.0 U 0 0 0 eth0169.254.0.0 0.0.0.0 255.255.0.0 U 1002 0 0 eth00.0.0.0 169.254.0.0 0.0.0.0 UG 0 0 0 eth00.0.0.0 172.31.255.253 0.0.0.0 UG 0 0 0 eth0# 先删除[root@iZm5ehzqow4ijp2ya2g2drZ etc]# route del -net default gw 169.254.0.0# 然后添加[root@iZm5ehzqow4ijp2ya2g2drZ etc]# route add default gw 192.168.1.2[root@iZm5ehzqow4ijp2ya2g2drZ etc]# route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface192.168.1.2 0.0.0.0 255.255.255.255 UH 0 0 0 eth0172.31.240.0 0.0.0.0 255.255.240.0 U 0 0 0 eth0169.254.0.0 0.0.0.0 255.255.0.0 U 1002 0 0 eth00.0.0.0 192.168.1.2 0.0.0.0 UG 0 0 0 eth00.0.0.0 172.31.255.253 0.0.0.0 UG 0 0 0 eth0","categories":[{"name":"Linux","slug":"Linux","permalink":"https://jjw-story.github.io/categories/Linux/"}],"tags":[{"name":"command","slug":"command","permalink":"https://jjw-story.github.io/tags/command/"},{"name":"网络管理","slug":"网络管理","permalink":"https://jjw-story.github.io/tags/网络管理/"}],"author":"JJW"},{"title":"Djongo-03","slug":"Djongo-03","date":"2019-08-11T05:30:43.000Z","updated":"2019-08-11T12:01:02.866Z","comments":true,"path":"2019/08/11/Djongo-03/","link":"","permalink":"https://jjw-story.github.io/2019/08/11/Djongo-03/","excerpt":"","text":"通用视图通用视图介绍通用视图把视图开发中常用的写法和模式抽象出来，让你编写少量代码就能快速实现常见的数据视图。显示对象列表就是这样一种任务。 有了通用视图，可以把模型作为额外的参数传给 URL 配置。Django 自带的通用视图能实现下述功能： 列出对象并显示单个对象的详细信息。如果创建一个管理会议的应用程序，那么TalkListView 和RegisteredUserListView就是列表视图。某一个演讲的页面就是详细信息视图。 呈现基于日期的对象，显示为年月日归档页面（带有详细信息），以及“最新”页面。 让用户创建、更新和删除对象——需不需要授权都行。 具体使用示例及说明示例展示的是一个查询出所有厂家及根据URl中传入的厂家名称查询出此厂家生产的所有商品的示例： 视图函数如下(在项目view.py下定义)： 12345678910111213141516171819202122232425262728293031323334353637from cerealsOils.models import Manufacturers, Productfrom django.views.generic import ListViewfrom django.shortcuts import get_object_or_404# Create your views here.# 定义通用视图class ManufacturersList(ListView): # 注意此行代码表示：其实是queryset = Publisher.objects.all() 的简洁形式。 # model = Manufacturers # 动态过滤 # 根据 URL 中指定的键过滤列表页面中的对象 # 我们可以覆盖ListView 的 get_queryset() 方法。它的默认实现是返回queryset 属性的值，不过我们可以添加更多逻辑 # 这里根据url中传入的厂家名称，过滤出指定厂家生产的产品 def get_queryset(self): # 获取到GET请求捕获到的参数 self.manu = get_object_or_404(Manufacturers, name=self.args[0]) # 过滤 return Product.objects.filter(manufacturers=self.manu) # 提供“友好的”模板上下文，如果我们不自已定义模板上下文名称，默认会将上述查询结果存储在名为 object_list 的变量中 # 现在我们将它存储在 manu_list 变量中 context_object_name = &quot;product_list&quot; # 自定义了模板名称，既指定使用的模板 # 如果没明确指定，Django 将从对象的名称中推知。这里，推知的模板是cerealsOils/manufacturers_list.html template_name = &apos;manu_list.html&apos; # 提供额外的上下文变量 # 就是扩展DetailView，自己实现get_context_data 方法，然后在此方法提供额外的数据 # 这里查询出所有的厂家返回给页面 def get_context_data(self, **kwargs): # 先调用原来的实现，获取上下文 context = super(ManufacturersList, self).get_context_data(**kwargs) # 查询出所有的产品 context[&apos;manu_list&apos;] = Manufacturers.objects.all() return context url定义如下： 1234urlpatterns = [ # 注意 as_view() 函数 url(r&apos;^manulist/([\\w-]+)$&apos;, views.ManufacturersList.as_view())] 模板代码如下： 1234567891011121314151617181920&lt;!DOCTYPE HTML PUBLIC &quot;-//W3C//DTD HTML 4.01//EN&quot;&gt;&lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;meta charset=&apos;UTF-8&apos;&gt; &lt;title&gt;通用视图测试&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;厂家名称&lt;/h1&gt; &#123;% for manu in manu_list %&#125; &lt;li&gt;&#123;&#123; manu.name &#125;&#125;&lt;/li&gt; &#123;% endfor %&#125; &lt;hr&gt; &lt;h1&gt;产品名称&lt;/h1&gt; &#123;% for prod in product_list %&#125; &lt;li&gt;&#123;&#123; prod.title &#125;&#125;&lt;/li&gt; &#123;% endfor %&#125; &lt;hr&gt; &lt;p&gt;谢谢光临&lt;/p&gt; &lt;/body&gt;&lt;/html&gt; 以上便是通用视图的实现，是不是很方便呢！","categories":[{"name":"Python","slug":"Python","permalink":"https://jjw-story.github.io/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://jjw-story.github.io/tags/Python/"},{"name":"Django","slug":"Django","permalink":"https://jjw-story.github.io/tags/Django/"}],"author":"JJW"},{"title":"网络状态查看","slug":"网络状态查看","date":"2019-08-08T12:20:20.000Z","updated":"2019-08-03T11:13:31.476Z","comments":true,"path":"2019/08/08/网络状态查看/","link":"","permalink":"https://jjw-story.github.io/2019/08/08/网络状态查看/","excerpt":"","text":"网络状态查看网络状态查看我们列举两套工具包，一套是net-tools，一套是iproute或者有时候也叫iproute2 使用两套工具的作用是，在CentOS7以前，我们一般使用的都是net-tools工具包，而在CentOS7以后，主推的使用iproute工具包 ifconfig查看网络状态既网卡状态，使用方法：ifconfig [网卡名称] 注意网卡名称是可选的，管理用户直接输入命令，普通用户需要 /sbin/ifconfig(注意普通用户需要加上命令的完整路径) 一般使用此命令查询出来的结果中，会显示etho，第一块网卡的状态信息，这个名字是默认的，但是有可能我们查询出来不叫这个名字，这是因为在CentOS7中使用了一致性网络设备命名，它会先去检测我们的网卡，检测后具体命名如下： en01 板载网卡 ens33 PCI-E网卡 enp0s3 无法获取物理信息的PCI-E网卡 eth0 如果以上都获取不到，会使用此命名 使用示例： 123456789101112131415161718wangjia3@CHJ-20190520VPS:~$ ifconfigeth3: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 172.31.34.113 netmask 255.255.255.240 broadcast 172.31.34.127 inet6 fe80::4c47:3429:b72c:5130 prefixlen 64 scopeid 0x0&lt;global&gt; ether 7e:15:d8:27:73:38 (Ethernet) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt; mtu 1500 inet 127.0.0.1 netmask 255.0.0.0 inet6 ::1 prefixlen 128 scopeid 0x0&lt;global&gt; loop (Local Loopback) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 我们还可以使用命令：ifconfig 网卡名称 来查看指定网卡，例如我们只查看lo网卡的信息： 以上查询结果我们需要关注的是： etho信息中的 inet选项，第一个参数addr是IP信息，Mask参数对应的是子网掩码，还要注意 有个 ether参数，它显示的是mac地址，RX、TX：发送数据包的个数及多少 lo网卡信息中：lo网卡表示的是本地环回，它的地址永远是127.0.0.1，这个网卡的作用就是我们在自己本地搭建了一个服务，在我们访问自己主机服务的时候，就使用这个IP 123456789wangjia3@CHJ-20190520VPS:~$ ifconfig lolo: flags=73&lt;UP,LOOPBACK,RUNNING&gt; mtu 1500 inet 127.0.0.1 netmask 255.0.0.0 inet6 ::1 prefixlen 128 scopeid 0x0&lt;global&gt; loop (Local Loopback) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 修改网卡名称有时候我们在管理Linux网卡的时候，可能会有很多机器，我们需要写一个通用的脚本来修改，但是我们多个机器的网卡名称不一样，那么我们就需要手动的修改网卡的名称，来保证多个机器的网卡名称保持一致，这样能便于管理，下面我们介绍的就是修改网卡名称的方法，分为两步： 第一步： 网卡命名规则受 biosdevname和net.ifnames两个参数影响，这两个参数我们需要编辑 /etc/defult/grub 文件来修改，为此文件增加如下两个参数： biosdevname=0 net.ifnames=0 第二步： 更新grup，上述编辑好的文件并不会在系统启动的时候被读取到，所以我们需要将上述文件转化为系统启动可读取的文件，使用命令： grub2-mkconfig -o /boot/grup2/grup.cfg 第三步： 重启，重启命令是reboot，重启完成之后，网卡名称就变成了 eth0 biosdevname和net.ifnames组合明细： 序列 biosdevname net.ifnames 网卡名 默认 0 1 ens33 组合1 1 0 em1 组合2 0 0 eth0 查看网卡物理连接情况查看网卡物理连接情况，比如查看网线是否连接好，Windows可以直接通过图形界面来查看，Linux需要用过命令来查看 mii-tool命令 使用方法：mii-tool [网卡名称] 注意CentOS7及以上使用此命令，网卡名称是必须要有的 12345678910111213141516root@CHJ-20190520VPS:/# mii-toolNo interface specifiedusage: mii-tool [-VvRrwl] [-A media,... | -F media] [-p addr] &lt;interface ...&gt; -V, --version display version information -v, --verbose more verbose output -R, --reset reset MII to poweron state -r, --restart restart autonegotiation -w, --watch monitor for link status changes -l, --log with -w, write events to syslog -A, --advertise=media,... advertise only specified media -F, --force=media force specified media technology -p, --phy=addr set PHY (MII address) to reportmedia: 1000baseTx-HD, 1000baseTx-FD, 100baseT4, 100baseTx-FD, 100baseTx-HD, 10baseT-FD, 10baseT-HD, (to advertise both HD and FD) 1000baseTx, 100baseTx, 10base 也可以使用：ethtool命令 使用方法：ethtool 网卡名称 123[root@iZm5ehzqow4ijp2ya2g2drZ etc]# ethtool eth0Settings for eth0: Link detected: ye 查看网关命令当我们机器需要网络通信的时候，需要连接其它的网络地址范围的时候，我们就需要配置网关，也叫配置路由 使用route命令来查看网关，使用方法：route [参数] 参数：-n 如果我们单独只用route命令时，默认使用时每一个IP都会反解成主机名，这个过程很慢，所以可以使用此参数可以不解析主机名 使用示例： 12345678910111213[root@iZm5ehzqow4ijp2ya2g2drZ etc]# routeKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface172.31.240.0 * 255.255.240.0 U 0 0 0 eth0link-local * 255.255.0.0 U 1002 0 0 eth0default 172.31.255.253 0.0.0.0 UG 0 0 0 eth0[root@iZm5ehzqow4ijp2ya2g2drZ etc]# route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface172.31.240.0 0.0.0.0 255.255.240.0 U 0 0 0 eth0169.254.0.0 0.0.0.0 255.255.0.0 U 1002 0 0 eth00.0.0.0 172.31.255.253 0.0.0.0 UG 0 0 0 eth0 输出项说明： 输出项 说明 Destination 目标网段或者主机 Gateway 网关地址，”*” 表示目标是本主机所属的网络，不需要路由 Genmask 网络掩码 Flags 标记。一些可能的标记如下： - U — 路由是活动的 - H — 目标是一个主机 - G — 路由指向默认网关 - R — 恢复动态路由产生的表项 - D — 由路由的后台程序动态地安装 - M — 由路由的后台程序修改 - ! — 拒绝路由 Metric 路由距离，到达指定网络所需的中转数（linux 内核中没有使用） Ref 路由项引用次数（linux 内核中没有使用） Use 此路由项被路由软件查找的次数 Iface 该路由表项对应的输出接口 主机路由：主机路由是路由选择表中指向单个IP地址或主机名的路由记录。主机路由的Flags字段为H。例如，在下面的示例中，本地主机通过IP地址192.168.1.1的路由器到达IP地址为10.0.0.10的主机 12Destination Gateway Genmask Flags Metric Ref Use Iface10.0.0.10 192.168.1.1 255.255.240.0 UH 0 0 0 eth0 网络路由：网络路由是代表主机可以到达的网络。网络路由的Flags字段为N。例如，在下面的示例中，本地主机将发送到网络192.19.12.20的数据包转发到IP地址为192.168.1.1的路由器 12Destination Gateway Genmask Flags Metric Ref Use Iface192.19.12.20 192.168.1.1 255.255.240.0 UN 0 0 0 eth0 默认路由：当主机不能在路由表中查找到目标主机的IP地址或网络路由时，数据包就被发送到默认路由（默认网关）上。默认路由的Flags字段为G。例如，在下面的示例中，默认路由是IP地址为192.168.1.1的路由器 12Destination Gateway Genmask Flags Metric Ref Use Ifacedefault 192.168.1.1 0.0.0.0 UG 0 0 0 eth0","categories":[{"name":"Linux","slug":"Linux","permalink":"https://jjw-story.github.io/categories/Linux/"}],"tags":[{"name":"command","slug":"command","permalink":"https://jjw-story.github.io/tags/command/"},{"name":"网络管理","slug":"网络管理","permalink":"https://jjw-story.github.io/tags/网络管理/"}],"author":"JJW"},{"title":"Django-02","slug":"Django-02","date":"2019-08-04T02:31:02.000Z","updated":"2019-08-11T05:40:34.779Z","comments":true,"path":"2019/08/04/Django-02/","link":"","permalink":"https://jjw-story.github.io/2019/08/04/Django-02/","excerpt":"","text":"Djongo表单从请求对象中获取数据 属性 方法说明 示例 request.path 完整的路径，不含域名，但是含前导斜线 “/hello/” request.get_host() 主机名（即通常所说的“域名”） “127.0.0.1:8000”或“www.example.com” request.get_full_path() 包含查询字符串（如果有的话）的路径 “/hello/?print=true” request.is_secure() 通过 HTTPS 访问时为True，否则为False True 或False request.META[‘HTTP_USER_AGENT’] 入站前的 URL（可能没有） request.META[‘HTTP_USER_AGENT’] 浏览器的用户代理（可能没有），请求头信息 “Mozilla/5.0 (X11; U; Linux i686; fr-FR; rv:1.8.1.17) Gecko/20080829 Firefox/2.0.0.17” request.META[‘REMOTE_ADDR’] 客户端的 IP 地址 “12.345.67.89”。（如果请求经由代理，这个首部的值可能是一组 IP 地址，以逗号分隔） 简单的表单使用示例这里可以打开页面及项目代码为大家演示 视图函数如下： 123456789101112131415161718192021222324from django.shortcuts import renderfrom django.http import HttpResponsefrom cerealsOils.models import Product# Create your views here.def product_search(request): return render(request, &apos;product_search.html&apos;)def search(request): errors = [] if &apos;q&apos; in request.GET : # 通过request对象直接获取传统get请求的参数： q=xxx if ( request.GET[&apos;q&apos;]) : # 判断表单q参数是否为空 q = request.GET[&apos;q&apos;] if len(q) &gt; 5 : errors.append(&quot;查询关键字不能超过五个字符&quot;) else : products = Product.objects.filter(title__contains=q) # 过滤查询 # name = products[0].vender[0] return render(request, &apos;product_search.html&apos;, &#123;&apos;products&apos;: products, &apos;query&apos;: q&#125;) else : # products = Product.objects.all() # 查询所有 errors.append(&quot;查询关键字不能为空&quot;) return render(request, &apos;product_search.html&apos;, &#123;&apos;errors&apos;:errors&#125;) URL配置如下： 12url(r&apos;^product_search/$&apos;, views.product_search), # 查询页面跳转url(r&apos;^search/$&apos;, views.search), # 查询控制层 product_search模板如下： 1234567891011121314151617181920212223242526272829303132&lt;html&gt; &lt;head&gt; &lt;title&gt;产品查询&lt;/title&gt; &lt;meta charset=&apos;UTF-8&apos;&gt; &lt;/head&gt; &lt;body&gt; &#123;% if errors %&#125; &lt;ul&gt; &#123;% for error in errors %&#125; &lt;li&gt;&#123;&#123; error &#125;&#125;&lt;/li&gt; &#123;% endfor %&#125; &lt;/ul&gt; &#123;% endif %&#125; &lt;!-- &lt;form action=&quot;/search/&quot; method=&quot;get&quot;&gt; --&gt; &lt;form action=&quot;/search/&quot; method=&quot;get&quot;&gt; &lt;input type=&quot;text&quot; name=&quot;q&quot;&gt; &lt;input type=&quot;submit&quot; value=&quot;Search&quot;&gt; &lt;/form&gt; &lt;p&gt;查询关键字: &lt;strong&gt;&#123;&#123; query &#125;&#125;&lt;/strong&gt;&lt;/p&gt; &#123;% if products %&#125; &lt;p&gt;产品总数 &#123;&#123; products|length &#125;&#125; 产品&#123;&#123; books|pluralize &#125;&#125;&lt;/p&gt; &lt;ul&gt; &#123;% for product in products %&#125; &lt;li&gt;产品名称：&#123;&#123; product.title &#125;&#125; 生产日期：&#123;&#123; product.product_date &#125;&#125;&lt;/li&gt; &#123;% endfor %&#125; &lt;/ul&gt; &#123;% else %&#125; &lt;p&gt;没有查询到商品&lt;/p&gt; &#123;% endif %&#125; &lt;/body&gt;&lt;/html&gt; 这样就完成了一个表单的使用示例 联系表单Django 自带了一个表单库，django.forms，它能处理从显示 HTML 表单到验证。 这个表单框架的主要用法是为要处理的每个 HTML 表单定义一个Form 类，这个类可以放在任意位置，例如直接放在views.py 文件中，不过社区的约定是，把Form 类放在单独的forms.py 文件中。 下面对表单框架的各部分功能以及自定义校验规则等进行示例： 在views.py 文件所在的目录（mysite）中创建这个文件，然后输入下述内容： 12345678910111213141516# 引入框架的表单库from django import formsclass ContactForm(forms.Form): subject = forms.CharField(max_length=20, min_length=2) # 校验长度 email = forms.EmailField(required=False) # 选项表示表单内容非必填 message = forms.CharField(widget=forms.Textarea) # 可以直接设置表单样式，注意表单样式设置也可以很灵活，使用时具体查看资料 # 自定义校验规则 # 注意校验方法名，需要以clean_开头，字段名称为结尾 # 再检查此规则前定义字段时设置的校验规则已经校验完毕 def clean_message(self): message = self.cleaned_data[&apos;message&apos;] if &quot;香港&quot; in message: raise forms.ValidationError(&quot;消息内容不能包含敏感词&quot;) return message # 一定要显式的返回清理后的值，cleaned_data是清理值 定义视图函数： 1234567891011121314151617def contact(request): if request.method == &apos;POST&apos;: form = ContactForm(request.POST) # Post请求体接受为form表单对象，这点类似于mvc if form.is_valid(): # 校验表单输入是否符合定义的校验规则 cd = form.cleaned_data send_mail( cd[&apos;subject&apos;], cd[&apos;message&apos;], cd.get(&apos;email&apos;, &apos;noreply@example.com&apos;), [&apos;siteowner@example.com&apos;], ) return HttpResponseRedirect(&apos;/contact/thanks/&apos;) else: form = ContactForm( initial=&#123;&apos;subject&apos;: &apos;默认值&apos;&#125; # 设置form表单默认值 ) return render(request, &apos;test/contact_form.html&apos;, &#123;&apos;form&apos;: form&#125;) 定义模板文件： 123456789101112131415161718192021222324252627282930313233&lt;html&gt; &lt;head&gt; &lt;title&gt;联系表单&lt;/title&gt; &lt;meta charset=&apos;UTF-8&apos;&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;表单测试&lt;/h1&gt; &#123;% if form.errors %&#125; &lt;!-- 接受表单对象数据 --&gt; &lt;p style=&quot;color: red;&quot;&gt; 请处理表单错误内容&#123;&#123; form.errors|pluralize &#125;&#125; &lt;/p&gt; &#123;% endif %&#125; &lt;form action=&quot;&quot; method=&quot;post&quot;&gt; &lt;div class=&quot;field&quot;&gt; &#123;&#123; form.subject.errors &#125;&#125; &lt;label for=&quot;id_subject&quot;&gt;科目:&lt;/label&gt; &#123;&#123; form.subject &#125;&#125; &lt;/div&gt; &lt;div class=&quot;field&quot;&gt; &#123;&#123; form.email.errors &#125;&#125; &lt;label for=&quot;id_email&quot;&gt;输入您的邮箱:&lt;/label&gt; &#123;&#123; form.email &#125;&#125; &lt;/div&gt; &lt;div class=&quot;field&quot;&gt; &#123;&#123; form.message.errors &#125;&#125; &lt;label for=&quot;id_message&quot;&gt;消息内容:&lt;/label&gt; &#123;&#123; form.message &#125;&#125; &lt;/div&gt; &#123;% csrf_token %&#125; &lt;!-- 跨域处理 --&gt; &lt;input type=&quot;submit&quot; value=&quot;提交&quot;&gt; &lt;/form&gt; &lt;/body&gt;&lt;/html&gt; 至此一个联系表单就创建完成了 高级视图和URL简化导入函数方式简化导入函数方式就是说我们直接导入views 模块自身，如下示例： 123456# 直接导入viewfrom cerealsOils import viewsurlpatterns = [ url(r&apos;^product_search/$&apos;, views.product_search), # 查询页面跳转 url(r&apos;^search/$&apos;, views.search), # 查询控制层 具名分组（Python具名函数的使用）正则表达式分组（通过括号实现）捕获 URL 中的片段， 123456urlpatterns = [ url(r&apos;^reviews/2003/$&apos;, views.special_case_2003), url(r&apos;^reviews/([0-9]&#123;4&#125;)/$&apos;, views.year_archive), url(r&apos;^reviews/([0-9]&#123;4&#125;)/([0-9]&#123;2&#125;)/$&apos;, views.month_archive), url(r&apos;^reviews/([0-9]&#123;4&#125;)/([0-9]&#123;2&#125;)/([0-9]+)/$&apos;, views.review_detail),] 如上捕获参数时，我们可以通过具名分组，为参数赋予名称： 123456urlpatterns = [ url(r&apos;^reviews/2003/$&apos;, views.special_case_2003), url(r&apos;^reviews/(?P&lt;year&gt;[0-9]&#123;4&#125;)/$&apos;, views.year_archive), url(r&apos;^reviews/(?P&lt;year&gt;[0-9]&#123;4&#125;)/(?P&lt;month&gt;[0-9]&#123;2&#125;)/$&apos;, views.month_archive), url(r&apos;^reviews/(?P&lt;year&gt;[0-9]&#123;4&#125;)/(?P&lt;month&gt;[0-9]&#123;2&#125;)/(?P&lt;day&gt;[0-9]&#123;2&#125;)/$&apos;,views.review_detail),] 如上示例含义如下： 对/reviews/2005/03/ 的请求调用views.month_archive(request, year=’2005’, month=’03’) 函数，而不是views.month_archive(request,’2005’,’03’)。 对/reviews/2003/03/03/ 的请求调用views.review_detail(request, year=’2003’, month=’03’,day=’03’) 函数。 匹配/分组算法URL 配置解析器解析正则表达式中具名分组和非具名分组所采用的算法如下： 如果有具名分组，使用具名分组，忽略非具名分组。 否则，以位置参数传递所有非具名分组。 不论如何，额外的关键字参数都会传给视图。 URL及视图一些特性 注意url的匹配规则，它不区分请求的类型，例如GET POST等，只要url一样，都交给同一个视图函数处理。 不管正则表达式匹配的是什么类型，捕获的每个参数都以普通的 Python 字符串传给视图。 例如： 1url(r&apos;^reviews/(?P&lt;year&gt;[0-9]&#123;4&#125;)/$&apos;, views.year_archive) 虽然[0-9]{4} 只匹配字符串中的整数，但是传给views.year_archive() 视图函数的year 参数是字符串，而不是整数。 可以为视图函数的参数指定默认值(利用的也是Python函数的特性) 例如： 12345678urlpatterns = [ url(r&apos;^reviews/$&apos;, views.page), # 使用默认参数 url(r&apos;^reviews/page(?P&lt;num&gt;[0-9]+)/$&apos;, views.page), # 这里有传值，不使用默认参数]# 视图（在 reviews/views.py 文件中）def page(request, num=&quot;1&quot;):# 输出指定数量的书评 性能问题：urlpatterns 中的每个正则表达式在首次访问时编译，因此系统的速度异常得快。 引入其他URl配置urlpatterns 在任何位置都可以“引入”其他 URL 配置模块。通过这一行为可以把一些 URL 放在另一些名下。 例如： 123456urlpatterns = [ # ... url(r&apos;^community/&apos;, include(&apos;django_website.aggregator.urls&apos;)), url(r&apos;^contact/&apos;, include(&apos;django_website.contact.urls&apos;)), # ...] 注意，这里的正则表达式没有$（匹配字符串末尾的符号），但是末尾有斜线。Django 遇到include() 时，会把截至那一位置匹配的 URL 截断，把余下的字符串传给引入它的 URL 配置，做进一步处理。 可以利用这一点将公共的路径提取出来，示例如下： 1234567891011注意，url的配置可以抽取共性配置urlpatterns = [ url(r&apos;^chehejia/&apos;, include([ # 引入 ，引入可以引入其他URL配置模块，这里是写死的，还可以写成引入 xxx，其中xxx指的是 .py 文件，此文件中也有urlpatterns变量定义了url映射。 可以根据url的全路径匹配到引入模块的映射函数 url(r&apos;^add/$&apos;, views.add), url(r&apos;^edit/$&apos;, views.edit), url(r&apos;^delete/$&apos;, views.delete), url(r&apos;^save/$&apos;, views.save), ]) ),] 注意：通过此方式引入的URl配置，我们在父URl中使用正则捕获到的参数，是可以传递给子URl视图函数的，所以可以放心使用 传递额外参数URL 配置允许向视图函数传递额外的参数，这些参数放在一个 Python 字典中。django.conf.urls.url() 函数的第三个参数是可选的，如果指定，应该是一个字典，指定要传给视图函数的额外关键字参数及其值。 例如： 12345urlpatterns = [ url(r&apos;^reviews/(?P&lt;year&gt;[0-9]&#123;4&#125;)/$&apos;, views.year_archive, &#123;&apos;foo&apos;: &apos;bar&apos;&#125; # 具名分组及设置默认参数 ),] 同样include()也同样适用此特性： 1234567891011# main.pyfrom django.conf.urls import include, url urlpatterns = [ url(r&apos;^reviews/&apos;, include(&apos;inner&apos;), &#123;&apos;reviewid&apos;: 3&#125;),]# inner.pyurlpatterns = [ url(r&apos;^archive/$&apos;, views.archive), url(r&apos;^about/$&apos;, views.about),] 反向解析URl这个不太明白，我认为就是转发请求的时候使用，注意讨论一下 Django 提供了一种方案，只需在 URL 映射中设计 URL。我们为其提供 URL 配置，然后可以双向使用： 从用户（浏览器）请求的 URL 开始，这个方案能调用正确的 Django 视图，并从 URL 中提取可能需要的参数及其值，传给视图。 从 Django 视图对应的标识以及可能传入的参数值开始，获取相应的 URL。 第一点就是我们目前所讨论的处理方式。第二点称为反向解析 URL、反向匹配 URL、反向查找 URL 或 URL反转。 Django 在不同的层中提供了执行 URL 反转所需的工具： 在模板中，使用url 模板标签。 在 Python 代码中，使用django.core.urlresolvers.reverse() 函数。 在处理 Django 模型实例 URL 相关的高层代码中，使用get_absolute_url() 方法。 示例： 123456789101112131415161718192021# URl描述urlpatterns = [ url(r&apos;^reviews/([0-9]&#123;4&#125;)/$&apos;, views.year_archive, name=&apos;reviews-year-archive&apos;),]# 模板中如下描述&lt;ul&gt; &#123;% for yearvar in year_list %&#125; &lt;li&gt;&lt;a href=&quot;&#123;% url &apos;reviews-year-archive&apos; yearvar %&#125;&quot;&gt;&#123;&#123; yearvar &#125;&#125; Archive&lt;/a&gt;&lt;/li&gt; &#123;% endfor %&#125;&lt;/ul&gt;# 视图函数如下from django.core.urlresolvers import reversefrom django.http import HttpResponseRedirectdef redirect_to_year(request): # ... year = 2012 # ... return HttpResponseRedirect(reverse(&apos;reviews-year-archive&apos;, args=(year,))) URl命名空间URL 命名空间在反转具名 URL 模式时具有唯一确定性，即便不同的应用使用相同的名称也不怕。 正确使用 URL 命名空间的 Django 应用程序可以在同一个网站中多次部署。例如，django.contrib.admin 中有个AdminSite 类，可以轻易部署多个管理后台。URL 命名空间分为两部分，而且都是字符串： 应用命名空间。指明应用的名称。一个应用的每个实例都具有相同的应用命名空间。例如，你可能猜到了，Django 管理后台的应用命名空间是admin。 实例命名空间。标识具体的应用程序实例。实例命名空间在整个项目范围内应该是唯一的。不过，实例命名空间可以与应用命名空间相同，供应用的默认实例使用。例如，Django 管理后台实例的默认实例命名空间是admin 命名空间中的 URL 使用: 运算符指定。例如，管理后台的主页使用 admin:index 引用。其中，admin 是命名空间，index 是 URL 的名称。 命名空间还可以嵌套。members:reviews:index 在命名空间members 中查找命名空间reviews，再在里面查找index URL。 反转命名空间的URl的步骤 首先，Django 查找有没有匹配的应用命名空间（这里的reviews）。为此，会产出那个应用的实例列表。 如果有这么一个应用实例，Django 返回它的 URL 解析程序。当前应用可以通过请求的一个属性指定。预期有多个部署实例的应用应该在处理的请求上设定current_app 属性。 当前应用也可以手动指定，方法是作为参数传给reverse() 函数。 如果没有当前应用，Django 查找默认的应用实例。默认应用实例是指实例命名空间与应用命名空间匹配的实例（在这里是指名为reviews 的reviews 实例）。 如果没有默认的应用实例，Django 选中最后部署的应用实例，而不管实例的名称。 如果第 1 步找不到匹配的应用命名空间，Django 直接把它视作实例命名空间查找。 URL 命名空间和引入的 URL 配置示例把引入的 URL 配置放入命名空间中有两种方式。 第一种，在 URL 模式中为include() 提供应用和实例命名空间： 1url(r&apos;^reviews/&apos;, include(&apos;reviews.urls&apos;, namespace=&apos;author-reviews&apos;, app_name=&apos;reviews&apos;)) 上述示例把reviews.urls 中定义的 URL 放在应用命名空间reviews 中，放在实例命名空间author-reviews中。 第二种，引入包含命名空间数据的对象。如果使用include() 引入一组url() 实例，那个对象中的 URL 都添加到全局命名空间中。然而，include() 的参数还可以是一个三元素元组： 123456reviews_patterns = [ url(r&apos;^$&apos;, views.IndexView.as_view(), name=&apos;index&apos;), url(r&apos;^(?P&lt;pk&gt;\\d+)/$&apos;, views.DetailView.as_view(), name=&apos;detail&apos;),]url(r&apos;^reviews/&apos;, include((reviews_patterns, &apos;reviews&apos;, &apos;author-reviews&apos;))), 上述示例把指定的 URL 模式引入指定的应用和实例命名空间中。 记得要把一个元组传给include()。如果直接传入三个参数，例如include(reviews_patterns, ‘reviews’,’author-reviews’)，Django 不会抛出错误，但是根据include() 的签名，’reviews’ 是实例命名空间，’author-reviews’ 是应用命名空间，而正确的顺序应该反过来。 高级模板技术RequestContext和上下文处理器模板要在上下文中渲染。上下文是django.template.Context 的实例，不过 Django 还提供了一个子类，django.template.RequestContext，其行为稍有不同。 RequestContext 默认为模板上下文添加很多变量，例如HttpRequest 对象或当前登录用户的信息，例如我们在视图函数中获取到的request对象，它就是Djongo为我们提供的上下文处理器，我们可以在此处理器中获取很多参数: 示例： 12345def view_1(request): # ... t = loader.get_template(&apos;template1.html&apos;) c = RequestContext(request, &#123;&apos;message&apos;: &apos;I am view 1.&apos;&#125;, processors=[custom_proc]) return t.render(c) 上下文处理器使用示例，提供公共的上下文处理器： 12345678910111213141516171819202122232425262728# 定义一个上下文处理器，提供 &apos;app&apos;、&apos;user&apos; 和 &apos;ip_address&apos;，可以在处理器中为多个请求提供共同的必要的上下文# 注意：上下文处理器必须返回一个字典# 自定义上下文处理器一般放在单独项目或者项目下的context_processors.py中def custom_proc(request): return &#123; &apos;app&apos;: &apos;我的上下文测试&apos;, &apos;user&apos;: request.user, &apos;ip_address&apos;: request.META[&apos;REMOTE_ADDR&apos;] &#125;# 引用上下文处理器直接返回给模板进行渲染# 注意processors函数的参数，第一个必须是request对象，第二个是可选的上下文处理器列表或元组def view_1(request): return render(request, &apos;template1.html&apos;, &#123;&apos;message&apos;: &apos;消息1&apos;&#125;, context_instance=RequestContext( request, processors=[custom_proc] ) )# 与上述一致，公用上下文处理器def view_2(request): return render(request, &apos;template2.html&apos;, &#123;&apos;message&apos;: &apos;消息2&apos;&#125;, context_instance=RequestContext( request, processors=[custom_proc] ) ) Djongo提供的上下文处理器在settings文件中，我们来逐一说明Djongo提供的上下文处理器 123456789101112131415161718192021222324252627282930313233343536&apos;OPTIONS&apos;: &#123; # 默认的处理器上下文 &apos;context_processors&apos;: [ # 启用这个处理器后，RequestContext 中将包含下面两个变量 # debug：True。可以在模板中测试是否在DEBUG 模式中。 # sql_queries：&#123;&apos;sql&apos;: …, &apos;time&apos;: …&#125; 字典构成的列表，表示处理请求的过程中执行的 SQL 查询及其用时。列表中的值按查询的执行顺序排列，在访问时惰性生成 &apos;django.template.context_processors.debug&apos;, # 启用这个处理器后，RequestContext 中将包含request 变量，它的值是当前的HttpRequest 对象 &apos;django.template.context_processors.request&apos;, # 启用此处理器后将包含： # user：auth.User 的实例，表示当前登录的用户（如未登录，是AnonymousUser 实例）。 # perms：django.contrib.auth.context_processors.PermWrapper 实例，表示当前登录用户拥有的权限。 &apos;django.contrib.auth.context_processors.auth&apos;, # 启用这个处理器后，RequestContext 中将包含下面两个变量： # messages：消息框架设定的消息列表（里面的值是字符串） # DEFAULT_MESSAGE_LEVELS：消息等级名称到数字值的映射 &apos;django.contrib.messages.context_processors.messages&apos;, # 非默认，启用后将包含： # LANGUAGES：LANGUAGES 设置的值 # LANGUAGE_CODE：如果request.LANGUAGE_CODE 存在，返回它的值；否则返回LANGUAGE_CODE 设置的值 # django.template.context_processors.i18n # 非默认，启用这个处理器后，RequestContext 中将包含MEDIA_URL 变量，提供MEDIA_URL 设置的值 # django.template.context_processors.media # 非默认，启用这个处理程序后，RequestContext 中将包含STATIC_URL 变量，提供STATIC_URL 设置的值 # jango.template.context_processors.static # 非默认，这个处理器添加一个令牌，供csrf_token 模板标签使用，用于防范跨站请求伪造，（暂时不清楚具体意思） # django.template.context_processors.csrf ],&#125;, 模板加载内部机制DIRS 选项告诉 Django 模板目录有哪些的方法是使用设置文件中TEMPLATES 设置的DIRS 选项，或者是Engine 的dirs 参数。这个选项的值是一个字符串列表，包含指向模板目录的完整路径： 123456789TEMPLATES = [ &#123; &apos;BACKEND&apos;: &apos;django.template.backends.django.DjangoTemplates&apos;, &apos;DIRS&apos;: [ &apos;/home/html/templates/lawrence.com&apos;, &apos;/home/html/templates/default&apos;, ], &#125;,] 模板可以放在任何位置，只要 Web 服务器有权限读取目录及里面的模板即可。模板的扩展名不限，可以是.html 或.txt，甚至可以没有。注意，这里的路径应该使用 Unix 风格的正斜线，即便在 Windows 中也是如此。 加载器类型说明123456789101112# 加载器# 默认使用 ilesystem.Loader 文件系统加载器，如果不设定DIRS 选项，这个加载器找不到任何模板。# DIRS 定义一个目录列表，模板引擎按顺序在里面查找模板源文件。# 当前设置表示在项目根目录中放一些主模板，模板目录不一定非得叫&apos;templates&apos;，可以自定义&apos;DIRS&apos;: [os.path.join(BASE_DIR, &apos;templates&apos;)],# 还有应用目录加载器 pp_directories.Loader# INSTALLED_APPS = [&apos;myproject.reviews&apos;, &apos;myproject.music&apos;]# 从文件系统中的 Django 应用里加载模板。这个加载器在INSTALLED_APPS 列出的各个应用中查找templates 子目录。如果找到，Django 在其中查找模板。# 这意味着，应用可以自带模板。通过这一行为，便于分发带默认模板的 Django 应用。例此加载器会在设置的文件夹中顺序的加载模板，最先找到的被加载，所以设置顺序很重要# 还有一些其他加载器，默认是禁用的，自行了解 Django模型的高级用法新增和修改对象save和create方法，如下： 12345678910111213141516m01 = Manufacturers(name=&apos;金龙鱼&apos;，address=&apos;铁岭&apos;, city=&apos;大连&apos;, province=&apos;沈阳&apos;, website=&apos;www.xmy.com&apos;)# save方法保存m01.save()# create方法保存m02 = Manufacturers.objects.create(name=&apos;金龙鱼&apos;，address=&apos;铁岭&apos;, city=&apos;大连&apos;, province=&apos;沈阳&apos;, website=&apos;www.xmy.com&apos;)# 当数据被保存后，及对象ID值是有的，直接再次调用save方法，就是修改对象，注意这里是全字段修改m02.name = &apos;鲁花&apos;m02.save()# 一个语句更新一个对象Manufacturers.objects.get(name=&apos;金龙鱼&apos;).save(city=&apos;黑龙江&apos;)# 一个语句中更新多条数据Manufacturers.objects.filter(name=&apos;金龙鱼&apos;).update(city=&apos;黑龙江&apos;) 查询数据all、filter、get方法等，如下： 1234567891011121314# 获取所有数据Manufacturers.objects.all()# 根据条件获取部分数据Manufacturers.objects.filter(name=&apos;金龙鱼&apos;)# 根据多个条件获取部分数据Manufacturers.objects.filter(name=&apos;金龙鱼&apos;, address=&apos;铁岭&apos;)# 类似SQL使用like语句过滤获取部分数据，字段加两个下划线，接containsManufacturers.objects.filter(name__contains=&apos;金&apos;)# 获取单个数据，此方法返回的就不是列表了，而是单条数据，如果查询出多条数据或者没有查询出数据，会抛出异常Manufacturers.objects.get(website=&apos;www.xmy.com&apos;) 排序数据order_by方法，具体如下： 12345678# 根据name排序，正向Manufacturers.objects.order_by(&apos;name&apos;)# 根据多个字段排序Manufacturers.objects.order_by(&apos;name&apos;, &apos;province&apos;)# 反向排序，方法是在字段名称前面加上“-”（减号）Manufacturers.objects.order_by(&apos;-name&apos;) 链式查找既过滤加排序，如下： 1Manufacturers.objects.filter(name=&apos;金龙鱼&apos;).order_by(&apos;-name&apos;) 切片数据及传统上理解的分页查找，如下： 12345# 返回查询出的第一条数据Manufacturers.objects.filter(name=&apos;金龙鱼&apos;)[0]# 分页查询，底层使用的是Mysql的Limit函数Manufacturers.objects.filter(name=&apos;金龙鱼&apos;)[0, 10] 删除数据delete方法，如下： 12345678# 删除一条数据Manufacturers.objects.get(name=&apos;金龙鱼&apos;).delete()# 删除多条数据Manufacturers.objects.filter(name=&apos;金龙鱼&apos;).delete()# 删除全部数据Manufacturers.objects.all().delete() 访问外键数据根据外键查询出关联的对象，如下： 123# 一对一关联manufacturers = Product.objects.get(title=&apos;小米&apos;).manufacturersmanufacturersName = Product.objects.get(title=&apos;小米&apos;).manufacturers.name 访问多对多数据多对多关联数据获取如下： 12345678910# 获取所有关联vender = Product.objects.get(title=&apos;小米&apos;).vender.all()# 过滤多对多数据vender = Product.objects.get(title=&apos;小米&apos;).vender.filter(name=&apos;供应商&apos;)# 反过来，查看经销商经销的所有产品，字段加 _setVender.objects.get(name=&apos;供应商&apos;).product_set.all()count = Product.vender.count() 管理器在Book.objects.all() 语句中，objects 是个特殊的属性，我们通过它查询数据库，这是模型的管理器（manager）。现在，我们要深入说明管理器的作用和用法。 添加额外的自定义管理器，修改模型如下： 123456789101112131415161718192021222324# 自定义模型管理器class MyProductManager(models.Manager): # 覆盖的get_queryset() 返回的是一个QuerySet 对象，它对应着我们管理器的all()方法 def get_queryset(self): return super(MyProductManager, self).get_queryset().filter(name=&apos;大米&apos;)# 产品class Product(models.Model): title = models.CharField(max_length=100, verbose_name=&apos;产品名称&apos;) vender = models.ManyToManyField(Vender, verbose_name=&apos;经销商&apos;) manufacturers = models.ForeignKey(Manufacturers, verbose_name=&apos;厂家&apos;) product_date = models.DateField(verbose_name=&apos;生产日期&apos;) # fields = (&apos;title&apos;, &apos;product_date&apos;, &apos;vender&apos;, &apos;manufacturers&apos;) # 我们明确地把objects 设为一个普通的Manager 示例，如若不然，唯一可用的管理器将是dahl_objects objects = models.Manager() # 默认的管理器 my_objects = MyProductManager() # 专门查询 产品名称为大米 的管理器 def __str__(self): return u&apos;%s %s&apos; % (self.title, self.product_date) # 任何模型都可以使用Meta 类指定多个针对所在模型的选项。 class Meta: ordering = [&apos;product_date&apos;] 下面是使用上述自定义管理器示例： 1234# get_queryset() 返回的是一个QuerySet 对象，因此可以在其上调用filter()、exclude() 和其他所有QuerySet 支持的方法Product.my_objects.all()Product.my_objects.filter(title=&apos;Matilda&apos;)Product.my_objects.count() 如果需要，我们可以在同一个模型上使用多个管理器。 模型方法模型方法就是为Model提供一些方法，我们调用这些方法的时候能处理一些我们想要的逻辑。 模型为我们自动提供的常用方法有如下： str()。这是 Python 的一个“魔法方法”，返回对象的 Unicode 表示形式。需要以普通的字符串显示模型实例时，Python 和 Django 会调用这个方法。尤其要注意，在交互式控制台或管理后台中显示对象调用的都是这个方法。这个方法一定要自定义，因为默认的实现没什么用。 get_absolute_url()。这个方法告诉 Django 如何计算一个对象的 URL。Django 在管理后台和需要生成对象的 URL 时调用这个方法。具有唯一标识的 URL 的对象都要定义这个方法。 模型方法大多可以被直接覆盖，最常见的就是覆盖str()方法 一下演示覆盖预定义的模型方法，是针对数据库执行行为来覆盖的，例如： 1234567891011# 定义Blog模型，覆盖它的save方法，如下定义某些情况下不允许保存class Blog(models.Model): name = models.CharField(max_length=100) tagline = models.TextField() def save(self, *args, **kwargs): if self.name == &quot;Yoko Ono&apos;s blog&quot;: return # Yoko 肯定不会开博客的！ else: super(Blog, self).save(*args, **kwargs) # 调用“真正的”save () 方法 执行原始SQL模型的查询 API 不够用时，可以编写原始 SQL。Django 为执行原始 SQL 查询提供了两种方式：使用Manager.raw() 执行，返回模型实例集合；或者完全不用模型层，直接执行自定义SQL 第一种方式执行示例： 123456789101112131415161718# 基本查询分页Product.objects.raw(&apos;SELECT * FROM CEREALSOILS_PRODUCT LIMIT 0, 5&apos;)# 当我们定义的模型字段名称与数据库字段名称不一致时，可以通过AS将字段对应起来Product.objects.raw(&apos;SELECT product_name as name FROM CEREALSOILS_PRODUCT&apos;)# 延期模型字段# 注意：指定查询字段的时候，必须要包含主键字段p = Product.objects.raw(&apos;SELECT id, title FROM CEREALSOILS_PRODUCT&apos;)title = p.title # 上述执行取出的数product_date = p.product_date # 又执行了一次SQL来取出的此字段的值# 为raw传递参数，注意，这里是防注入的用法，参数写在raw方法内才有防注入的作用# 注意：Djongo中的占位符是 %s ，而不是 ?# 查询中有 % ，则需要写两个 %title = &apos;大米&apos;pa = Product.objects.raw(&apos;SELECT * FROM CEREALSOILS_PRODUCT where title = %s&apos;, title)p9 = Product.objects.raw(&apos;SELECT * FROM cerealsOils_product where title like %s LIMIT 0, 5&apos;, [&apos;%米%&apos;]) 第二种方式执行示例： django.db.connection 对象表示默认的数据库连接。若想使用这个数据库连接，调用connection.cursor()，然后，调用cursor.execute(sql, [params]) 执行 SQL，再调用cursor.fetchone() 或cursor.fetchall() 返回所得的行。 12345678910111213141516171819202122232425262728293031323334353637from django.db import connectiondef my_custom_sql(self): cursor = connection.cursor() cursor.execute(&quot;UPDATE bar SET foo = 1 WHERE baz = %s&quot;, [self.baz]) cursor.execute(&quot;SELECT foo FROM bar WHERE baz = %s&quot;, [self.baz]) row = cursor.fetchone() return row# 当需要连接多个数据库时，可以获取指定的数据库连接cursor = connections[&apos;my_db_alias&apos;].cursor()# 连接和游标（类似于Java中 Try-with-resouce）with connection.cursor() as c: c.execute(...)等效于：c = connection.cursor()try: c.execute(...)finally: c.close()# 查询数据，只返回结果没有字段名称映射cursor = connection.cursor()cursor.execute(&quot;SELECT id, title FROM cerealsOils_product&quot;)row01 = cursor.fetchone()row02 = cursor.fetchone()print(row01)print(row02)# 查询数据，有字段名称映射cursor01 = connection.cursor()cursor01.execute(&quot;SELECT id, title FROM cerealsOils_product&quot;)desc = cursor01.descriptiondict(zip([col[0] for col in desc], row))for row in cursor01.fetchall(): print(row)","categories":[{"name":"Python","slug":"Python","permalink":"https://jjw-story.github.io/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://jjw-story.github.io/tags/Python/"},{"name":"Django","slug":"Django","permalink":"https://jjw-story.github.io/tags/Django/"}],"author":"JJW"},{"title":"Django-01","slug":"Django-01","date":"2019-08-04T02:31:02.000Z","updated":"2019-08-05T09:23:05.959Z","comments":true,"path":"2019/08/04/Django-01/","link":"","permalink":"https://jjw-story.github.io/2019/08/04/Django-01/","excerpt":"","text":"Djongo入门Djongo介绍Django是一个开放源代码的Web应用框架，由Python写成。采用了MTV的框架模式，即模型M，视图V和模版T。它最初是被开发来用于管理劳伦斯出版集团旗下的一些以新闻内容为主的网站的，即是CMS（内容管理系统）软件。并于2005年7月在BSD许可证下发布。这套框架是以比利时的吉普赛爵士吉他手Django Reinhardt来命名的。 Django是一个基于MVC构造的框架。但是在Django中，控制器接受用户输入的部分由框架自行处理，所以 Django 里更关注的是模型（Model）、模板(Template)和视图（Views），称为 MTV模式，各自职责如下： 层次 职责 模型（Model），即数据存取层 处理与数据相关的所有事务： 如何存取、如何验证有效性、包含哪些行为以及数据之间的关系等。 模板(Template)，即表现层 处理与表现相关的决定： 如何在页面或其他类型文档中进行显示。 视图（View），即业务逻辑层 存取模型及调取恰当模板的相关逻辑。模型与模板的桥梁 Django 框架的核心组件及设计哲学： 对象关系映射 (ORM,object-relational mapping)：以Python类形式定义你的数据模型，ORM将模型与关系数据库连接起来，你将得到一个非常容易使用的数据库API，同时你也可以在Django中使用原始的SQL语句。 URL 分派：使用正则表达式匹配URL，你可以设计任意的URL，没有框架的特定限定。像你喜欢的一样灵活。 模版系统：使用Django强大而可扩展的模板语言，可以分隔设计、内容和Python代码。并且具有可继承性。 表单处理：你可以方便的生成各种表单模型，实现表单的有效性检验。可以方便的从你定义的模型实例生成相应的表单。 Cache系统：可以挂在内存缓冲或其它的框架实现超级缓冲 －－ 实现你所需要的粒度。 会话(session)，用户登录与权限检查，快速开发用户会话功能。 国际化：内置国际化系统，方便开发出多种语言的网站。 自动化的管理界面：不需要你花大量的工作来创建人员管理和更新内容。Django自带一个ADMIN site,类似于内容管理系统 Djongo安装Djongo安装分为三步： 安装 Python 安装 Python 虚拟环境 安装 Django 第一步不在赘述，注意使用Python3及以上版本 第二步安装虚拟环境的目的是为了解决电脑中的软件相互依赖，每个程序都要依赖某些其他程序，而且要找到运行其他软件的设置（环境变量），编写新软件程序时，可能（经常）要修改其他软件所需的依赖或环境变量，这一步可能会导致各种问题，因此要避免。 Python 虚拟环境能解决这个问题。它把软件所需的全部依赖和环境变量包装到一个文件系统中，与电脑中的其他软件隔离开。 直接使用命令：pip install virtualenv 即可安装完成。 安装完成后执行命令：virtualenv env_mysite为我们自己的项目创建虚拟环境，注意env_mysite可以自定义，执行完成后我们发现在我们电脑家目录下就创建好了一个 \\env_mysite 的文件夹，virtualenv 创建了一个完整的 Python 安装，它与其他软件是隔离开的，因此开发项目时不会影响系统中的其他软件。 我们需要激活此虚拟环境，使用命令：env_mysite\\scripts\\activate，激活后我们就可以使用此虚拟环境。 第三步安装Djongo，直接在虚拟环境下执行命令：pip install django==1.8.13，即可安装Djongo1.8.13版本完成 新建Djongo项目在虚拟环境中执行django-admin startproject mysite，如果不使用虚拟环境，也可以自己找到项目位置，执行此命令创建项目。命令执行完成后我们看到Djongo为我们创建了如下文件： 1234567mysite/ manage.py mysite/ __init__.py settings.py urls.py wsgi.py 外层的mysite/ 根目录是项目的容器。这个目录的名称对 Django 没有什么作用，你可以根据喜好重命名。 manage.py 是一个命令行实用脚本，可以通过不同的方式与 Django 项目交互。 内部的mysite/ 目录是项目的 Python 包。导入这里面的内容时要使用目录的名称（如mysite.urls）。 mysite/init.py 是一个空文件，目的是让 Python 把这个目录识别为 Python 包。 mysite/settings.py 是 Django 项目的设置/配置。 mysite/urls.py 是 Django 项目的 URL 声明，即 Django 驱动的网站的“目录”。 mysite/wsgi.py 是兼容 WSGI 的 Web 服务器的入口点，用于伺服项目。 这里说明一下settings文件，这是整个项目的配置和设置，我们发现Djongo框架本身已经帮我们创建好了一些项目，这是为常见场景所做的约定，具体看INSTALLED_APPS的配置（这里打开项目为大家讲解一下此文件的配置内容）： 1234567891011# Application definition# 注意：此处添加自己开发的应用INSTALLED_APPS = ( &apos;django.contrib.admin&apos;, # 管理后天 &apos;django.contrib.auth&apos;, # 身份验证系统 &apos;django.contrib.contenttypes&apos;, # 内容类型框架 &apos;django.contrib.sessions&apos;, # 会话框架 &apos;django.contrib.messages&apos;, # 消息框架 &apos;django.contrib.staticfiles&apos;, # 管理静态文件的框架 &apos;cerealsOils&apos;, # 自己开发的应用) 使用这些项目我们需要在数据库中创建这些项目所需的表，执行命令即可自动创建：python manage.py migratehibernate框架，通过实体类上使用注解，自动创建表。 这样我们的项目就创建完成了，使用命令：python manage.py runserver 就可以启动项目啦，默认端口为8000，我们访问就可以看到主页了。 视图和URl配置创建视图函数创建视图需要在项目目录下新创建一个view.py文件，此文件中我们定义函数，返回给视图我们要展示的内容，如下： 12345678910111213141516171819202122232425# 从django.http 模块中导入HttpResponse 类。导入这个类是因为后面的代码要使用from django.http import HttpResponse# 视图函数，传入参数：jango.http.HttpRequest对象实例，注意此参数是视图函数必须的且是第一位的参数# 静态内容def hello(request): # 返回 Hello World 给response return HttpResponse(&quot;Hello World&quot;)# 动态内容def currentDatetime(request): now = datetime.datetime.now() html = &quot;现在时间： % now return HttpResponse(html)# 动态urldef timeAhead(request, offset): try: offset = int(offset) except ValueError: # 如果传给int() 函数的值不能转换成整数（如字符串&quot;foo&quot;），Python 会抛出ValueError 异常 raise Http404() dt = datetime.datetime.now() + datetime.timedelta(hours=offset) html = &quot;In %s hour(s), it will be %s.&quot; % (offset, dt) return HttpResponse(html) 配置URl若想把视图函数与特定的 URL 对应起来，要使用 URL 配置（URLconf）。URL 配置相当于 Django 驱动的网站的目录。简单来说，URL 配置把 URL 映射到相应的视图函数上，具体配置及说明如下： 12345678910111213141516171819# 从django.conf.urls 模块中导入两个函数：include，用于导入另一个 URL 配置模块；url，使用正则表达式模式匹配浏览器中的 URL，把它映射到 Django 项目中的某个模块上。from django.conf.urls import include, url# 从django.contrib 模块中导入admin 函数。这个函数传给include 函数，加载 Django 管理后台的 URLfrom django.contrib import admin# url实例列表urlpatterns = [ # 注意：正则表达式字符串前面的&apos;r&apos; 字符。它的目的是告诉 Python，那是“原始字符串”，不要解释里面的反斜线 # 第一个参数是模式匹配字符串（一个正则表达式，稍后说明），第二个参数是模式使用的视图函数 # url(r&apos;^$&apos;, index), # 为根地址指定一个 URL 模式 url(r&apos;^admin/&apos;, include(admin.site.urls)), # 静态类容 url(r&apos;^hello/$&apos;, hello), # ^ 和 $ 开头和结尾匹配模式 去掉hello就可以作为根地址 # 动态内容 url(r&apos;^nowTime/$&apos;, currentDatetime), # 动态URl，Django 的核心哲学之一是，URL 应该美观，既符合REST风格，这里能匹配time/plus/2 time/plus/20 url(r&apos;^time/plus/(\\d&#123;1,2&#125;)/$&apos;, timeAhead), # 正则匹配] 处理请求过程运行python manage.py runserver 命令时，manage.py 脚本在内层mysite 目录中寻找名为settings.py 的文件。这个文件中保存着当前 Django 项目的全部配置，各个配置的名称都是大写的，然后找到如下配置： 12# 指向URl配置文件，寻找URl详细配置ROOT_URLCONF = &apos;mysite.urls&apos; 找到匹配的模式之后，调用对应的视图函数，并把一个HttpRequest 对象作为第一个参数传给视图,视图函数必须返回一个HttpResponse 对象。 随后，余下的工作交给 Django 处理：把那个 Python 对象转换成正确的 Web 响应，并且提供合适的 HTTP 首部和主体（即网页的内容）。综上： 请求/hello/。 Django 查看ROOT_URLCONF 设置，找到根 URL 配置。 Django 比较 URL 配置中的各个 URL 模式，找到与/hello/ 匹配的那个。 如果找到匹配的模式，调用对应的视图函数。 视图函数返回一个HttpResponse 对象。 Django 把HttpResponse 对象转换成正确的 HTTP 响应，得到网页。 Djongo模板Django 模板是一些文本字符串，作用是把文档的表现与数据区分开。模板定义一些占位符和基本的逻辑（模板标签），规定如何显示文档。通常，模板用于生成 HTML，不过 Django 模板可以生成任何基于文本的格式。 变量和模板标签123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141* &#123;&#123; xxx &#125;&#125; 指定变量的值插入这里* &#123;% xxx %&#125; 模板标签，基本模板标签有如下 # 逻辑判断标签 # 注意，此示例中使用了 if elif else and not or 等逻辑判断语句，与python保持一致 # if标签中不能包含括号，如果需要使用括号判断，必须写成嵌套 if 标签语句 &#123;% if a1 and a2 %&#125; &lt;p&gt;a1为真并且a2为真，显示此内容&lt;/p&gt; &#123;% elif not a3 %&#125; &lt;p&gt; else if a3 为假，显示此内容，注意elif是可选标签&lt;/p&gt; &#123;% elif a4 or not a5 %&#125; &lt;p&gt; else if a4 为真，或者 a5 为假，显示此内容，注意elif是可选标签&lt;/p&gt; &#123;% else %&#125; &lt;p&gt; else显示此内容，注意else是可选标签&lt;/p&gt; &#123;% endif %&#125; # 迭代元素标签 # 正向迭代 &#123;% for item in item_list %&#125; &lt;li&gt;&#123;&#123; item &#125;&#125;&lt;/li&gt; &#123;% endfor %&#125; # 反向迭代 &#123;% for item in item_list reversed %&#125; &lt;li&gt;&#123;&#123; item &#125;&#125;&lt;/li&gt; &#123;% endfor %&#125; # 定义迭代列表为空的行为 &#123;% for item in item_list %&#125; &lt;p&gt;&#123;&#123; item &#125;&#125;&lt;/p&gt; &#123;% empty %&#125; &lt;p&gt;此处定义要迭代的元素为空的行为&lt;/p&gt; &#123;% endfor %&#125; # 获取迭代当前元素索引 &#123;% for item in item_list %&#125; &lt;p&gt;&#123;&#123; forloop.counter &#125;&#125;: forloop.counter表示当前元素索引&lt;/p&gt; &lt;p&gt;&#123;&#123; forloop.revcounter &#125;&#125;: forloop.revcounter表示剩余元素数量&lt;/p&gt; &#123;% if forloop.first %&#125; &lt;p&gt;forloop.first返回的是boolean，表示是否第一个元素&lt;/p&gt; &#123;% elif forloop.last %&#125; &lt;p&gt;forloop.last返回的也是boolean，表示是否最后一个元素&lt;/p&gt; &#123;% endif %&#125; &#123;% endfor %&#125; # 比较值相等标签 &#123;% ifequal A B %&#125; &lt;h1&gt;A 的值和 B 的值相等!&lt;/h1&gt; &#123;% else %&#125; &lt;h1&gt;A 的值和 B 的值不相等!&lt;/h1&gt; &#123;% endifequal %&#125; # 比较值不相等标签 &#123;% ifnotequal A &apos;JJW&apos; %&#125; &lt;h1&gt;A 的值不等于JJW!&lt;/h1&gt; &#123;% else %&#125; &lt;h1&gt;A 的值等于JJW!&lt;/h1&gt; &#123;% endifnotequal %&#125; # 模板注释 # 单行注释 &#123;# 这里是一个注释 #&#125; # 多行注释，comment标签 &#123;% comment %&#125; 第一行注释 第二行注释 &#123;% endcomment %&#125; # 过滤器 # 模板过滤器是在显示变量之前调整变量值的简单方式 # 把文本转换成小写，然后再显示 &#123;&#123; name|lower &#125;&#125; # 获取列表中的第一个元素，然后将其转换成大写 &#123;&#123; my_list|first|upper &#125;&#125; # 显示bio 变量的前 30 个词 &#123;&#123; bio|truncatewords:&quot;30&quot; &#125;&#125; # 在反斜线、单引号和双引号前面添加一个反斜线。可用于转义字符串 &#123;&#123; value|addslashes &#125;&#125; # 返回值长度，如果是列表，返回列表元素个数 &#123;&#123; name|length &#125;&#125; # include 模板标签 这个标签的作用是引入另一个模板的内容。它的参数是要引入的模板的名称，可以是变量，也可以是硬编码的字符串（放在引号里，单双引号都行） &#123;% include &apos;nav.html&apos; %&#125; &#123;% include &quot;nav.html&quot; %&#125; # 以下是使用示例 &lt;html&gt; &lt;body&gt; &#123;% include &quot;includes/nav.html&quot; %&#125; &lt;h1&gt;&#123;&#123; title &#125;&#125;&lt;/h1&gt; &lt;/body&gt; &lt;/html&gt; # includes/nav.html &lt;div id=&quot;nav&quot;&gt; You are in: &#123;&#123; current_section &#125;&#125; &lt;/div&gt; # 模板继承 # 模板继承是指创建一个基底“骨架”模板，包含网站的所有通用部分，并且定义一些“块”，让子模板覆盖。 # 首先定义一个基地模板 # &#123;% block xxx %&#125;&#123;% endblock %&#125; 表示此标签内容可以被子模板重写 &lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;title&gt;&#123;% block title %&#125;&#123;% endblock %&#125;&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;My helpful timestamp site&lt;/h1&gt; &#123;% block content %&#125;&#123;% endblock %&#125; &#123;% block footer %&#125; &lt;hr&gt; &lt;p&gt;Thanks for visiting my site.&lt;/p&gt; &#123;% endblock %&#125; &lt;/body&gt; &lt;/html&gt; # 然后定义子模板 # 子模板需要继承父模板 &#123;% extends &quot;base.html&quot; %&#125; # 重写依然要使用 &#123;% block xxx %&#125;&#123;% endblock %&#125; 标签 &#123;% extends &quot;base.html&quot; %&#125; &#123;% block title %&#125;Future time&#123;% endblock %&#125; &#123;% block content %&#125; &lt;p&gt; In &#123;&#123; hour_offset &#125;&#125; hour(s), it will be &#123;&#123; next_time &#125;&#125;. &lt;/p&gt; &#123;% endblock %&#125; 使用模板系统Django 系统经过配置后可以使用一个或多个模板引擎（如果不用模板，那就不用配置）。Django 自带了一个内置的后端，用于支持自身的模板引擎，即 Django Template Language（DTL），若想在 Python 代码中使用 Django 的模板系统，基本方式如下： 以字符串形式提供原始的模板代码，创建Template 对象。 在Template 对象上调用render() 方法，传入一系列变量（上下文）。返回的是完全渲染模板后得到的字符串，模板中的变量和模板标签已经根据上下文求出值了。 以上步骤我们都可以使用一个函数来完成，那就是render()函数，render() 的第一个参数是请求对象，第二个参数是模板名称，第三个参数可选，是一个字段，用于创建传给模板的上下文。如果不指定第三个参数，render() 使用一个空字典，具体使用如下介绍。 模板目录及模板加载为了从文件系统中加载模板，Django 提供了便利而强大的 API，力求去掉模板加载调用和模板自身的冗余。若想使用这个模板加载 API，首先要告诉框架模板的存储位置。这个位置在设置文件中配置，打开settings.py 文件，找到TEMPLATES 设置。它的值是一个列表，分别针对各个模板引擎： 123456789101112131415161718192021222324TEMPLATES = [ &#123; # BACKEND 的值是一个点分 Python 路径，指向实现 Django 模板后端 API 的模板引擎类 &apos;BACKEND&apos;: &apos;django.template.backends.django.DjangoTemplates&apos;, # DIRS 定义一个目录列表，模板引擎按顺序在里面查找模板源文件。 # 当前设置表示在项目根目录中放一些主模板，模板目录不一定非得叫&apos;templates&apos;，可以自定义 &apos;DIRS&apos;: [os.path.join(BASE_DIR, &apos;templates&apos;)], # 去应用所在位置查找模板，APPS_DIRS 设为True 时，DjangoTemplates 会在INSTALLED_APPS 中的各个应用里查找名为“templates”的子目录。这样，即使DIRS 为空，模板引擎还能查找应用模板。 &apos;APP_DIRS&apos;: True, # OPTIONS 是一些针对后端的设置 &apos;OPTIONS&apos;: &#123; # 默认的处理器上下文 &apos;context_processors&apos;: [ &apos;django.template.context_processors.debug&apos;, &apos;django.template.context_processors.request&apos;, &apos;django.contrib.auth.context_processors.auth&apos;, &apos;django.contrib.messages.context_processors.messages&apos;, ], &#125;, &#125;,] 查找模板逻辑 如果APP_DIRS 的值是True，而且使用 DTL，在当前应用中查找“templates”目录。 如果在当前应用中没找到模板，把传给它的模板名称添加到DIRS 中的各个目录后面，按顺序在各个目录中查找。假如DIRS 的第一个元素是’/home/django/mysite/templates’，调用查找的模板是/home/django/mysite/templates/current_datetime.html。 找不到指定名称对应的模板，抛出TemplateDoesNotExist 异常。 使用示例及说明视图函数如下定义： 123456from django.shortcuts import renderimport datetimedef currentDatetime(request): now = datetime.datetime.now() return render(request, &apos;test/current_datetime.html&apos;, &#123;&apos;current_date&apos;: now&#125;) 通过以上示例我们发现： 不用再导入get_template、Template、Context 或HttpResponse 了，而要导入django.shortcuts.render import datetime 不变。 在current_datetime 函数中，仍然要计算now，不过加载模板、创建上下文、渲染模板和创建HttpResponse对象全由render() 调用代替了。render() 的返回值是一个HttpResponse 对象，因此在视图中可以直接返回那个值。 注意上述我们还使用了模板子目录：test/current_datetime.html，表示去根目录下寻找templates目录下的test目录，找到模板。 Djongo模型Django 非常适合构建数据库驱动型网站，它提供了简单而强大的工具，易于使用 Python 执行数据库查询，本章就说明这个功能，即 Django 的数据库层。 配置数据库数据库连接的配置也在settings文件中，具体如下： 1234567891011121314151617181920# 数据库配置，这里使用集成的sqllite3，我们配置自己的数据库，类似于我们Java项目中的配置文件中配置即可DATABASES = &#123; &apos;default&apos;: &#123; &apos;ENGINE&apos;: &apos;django.db.backends.sqlite3&apos;, # ENGINE 告诉 Django 使用哪个数据库引擎。 &apos;NAME&apos;: os.path.join(BASE_DIR, &apos;db.sqlite3&apos;), # NAME 告诉 Django 数据库的名称。 &#125;&#125;# 配置MySQL数据库# DATABASES = &#123;# &apos;default&apos;: &#123;# &apos;ENGINE&apos;: &apos;django.db.backends.mysql&apos;, # 或者使用 mysql.connector.django# &apos;NAME&apos;: &apos;test&apos;,# &apos;USER&apos;: &apos;test&apos;,# &apos;PASSWORD&apos;: &apos;test123&apos;,# &apos;HOST&apos;:&apos;localhost&apos;,# &apos;PORT&apos;:&apos;3306&apos;,# &#125;# &#125; 创建应用下面说明项目和应用的区别： 一个项目是一系列 Django 应用的实例，外加那些应用的配置。严格来说，一个项目唯一需要的是一个设定文件，定义数据库连接信息、安装的应用列表、DIRS，等等。 一个应用是一系列便携的 Django 功能，通常包含模型和视图。打包在一个 Python 包里。Django 自带了一些应用，例如管理后台。这些应用的独特之处是便携，可以在多个项目中复用。 在项目目录，注意是项目目录，使用如下命令创建新的应用，并指定自定义应用名称：python manage.py startapp 应用名称。 Django 通过模型在背后执行 SQL，返回便利的 Python 数据结构，表示数据库表中的行。Django 还通过模型表示 SQL 无法处理的高层级概念，这么做的好处如下： 内省（introspection）有开销，而且不完美。为了提供便利的数据访问 API，Django 需要以某种方式知晓数据库布局，而这一需求有两种实现方式。第一种是使用Python 明确描述数据，第二种是在运行时内省数据库，推知数据模型。第二种方式在一个地方存储表的元数据，看似更简单，其实会导致几个问题。首先，运行时内省数据库肯定有消耗。如果每次执行请求，或者只是初始化 Web 服务器都要内省数据库，那带来的消耗是无法接受的，其次，有些数据库，尤其是旧版 MySQL，存储的元数据不足以完成内省。 Python 编写起来让人心情舒畅，而且使用 Python 编写所有代码无需频繁让大脑切换情境。在一个编程环境（思维）中待久了，有助于提升效率。在 SQL 和 Python 之间换来换去容易打断状态。 把数据模型保存在代码中比保存在数据库中易于做版本控制，易于跟踪数据布局的变化。 SQL 对数据布局的元数据只有部分支持。例如，多数数据库系统没有提供专门表示电子邮件地址或URL 的数据类型。而 Django 模型有。高层级的数据结构有助于提升效率，让代码更便于复用。 不同数据库平台使用的 SQL 不一致。 分发 Web 应用程序时，更务实的做法是分发一个描述数据布局的 Python 模块，而不是分别针对MySQL、PostgreSQL 和 SQLite 的CREATE TABLE 语句。 创建自己的模型在我们新创建的应用的models.py文件中，添加自己定义的模型，如下： 让 Django 具有基本的数据访问能力只需编写这些代码。一般，一个模型对应于一个数据库表，模型中的各个属性分别对应于数据库表中的一列。属性的名称对应于列的名称，字段的类型（如CharField）对应于数据库列的类型(如varchar) 123456789101112131415161718192021222324252627282930313233343536# 厂家class Manufacturers(models.Model): name = models.CharField(max_length=30) address = models.CharField(max_length=50) city = models.CharField(max_length=60) province = models.CharField(max_length=30) website = models.URLField(blank=True, null=True, verbose_name=&apos;网址&apos;) # 表单允许为空 修改数据库结构，表示字段可为空 def __str__(self): return u&apos;%s&apos; % (self.name)# 经销商class Vender(models.Model): name = models.CharField(max_length=30) address = models.CharField(max_length=50) city = models.CharField(max_length=60) province = models.CharField(max_length=30) telephone = models.CharField(max_length=20) def __str__(self): return u&apos;%s %s %s %s %s&apos; % (self.name, self.address, self.city, self.province, self.telephone)# 产品class Product(models.Model): title = models.CharField(max_length=100) vender = models.ManyToManyField(Vender) # 多对多关系 manufacturers = models.ForeignKey(Manufacturers) # 一对多 product_date = models.DateField() # fields = (&apos;title&apos;, &apos;product_date&apos;, &apos;vender&apos;, &apos;manufacturers&apos;) def __str__(self): return u&apos;%s %s&apos; % (self.title, self.product_date) # 任何模型都可以使用Meta 类指定多个针对所在模型的选项。 class Meta: ordering = [&apos;product_date&apos;] 注意：多对多关系，在上述示例模型中，Django 会创建一个额外的表，一个多对多联结表（join table），处理Product与Vender之间的对应关系。 安装模型在settings文件中注册上我们自己创建的应用，注册位置已经在之前描述过，如下： 123456789101112# Application definition# 注意：此处添加自己开发的应用INSTALLED_APPS = ( &apos;django.contrib.admin&apos;, # 管理后台 &apos;django.contrib.auth&apos;, # 身份验证系统 &apos;django.contrib.contenttypes&apos;, # 内容类型框架 &apos;django.contrib.sessions&apos;, # 会话框架 &apos;django.contrib.messages&apos;, # 消息框架 &apos;django.contrib.staticfiles&apos;, # 管理静态文件的框架 &apos;cerealsOils&apos;, # 自己开发的应用) 注册好后就可以验证和安装模型： 验证模型使用命令：python manage.py check check 命令运行 Django 系统检查框架，即验证 Django 项目的一系列静态检查。如果一切正常，你将看到这个消息：System check identified no issues (0 silenced)，不然会抛出出错位置的异常 安装模型使用命令：python manage.py makemigrations cerealsOils，这样我们就安装好了模型，并根据模型定义创建好了数据库表 查看建表语句可以执行命令：python manage.py sqlmigrate cerealsOils 0001，这样建表语句就会输出出来 Djongo后台管理对多数现代的网站而言，管理界面是基础设施的重要组成部分。这是一个 Web 界面，限制只让授信的网站管理员访问，用于添加、编辑和删除网站内容。常见的示例有：发布博客的界面，网站管理人员审核用户评论的后端，客户用来更新新闻稿的工具。不过，管理界面有个问题：构建起来繁琐。构建面向公众的功能时，Web 开发是有趣的，但是管理界面一成不变，要验证用户身份、显示并处理表单、验证输入，等等。这个过程无趣、乏味。在 Django 中，构建管理界面不算个事， Django 为我们自动生成的管理界面，了解它为模型提供的便利界面，以及可以使用的其他功能。 使用管理后台之前创建项目时我们执行了django-admin startproject mysite命令时，Django 为我们创建并配置了默认的管理后台。我们只需创建一个管理员用户（超级用户），就可以登录管理后台。 创建管理用户：python manage.py createsuperuser 输入要创建的用户：Username: admin 输入邮箱地址：Email address: admin@example.com 输入用户密码，需要输入两次确认：Password: ** 启动服务器，访问ttp://127.0.0.1:8000/admin/就可以进入登录页面，登录后具体操作就可以被看懂了，这里不再赘述，可以启动项目为大家演示一下。 将我们创建的模型添加至后台管理在我们新创建的项目目录下创建admin.py文件，并添加如下代码，这样就将我们创建的模型添加至了后天管理系统： 1234567from django.contrib import adminfrom .models import Manufacturers, Vender, Product# 注册我们创建的模型admin.site.register(Manufacturers, ManufacturersAdmin)admin.site.register(Vender, VenderAdmin)admin.site.register(Product, ProductAdmin) 将字段定义为可选（非必填）及自定义字段标注默认我们创建的模型在后台管理页面都是必填字段，及显示的名称都是字段的英文名称，我们可以修改model，添加一下属性，来设置字段为非必填及显示的名称为可以看懂的名称，如下示例： 1234567891011# 厂家class Manufacturers(models.Model): name = models.CharField(max_length=30, verbose_name=&apos;厂家名称&apos;) address = models.CharField(max_length=50, verbose_name=&apos;具体地址&apos;) city = models.CharField(max_length=60, verbose_name=&apos;所在地市&apos;) province = models.CharField(max_length=30, verbose_name=&apos;所在省份&apos;) website = models.URLField(blank=True, null=True, verbose_name=&apos;网址&apos;) # 表单允许为空 修改数据库结构，表示字段可为空 def __str__(self): return u&apos;%s&apos; % (self.name)... 注：上述示例中：blank=True表示表单输入可为空， null=True表示数据库存值是如果是空也存为空，而不是字符”NULL”,verbose_name=’网址’表示自定义名称 自定义ModelAdmin类具体使用及属性设置明细见如下示例（此处可以打开后台管理界面给大家演示一下）： 123456789101112131415161718192021222324252627from django.contrib import adminfrom .models import Manufacturers, Vender, Product# Register your models here.class ProductAdmin(admin.ModelAdmin): list_display = (&apos;title&apos;, &apos;product_date&apos;, &apos;manufacturers&apos;) # 注意 此处不能包含多对多字段 search_fields = (&apos;title&apos;, &apos;product_date&apos;) # 添加列表搜索框内容，注意只有一个框，但输入内容后悔搜索多个字段，类似于ES的机制 list_filter = (&apos;product_date&apos;,) # 右侧的过滤条 可以是日期 布尔 一对一外键类型 date_hierarchy = &apos;product_date&apos; # 显示日期导航，注意只能添加一个导航 ordering = (&apos;-product_date&apos;,) # 列表根据日期降序排序 fields = (&apos;product_date&apos;, &apos;title&apos;, &apos;manufacturers&apos;, &apos;vender&apos;) # 自定义编辑表单，修改卡片页面排序，还可以排除字段，排除的字段将不能编辑 raw_id_fields = (&apos;manufacturers&apos;,) # 针对一对一内容太多而做的界面优化，一般为下拉框内容太多的优化 filter_horizontal = (&apos;vender&apos;,) # 针对一对多内容太多而做的通过弹出框筛选class VenderAdmin(admin.ModelAdmin): list_display = (&apos;name&apos;, &apos;address&apos;) search_fields = (&apos;name&apos;, &apos;address&apos;)class ManufacturersAdmin(admin.ModelAdmin): list_display = (&apos;name&apos;, &apos;address&apos;) search_fields = (&apos;name&apos;, &apos;address&apos;) # 将自定义的ModelAdmin注册到后台管理admin.site.register(Manufacturers, ManufacturersAdmin)admin.site.register(Vender, VenderAdmin)admin.site.register(Product, ProductAdmin)","categories":[{"name":"Python","slug":"Python","permalink":"https://jjw-story.github.io/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://jjw-story.github.io/tags/Python/"},{"name":"Django","slug":"Django","permalink":"https://jjw-story.github.io/tags/Django/"}],"author":"JJW"},{"title":"文件及目录权限","slug":"文件及目录权限","date":"2019-08-03T12:20:20.000Z","updated":"2019-08-03T06:13:49.717Z","comments":true,"path":"2019/08/03/文件及目录权限/","link":"","permalink":"https://jjw-story.github.io/2019/08/03/文件及目录权限/","excerpt":"","text":"文件及目录权限的表示方法当我们使用 ls -l 命令查看详细文件内容时，可以看到查询出的内容如下： 123456789root@CHJ-20190520VPS:/usr/lib# ls -ltotal 920drwxr-xr-x 1 root root 4096 May 21 22:39 kerneldrwxr-xr-x 1 root root 4096 May 21 22:39 klibcdrwxr-xr-x 1 root root 4096 May 21 22:40 language-selectorlrwxrwxrwx 1 root root 21 Feb 12 16:55 libDeployPkg.so.0 -&gt; libDeployPkg.so.0.0.0-rw-r--r-- 1 root root 31280 Feb 12 16:55 libDeployPkg.so.0.0.0lrwxrwxrwx 1 root root 20 Feb 12 16:55 libguestlib.so.0 -&gt; libguestlib.so.0.0.0-rw-r--r-- 1 root root 22656 Feb 12 16:55 libguestlib.so.0.0.0 一共查询出七列内容，分别表示： 文件属性(占10个字符空间)、拥有的文件数量、文件的创建者、所属的group、文件大小、建档日期、文件名 文件属性Linux的文件基本上分为三个属性：可读（r），可写（w），可执行（x） 但是这里有十个格子可以填（具体程序实现时，实际上是十个bit位） 文件类型第一个小格是特殊表示格，表示目录或连结文件等等 d 表示目录，这个是在创建下来文件的类型就固定了下来，不可以人为进行更改 l 表示链接文件，类似于快捷方式 - 表示这是普通文件 b 块特殊文件，其实是指的是设备，比如我们插入一个移动硬盘，插入一个硬盘之后，Linux系统就会把他当成一个特出文件块文件来表示 c 字符特殊文件，就是终端 f 命名管道 s 套接字文件 文件权限表示方法字符权限表示方法： r 读 w 写 x 执行 数字权限的表示方法（8进制数字表示）： r=4 w=2 x=1 其余剩下的格子就以每3格为一个单位，因为Linux是多用户多任务系统，所以一个文件可能同时被许多人使用，所以我们一定要设好每个文件的权限，其文件的权限位置排列顺序是（以-rwxr-xr-x为例）： rwx(Owner)r-x(Group)r-x(Other) 这个例子表示的权限是：使用者自己可读，可写，可执行；同一组的用户可读，不可写，可执行；其它用户可读，不可写，可执行。 另外，有一些程序属性的执行部分不是X,而是S,这表示执行这个程序的使用者，临时可以有和拥有者一样权力的身份来执行该程序。一般出现在系统管理之类的指令或程序，让使用者执行时，拥有root身份。 文件权限的修改修改权限命令chown命令修改属主或数组命令，使用方法： 修改属主：chown 用户名称 文件名称 修改属组：chown :用户组名称 文件名称 修改文件、目录权限。Linux/Unix 的文件调用权限分为三级 : 文件拥有者、群组、其他。利用 chmod 可以藉以控制文件如何被他人所调用 首先我们新创建一个目录，查看root用户新创建目录的默认权限，如下： 12root@CHJ-20190520VPS:/tmp# ls -ld testdir/drwxr-xr-x 1 root root 4096 Jul 27 15:05 testdir/ 表示文件的属主是root用户，root用户可以读写删除等，所属用户组不能删除，其他其他用户不能删除 这里我们需要了解，Linux权限限制是非root用户的，这里既是我们将文件或目录的权限给root修改了，但是root用户还是不受限制的 所以为了方便测试我们不要用root用户来操作，命令使用示例如下： 123456789101112131415# 修改属主root@CHJ-20190520VPS:/tmp# chown wangjia3 testdirroot@CHJ-20190520VPS:/tmp# ls -ld testdirdrwxr-xr-x 1 wangjia3 root 4096 Jul 27 15:05 testdir# 修改属组root@CHJ-20190520VPS:/tmp# groupadd group01root@CHJ-20190520VPS:/tmp# chown :group01 testdirroot@CHJ-20190520VPS:/tmp# ls -ld testdirdrwxr-xr-x 1 wangjia3 group01 4096 Jul 27 15:05 testdir# 属主属组一起修改root@CHJ-20190520VPS:/tmp# chown wangjia3:group01 testdir/root@CHJ-20190520VPS:/tmp# ls -ld testdir/drwxr-xr-x 1 wangjia3 group01 4096 Aug 3 12:35 testdir/ 可以看到文件的属主和属组已经改变 chgrp命令修改属组命令，使用方法：chgrp 用户组名称 文件名称 使用示例： 123root@CHJ-20190520VPS:/tmp# chgrp root testdirroot@CHJ-20190520VPS:/tmp# ls -ld testdirdrwxr-xr-x 1 wangjia3 root 4096 Jul 27 15:05 testdir 可以看到文件的属组已经被修改回为root分组 创建文件的默认权限我们创建一个新的文件，默认的权限如下所示： 123root@CHJ-20190520VPS:/tmp/testdir# ls -ltotal 0-rw-r--r-- 1 root root 0 Aug 3 12:35 demoFile 那它是怎么来的呢？其实创建新的文件默认的权限是数字表示法：666，表示属主属组其他都是拥有读写权限，但它会根据数字权限表示减去一个uumask，umask表示如下： 12root@CHJ-20190520VPS:/tmp/testdir# umask0022 所以这就是我们创建文件的默认权限的由来，是使用 666 减去 umask 得到的默认权限 chmod命令chmod是Linux/Unix中修改文件或者目录权限的命令，通过修改权限可以让指定的人对文件可读、可写、可运行，极大地保证了数据的安全性 使用方法：chmod [修改内容 修改符号 权限] 文件 修改字符权限参数详解修改内容 u 修改文件属主的权限 g 修改文件属组的权限 r 修改其他以外的权限 a 以上三者都修改 具体权限修改 + 增加权限 - 取消权限 = 直接设定权限 此三条具体设置的权限就是我们之前了解的：r、w、x 使用示例： 123456789101112131415161718192021222324252627root@CHJ-20190520VPS:/tmp/testdir# ls -ltotal 0-rw-r--r-- 1 root root 0 Aug 3 12:35 demoFile# 属主增加执行权限root@CHJ-20190520VPS:/tmp/testdir# chmod u+x demoFileroot@CHJ-20190520VPS:/tmp/testdir# ls -ltotal 0-rwxr--r-- 1 root root 0 Aug 3 12:35 demoFile# 属组取消读权限root@CHJ-20190520VPS:/tmp/testdir# chmod o-r demoFileroot@CHJ-20190520VPS:/tmp/testdir# ls -ltotal 0-rwxr----- 1 root root 0 Aug 3 12:35 demoFile# 其他设置执行和读权限root@CHJ-20190520VPS:/tmp/testdir# chmod o=xr demoFileroot@CHJ-20190520VPS:/tmp/testdir# ls -ltotal 0-rwxr--r-x 1 root root 0 Aug 3 12:35 demoFile# 所有设置读写执行权限root@CHJ-20190520VPS:/tmp/testdir# chmod a=xwr demoFileroot@CHJ-20190520VPS:/tmp/testdir# ls -ltotal 0-rwxrwxrwx 1 root root 0 Aug 3 12:35 demoFile 修改数字权限修改方法：chmod [数字] 文件 注意：以上参数中数字为3位数 参数详解三位数字第一位代表属主权限，第二位代表属组权限，第三位代表其他权限 数字则分别用 1、2、4 来分别表示 执行、写、读 使用示例： 123456789101112131415root@CHJ-20190520VPS:/tmp/testdir# ls -ltotal 0-rwxrwxrwx 1 root root 0 Aug 3 12:35 demoFile# 设置取消所有权限root@CHJ-20190520VPS:/tmp/testdir# chmod 000 demoFileroot@CHJ-20190520VPS:/tmp/testdir# ls -ltotal 0---------- 1 root root 0 Aug 3 12:35 demoFile# 设置属主读写权限，属组和其他读权限root@CHJ-20190520VPS:/tmp/testdir# chmod 644 demoFileroot@CHJ-20190520VPS:/tmp/testdir# ls -ltotal 0-rw-r--r-- 1 root root 0 Aug 3 12:35 demoFile 特殊权限SUID用于二进制可执行文件，执行命令时取得文件的属主权限，例如 /usr/bin/password 12wangjia3@CHJ-20190520VPS:/tmp/testdir$ ls -l /usr/bin/passwd-rwsr-xr-x 1 root root 59640 Mar 23 03:05 /usr/bin/passwd 如上示例中：属主权限是 ws，s 之前是我们没有解释过的，它表示的是不管是root用户还是普通用户，它在执行这条命令时，它都会以文件的属主的这种身份来进行操作 它的作用就是，我们有些文件用户是没有任何权限的，例如保存用户账户密码的文件，/etc/shadow: 12wangjia3@CHJ-20190520VPS:/tmp/testdir$ ls -l /etc/shadow-rw-r----- 1 root shadow 1153 Jul 27 13:38 /etc/shadow 我们当前登录的用户是没有此文件的任何权限的，而root用户有此文件的权限，那我们普通用户为什么能修改密码呢，就是我们在修改密码例如passwd文件的时候，它能以root用户的身份来执行，这样就避免了我们需要主动去切换用户的修改密码的问题。 SGID用于目录，在该目录下创建新的文件和目录，权限自动更改为该目录的数组，一般是我们在文件共享的时候，一般会用到SET GID SBIT用于目录，该目录下新建的文件和目录，仅root和自己可以删除，如/tmp 12wangjia3@CHJ-20190520VPS:/$ ls -ld /tmpdrwxrwxrwt 1 root root 4096 Aug 3 13:50 /tmp 注意在其他位有一个t，这样就可以防止自己创建的文件被其他的普通用户修改或删除 设置特殊权限使用的也是 chmod命令，用法与上述修改权限用法一致，只不过多了由三位数变为了四位数，第一位为特殊权限的表示数字 特殊权限数字表示： 4 SET UID 123456789root@CHJ-20190520VPS:/tmp/testdir# ls -ltotal 0----rw---- 1 wangjia3 wangjia3 0 Aug 3 12:35 demoFileroot@CHJ-20190520VPS:/tmp/testdir# chmod 4644 demoFileroot@CHJ-20190520VPS:/tmp/testdir# ls -ltotal 0-rwSr--r-- 1 wangjia3 wangjia3 0 Aug 3 12:35 demoFile 1 SET BIT 1234root@CHJ-20190520VPS:/tmp/testdir# chmod 1644 demoFileroot@CHJ-20190520VPS:/tmp/testdir# ls -ltotal 0-rw-r--r-T 1 wangjia3 wangjia3 0 Aug 3 12:35 demoFile 2 SET GID 1234root@CHJ-20190520VPS:/tmp/testdir# chmod 2644 demoFileroot@CHJ-20190520VPS:/tmp/testdir# ls -ltotal 0-rw-r-Sr-- 1 wangjia3 wangjia3 0 Aug 3 12:35 demoFile 注意特殊权限一般不要去自己随便指定，使用系统默认就行","categories":[{"name":"Linux","slug":"Linux","permalink":"https://jjw-story.github.io/categories/Linux/"}],"tags":[{"name":"command","slug":"command","permalink":"https://jjw-story.github.io/tags/command/"},{"name":"文件及目录权限","slug":"文件及目录权限","permalink":"https://jjw-story.github.io/tags/文件及目录权限/"}],"author":"JJW"},{"title":"su-sudo命令","slug":"su-sudo命令","date":"2019-07-27T01:07:11.000Z","updated":"2019-07-27T04:15:12.298Z","comments":true,"path":"2019/07/27/su-sudo命令/","link":"","permalink":"https://jjw-story.github.io/2019/07/27/su-sudo命令/","excerpt":"","text":"su命令Linux su命令用于变更为其他使用者的身份，除 root 外，需要键入该使用者的密码 使用方法：su [选项] [用户名称] 选项说明 -f 不必读启动档（如 csh.cshrc 等），仅用于 csh 或 tcsh -c 既command，变更为帐号为指定账号的使用者并执行指定指令（command）后再变回原来使用者，使用方法：su -c [指定命令] 用户名称 -m -p 既preserve、environment，执行 su 时不改变环变量 - -l login这个参数加了之后，就好像是重新login为该使用者一样，大部份环境变数（HOME SHELL USER等等）都是以该指定用户为主，并且工作目录也会改变，如果没有指定用户，内定是 root -s 指定要执行的shell （bash csh tcsh 等），预设值为 /etc/passwd 内的指定用户shell 使用示例： 1234567891011121314wangjia3@CHJ-20190520VPS:~$ pwd/home/wangjia3wangjia3@CHJ-20190520VPS:~$ su rootPassword:root@CHJ-20190520VPS:/home/wangjia3# pwd/home/wangjia3root@CHJ-20190520VPS:~# su - wangjia3wangjia3@CHJ-20190520VPS:~$ pwd/home/wangjia3wangjia3@CHJ-20190520VPS:~$ su - rootPassword:root@CHJ-20190520VPS:~# pwd/root 注意 su 与 su - 的区别 sudo命令sudo 表示 “superuser do”。 它允许已验证的用户以其他用户的身份来运行命令。其他用户可以是普通用户或者超级用户。然而，大部分时候我们用它来以提升的权限来运行命令 以系统管理者的身份执行指令，也就是说，经由 sudo 所执行的指令就好像是 root 亲自执行 使用方法：su [参数] 参数说明 -V 显示版本编号 -h 显示版本编号及指令的使用方式说明你 -l 显示出当前用户的权限 -v 因为 sudo 在第一次执行时或是在 N 分钟内没有执行（N 预设为五）会问密码，这个参数是重新做一次确认，如果超过 N 分钟，也会问密码 -k 将会强迫使用者在下一次执行 sudo 时问密码（不论有没有超过 N 分钟） -b 将要执行的指令放在背景执行 -s 执行环境变数中的 SHELL 所指定的 shell ，或是 /etc/passwd 里所指定的 shell -i Linux终端命令下改变用户对命令使用权限的命令，加载用户变量，并跳转到目标用户home目录 经常使用参数示例： 1234567wangjia3@CHJ-20190520VPS:/$ sudo -l[sudo] password for wangjia3:Matching Defaults entries for wangjia3 on CHJ-20190520VPS: env_reset, mail_badpass, secure_path=/usr/local/sbin\\:/usr/local/bin\\:/usr/sbin\\:/usr/bin\\:/sbin\\:/bin\\:/snap/binUser wangjia3 may run the following commands on CHJ-20190520VPS: (ALL : ALL) ALL 12345678wangjia3@CHJ-20190520VPS:~$ pwd/home/wangjia3wangjia3@CHJ-20190520VPS:~$ sudo -sroot@CHJ-20190520VPS:~# pwd/home/wangjia3root@CHJ-20190520VPS:~# sudo -iroot@CHJ-20190520VPS:~# pwd/root 注意 -s 和 -i 的区别 sudo命令使用补充通常我们使用普通用户使用一些命令是没有权限的，在使用这些没有权限的命令时需要切换到root用户，这样就需要告知普通用户root用户的密码，这样做是不安全的 例如我们执行shutdown命令时： 12[frog@iZm5ehzqow4ijp2ya2g2drZ ~]$ shutdown -h 60shutdown: Need to be root 显示需要使用root用户来操作此命令 这时我们可以使用visudo来修改sudo的配置文件，将此命令的使用权限赋给普通用户，来让普通用户有权限使用此命令，就可以不将root用户的密码告知与普通用户，安全的使用系统 visudo的使用时以vi开头的，其实就类似于使用 vi 打开了一个文件，使用操作与 vi 一致 1234567891011121314151617181920212223242526272829303132[root@iZm5ehzqow4ijp2ya2g2drZ /]# visudo## Sudoers allows particular users to run various commands as## the root user, without needing the root password.#### Examples are provided at the bottom of the file for collections...## user MACHINE=COMMANDS#### The COMMANDS section may have other options added to it.#### Allow root to run any commands anywhereroot ALL=(ALL) ALL## Allows members of the &apos;sys&apos; group to run networking, software,## service management apps and more.# %sys ALL = NETWORKING, SOFTWARE, SERVICES, STORAGE, DELEGATING, PROCESSES, LOCATE, DRIVERS## Allows people in group wheel to run all commands# %wheel ALL=(ALL) ALL## Same thing without a password# %wheel ALL=(ALL) NOPASSWD: ALL## Allows members of the users group to mount and unmount the## cdrom as root# %users ALL=/sbin/mount /mnt/cdrom, /sbin/umount /mnt/cdrom## Allows members of the users group to shutdown this system# %users localhost=/sbin/shutdown -h now## Read drop-in files from /etc/sudoers.d (the # here does not mean a comment) 注意此文件最下方有几段关于使用sudo的设置说明，下面是设置说明： 12345## Allows people in group wheel to run all commands# %wheel ALL=(ALL) ALL## Same thing without a password# %wheel ALL=(ALL) NOPASSWD: ALL %wheel 表示的是如果我们要设置的是用户组，则需要用 % 加上用户组名称，如果只是单个用户，就直接写用户名即可 ALL=(ALL) 表示在哪台主机上可以执行哪些命令，哪来主机指的是我们登陆的主机，Linux可以在本地登陆，也可以远程登陆，如果在本地登陆那么主机就是localhost，locachost是字符端登陆，如果是字符或远程都去登陆，就赋予 ALL 的权限。 如果只赋予一些命令，如上述中：# %users localhost=/sbin/shutdown -h now，意思是赋予了用户shutdown -h now 的命令的使用权限 如果有多条命令，就将命令用 “,” 隔开，例如上述段落中示例：%users ALL=/sbin/mount /mnt/cdrom, /sbin/umount /mnt/cdrom，表示赋予了用户mount、unmount命令 NOPASSWD: ALL 表示普通用户在使用管理员账户赋予它的这些命令时是否需要输入密码，这里 NOPASSWD: ALL 表示不需要输入密码，但是这种是不安全的，所以我们不建议此种设置类型 使用示例我们现在配置普通用户 frog 被赋予使用 shutdown -h 60 的权限，使用visudo来设置，修改如下： 123## Read drop-in files from /etc/sudoers.d (the # here does not mean a comment)#includedir /etc/sudoers.dforg ALL=/sbin/shutdown -h 60 修改完成然后切换到frog用户执行此命令： 12345678910[root@iZm5ehzqow4ijp2ya2g2drZ /]# su -l frog[frog@iZm5ehzqow4ijp2ya2g2drZ ~]$ shutdown -h 60shutdown: Need to be root[frog@iZm5ehzqow4ijp2ya2g2drZ ~]$ sudo /sbin/shutdown -h 60[sudo] password for frog:Broadcast message from root@iZm5ehzqow4ijp2ya2g2drZ (/dev/pts/1) at 12:14 ...The system is going down for halt in 60 minutes! 注意：直接执行还是会告诉你没有权限，我们需要使用sudo命令来执行root赋予权限的命令，需要使用命令的全路径，然后提示输入密码之后就执行成功啦","categories":[{"name":"Linux","slug":"Linux","permalink":"https://jjw-story.github.io/categories/Linux/"}],"tags":[{"name":"command","slug":"command","permalink":"https://jjw-story.github.io/tags/command/"},{"name":"su-sudo","slug":"su-sudo","permalink":"https://jjw-story.github.io/tags/su-sudo/"}],"author":"JJW"},{"title":"用户和权限管理","slug":"用户和用户组管理","date":"2019-07-25T12:00:00.000Z","updated":"2019-07-27T06:08:31.650Z","comments":true,"path":"2019/07/25/用户和用户组管理/","link":"","permalink":"https://jjw-story.github.io/2019/07/25/用户和用户组管理/","excerpt":"","text":"用户管理Linux系统是一个多用户多任务的分时操作系统，任何一个要使用系统资源的用户，都必须首先向系统管理员申请一个账号，然后以这个账号的身份进入系统。 用户的账号一方面可以帮助系统管理员对使用系统的用户进行跟踪，并控制他们对系统资源的访问；另一方面也可以帮助用户组织文件，并为用户提供安全性保护。 每个用户账号都拥有一个惟一的用户名和各自的口令，用户在登录时键入正确的用户名和口令后，就能够进入系统和自己的主目录。 实现用户账号的管理，要完成的工作主要有如下几个方面： 用户账号的添加、删除与修改 用户口令的管理 用户组的管理 用户管理常用命令当前使用的Linux系统中已经有了两个用户，一个是root用户，一个是自己创建的用户，root用户是超级管理员，我们自己创建的用户是普通用户。LInux多用户其实就是将用户分成了两类用户，一类是root用户，一类是普通用户 root用户的权限比较大，它可以访问自己的家目录，访问系统的配置文件，例如之前我们修改的vim的配置文件，还有就是root用户还可以访问普通用户的家目录，但是普通用户的权限就受到了下去限制，它只能访问自己的家目录，以及root用户开放给它的一些没有危害到系统安全的目录文件 普通用户和普通用户之间是没有权限互相访问他们对方的家目录的，Linux就是通过这两种用户的区别，来做了最基本的权限隔离 用户添加命令用户添加命令实际使用的是 useradd命令，使用方法：useradd [选项] 用户名称 在添加用户完成后，我们可以使用 id 命令来验证是否添加成功，通过 id 命令，我们可以查看系统中有哪些已经存在的用户 1234567root@CHJ-20190520VPS:/# useradd wangjiasroot@CHJ-20190520VPS:/# id rootuid=0(root) gid=0(root) groups=0(root)root@CHJ-20190520VPS:/# id wangjiasuid=1001(wangjias) gid=1001(wangjias) groups=1001(wangjias)root@CHJ-20190520VPS:/# id abcid: ‘abc’: no such user 下面分析我们添加用户的时候Linux都做了哪些操作： 首先第一是为新添加的用户创建了它的家目录，创建完成我们访问的时候发现家目录是空的，但其实用户的家目录是存放了很多与用户相关的隐藏配置文件 第二步就是将我们创建的用户记录在 /etc/passwd 文件中，只要包含了如下所示内容，就说明我们系统中存在这样的一个用户 123root@CHJ-20190520VPS:/# cat /etc/passwd...wangjias:x:1001:1001::/home/wangjias:/bin/sh 第三步还会在 etc/shadow 文件中添加我们创建的用户信息，这个文件是用户密码相关的文件 还有就是我们每创建一个用户，都会创建一个独立的用户id，叫uid，如上述我们通过id命令查询出来的内容。注意root用户的id是0，如果我们把普通用户的id也修改为0，那么系统就会把此用户也当成root用户 第四就是还会为用户创建用户所属的组，如果我们没有明确指定所属的组，系统就会创建一个与用户同名的组作为新创建用户所属的组。如果我们希望有一组用户他们使用同样的资源的时候，就可以建立一个这样的用户组，然后把他们都加入到这个组里面，如果我们对这个组进行修改，就相当于对一组的用户全都进行修改 注意创建用户只有root用户有这样的权限，普通用户没有创建用户的权限 上面的创建我们没有指定选项，下面介绍一些选项： -c comment 指定一段注释性描述 -d 目录 指定用户主目录，如果此目录不存在，则同时使用-m选项，可以创建主目录 -g 用户组 指定用户所属的用户组 -G 用户组，用户组 指定用户所属的附加组 -s Shell文件 指定用户的登录Shell -u 用户号 指定用户的用户号，如果同时有-o选项，则可以重复使用其他用户的标识号 为用户设置密码用户登录是需要登录密码的，为用户设置密码的命令使用的是 passwd命令，使用方法：passwd [用户名] 注意用户名选项是可选的，如果不指定要修改密码的用户名，那就是修改当前用户的密码 1234root@CHJ-20190520VPS:/# passwd wangjiasEnter new UNIX password:Retype new UNIX password:passwd: password updated successfully 删除用户删除用户使用的是userdel命令，使用方法： userdel [选项] 用户名 注意我们一般删除用户的时候会添加上 “-r” 选项，如果我们直接使用用户删除命令删除用户，则此用户的家目录会被保留下来，当我们确认用户的家目录中的数据都可以被直接删除的时候，就可以添加 -r 这个选项，直接删除彻底。 如果执行的是彻底删除的命令，那么 /etc/passed 和 /etc/shadow 中的用户信息也会被删除 修改账号修改用户账号就是根据实际情况更改用户的有关属性，如用户号、主目录、用户组、登录Shell等。 修改已有用户的信息使用usermod命令，使用方法：usermod 选项 用户名 常用的选项包括-c, -d, -m, -g, -G, -s, -u以及-o等，这些选项的意义与useradd命令中的选项一样，可以为用户指定新的资源值 经常使用的选项是 -d 选项，既指定用户新的家目录，使用方法：usermod -d 新的家目录 用户名 如果我们修改了用户的家目录，那么我们重新登录此用户的时候，它的默认目录就会成为我们修改的目录，并且关于此用户的配置文件也会放在新的家目录中 用户组管理每个用户都有一个用户组，系统可以对一个用户组中的所有用户进行集中管理。不同Linux 系统对用户组的规定有所不同，如Linux下的用户属于与它同名的用户组，这个用户组在创建用户时同时创建 用户组的管理涉及用户组的添加、删除和修改。组的增加、删除和修改实际上就是对/etc/group文件的更新 用户组管理命令新建用户组新建用户组使用groupadd命令，使用方法：groupadd [选项] 用户组 选项一般使用 -g 选项，此选项用于指定用户组的组标识号 新建好组之后，有两种方式将用户添加至先建好的组，第一种是使用 usermod 命令： 12345root@CHJ-20190520VPS:/# groupadd -g 1001 group1root@CHJ-20190520VPS:/# useradd user1root@CHJ-20190520VPS:/# usermod -g group1 user1root@CHJ-20190520VPS:/# id user1uid=1001(user1) gid=1001(group1) groups=1001(group1) 可以看到我们已经将user1用户添加到了group1组中 第二种就是在新建用户的时候直接将用户添加至指定用户组中: 123root@CHJ-20190520VPS:/# useradd -g group1 user2root@CHJ-20190520VPS:/# id user2uid=1002(user2) gid=1001(group1) groups=1001(group1 修改用户组修改用户组的属性使用groupmod命令，使用方法：groupmod [选项] 用户组 常用选项如下： -g GID 为用户组指定新的组标识号 -o 与-g选项同时使用，用户组的新GID可以与系统已有用户组的GID相同 -n 新用户组 将用户组的名字改为新名字 使用示例： 123root@CHJ-20190520VPS:/# groupmod -n group2 group1root@CHJ-20190520VPS:/# id user2uid=1002(user2) gid=1001(group2) groups=1001(group2) 删除用户组如果要删除一个已有的用户组，使用groupdel命令，使用方法：groupdel 用户组 1root@CHJ-20190520VPS:/# groupdel group2 用户和用户组配置文件用户和用户组相关的配置文件主要有三个，/etc/passwd、/ect/shadow、/etc/group passwd文件内容如下： 12345671 root:x:0:0:root:/root:/bin/bash2 daemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologin3 bin:x:2:2:bin:/bin:/usr/sbin/nologin4 sys:x:3:3:sys:/dev:/usr/sbin/nologin...30 wangjia3:x:1000:1000:,,,:/home/wangjia3:/bin/bash31 user01:x:1001:1001::/home/user01:/bin/sh 我们发现此文件被分成了七个字段，下面分别解释每个字段的含义： 用户名称字段，表示用户的名称，可以看到此文件最后的两行是我们之前新创建的用户 第二个字段表示此用户登录需要不需要密码验证，如果把这个 “x” 删除之后，我们发现登录用户将不需要验证 1234wangjia3@CHJ-20190520VPS:~$ su -l wangjia3Password:wangjia3@CHJ-20190520VPS:~$ su -l user01user01@CHJ-20190520VPS:/$ 第三个字段是用户的uid字段，Linux并不是通过用户的名称来识别用户的，它是通过用户的id来识别用户，如果id重复了就会用最小id的用户使用 第四个字段是gid，是当前用户属于哪一个组的标识字段 第五个字段是注释 第六个字段表示用户的家目录的位置 用户登录后使用的命令解释器，现在所通用的命令解释器都是bash命令解释器。我们发现有很多第七个字段显示的是 /usr/sbin/nologin， 这里表示的是此用户是不能登录终端的，例如我们将user01用户的此字段修改为nologin： 123456 30 wangjia3:x:1000:1000:,,,:/home/wangjia3:/bin/bash 31 user01:x:1001:1001::/home/user01:/usr/sbin/nologinroot@CHJ-20190520VPS:~# su -l user01This account is currently not available.root@CHJ-20190520VPS:~# 切换用户失败，提示此账户不能登录 我们可以直接在这里添加一行数据，来添加用户 shadowshadow文件是保存用户和用户密码相关信息的，我们需要了解它的前两个字段 1234528 sshd:*:18037:0:99999:7:::29 pollinate:*:18037:0:99999:7:::30 wangjia3:$6$486gKZ88$cobO1oh/kuz4HwAmnpnb.OQtszzD78m0e.KvbbxcEbNfIA9/4cSKvU78iTMOgFL8FstKrk0hIQ/S16P/R5o6t.:18080:0: 99999:7:::31 user01:$6$Pe7lIEqi$28CGKQAIa3E4JvTvAZKeymjFgVY5HvGZXVg0RuUWetl2YTlgU5sLcMzRs6FZmJbnIvad3IeJO4bPXs082KqL10:18104:0:99 999:7::: 第一个字段是用户名称字段，用来和passwd字段来进行对应 是用户加密过的密码，加密的密码是以$开头，然后一串字符，这样主要是为了保护用户的密码，及时用户的密码是相同的，但是在此文件中的显示也是不同的，防止被破解 group和用户组相关的配置文件，里面包含四个字段： 第一个字段是组的名称 第二个字段这个组是否需要密码验证 第三个字段表示这个组的gid 第四个字段，表示其他组字段，表示哪些用户属于其他组，这个其他组里面又包含了用户名称","categories":[{"name":"Linux","slug":"Linux","permalink":"https://jjw-story.github.io/categories/Linux/"}],"tags":[{"name":"command","slug":"command","permalink":"https://jjw-story.github.io/tags/command/"},{"name":"用户和权限管理","slug":"用户和权限管理","permalink":"https://jjw-story.github.io/tags/用户和权限管理/"}],"author":"JJW"},{"title":"Python","slug":"Python","date":"2019-07-20T12:00:00.000Z","updated":"2019-07-24T09:40:11.920Z","comments":true,"path":"2019/07/20/Python/","link":"","permalink":"https://jjw-story.github.io/2019/07/20/Python/","excerpt":"","text":"Python基础Python语法注释注释的三种方式如下： 123456789# 注释&apos;&apos;&apos;注释&apos;&apos;&apos;&quot;&quot;&quot;这也是注释&quot;&quot;&quot; 缩进python不需要 {} 都是使用缩进表示代码块 字符串字符串可以 ‘ ‘， “ “, “”” “”” 123456&apos;字符串&apos;&quot;字符串&quot;&quot;&quot;&quot;多行字符串&quot;&quot;&quot; 空行函数之间或类方法之间用空行分开 ; 符号同一行可以显示多条语句，使用 ; 隔开 导入 在 python 用 import 或者 from…import 来导入相应的模块 将整个模块(somemodule)导入，格式为： import somemodule 从某个模块中导入某个函数,格式为： from somemodule import somefunction 从某个模块中导入多个函数,格式为： from somemodule import firstfunc, secondfunc, thirdfunc 将某个模块中的全部函数导入，格式为： from somemodule import * end关键字关键字end可以用于将结果输出到同一行，或者在输出的末尾添加不同的字符 123while b &lt; 1000: print(b, end=&apos;,&apos;) b += 1 条件控制123456789101112if 表达式1: 语句 if 表达式2: 语句 elif 表达式3: 语句 else: 语句elif 表达式4: 语句else: 语句 循环while循环: 123456count = 0while count &lt; 5:print (count, &quot; 小于 5&quot;)count = count + 1else:print (count, &quot; 大于或等于 5&quot;) for循环： 12345678sites = [&quot;Baidu&quot;, &quot;Google&quot;,&quot;Runoob&quot;,&quot;Taobao&quot;]for site in sites: if site == &quot;Runoob&quot;: print(&quot;菜鸟教程!&quot;) break print(&quot;循环数据 &quot; + site)else: print(&quot;没有循环数据!&quot;) 注意：以上循环中，else为跳出循环后执行的逻辑，且只执行一次，可以不存在else range()函数： 12345for i in range(103) : print(i)for i in range(0, 10, 3) : print(i) 参数最多可以有三个，第一个为开始限定，第二个为结束限定，第三个为步长 123a = [&apos;Google&apos;, &apos;Baidu&apos;, &apos;Runoob&apos;, &apos;Taobao&apos;, &apos;QQ&apos;]for i in range(len(a)): print(i, a[i]) break、continue break 语句可以跳出 for 和 while 的循环体。如果你从 for 或 while 循环中终止，任何对应的循环 else 块将不执行 continue语句被用来告诉Python跳过当前循环块中的剩余语句，然后继续进行下一轮循环 pass 语句： 12while True: pass 遍历技巧： 在序列中遍历时，索引位置和对应值可以使用 enumerate() 函数同时得到： 1234567for i, v in enumerate([&apos;tic&apos;, &apos;tac&apos;, &apos;toe&apos;]): print(i, v)# 结果0 tic1 tac2 toe 反向遍历： 12for i in reversed(range(1, 10, 2)): print(i) 迭代器迭代器有两个基本的方法：iter( 和 next() 字符串，列表或元组对象都可用于创建迭代器 示例： 123456789101112list=[1,2,3,4]it = iter(list) # 创建迭代器对象for x in it: print (x, end=&quot; &quot;)list=[1,2,3,4]it = iter(list) # 创建迭代器对象while True: try: print (next(it)) except StopIteration: sys.exit() StopIteration 异常用于标识迭代的完成，防止出现无限循环的情况，在 next() 方法中我们可以设置在完成指定循环次数后触发 StopIteration 异常来结束迭代。 函数1.语法12def 函数名（参数列表）: 函数体 可更改(mutable)与不可更改(immutable)对象： 不可变类型：变量赋值 a = 5 后再赋值 a = 10，这里实际是新生成一个 int 值对象 10，再让 a 指向它，而 5 被丢弃，不是改变a的值，相当于新生成了a 可变类型：变量赋值 la=[1,2,3,4] 后再赋值 la[2]=5 则是将 list la 的第三个元素值更改，本身la没有动，只是其内部的一部分值被修改了 python 函数的参数传递： 不可变类型：类似 c++ 的值传递，如 整数、字符串、元组。如fun(a)，传递的只是a的值，没有影响a对象本身。比如在 fun(a)内部修改 a 的值，只是修改另一个复制的对象，不会影响 a 本身 可变类型：类似 c++ 的引用传递，如 列表，字典。如 fun(la)，则是将 la 真正的传过去，修改后fun外部的la也会受影响 2.参数必需参数： 必需参数须以正确的顺序传入函数。调用时的数量必须和声明时的一样，既只要声明了参数，调用时就必须传递 关键字参数：使用关键字参数允许函数调用时参数的顺序与声明时不一致，因为 Python 解释器能够用参数名匹配参数值。 例如： 1234567def printme( name, age ): &quot;打印任何传入的字符串&quot; print (str) return#调用printme函数printme( age = 10, name = &quot;菜鸟教程&quot;) 默认参数：调用函数时，如果没有传递参数，则会使用默认参数,与Kotlin一样 不定长参数：就是可变参数，python的可变参数可以有多种类型，任意指定 例如： 123456789# 可写函数说明def printinfo( arg1, **vardict ):&quot;打印任何传入的参数&quot;print (&quot;输出: &quot;)print (arg1)print (vardict)# 调用printinfo 函数printinfo(1, a=2,b=3) 3.匿名函数语法：lambda [arg1 [,arg2,…..argn]]:expression 示例： 12345# 可写函数说明sum = lambda arg1, arg2: arg1 + arg2# 调用sum函数print (&quot;相加后的值为 : &quot;, sum( 10, 20 )) 4.return语句return [表达式] 语句用于退出函数，选择性地向调用方返回一个表达式，不带参数值的return语句返回None 示例： 1234567def sum( arg1, arg2 ):total = arg1 + arg2print (&quot;函数内 : &quot;, total)return total# 调用sum函数total = sum( 10, 20 ) 变量作用域1.Python的作用域一共有4种 L： （Local） 局部作用域 E： （Enclosing） 闭包函数外的函数中 G： （Global） 全局作用域 B： （Built-in） 内置作用域（内置函数所在模块的范围） 以 L –&gt; E –&gt; G –&gt;B 的规则查找，即：在局部找不到，便会去局部外的局部找（例如闭包），再找不到就会去全局找，再者去内置中找。 示例： 12345g_count = 0 # 全局作用域def outer(): o_count = 1 # 闭包函数外的函数中 def inner(): i_count = 2 # 局部作用域 全局变量和局部变量，与Java类似 2.global 和 nonlocal 关键字当内部作用域想修改外部作用域的变量时，就要用到global和nonlocal关键字: 示例： 1234567891011num = 1 # 外部作用域定义变量def fun1(): global num # 需要使用 global 关键字声明 print(num) # 注意这两想要打印成功，一方面可思议使用global关键字，如果不适用此关键词声明，可以将num放在方法中传递进来使用，否则将会报错，这里跟Java不同，这是因为 fun1 函数中的 num 使用的是局部，未定义，无法修改。 num = 123 print(num)fun1() # 输出: 1 123print(num) # 输出： 123 如果要修改嵌套作用域（enclosing 作用域，外层非全局作用域）中的变量则需要 nonlocal 关键字: 示例： 123456789def outer(): num = 10 # 嵌套作用域 def inner(): nonlocal num # nonlocal关键字声明 num = 100 print(num) inner() print(num)outer() 输出 100 100 模块和包1.模块模块是一个包含所有你定义的函数和变量的文件，其后缀名是.py。模块可以被别的程序引入，以使用该模块中的函数等功能，这也是使用 python 标准库的方法import 语句 想使用 Python 源文件，只需在另一个源文件里执行 import 语句，语法如下： import module1, module2,... moduleNfrom … import 语句 Python 的 from 语句让你从模块中导入一个指定的部分到当前命名空间中，语法如下： from modname import name1, name2, ... nameNfrom … import * 语句 把一个模块的所有内容全都导入到当前的命名空间也是可行的，只需使用如下声明： from modname import *dir() 函数 内置的函数 dir() 可以找到模块内定义的所有名称，以一个字符串列表的形式返回2.包包是一种管理 Python 模块命名空间的形式，采用”点模块名称” 比如一个模块的名称是 A.B， 那么他表示一个包 A 中的子模块 B 用户可以每次只导入一个包里面的特定模块，比如: 123import sound.effects.echo这将会导入子模块:sound.effects.echo 它必须使用全名去访问:sound.effects.echo.echofilter(input, output, delay=0.7, atten=4) 还有一种导入子模块的方法是: 123from sound.effects import echo这同样会导入子模块: echo，并且他不需要那些冗长的前缀，所以他可以这样使用:echo.echofilter(input, output, delay=0.7, atten=4) 还有一种变化就是直接导入一个函数或者变量: 123from sound.effects.echo import echofilter同样的，这种方法会导入子模块: echo，并且可以直接使用他的 echofilter() 函数:echofilter(input, output, delay=0.7, atten=4) 基本数据类型变量不需要声明，直接赋值，且赋值后才能使用 1234counter = 1000name = &quot;wangjia&quot;a = b = c = 100 python基本类型 Number（数字） String（字符串） Tuple（元组） List（列表） Set（集合） Dictionary（字典） 注意：前三类是不可变类型 1.python数字类型 Numberint、bool、float、complex（复数） 可以删除对象引用 del var, (del var_a, var_b) 有很多数学函数可以直接调用，比如Java中Math函数中的很多计算函数，在python中直接用就可以，例如 ：abs(-1)，还有一些随机数函数，用的时候查就可以 2.字符串python中没有字符类型，单个字符当做字符串处理 字符串截取：变量[头下标:尾下标] 支持负数，负数代表从后往前截取 使用 “/“ 转义特殊字符，可以在字符串前加 “r” 表示原始字符，例如 r”abc/nvc” 注意字符串格式化： 一般用于日志输出，print (“我叫 %s 今年 %d 岁!” % (‘小明’, 10)) 注意字符串中有四十多个功能内建函数，我们在操作判断关于字符串时查看以后函数是否支持 3.list 列表可以直接初始化: list = [‘12321’, 299, 12.80] 也支持截取，截取方法特性与字符串一样 list是可变的，可以更改元素，list[0] = ‘45654’, 或者批量修改：list[1:3] = [‘45654’, 300, 11.20] 删除元素：list[0] = [], list[0:2] = [] 合并列表，直接 + ，例如： list1 + list2。 list * 2 表示列表元素复制两倍 列表函数： 123456781. 获取长度函数：len(list)2. max(list)：返回列表元素最大值3. min(list)：返回列表元素最小值4. ist(seq)：将元组转换为列表5. list.append(obj)：在列表末尾添加新的对象6. list.index(obj)：从列表中找出某个值第一个匹配项的索引位置7. list.insert(index, obj)：将对象插入列表8. list.remove(obj)：移除列表中某个值的第一个匹配项 del可以根据索引来删除列表元素，例如： del list[2:4] 可以使用append和pop方法将列表作为堆栈使用，等等 4.tuple元组与list类似，但是元素不可变，也支持截取输出 tuple不可变，但是可以包含可变的对象，或list 创建空元组：tup1 = (); 元组不可以修改，但是可组合： tup3 = tup1 + tup2 元组元素不能删除，可以删除整个元组： del tup1 元组运算符支持与list一致 内置函数有：len、max、min、tuple 5.set集合创建方式： set = {1, 2, 3, 4} 或者，set(1) 创建空set 必须使用 set = set() 可以使用 in 关键字判断元素在不在set中， 例如 bool = 2 in set set支持运算，- 表示差集， | 表示并集， &amp; 交集， ^ 不同时存在的元素 基本内置函数： 12341. 添加元素：set.add(元素)2. 删除元素：set.remove( x )3. 计算元素个数：len(s)4. 清空集合：s.clear() 6.Dictionary字典列表是有序的对象集合，字典是无序的对象集合,字典当中的元素是通过键来存取的，类似于map 使用： dict = {} dict[“jjw”] = “wangjia” 字典键不能重复，值无所谓 可以这样创建：d = {key1 : value1, key2 : value2 } 使用字典取值的时候： dict[key] 如果key不存在于字典中，就会抛出异常 字典修改与 Kotlin修改map值一样 删除元素： del dict[key] 字典的键必须是不可变的，不可以使用列表作为键 基本内置函数： 12345671. len(dict)：计算字典元素个数，即键的总数2. str(dict)：输出字典，以可打印的字符串表示，类似于toString()3. radiansdict.get(key, default=None)：返回指定键的值，如果值不在字典中返回default值4. key in dict：如果键在字典dict里返回true，否则返回false5. radiansdict.items()：以列表返回可遍历的(键, 值) 元组数组6. radiansdict.keys()：返回一个迭代器，可以使用 list() 来转换为列表7. radiansdict.values()：返回一个迭代器，可以使用 list() 来转换为列表 遍历字典技巧： 123knights = &#123;&apos;gallahad&apos;: &apos;the pure&apos;, &apos;robin&apos;: &apos;the brave&apos;&#125;for k, v in knights.items(): print(k, v) 7.数据转换方法：数据类型(数据) 即可。 例如 ： float(“10.00”) Python运算符数值运算符数值运算可以直接运算，运算的结果是精确的 (+、-、、/、%、*、\\) 主要说明：其他运算符于Java一致， /是精确除法，与Java不一样 ** 是幂，返回x的y次幂 // 取整除,向下取接近除数的整数 类似于我们Java中的 “&quot; 注意以上运算符都支持赋值运算，例如： += 、 *=、 //= 类型判断内置的 type() 函数可以用来查询变量所指的对象类型， isinstance()会判断类型是否属于某种类型 位运算与Java一致 逻辑运算符例如：a = 10; b = 20; and： x and y: 布尔”与” - 如果 x 为 False，x and y 返回 False，否则它返回 y 的计算值。 (a and b) 返回 20 or x or y: 布尔”或” - 如果 x 是 True，它返回 x 的值，否则它返回 y 的计算值。 (a or b) 返回 10 not not x: 布尔”非” - 如果 x 为 True，返回 False 。如果 x 为 False，它返回 True。 not(a and b) 返回 False 成员运算符in 如果在指定的序列中找到值返回 True，否则返回 False not in 如果在指定的序列中没有找到值返回 True，否则返回 False 一般用来判断变量在不在集合中，或者指定字符串中包含不包含特定字符串 身份运算符is: 是判断两个标识符是不是引用自一个对象 is not: 是判断两个标识符是不是引用自不同对象 例如：a = 10; b = 20; a is b 返回结果 true is 用于判断两个变量引用对象是否为同一个， == 用于判断引用变量的值是否相等 错误和异常异常即便Python程序的语法是正确的，在运行它的时候，也有可能发生错误。运行期检测到的错误被称为异常，异常的类型有多种，与Java类似 异常处理，使用类似于try-catch语句捕获处理： 12345678for arg in sys.argv[1:]: try: f = open(arg, &apos;r&apos;) except IOError: print(&apos;cannot open&apos;, arg) # 处理异常 else: # else语句表示没有发生任何异常的时候执行的代码块 print(arg, &apos;has&apos;, len(f.readlines()), &apos;lines&apos;) f.close() except就类似于catch，except可以处理多个异常： 12except (RuntimeError, TypeError, NameError): pass 抛出异常Python 使用 raise 语句抛出一个指定的异常，示例： 1raise NameError(&apos;HiThere&apos;) 定义清理行为try 语句还有另外一个可选的子句，它定义了无论在任何情况下都会执行的清理行为，就是finally代码块，具体执行与Java类似： 123456789def divide(x, y): try: result = x / y except ZeroDivisionError: print(&quot;division by zero!&quot;) else: print(&quot;result is&quot;, result) finally: print(&quot;executing finally clause&quot;)","categories":[{"name":"Python","slug":"Python","permalink":"https://jjw-story.github.io/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://jjw-story.github.io/tags/Python/"},{"name":"Python基础","slug":"Python基础","permalink":"https://jjw-story.github.io/tags/Python基础/"}],"author":"JJW"},{"title":"vim","slug":"vim","date":"2019-07-20T04:21:42.000Z","updated":"2019-07-25T02:02:10.245Z","comments":true,"path":"2019/07/20/vim/","link":"","permalink":"https://jjw-story.github.io/2019/07/20/vim/","excerpt":"","text":"vi编辑器vi编辑器是所有Unix及Linux系统下标准的编辑器，它的强大不逊色于任何最新的文本编辑器。 由于对Unix及Linux系统的任何版本，vi编辑器是完全相同的，因此您可以在其他任何介绍vi的地方进一步了解它。Vi也是Linux中最基本的文本编辑器，学会它后，您将在Linux的世界里畅行无阻。 vim vi的多模式 正常模式(Normal-mode) 启动vim后默认处于正常模式，其他模式都可以用ESC键直接转换到正常模式。在这个模式我们键盘所敲的任何按键都是对vim所下的命令，如何进行复制如何进行粘贴都是要在这个模式下进行的。 命令模式(Command-mode) 是指可以在界面最底部的一行输入控制操作命令，主要用来进行一些文字编辑的辅助功能，比如字串搜寻、替代、保存文件，以及退出vim等。在命令行模式下输入”:”，或者是使用”?”和”/”键，就可以进入命令模式了。命令模式下输入的命令都会在最底部的一行中显示，按Enter键vim便会执行命令。 插入模式(Insert-mode) 插入模式用来修改文件内容的，只有在Insert mode下，才可以做文字输入，按「ESC」键可回到命令行模式。 可视模式(Visual-mode) 有一些情况我们要进行一个高级编辑，比如对一块文件进行插入操作，就需要进入此模式。相当于高亮选取文本后的普通模式。在命令模式按下v, V, +v，ctrl+v可以进入可视模式。 vim编辑器所有的 Unix Like 系统都会内建 vi 文书编辑器，其他的文书编辑器则不一定会存在，但是目前我们使用比较多的是 vim 编辑器。 vim 具有程序编辑的能力，可以主动的以字体颜色辨别语法的正确性，方便程序设计。 Vim是从 vi 发展出来的一个文本编辑器。代码补完、编译及错误跳转等方便编程的功能特别丰富，在程序员中被广泛使用。 简单的来说，vi 是老式的字处理器，不过功能已经很齐全了，但是还是有可以进步的地方。 vim 则可以说是程序开发者的一项很好用的工具。 vim正常模式首先使用vim命令进入正常模式，使用方法如下： vim [文件] 文件可以不写，类似于我们Windows记事本一样，可以点击一个文本文档打开，或者直接打开记事本进行编写内容。 正常模式常用命令 在正常模式下可以使用 i、I、a、A、o、O 命令进入到插入模式 i 表示从光标当前位置进入插入模式 I 表示从光标当前所在行的行首进入插入模式 a 表示从光标当前位置的下一位进入插入模式 A 表示从光标当前所在行的行尾进图插入模式 o 表示从当前光标所在行的下一行并插入一行进入插入模式 O 表示从当前光标所在行的上一行并插入一行进入插入模式 v命令 正常模式下输入 v 命令可以进入可视模式 :命令 可以进入命令模式，也称为末行模式 esc命令 在其他模式下可以使用 esc 返回到正常模式 h、j、k、l h 光标向左移动 l 光标向右移动 j 光标向下移动 k 光标向上移动 y复制命令 yy:复制光标所在行到缓冲区 nyy:注意n表示行数，表示复制当前行向下n行的内容 y$:复制当前光标所在位置到行尾的内容 yw:与y$效果一致 ny$:注意n表示字数，表示复制当前光标所在位置后n个字符 d剪切命令 dd:剪切光标所在行到缓冲区 ndd:注意n表示行数，表示剪切当前行向下n行的内容 d$:剪切光标所在位置到行尾的内容 dw:与d$效果一致 p粘贴命令 将复制或剪切的内容粘贴到光标所在位置 u撤销命令 撤销命令，可以将失误的操作进行撤销，如果我们连续失误了很多个命令，就多次使用u命令，一条一条撤销 Ctrl + r 重做撤销命令 就是将使用u命令撤销的命令重做，类似于撤回撤销 x命令 删除光标所在的单个字符 r命令 替换光标所在单个字符，使用时先按r键，再输入新的字符 n + G命令 n表示行数，G是大写，既将光标移动到指定的行 如果不指定 n 则直接将光标跳转到文件的最后一行 ^命令 将光标移动到所在行的行尾 $命令 将光标移动到所在行的行首 vim命令模式下面介绍命令模式常用命令操作 :w [文件名] 如果是新建文件，则使用 :w 文件目录+文件名 来将编辑好的内容保存为指定的文件 如果是修改文件，则直接使用 :w 命令保存文件 :q 使用 :q 退出vim w和q命令可以组合起来使用，直接 :wq 来保存并退出vim 注意：:wq 也可以使用快捷键 shift + z z 来实现 :q! 不保存退出 注意：可以使用快捷键 shift + z + q 来实现 :! 有时候我们在打开vim的时候，需要临时执行一条命令，并查看命令执行的结果，就可以使用 ！ 命令 12345678910111213:!ifconfigroot@CHJ-20190520VPS:/# vim /tmp/test.txteth3: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 172.31.34.113 netmask 255.255.255.240 broadcast 172.31.34.127 inet6 fe80::4c47:3429:b72c:5130 prefixlen 64 scopeid 0x0&lt;global&gt; ether 7e:15:d8:27:73:38 (Ethernet) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 ... / + 字符 向下搜索字符，例如使用 /h 可以在文本中查到h出现的地方，并将光标移动到第一次出现的位置 在查找到的时候，我们还可以使用 “n” 键来将光标移动到下一个此字符出现的位置 还可以使用 “shift + n” 来向上查到此字符出现的位置 ? + 字符 向上搜索字符，例如使用 /h 可以在文本中查到h出现的地方，并将光标移动到第一次出现的位置 在查找到的时候，我们还可以使用 “n” 键来将光标移动到下一个此字符出现的位置 还可以使用 “shift + n” 来向上查到此字符出现的位置 :s/旧的字符/新的字符 此命令的作用是将文本中旧的字符替换成新的字符，模式只是将光标当前所在行的字符替换 我们还可以将文本中每一行第一次出现的指定字符替换，可以使用命令 “:%s/旧的字符/新的字符” 如果我们需要将文本跟中所有的指定的字符替换为新的字符，就需要使用命令 “:%s/旧的字符/新的字符/g” ，命令中的g表示global 1234567891011sdaaaaaaaaaaaaaaaaaaaaaasdfsdaaaaasddsaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaag:%s/a/0/gsd0000000000000000000000sdfsd00000sdds00000000000000000000000000000000000000000000g 有的时候我们需要替换指定的行的特定字符，则需要使用命令 “:3,5/s/旧的字符/新的字符/g”, 表示将第3-5行中的旧的字符替换 :set命令 :set nu: 表示设置显示文本的行号 :set nonu: 表示关闭显示文本的行号 :set hlsearch 在使用查找字符命令时，高亮显示查找到的所有字符 :set nohlsearch 关闭查找字符高亮显示 默认情况下，我们使用set命令设置只在当次vim命令中生效，当我们下次进入vim的时候，set命令设置的东西就又会恢复为默认，这样的话很多时候回造成不必要的麻烦，如果我们需要将set命令设置的内容保存，以便于每次打开都能用，例如 set nu 命令，我们希望每次打开vim编辑文本的时候都能显示行号，这样的话，就需要去修改vim的配置文件，配置文件目录为：/etc/vim/vimrc 我们直接使用 vim /etc/vim/vimrc 命令编辑此配置文件，然后使用 G 命令直接将光标跳转到最后一行，然后使用命令 o 向下插入一行空行，直接编辑我们要设置的内容即可 添加如下： 123456&quot; Source a global configuration file if availableif filereadable(&quot;/etc/vim/vimrc.local&quot;) source /etc/vim/vimrc.localendifset nu 编辑完成之后，使用 esc 退出编辑模式，使用 :wq 保存并退出，这样当我们每次打开文件的时候就都会显示行号 vim插入模式 字符按键以及Shift组合，输入字符 ENTER，回车键，换行 BACK SPACE，退格键，删除光标前一个字符 DEL，删除键，删除光标后一个字符 方向键，在文本中移动光标 HOME/END，移动光标到行首/行尾 Page Up/Page Down，上/下翻页 Insert，切换光标为输入/替换模式，光标将变成竖线/下划线 ESC，退出输入模式，切换到命令模式 vim可视模式可视模式主要是针对于我们对文件的大量操作使用此模式一次性执行完成，通常我们都是配合 “I”, “d” 命令来快捷操作 可以在正常模式下使用 v、V、Ctrl + v三种方式进入: 命令 进入字符可视模式，字符可视模式就是当我们移动光标的时候，它是以字符为单位进行选择的 V 进入行可视模式，当我们移动光标的时候是对行进行选中 Ctrl + v 进入块可视模式，移动光标时选中的是上下对齐的一个块，此命令是使用较多的命令 使用示例如下： 我们要在多个行中同时插入一下字符，就可以使用vim先打开文件，然后使用 “Ctrl + v” 选中要操作的多个行为块，然后输入 “I” 命令进入行首进行编辑，插入我们要插入的字符后，连续按两次 esc 按键，就会发现，之前选中的行都被添加进去了我们新添加的字符 1234567891011 18 tyutyutyutyutyustyukcdefsdf 19 sdfsdf 20 sdf 21 sdf# 操作完成后 18 wangjia3tyutyutyutyutyustyukcdefsdf 19 wangjia3sdfsdf 20 wangjia3sdf 21 wangjia3sdf 也可以使用 “d” 命令，将选中的块或字符直接删除，使用方法同上，在块选择后，直接输入 d 即可完成删除，此命令比较常用","categories":[{"name":"Linux","slug":"Linux","permalink":"https://jjw-story.github.io/categories/Linux/"}],"tags":[{"name":"command","slug":"command","permalink":"https://jjw-story.github.io/tags/command/"},{"name":"vim","slug":"vim","permalink":"https://jjw-story.github.io/tags/vim/"}],"author":"JJW"},{"title":"打包压缩与解压缩","slug":"打包压缩与解压缩","date":"2019-07-17T11:43:36.000Z","updated":"2019-07-18T12:48:43.436Z","comments":true,"path":"2019/07/17/打包压缩与解压缩/","link":"","permalink":"https://jjw-story.github.io/2019/07/17/打包压缩与解压缩/","excerpt":"","text":"打包压缩与解压缩打包与压缩windows常见压缩文件格式：.rar .zip .7z Linux常见压缩文件格式 ：.tar.gz; .tar.bz2; .tgz; tbz2 在linux系统中，文件的格式与后缀名没有关系，一般压缩工具压缩之后会在压缩文件后添加对应压缩工具的后缀名 在Windows中，打包与压缩是一个软件功能，但是在Linux中，它是由两个软件构成的 打包命令Linux早期的打包命令其实是备份命令，备份的介质是磁带，使用的命令是 tar 可以对打包后的磁带文件进行压缩存储，压缩的命令是 gzip 和 bzip2，所以我们可以看到，打包和压缩的命令是分开的 tar命令打包的使用方法：tar [选项] 打包后的文件名 要打包的文件 注意：tar命令 使用tar命令需要了解它的选项，来帮助我们完成打包过程，常用的选项如下： c 建立压缩档案，及打包必须的参数 f 打包成文件并指定文件名称，切记，这个参数是最后一个参数，后面只能接文件名 使用示例： 123root@CHJ-20190520VPS:/# tar cf /tmp/etc-backup.tar /etctar: Removing leading `/&apos; from member namesroot@CHJ-20190520VPS:/# 如上示例中，我们将 /etc 目录打包成文件，放置在 /tmp 目录下，并指定打包后的文件名称为 etc-backup.tar ，执行命令后提示会把根目录开头的斜杠 “/“ 去掉，方便我们在解包的时候可以解压到任何目录 压缩命令单纯的打包的打包后的文件一般都很大，因为他并没有做过压缩，一般我们都会在存储的时候进行压缩，如上述打包文件的大小： 12root@CHJ-20190520VPS:/# ls -lh /tmp/etc-backup.tar-rw-r--r-- 1 root root 2.7M Jul 17 20:11 /tmp/etc-backup.tar 通常使用的压缩命令有 gzip bzip2 使用方法如下： gzip [文件名] bzip2 [文件名] 1234root@CHJ-20190520VPS:/# gzip /tmp/etc-backup.tarroot@CHJ-20190520VPS:/# ls -lh /tmptotal 488K-rw-r--r-- 1 root root 459K Jul 17 20:40 etc-backup.tar.gz 在我们使用tar命令的时候，其实已经把这两个命令集成进去了，只需要使用的时候添加参数就可以完成压缩解压缩，下面介绍使用此两个压缩命令的tar选项： z 打包文件并使用gzip压缩文件 j 打包文件并使用bzip2压缩文件 一般在使用打包和压缩命令时，为了方便人看到压缩文件是使用哪种压缩方式压缩的文件，对压缩后的文件使用双扩展名，例如 “xxx.tar.xx”，具体使用如下： 12345678910tar: Removing leading `/&apos; from member namesroot@CHJ-20190520VPS:/# tar czf /tmp/etc-backup.tar.gz /etctar: Removing leading `/&apos; from member namesroot@CHJ-20190520VPS:/# ls -lh /tmptotal 1.0Mdrwxr-xr-x 1 root root 4.0K Jul 13 18:34 a-rw-r--r-- 1 root root 437K Jul 17 20:35 etc-backup.tar.bz2-rw-r--r-- 1 root root 459K Jul 17 20:35 etc-backup.tar.gz-rw-r--r-- 1 root root 551 Jul 14 14:03 testtextroot@CHJ-20190520VPS:/# 虽然压缩后的文件都不大，但是能感觉到使用 bzip2 压缩用的时间明显能更长一点，但是 bzip2 压缩后的文件更小一些，因为 bzip2 压缩后的比例更高一些 两种压缩方式都可以，如果我们希望压缩后的比例更高一下，就使用bzip2进行压缩 解压缩命令解压缩我们使用的命令还是 tar 命令，但是需要更换选项 使用方法：tar [参数] 压缩文件 [-C] [解压后目录] 常用选项说明： x 与上述 c 命令对应，x 参数是解压缩参数 f 与上述一致 v 显示所有进程，及压缩或解压明细 C 注意：C是大写，此选项是可以指定解压后的目录地址 使用示例： 12345root@CHJ-20190520VPS:/# ls /tmpetc-backup.tar etc-backup.tar.gz testtextroot@CHJ-20190520VPS:/# tar xf /tmp/etc-backup.tar -C /rootroot@CHJ-20190520VPS:/# ls /rootetc 将/tmp/etc-backup.tar压缩文件解压到 /root 目录下 实际我们见到的很多的压缩文件是 .tbz2 .tgz 的文件，这两种其实是 .tar.bz2 .tar.gz 的缩写，为了方便网络上的传播，将双扩展名的文件进行的缩写 解压我们不需要因为压缩软件的不同而使用不同的选项，只使用标准的 tar 解压就可以，如下： 12345678root@CHJ-20190520VPS:/# ls /tmpetc-backup.tar etc-backup.tar.gz testtextroot@CHJ-20190520VPS:/# tar -xvf /tmp/etc-backup.tar.gz -C /rootetc/etc/.pwd.lock...... 解压文件明细root@CHJ-20190520VPS:/# ls /rootetc","categories":[{"name":"Linux","slug":"Linux","permalink":"https://jjw-story.github.io/categories/Linux/"}],"tags":[{"name":"command","slug":"command","permalink":"https://jjw-story.github.io/tags/command/"},{"name":"打包压缩与解压缩","slug":"打包压缩与解压缩","permalink":"https://jjw-story.github.io/tags/打包压缩与解压缩/"}],"author":"JJW"},{"title":"文本查看命令","slug":"文本查看命令","date":"2019-07-15T05:55:16.000Z","updated":"2019-07-14T06:58:51.714Z","comments":true,"path":"2019/07/15/文本查看命令/","link":"","permalink":"https://jjw-story.github.io/2019/07/15/文本查看命令/","excerpt":"","text":"文本查看命令cat命令显示文本文件内容，适用于查看整体内容，文件内容不多的，将所有的文本内容都显示到终端 使用方法：cat [参数] 文件 参数说明-n 显示的文本的行编号 -e 显示行结束符号$ 示例： 123456root@CHJ-20190520VPS:/tmp# cat -n -E testtext 1 sdf$ 2 $ 3 sd$ 4 f$ 5 ds$ head命令查看文件的开头的内容，默认显示文件开头的前十行 使用方法：head [参数] 文件 参数说明-n 注意：n 表示行数，意为查看文件的前n行内容 1234root@CHJ-20190520VPS:/tmp# head -3 testtextsdfsd tail命令查看文件的末尾的内容，默认显示文件末的后十行 使用方法：tail [参数] 文件 参数说明-n 注意：n 表示行数，意为查看文件的后n行内容 -f 循环读取文本信息，此命令一般用于文件内容在不断变化的文本查看，一般在查看服务器日志内容时使用 当我们看到文件在一直滚动循环查看，想要停止的时候，使用 ctrl + c命令，退出循环查看，即可停止来具体查看 wc命令wc(Word Count)命令的功能为统计指定文件中的字节数、字数、行数，并将统计结果显示输出。 参数说明-l 统计文本文件的内容行数，一般我们在使用文本查看命令时，不清粗应该使用哪种命令来查看，可以使用此命令来查看文本的行数，然后选择要使用的文本查看命令 12root@CHJ-20190520VPS:/tmp# wc -l testtext206 testtext -c 统计字节数 -m 统计字符数。这个标志不能与 -c 标志一起使用 -w 统计字数。一个字被定义为由空白、跳格或换行字符分隔的字符串 -L 打印最长行的长度 12root@CHJ-20190520VPS:/tmp# wc -L testtext7 testtext more命令分页显示文件内容，还支持直接跳转行等功能，最大的特点是查看每一页文本内容下方都会显示当前当前查看的文本内容所在位置百分比 使用方法：more 文件名 具体操作 Space：显示文本下一屏内容 Enter：只显示文本下一行内容 b：显示文本上一屏内容 q：退出 less命令分页显示文件内容，操作比more更为详细 使用方法：less [参数] 文件名 参数说明-m 显示类似more命令的百分比 -N 注意这里是大写N，显示每行的行号 具体操作 Space：显示文本下一屏内容 b：显示文本上一屏内容 Enter：前进一行 v：后退一行 d：前进半页 u：后退半页 /字符串 向下搜索 ?字符串 向上搜索 左右方向键 相当于水平滚动条 q键：退出","categories":[{"name":"Linux","slug":"Linux","permalink":"https://jjw-story.github.io/categories/Linux/"}],"tags":[{"name":"command","slug":"command","permalink":"https://jjw-story.github.io/tags/command/"},{"name":"文本查看命令","slug":"文本查看命令","permalink":"https://jjw-story.github.io/tags/文本查看命令/"}],"author":"JJW"},{"title":"文件管理命令","slug":"文件管理命令","date":"2019-07-11T12:32:46.000Z","updated":"2019-07-14T05:53:08.747Z","comments":true,"path":"2019/07/11/文件管理命令/","link":"","permalink":"https://jjw-story.github.io/2019/07/11/文件管理命令/","excerpt":"","text":"文件管理命令mkdir命令创建目录 使用方法：mkdir [参数] [目录…] 省略号代表可以建立多个目录 例如：建立一个 demo 目录 在根目录下建立：mkdir /demo 在当前目录下建立：mkdir ./demo “./“可以省略 建立多个目录：mkdir demo1 demo2 demo3 如果目录已存在，建立会失败 12root@CHJ-20190520VPS:/# mkdir homemkdir: cannot create directory ‘home’: File exists 参数的使用-p 一次创建多级目录，既父目录不存在先创建父目录 123456789101112root@CHJ-20190520VPS:/# mkdir -p a/b/c/droot@CHJ-20190520VPS:/# ls -R /a/a:b/a/b:c/a/b/c:d/a/b/c/d: 相比Windows，我们发现命令行的好处就在于可以一次创建多级目录 -v 显示目录创建的过程 123root@CHJ-20190520VPS:/# mkdir -p -v /e/fmkdir: created directory &apos;/e&apos;mkdir: created directory &apos;/e/f&apos; rmdir命令删除目录 使用方法：rmdir [目录…] 注意：rmdir 只能删除空的目录，删除非空目录会失败，必须逐级删除目录中的文件 12root@CHJ-20190520VPS:/# rmdir armdir: failed to remove &apos;a&apos;: Directory not empty rm命令删除文件或目录 使用方法：rm [参数] [目录…] 参数的使用-i 交互模式，在删除前询问用户是否操作 -r 如果删除的是目录，则需要使用此参数，作用是即使目录是非空的，也能逐级删除，但是每一级都要手动确认 -f 即使原档案属性设为唯读，亦直接删除，无需逐一确认。 特别需要注意这条命令，注意他的目录是可以写多个的，如果我们的命令写成 “rm -r -f / a “，既 不小心在 “/“ 与 “a” 之间多了一个空格，那么系统下所有的文件都会被删除，而且不会有任何提示。 所以我们在使用此项命令时一定要留意检查，避免操作失误 -r -f 可以合并使用： 12345root@CHJ-20190520VPS:/# mkdir -p a/b/c/d/f/eroot@CHJ-20190520VPS:/# rm -rf aroot@CHJ-20190520VPS:/# lsbin boot dev e etc home init lib lib64 media mnt opt proc root run sbin snap srv sys tmp usr varroot@CHJ-20190520VPS:/# cp命令文件复制命令，copy简写 使用方法： cp [参数] [文件…] 目录 cp [参数] [文件] 文件…目录 参数的使用-r 当我们直接使用cp命令复制目录的时候，是会失败的，因为cp命令本身是只复制文件，递归复制，用于目录的复制操作 12345root@CHJ-20190520VPS:/# cp a /tmpcp: -r not specified; omitting directory &apos;a&apos;root@CHJ-20190520VPS:/# cp -r a /tmproot@CHJ-20190520VPS:/# ls /tmpa -v 复制时显示复制信息，类似进度条，直接复制文件的时候不会有任何提示 12root@CHJ-20190520VPS:/# cp -v /filea /tmp&apos;/filea&apos; -&gt; &apos;/tmp/filea&apos; -p 与文件的属性一起复制，而非使用默认属性，例如文件创建更新时间 -a 与文件的属性一起复制，包括文件的属主，权限等 123456root@CHJ-20190520VPS:/# cp -v -a filea /tmp&apos;filea&apos; -&gt; &apos;/tmp/filea&apos;root@CHJ-20190520VPS:/# ls -l /tmp/filea-rw-r--r-- 1 root root 0 Jul 13 18:47 /tmp/filearoot@CHJ-20190520VPS:/# ls -l filea-rw-r--r-- 1 root root 0 Jul 13 18:47 filea -i 若目标文件已存在，在覆盖时会先询问是否真的操作 123root@CHJ-20190520VPS:/# cp -v -a -i filea /tmpcp: overwrite &apos;/tmp/filea&apos;? yes&apos;filea&apos; -&gt; &apos;/tmp/filea&apos; 注意词命令的第二种语法 表示将文件复制并重命令为自定义名称 12345root@CHJ-20190520VPS:/# cp -v -a -i -r filea /tmp/fileb&apos;filea&apos; -&gt; &apos;/tmp/fileb&apos;root@CHJ-20190520VPS:/# ls /tmpa filea filebroot@CHJ-20190520VPS:/# mv命令mv命令有两个功能，一个是文件及文件夹的移动功能，另一个是重命名功能 使用方法： mv [参数] 源文件 目录…文件名 重命名演示： 1234root@CHJ-20190520VPS:/# mv filea filebroot@CHJ-20190520VPS:/# lsa boot e fileb init lib64 mnt proc run snap sys usrbin dev etc home lib media opt root sbin srv tmp var 注意：重命名的本质其实就是将文件移动 移动演示： 123root@CHJ-20190520VPS:/# mv fileb /tmproot@CHJ-20190520VPS:/# ls /tmpa filea fileb 还可以移动并重命名，使用命令： mv filea /tmp/filec 通配符的使用* *号表示匹配当前目录下所有目录及文件 使用示例，例如我们在 /tmp 目录下创建三个文件 filea、filebb、fileccc，然后使用通配符将此三个文件复制到其他目录下 123456root@CHJ-20190520VPS:/tmp# lsa dira dirb dirc filea fileb filecroot@CHJ-20190520VPS:/# cp /tmp/file* /root@CHJ-20190520VPS:/# lsa boot e filea fileccc init lib64 mnt proc run snap sys usrbin dev etc filebb home lib media opt root sbin srv tmp var ? ? 号与 * 作用相同，但是它只匹配一个字符，* 匹配多个字符 1234567891011root@CHJ-20190520VPS:/# lsa boot e home lib media opt root sbin srv tmp varbin dev etc init lib64 mnt proc run snap sys usrroot@CHJ-20190520VPS:/# ls /tmp/file*/tmp/filea /tmp/filebb /tmp/filecccroot@CHJ-20190520VPS:/# cp -v /tmp/file? /&apos;/tmp/filea&apos; -&gt; &apos;/filea&apos;root@CHJ-20190520VPS:/# lsa boot e filea init lib64 mnt proc run snap sys usrbin dev etc home lib media opt root sbin srv tmp var 通过示例我们发现这里只复制过来 filea 目录，所以 ? 表示只匹配一个字符 注意上面我们使用ls命令也是用了通配符，表示通配符可以在很多命令中使用","categories":[{"name":"Linux","slug":"Linux","permalink":"https://jjw-story.github.io/categories/Linux/"}],"tags":[{"name":"command","slug":"command","permalink":"https://jjw-story.github.io/tags/command/"},{"name":"文件管理命令","slug":"文件管理命令","permalink":"https://jjw-story.github.io/tags/文件管理命令/"}],"author":"JJW"},{"title":"文件查看命令","slug":"文件查看命令","date":"2019-07-08T04:55:40.000Z","updated":"2019-07-27T06:23:23.261Z","comments":true,"path":"2019/07/08/文件查看命令/","link":"","permalink":"https://jjw-story.github.io/2019/07/08/文件查看命令/","excerpt":"","text":"文件查看命令文件管理命令是Linux管理的核心，因为Linux中有一个非常重要的概念-一切皆文件。在Windows系统中存在注册表、设备管理器了等等各种各样的组建来管理Windows，但是在Linux中，我们系统的管理控制等通通都是文件，所以文件管理命令是Linux管理中非常重要的内容。 pwd命令显示出完整的当前活动目录名称 注意：目录结构中 “/“ 目录和 “/root” 目录是两个不同的目录，”/“目录是我们的根目录，”/root”是root用户的家目录 ls命令列出目录的内容 使用方法：ls [选项] [文件名称…] 如果不写文件名称，默认代表当前目录 省略号表示支持多个文件或者目录名称，多个文件或目录中间用空格隔开（可以用多个空格） 查询内容有颜色不同，代表着不同的权限。不同的客户端颜色展示可能不同 ls基本选项说明-l使用详细格式列表，此命令可以直接缩写为 ll 命令执行如下及结果说明： 123456789root@CHJ-20190520VPS:/usr/lib# ls -ltotal 920drwxr-xr-x 1 root root 4096 May 21 22:39 kerneldrwxr-xr-x 1 root root 4096 May 21 22:39 klibcdrwxr-xr-x 1 root root 4096 May 21 22:40 language-selectorlrwxrwxrwx 1 root root 21 Feb 12 16:55 libDeployPkg.so.0 -&gt; libDeployPkg.so.0.0.0-rw-r--r-- 1 root root 31280 Feb 12 16:55 libDeployPkg.so.0.0.0lrwxrwxrwx 1 root root 20 Feb 12 16:55 libguestlib.so.0 -&gt; libguestlib.so.0.0.0-rw-r--r-- 1 root root 22656 Feb 12 16:55 libguestlib.so.0.0.0 一共查询出七列内容，分别表示： 文件属性(占10个字符空间)、拥有的文件数量、文件的创建者、所属的group、文件大小、建档日期、文件名 重点说明文件属性代表的内容： Linux的文件基本上分为三个属性：可读（r），可写（w），可执行（x） 但是这里有十个格子可以添（具体程序实现时，实际上是十个bit位） 第一个小格是特殊表示格，表示目录或连结文件等等，d表示目录，例如drwx——;l表示连结文件，如lrwxrwxrwx;如果是以一横“-”表示，则表示这是文件 其余剩下的格子就以每3格为一个单位，因为Linux是多用户多任务系统，所以一个文件可能同时被许多人使用，所以我们一定要设好每个文件的权限，其文件的权限位置排列顺序是（以-rwxr-xr-x为例）： rwx(Owner)r-x(Group)r-x(Other) 这个例子表示的权限是：使用者自己可读，可写，可执行；同一组的用户可读，不可写，可执行；其它用户可读，不可写，可执行。 另外，有一些程序属性的执行部分不是X,而是S,这表示执行这个程序的使用者，临时可以有和拥有者一样权力的身份来执行该程序。一般出现在系统管理之类的指令或程序，让使用者执行时，拥有root身份。 -a显示全部文件包括隐藏的文件 Linux隐藏文件的目的是为了在用户日常操作中不会误操作或修改掉一些不可修改的文件内容 Linux创建隐藏文件的方式很简单，只需要在文件名前面加一个 “.” 即可 -t按照文件创建或最后修改的时间排序，默认是根据文件的名称来逆向排序 -r逆向排序显示文件 一般是配合 -l 来使用，例如： ls -l -r 如果我们需要按照文件的创建/修改时间来进行逆向排序则可以使用命令 “-t”，例如： ls -l -r -t 可以组合命令，多个参数不需要每个都用空格隔开，例如上述命令，可以写为： ls -lrt -R递归显示文件，就是罗列出当前文件中所有的文件及文件夹，还有子文件夹中的文件夹及文件，都罗列出来 -h将文件大小数据显示转化为可以阅读清楚的大小表示单位 –full-time列出文件完整的日期时间 –color={auto,never,always}用颜色来表示不同的文件类型，大括号内是参数选项 never：从不使用颜色表示不同类型 always：总是使用颜色表示不同类型 auto：根据终端属性自动确定是否使用颜色表示不同类型 cd命令cd命令用于切换当前工作目录至 dirName(目录参数) 使用方法： cd /path/to…绝对路径 cd /path/to…相对路径 注意一些特殊参数： 路径缺省，表示切换到当前用户的目录 ~ 也是切换到当前用户的目录 / 切换到根目录 ../ 切换到上一层目录，注意 “/“ 可以省略也可以 “cd ../..” 切换到上两级目录 - 切换到上一次访问的目录 12345wangjia3@CHJ-20190520VPS:/home$ pwd/homewangjia3@CHJ-20190520VPS:/home$ cd -/usr/local/libwangjia3@CHJ-20190520VPS:/usr/local/lib$ 当我们要切换的目录离根目录比较近，那就使用绝对路径 当我们要切换的目录离当前目录比较近，那就使用相对路径","categories":[{"name":"Linux","slug":"Linux","permalink":"https://jjw-story.github.io/categories/Linux/"}],"tags":[{"name":"command","slug":"command","permalink":"https://jjw-story.github.io/tags/command/"},{"name":"文件查看命令","slug":"文件查看命令","permalink":"https://jjw-story.github.io/tags/文件查看命令/"}],"author":"JJW"},{"title":"IDEA快捷键","slug":"IDEA快捷键","date":"2019-07-07T10:00:00.000Z","updated":"2019-11-20T01:37:16.449Z","comments":true,"path":"2019/07/07/IDEA快捷键/","link":"","permalink":"https://jjw-story.github.io/2019/07/07/IDEA快捷键/","excerpt":"","text":"IDEA快捷键 向上箭头 ctrl+i 向上一行选中 ctrl+shfit+i 当前行内容向上移动一行 ctrl+alt+i 当前行内容向上插入复制一行 ctrl+shift+alt+i 向下箭头 ctrl+k 向下选中一行 ctrl+shift+k 当前行内容向下移动一行 ctrl+alt+k 当前行内容向下插入复制一行 ctrl+shift+alt+k END ctrl+o 选中到END ctrl+shift+o HOME ctrl+u 选中到HOME ctrl+shift+u 向左移动一个单词 ctrl+j 向左移动一个字母 ctrl+alt+j 向左选中一个单词 ctrl+shift+j 向左选中一个字母 ctrl+shift+alt+j 向右移动一个单词 ctrl+l 向右移动一个字母 ctrl+alt+l 向右选中一个单词 ctrl+shift+l 向右选中一个字母 ctrl+shift+alt+l 打开行数跳转框 ctrl+g 切换到上一个编辑窗口 ctrl+, 切换到下一个编辑窗口 ctrl+. 关闭当前编辑窗口 ctrl+w 打开查找框 ctrl+f3 向下查找 f3 向上查找 shift+f3 显示意图动作 ctrl+空格，alt+enter project框移动 ctrl+i，ctrl+k 打开关闭：enter 删除一行 ctrl+alt+d 打开各种功能框 alt+功能框框对应数字 打开接口实现类，进入方法内部，获取方法在哪里被调用（类似eclipse的ctrl+alt+h） ctrl+b或者ctrl+shift+F7 RUN shift+f9 DEBUG shift+f10 括号跳转（头-尾） ctrl+m+b 当前文件文本查找 ctrl+f 查找文件（查找类文件） 双击shift project中查找包含指定文本的文件 ctrl+shift+f 查看某个类包含的所有属性方法 ctrl+F12 打开后可以直接输入方法名查找过滤，对应Eclipse ctrl+o","categories":[{"name":"IDEA","slug":"IDEA","permalink":"https://jjw-story.github.io/categories/IDEA/"}],"tags":[{"name":"IDEA","slug":"IDEA","permalink":"https://jjw-story.github.io/tags/IDEA/"}],"author":"JJW"},{"title":"帮助命令","slug":"帮助命令","date":"2019-07-06T12:58:05.000Z","updated":"2019-07-27T05:13:22.166Z","comments":true,"path":"2019/07/06/帮助命令/","link":"","permalink":"https://jjw-story.github.io/2019/07/06/帮助命令/","excerpt":"","text":"man命令man命令 man是manual的缩写（有问题找男人帮忙） 使用方法：man [章数] [命令] 可以查询到要查询的命令具体作用、参数选项、描述等。查看完毕后按 q 退出 man命令本身也是一个命令，所以可以通过 [man man] 命令查看此命令本身的一些帮助文档 man命令帮助内容man命令帮助内容一共可以有九章的帮助内容，分别如下： Commands 用户可从 shell 运行的命令,查询第一章的内容的时候 1 可以省略 System calls 必须由内核完成的功能，系统调用 Library calls 大多数 libs 函数，如 sort(3) 此命令与第三章命令一般是用在我们在编程过程中获取函数的帮助文档使用的 Special files /dev 目录中的文件，第四章和第五章主要是文件的帮助 File formats and conventions /etc/pass 等人类可读的配置文件等格式及说明 Game Macro packages and conveentions 文件系统标准描述，网络协议，ASCII和其他字符集等 System Management commands 类似 mount(8) 等命令，大部分只能由 root 执行 Kernel routes 废弃的章节，原本是想把一些关于核心的文件放在这里 man一共有九个章节的帮助，分为这么多章主要是因为命令和系统调用还有文件有的时候会出现重名的情况，一旦重名，我们只单用一个man不加章节很难区分 例如 passwd 命令，这个命令是进行用户密码设置的命令，但是在我们的 /etc 目录下，还有一个 passwd 的一个配置文件，如果我们只使用 man passwd 的命令，很难区分出到底是对这个命令的帮助文档，还是对这个配置文件的帮助文档，这时，我们就可以通过章节这个参数来进行区分 有的时候我们并不知道要查看的帮助到底是命令还是配置文件等，可以使用 man a [参数] 来详细查看所有的帮助文档，在查看完一条之后，按 q 退出，即会提示有其他条的帮助文档，我们可以选择查看 man命令说明页含义 标头 含义 Name 命令的名称和用途 Synopsis 命令语法 Description 完整描述 Environment 命令使用的环境变量 Author 开发该程序者 Files 对该命令重要的文件列表 See also 相关信息 Diagnostics 可能的错误和警告 Bugs （可能没有） help命令help命令也是帮助命令，它使用分为内部命令使用帮助、外部命令使用帮助 内部命令和外部命令shell（命令解释器）自带的命令成为内部命令，其他的是外部命令 内部命令内部命令实际上是shell程序的一部分，其中包含的是一些比较简单的linux系统命令，这些命令由shell程序识别并在shell程序内部完成运行，通常在linux系统加载运行时shell就被加载并驻留在系统内存中。内部命令是写在bashy源码里面的，其执行速度比外部命令快，因为解析内部命令shell不需要创建子进程。比如：exit，history，cd，echo等。 外部命令外部命令是linux系统中的实用程序部分，因为实用程序的功能通常都比较强大，所以其包含的程序量也会很大，在系统加载时并不随系统一起被加载到内存中，而是在需要时才将其调用内存。通常外部命令的实体并不包含在shell中，但是其命令执行过程是由shell程序控制的。shell程序管理外部命令执行的路径查找、加载存放，并控制命令的执行。外部命令是在bash之外额外安装的，通常放在/bin，/usr/bin，/sbin，/usr/sbin 等等。可通过 “echo $PATH” 命令查看外部命令的存储路径，比如：ls、vi等。 使用type命令区分内外部命令使用方法：type [命令] 1234root@CHJ-20190520VPS:~# type cdcd is a shell builtinroot@CHJ-20190520VPS:~# type mkdirmkdir is /bin/mkdir 内部命令和外部命令最大的区别之处就是性能。内部命令由于构建在shell中而不必创建多余的进程，要比外部命令执行快得多。因此和执行更大的脚本道理一样，执行包含很多外部命令的脚本会损害脚本的性能。 help命令用法 内部命令 help [命令] 外部命令 [命令] --help 帮助命令总结Linux的基本操作方式是命令行，通过命令行的话就需要熟记很多的操作命令，但是海量的命令不适合死记硬背。 当我们使用到陌生的命令的时候，就可以使用 man help 等帮助命令查询它的帮助文档，来帮助我们了解这些命令。 注意：很多内部命令 man 是没有帮助文档的，所以我们使用更多的应该是 help 命令。 which命令查看可执行文件的位置，从全局环境变量PATH里面查找对应的路径，默认是找 bash内所规范的目录，一般用来确认系统中是否安装了指定软件 在PATH变量指定的路径中，搜索某个系统命令的位置，并返回第一个搜索结果 使用方法：which [参数] 命令 -a 打印出PATH中的所有匹配项，而不是仅仅第一个 –skip-dot 跳过PATH中以点开头的目录 –skip-tilde 跳过PATH中以波浪号开头的目录 使用示例： 1234root@CHJ-20190520VPS:~# which shutdown/sbin/shutdownroot@CHJ-20190520VPS:~# which cdroot@CHJ-20190520VPS:~# 注意：我们发现查找 cd 命令竟然没有找到，这是因为 cd 是bash 内建的命令！ 但是 which 默认是找 PATH 内所规范的目录，所以当然一定找不到的","categories":[{"name":"Linux","slug":"Linux","permalink":"https://jjw-story.github.io/categories/Linux/"}],"tags":[{"name":"command","slug":"command","permalink":"https://jjw-story.github.io/tags/command/"},{"name":"帮助命令","slug":"帮助命令","permalink":"https://jjw-story.github.io/tags/帮助命令/"}],"author":"JJW"},{"title":"初识Linux","slug":"什么是Linux","date":"2019-07-06T01:49:19.000Z","updated":"2019-07-07T04:57:08.258Z","comments":true,"path":"2019/07/06/什么是Linux/","link":"","permalink":"https://jjw-story.github.io/2019/07/06/什么是Linux/","excerpt":"","text":"什么是LinuxLinux有两种含义 一种是Linus编写的操作系统的内核 另一种是广义的操作系统 一般我们所说的Linux就是说广义的操作系统 服务端操作系统一般都是使用命令行的方式进行操作,主要因为服务端操作系统与客户端操作系统所做的事情不一样,服务端主要追求稳定 Linux版本内核版本 内核版本分为三个部分,一般使用的是稳定版 稳定版又分为三个版本号，分别是 主版本号 次版本号 末版本号 次版本号为奇数为开发版，偶数为稳定版 发行版本 Red Hat EnterPrise 特点：软件经过专业人员的测试，非常稳定，有大公司支持，但是在技术支持和更新最新的安全漏洞补丁的时候是需要付费的 Fedora 特点：也是Red Hat公司发行的，不同之处是发行方式是组建一个社区，来免费提供操作系统，软件要比上述新，但是没有经过专业的测试，稳定性要差 CentOS 特点：基于Red Hat EnterPrise源代码进行编译的，可以免费试用 Ubuntu 特点：定制了非常华丽的界面，可以直接安装在PC机上进行操作 Debian 特点：与Ubantu一样 终端的使用 图形终端 命令行终端 远程终端（SSH VNC） 通过互联网远程连接终端，实际生产使用较多 Linux常见目录介绍 / 根目录 /root root用户的家目录 /home/username 普通用户的家目录 /etc 配置文件目录 /bin 命令目录 /sbin 管理命令目录 /usr/bin /usr/sbin 系统预装的其他命令","categories":[{"name":"Linux","slug":"Linux","permalink":"https://jjw-story.github.io/categories/Linux/"}],"tags":[{"name":"overview","slug":"overview","permalink":"https://jjw-story.github.io/tags/overview/"}],"author":"JJW"}]}