{"meta":{"title":"JJW-STORY","subtitle":null,"description":null,"author":"JJW","url":"https://jjw-story.github.io","root":"/"},"pages":[{"title":"","date":"2020-04-26T03:11:43.119Z","updated":"2020-04-26T03:11:43.119Z","comments":true,"path":"about/index.html","permalink":"https://jjw-story.github.io/about/index.html","excerpt":"","text":"关于我理想汽车~开发工程师 关于工作城市：北京 关于学习每天都走在学习的大路上 关于座右铭 The Harder You Work, The Luckier You Will Be. (越努力，越幸运) 关于爱好杂乱无章 联系我 Home: JJW-STORE.GITHUB.IO Blog: JJW-STORE.GITHUB.IO Email: JJWSTORY.CHINA@gmail.com GitHub: JJW-STORE WeiBo: JJWStrive"}],"posts":[{"title":"Scala-语法","slug":"Scala-语法","date":"2020-08-06T07:22:56.000Z","updated":"2020-08-06T07:27:53.218Z","comments":true,"path":"2020/08/06/Scala-语法/","link":"","permalink":"https://jjw-story.github.io/2020/08/06/Scala-语法/","excerpt":"","text":"Scala-语法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662package story.jjwimport java.io.IOExceptionimport scala.beans.BeanPropertyimport scala.collection.mutable.ArrayBufferimport scala.util.control.Breaks/** * 除了自己实现main方法之外，还可以继承App Trait，然后将需要在main方法中运行的代码，直接作为object的constructor代码；而且用args可以接受传入的参数 * * App Trait的工作原理为：App Trait继承自DelayedInit Trait，scalac命令进行编译时，会把继承App Trait的object的constructor代码都放到DelayedInit Trait的delayedInit方法中执行 */object HelloWorld extends App &#123; if (args.length &gt; 0) &#123; println(&quot;hello, &quot; + args(0)) &#125; else &#123; println(&quot;Hello World!!!&quot;) &#125;&#125;object One &#123; /** * 就如同java中，如果要运行一个程序，必须编写一个包含main方法类一样；在scala中，如果要运行一个应用程序，那么必须有一个main方法，作为入口 * scala中的main方法定义为def main(args: Array[String])，而且必须定义在object中 */ def main(args: Array[String]): Unit = &#123; // 1. while循环 var n = 10 while (n &gt; 0) &#123; println(n) n = n - 1 &#125; // 2.for循环 val n1 = 10 for (i &lt;- 0 to n1) &#123; println(&quot;n1..&quot; + i) &#125; // 3.for循环遍历字符串 val n2 = &quot;Hello World&quot; for (i &lt;- n2) &#123; println(i) &#125; // 4.跳出循环语句,scala没有提供类似于java的break语句，使用Breaks提供的函数实现 Breaks.breakable &#123; var n = 10 for (i &lt;- &quot;Hello World&quot;) &#123; if (n == 5) &#123; Breaks.break &#125; println(i) n -= 1 &#125; &#125; // 5.多重for循环 for (i &lt;- 1 to 9; j &lt;- 1 to 9) &#123; if (j == 9) &#123; println(i * j) &#125; else &#123; print(i * j + &quot; &quot;) &#125; &#125; // 6.if守卫，取偶数 for (i &lt;- 0 to 9 if i % 2 == 0) &#123; println(i) &#125; // 7.for推导式：构造集合 val vector = for (i &lt;- -1 to 9) yield i println(vector) // 8.函数示例 println(sayHello(&quot;JJW&quot;, 27)) // 9.函数调用默认参数示例 println(sayHello(&quot;SS&quot;)) // 10.斐波那契数列 println(fab(9)) // 11.变长参数 println(sum(1, 2, 3, 4, 5)) // 12.使用序列调用变长参数 println(sum(1 to 5: _*)) // 13.lazy值，如果将一个变量声明为lazy，则只有在第一次使用该变量时，变量对应的表达式才会发生计算 val valueA = &#123; println(&quot;开始初始化valueA&quot;); 1 + 1 &#125; lazy val valueB = &#123; println(&quot;开始初始化valueB&quot;); 1 + 1 &#125; println(valueA) println(valueB) // 14.异常捕获 exceptionProcess(new IOException(&quot;IO 异常&quot;)) // 15.Array 和 ArrayBuffer val arrA = new Array[Int](10) arrA(0) = 10 println(arrA(0)) val arrB = Array(&quot;hello&quot;, &quot;world&quot;) println(arrB(1)) val ab = ArrayBuffer[Int]() ab += 10 ab += (11, 12) ab ++= Array(13, 14) println(ab) ab.trimEnd(3) // 从头截取指定个元素 println(ab) // 指定索引位置插入元素 ab.insert(0, 15) ab.insertAll(2, Array(7, 8, 9)) println(ab) // 删除指定位置元素 ab.remove(1) ab.remove(1, 3) // Array 与 ArrayBuffer 相互转换 println(arrB.toBuffer) println(ab.toArray) // 普通遍历 for (i &lt;- 0 until arrA.length) &#123; println(arrA(i)) &#125; // 跳跃遍历 for (i &lt;- 0 until(ab.length, 2)) &#123; println(ab(i)) &#125; // 增强for for (e &lt;- ab) &#123; println(e) &#125; // 数组一些api println(ab.sum) println(ab.max) scala.util.Sorting.quickSort(arrA) println(ab.mkString(&quot;, &quot;)) println(ab.mkString(&quot;(&quot;, &quot;, &quot;, &quot;)&quot;)) // 使用yield和函数式编程转换数组 // val arrC = Array(1, 2, 3, 4, 5) val arrC = ArrayBuffer(1, 2, 3, 4, 5) val arrD = for (ele &lt;- arrC) yield &#123; ele * 3 &#125; println(arrD) val arrE = arrC.filter(_ % 2 == 1).map(_ * 3) val arrF = arrC.filter &#123; _ % 2 == 0 &#125;.map &#123; _ * 2 &#125; println(&quot;arrE &quot; + arrE) println(&quot;arrF &quot; + arrF) // 16.Map和Tuple // 创建不可变Map val mapA = Map(&quot;JJW&quot; -&gt; 20, &quot;SS&quot; -&gt; 20) // mapA(&quot;JJW&quot;) = 18 map不可变，报错 val mapB = Map((&quot;Leo&quot;, 30), (&quot;Jen&quot;, 25), (&quot;Jack&quot;, 23)) // 创建可变Map val mapC = scala.collection.mutable.Map(&quot;Leo&quot; -&gt; 30, &quot;Jen&quot; -&gt; 25, &quot;Jack&quot; -&gt; 23) mapC(&quot;JJW&quot;) = 18 println(mapC) // Map取值 val age = mapC(&quot;JJW&quot;) val leoAge = if (mapC.contains(&quot;leo&quot;)) mapC(&quot;leo&quot;) else 0 val jenAge = mapC.getOrElse(&quot;Jen&quot;, 0) // 上述简化 // 更新元素 mapC(&quot;JJW&quot;) = 20 // 增加多个元素, 不可变Map元素不可变，不可修改和添加元素，但是可以通过操作得到新的Map mapC += (&quot;Mike&quot; -&gt; 35, &quot;Tom&quot; -&gt; 40) // 移除元素 mapC -= &quot;Mike&quot; // 更新不可变的map val mapD = mapB + (&quot;Mike&quot; -&gt; 36, &quot;Tom&quot; -&gt; 40) // 移除不可变map的元素 val mapE = mapB - &quot;Jack&quot; println(mapC) println(mapB) println(mapD) println(mapE) // 创建空的HashMap val hashMap = new scala.collection.mutable.HashMap[String, String] // 遍历Map // 普通遍历 for ((key, value) &lt;- mapD) &#123; println(key + &quot; &quot; + value) &#125; // 遍历map的key for (key &lt;- mapD.keySet) &#123; println(key) &#125; // 遍历map的value for (value &lt;- mapD.values) &#123; println(value) &#125; // 生成新map，反转key和value val mapF = for ((key, value) &lt;- mapD) yield &#123; (value, key) &#125; println(mapF) // SortedMap 和 LinkedHashMap // SortedMap可以自动对Map的key的排序 val sortedMap = scala.collection.immutable.SortedMap(20 -&gt; &quot;JJW&quot;, 10 -&gt; &quot;SS&quot;, 30 -&gt; &quot;DD&quot;) println(sortedMap) // LinkedHashMap是有序的，根据插入数据的顺序 val linkedHashMap = new scala.collection.mutable.LinkedHashMap[String, Int] linkedHashMap(&quot;leo&quot;) = 30 linkedHashMap(&quot;alice&quot;) = 15 linkedHashMap(&quot;jen&quot;) = 25 println(linkedHashMap) // Tuple // 创建 val tuple2 = (&quot;JJW&quot;, 20) // 访问Tuple tuple2._1 tuple2._2 // zip操作 val names = Array(&quot;leo&quot;, &quot;jack&quot;, &quot;mike&quot;) val ages = Array(30, 24, 26) val nameAges = names.zip(ages) for ((name, age) &lt;- nameAges) &#123; println(name + &quot;: &quot; + age) &#125; // 17.类 // 创建类的对象，并调用其方法 val helloWorld = new HelloWorld helloWorld.sayHello() // 也可以不加括号，如果定义方法时不带括号，则调用方法时也不能带括号 print(helloWorld.getName) // 使用scala自己生成的get set方法 helloWorld.age = 27 println(helloWorld.age) // val修饰的，只生成get方法 println(helloWorld.gender) // 自定义get set方法 helloWorld.myHobby = &quot;玩&quot; println(helloWorld.myHobby) // java式的 get set helloWorld.stature = &quot;178&quot; println(helloWorld.stature) helloWorld.setStature(&quot;180&quot;) println(helloWorld.stature) // Java式的构造函数 val s1 = new Student(&quot;JJW&quot;) val s2 = new Student(&quot;JJW&quot;, 20) // 主constructor创建对象 val t = new Teacher(&quot;JJW&quot;, &quot;学习&quot;, 27) // object定义的类会在第一次使用的时候初始化构造函数，下载再使用的时候构造函数中的内容不会执行 // println(Person.getEyeNum) println(&quot;++++++++++&quot;) val p = Person new Person(&quot;JJW&quot;, 20).sayHello // 使用object class 类的 apply构造伴生对象（此方法很重要，多处都是这样用的） Person(&quot;SS&quot;, 18).sayHello // 抽象类实例化 val pc: PersonC = new StudentC(&quot;JJW&quot;) pc.sayHello // 18.枚举 println(Season(0)) println(Season.withName(&quot;summer&quot;)) for (ele &lt;- Season.values) println(ele) // 19.类型判断 // isInstanceOf和asInstanceOf // 需要使用isInstanceOf判断对象是否是指定类的对象，如果是的话，则可以使用asInstanceOf将对象转换为指定类型 val pa: PersonA = new StudentA var sa: StudentA = null // 判断类型 if (pa.isInstanceOf[StudentA]) &#123; // 转换类型 sa = pa.asInstanceOf[StudentA] &#125; println(sa) // getClass和classOf // isInstanceOf只能判断出对象是否是指定类以及其子类的对象，而不能精确判断出，对象就是指定类的对象 // 如果要求精确地判断对象就是指定类的对象，那么就只能使用getClass和classOf了 println(pa.getClass == classOf[PersonA]) // false println(pa.getClass == classOf[StudentA]) // true // 模式匹配判断，isInstanceOf 式的判断，并不是精确判断，既如果是子类依然会匹配成功 pa match &#123; case per: PersonA =&gt; println(&quot;it&apos;s PersonA&apos;s object&quot;) case _ =&gt; println(&quot;unknown type&quot;) &#125; val pd = new PersonD(&quot;PZ&quot;, &quot;好好学习&quot;) pd.eyeNum = 0 pd.sayHello(&quot;BQ&quot;) // 创建类的对象时，指定该对象混入某个trait val pdd = new PersonD(&quot;PZ&quot;, &quot;好好学习&quot;) with MyLogger pdd.myLog(&quot;为实例混入trait&quot;) // trait一个接口，多个实现，一个类又继承了此多个实现，然后我们调用接口的一个方法，这样会从右到左依次执行每个实现中的这个方法 // 重点：责任链模式 val pe = new PersonE(&quot;JJW&quot;) pe.sayHello &#125; def sayHello(name: String, age: Int = 20) = &#123; if (age &gt; 18) &#123; printf(&quot;你好， %s， 你成年了： %s \\n&quot;, name, age) &#125; else &#123; printf(&quot;你好， %s， 你未成年： %s \\n&quot;, name, age) &#125; age &#125; def fab(n: Int): Int = &#123; if (n &lt;= 1) &#123; 1 &#125; else &#123; fab(n - 1) + fab(n - 2) &#125; &#125; def sum(nums: Int*): Int = &#123; var res = 0 for (num &lt;- nums) &#123; res += num &#125; res &#125; def sum2(nums: Int*): Int = &#123; if (nums.length == 0) &#123; 0 &#125; else &#123; nums.head + sum2(nums.tail: _*) &#125; &#125; def exceptionProcess(err: Exception): Unit = &#123; try &#123; throw err &#125; catch &#123; case e1: IllegalArgumentException =&gt; println(&quot;illegal argument&quot;) case e2: IOException =&gt; println(&quot;io exception&quot;) &#125; &#125;&#125;/** * 定义类 */class HelloWorld &#123; // 如果不希望生成setter和getter方法，则将field声明为private[this] // 定义不带private的var field，JVM会提供public的getter和setter方法 var age = 20; // 而如果使用private修饰field，则生成的getter和setter也是private的 private var name = &quot;leo&quot; // 如果定义val field，则只会生成getter方法 val gender = &quot;男&quot; // 由于field是private的，所以setter和getter都是private，对外界没有暴露；自己可以实现修改field值的方法；自己可以覆盖getter方法 private var hobby = &quot;学习&quot; // Scala的getter和setter方法的命名与java是不同的，是field和field_=的方式 // 如果要让scala自动生成java风格的getter和setter方法，只要给field添加@BeanProperty注解即可 // 此时会生成4个方法，stature: String、stature_=(newValue: String): Unit、getStature(): String、setStature(newValue: String): Unit @BeanProperty var stature: String = _ def myHobby = hobby def myHobby_=(newValue: String) &#123; print(&quot;自定义set方法&quot;) hobby = newValue &#125; def sayHello() &#123; println(&quot;Hello, &quot; + name) &#125; def getName = name&#125;class Student &#123; private var name = &quot;&quot; private var age = 0 def this(name: String) &#123; this() this.name = name &#125; def this(name: String, age: Int) &#123; this(name) this.age = age &#125;&#125;// 主constructor中还可以通过使用默认参数，来给参数默认的值// 如果主constrcutor传入的参数什么修饰都没有，比如name: String，那么如果类内部的方法使用到了，则会声明为private[this] name；否则没有该field，就只能被constructor代码使用而已class Teacher(val name: String, gender: String, val age: Int = 30) &#123; println(&quot;your name is &quot; + name + &quot;, your age is &quot; + age + &quot;, gender is &quot; + gender)&#125;/** * 内部类示例 */class Class &#123; class Student(val name: String) val students = new ArrayBuffer[Student] def getStudent(name: String) = &#123; new Student(name) &#125;&#125;/** * object，相当于class的单个实例，通常在里面放一些静态的field或者method * 第一次调用object的方法时，就会执行object的constructor，也就是object内部不在method中的代码；但是object不能定义接受参数的constructor * 注意，object的constructor只会在其第一次被调用时执行一次，以后再次调用就不会再次执行constructor了 * object通常用于作为单例模式的实现，或者放class的静态成员，比如工具方法 */object Person &#123; private var eyeNum = 2 /** * 通常在伴生对象中实现apply方法，并在其中实现构造伴生类的对象的功能 * 而创建伴生类的对象时，通常不会使用new Class的方式，而是使用Class()的方式，隐式地调用伴生对象得apply方法，这样会让对象创建更加简洁 */ def apply(name: String, age: Int) = new Person(name, age) println(&quot;this Person object!&quot;) // def getEyeNum = eyeNum&#125;/** * 伴生对象 * * 如果有一个class，还有一个与class同名的object，那么就称这个object是class的伴生对象，class是object的伴生类 * 伴生类和伴生对象必须存放在一个.scala文件之中 * /伴生类和伴生对象，最大的特点就在于，互相可以访问private field */class Person(val name: String, val age: Int) &#123; def sayHello = println(&quot;Hi, &quot; + name + &quot;, I guess you are &quot; + age + &quot; years old!&quot; + &quot;, and usually you must have &quot; + Person.eyeNum + &quot; eyes.&quot;)&#125;/** * object继承类示例 * * @param message */abstract class Hello(var message: String) &#123; def sayHello(name: String): Unit&#125;object HelloImpl extends Hello(&quot;hello&quot;) &#123; override def sayHello(name: String) = &#123; println(message + &quot;, &quot; + name) &#125;&#125;/** * scala枚举 */object Season extends Enumeration &#123; val SPRING = Value(0, &quot;spring&quot;) val SUMMER = Value(1, &quot;summer&quot;) val AUTUMN = Value(2, &quot;autumn&quot;) val WINTER = Value(3, &quot;winter&quot;)&#125;/** * Scala中，让子类继承父类，与Java一样，也是使用extends关键字 * 继承就代表，子类可以从父类继承父类的field和method；然后子类可以在自己内部放入父类所没有，子类特有的field和method；使用继承可以有效复用代码 * 子类可以覆盖父类的field和method；但是如果父类用final修饰，field和method用final修饰，则该类是无法被继承的，field和method是无法被覆盖的 */class PersonA &#123; private var name = &quot;leo&quot; val age: Int = 20 def getName = name&#125;class StudentA extends PersonA &#123; private var score = &quot;A&quot; def getScore = score // 重写父类 filed override val age: Int = 27 // 重写父类getName方法 override def getName = &quot;Hi, I&apos;m &quot; + super.getName&#125;/** * 通过子类的主构造函数来调用父类的构造函数(与 Kotlin 一样) * 注意！如果是父类中接收的参数，比如name和age，子类中接收时，就不要用任何val或var来修饰了，否则会认为是子类要覆盖父类的field */class PersonB(val name: String, val age: Int)class StudentB(name: String, age: Int, var score: Double) extends PersonB(name, age) &#123; def this(name: String) &#123; this(name, 0, 0) &#125; def this(age: Int) &#123; this(&quot;leo&quot;, age, 0) &#125;&#125;/** * 子类必须覆盖field，以定义自己的具体field，并且覆盖抽象field，不需要使用override关键字 * * 而一个类中如果有一个抽象方法，那么类就必须用abstract来声明为抽象类，此时抽象类是不可以实例化的，在子类中覆盖抽象类的抽象方法时，不需要使用override关键字 * * 与 Kotlin 一样 */abstract class PersonC(val name: String) &#123; val age: Int def sayHello: Unit&#125;class StudentC(name: String) extends PersonC(name) &#123; val age: Int = 20 def sayHello: Unit = println(&quot;Hello, &quot; + name)&#125;/** * 在Scala中，trait是没有接收参数的构造函数的，这是trait与class的唯一区别 * * Scala中的Triat是一种特殊的概念 * 首先我们可以将Trait作为接口来使用，此时的Triat就与Java中的接口非常类似,在triat中可以定义抽象方法，就与抽象类中的抽象方法一样，只要不给出方法的具体实现即可 * 类可以使用extends关键字继承trait，注意，这里不是implement,在scala中没有implement的概念，无论继承类还是trait，统一都是extends * 类继承trait后，必须实现其中的抽象方法，实现时不需要使用override关键字 * scala不支持对类进行多继承，但是支持多重继承trait，使用with关键字即可 * * Scala中的Triat可以不是只定义抽象方法，还可以定义具体方法 * * Scala中的Triat可以定义具体field，此时继承trait的类就自动获得了trait中定义的field * 但是这种获取field的方式与继承class是不同的：如果是继承class获取的field，实际是定义在父类中的；而继承trait获取的field，就直接被添加到了类中 * * Scala中的Triat可以定义抽象field，而trait中的具体方法则可以基于抽象field来编写 * 但是继承trait的类，则必须覆盖抽象field，提供具体的值 * * 有时我们可以在创建类的对象时，指定该对象混入某个trait，这样，就只有这个对象混入该trait的方法，而类的其他对象则没有 * * 在Scala中，trait也是有构造代码的，也就是trait中的，不包含在任何方法中的代码 * 而继承了trait的类的构造机制如下：1、父类的构造函数执行；2、trait的构造代码执行，多个trait从左到右依次执行；3、构造trait时会先构造父trait，如果多个trait继承同一个父trait，则父trait只会构造一次；4、所有trait构造完毕之后，子类的构造函数执行 * * 重点：在Scala中，trait也可以继承自class，此时这个class就会成为所有继承该trait的类的父类（trait不能直接实例化，跟接口一样） */trait Hellotrait &#123; // 定义具体field var eyeNum: Int = 2 // 定义抽象字段 val msg: String // 定义抽象方法 def sayHello(name: String) // 定义具体方法（类似于Java8 中接口有默认实现一样） def log(message: String) = println(message)&#125;trait MakeFriendsTrait &#123; def makeFriends(name: String)&#125;trait MyLogger&#123; def myLog(msg: String) &#123; println(&quot;log: &quot; + msg) &#125;&#125;class PersonD(val name: String, override val msg: String) extends Hellotrait with MakeFriendsTrait with Serializable &#123; override def sayHello(name: String): Unit = &#123; println(&quot;Hello &quot; + name + &quot; I have &quot; + eyeNum + &quot; eyes; &quot; + msg) &#125; override def makeFriends(name: String): Unit = &#123; println(&quot;Hello friend &quot; + name) log(&quot;log&quot; + name) &#125;&#125;/** * Scala中支持让类继承多个trait后，依次调用多个trait中的同一个方法，只要让多个trait的同一个方法中，在最后都执行super.方法即可 * 类中调用多个trait中都有的这个方法时，首先会从最右边的trait的方法开始执行，然后依次往左执行，形成一个调用链条 * 这种特性非常强大，其实就相当于设计模式中的责任链模式的一种具体实现依赖 * * 注意：要实现责任链这种模式，每种实现中必须要调用 super.(抽象函数) */trait Handler &#123; def handle(data: String) &#123;&#125;&#125;trait DataValidHandler extends Handler &#123; override def handle(data: String) &#123; println(&quot;check data: &quot; + data) super.handle(data) &#125;&#125;trait SignatureValidHandler extends Handler &#123; override def handle(data: String) &#123; println(&quot;check signature: &quot; + data) super.handle(data) &#125;&#125;class PersonE(val name: String) extends SignatureValidHandler with DataValidHandler &#123; def sayHello = &#123; println(&quot;Hello, &quot; + name); handle(name) &#125;&#125;","categories":[{"name":"Scala","slug":"Scala","permalink":"https://jjw-story.github.io/categories/Scala/"}],"tags":[{"name":"Scala","slug":"Scala","permalink":"https://jjw-story.github.io/tags/Scala/"},{"name":"语法","slug":"语法","permalink":"https://jjw-story.github.io/tags/语法/"}],"author":"JJW"},{"title":"Scala-高阶","slug":"Scala-高阶","date":"2020-08-06T07:22:56.000Z","updated":"2020-08-06T07:27:33.593Z","comments":true,"path":"2020/08/06/Scala-高阶/","link":"","permalink":"https://jjw-story.github.io/2020/08/06/Scala-高阶/","excerpt":"","text":"Scala-高阶123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428package story.jjwimport java.io.IOExceptionobject Two &#123; def main(args: Array[String]): Unit = &#123; // 1. 将函数赋值给变量 sayHelloFunc(&quot;JJW&quot;) // 2.匿名函数 sayHelloFuncA(&quot;JJW&quot;) // 3.高阶函数 greeting(sayHelloFunc, &quot;SS&quot;) // 4.scala常用高阶函数 // map: 对传入的每个元素都进行映射，返回一个处理后的元素 val arr = Array(1, 2, 3, 4, 5).map(2 * _) println(arr.toBuffer) // foreach: 对传入的每个元素都进行处理，但是没有返回值 arr.map(2 * _).foreach(println _) // filter: 对传入的每个元素都进行条件判断，如果对元素返回true，则保留该元素，否则过滤掉该元素 var arrA = arr.filter(_ % 3 == 0) println(arrA.toBuffer) // reduceLeft: 从左侧元素开始，进行reduce操作，即先对元素1和元素2进行处理，然后将结果与元素3处理，再将结果与元素4处理，依次类推，即为reduce；reduce操作必须掌握！spark编程的重点！！！ // 下面这个操作就相当于1 * 2 * 3 * 4 * 5 * 6 * 7 * 8 * 9 val sum = (1 to 9).reduceLeft(_ + _) println(sum) // sortWith: 对元素进行两两相比，进行排序 val sortArr = Array(3, 2, 5, 4, 10, 1).sortWith(_ - _ &gt; 0) println(sortArr.toBuffer) // 5.闭包 // 闭包最简洁的解释：函数在变量不处于其有效作用域时，还能够对变量进行访问，即为闭包 // 两次调用getGreetingFunc函数，传入不同的msg，并创建不同的函数返回 // 然而，msg只是一个局部变量，却在getGreetingFunc执行完之后，还可以继续存在创建的函数之中；greetingFuncHello(&quot;JJW&quot;)，调用时，值为&quot;hello&quot;的msg被保留在了函数体内部，可以反复的使用 // 这种变量超出了其作用域，还可以使用的情况，即为闭包 // Scala通过为每个函数创建对象来实现闭包，实际上对于getGreetingFunc函数创建的函数，msg是作为函数对象的变量存在的，因此每个函数才可以拥有不同的msg val greetingFuncHello = getGreetingFunc(&quot;hello&quot;) val greetingFuncHi = getGreetingFunc(&quot;hi&quot;) greetingFuncHello(&quot;JJW&quot;) greetingFuncHi(&quot;SS&quot;) // 6.Curring函数 // Curring函数，指的是，将原来接收两个参数的一个函数，转换为两个函数，第一个函数接收原先的第一个参数，然后返回接收原先第二个参数的第二个函数。 // 在函数调用的过程中，就变为了两个函数连续调用的形式 sum1(1, 1) sum2(1)(1) sum3(1)(1) // 7.集合 // Scala中的集合体系主要包括：Iterable、Seq、Set、Map。其中Iterable是所有集合trait的根trai // Scala中的集合是分成可变和不可变两类集合的，其中可变集合就是说，集合的元素可以动态修改，而不可变集合的元素在初始化之后，就无法修改了。分别对应scala.collection.mutable和scala.collection.immutable两个包。 // 7.1 List // List代表一个不可变的列表 // List的创建 val list = List(1, 2, 3, 4) // List有head和tail，head代表List的第一个元素，tail代表第一个元素之后的所有元素，list.head，list.tail // List有特殊的::操作符，可以用于将head和tail合并成一个List，0 :: list // 7.2 LinkedList // LinkedList代表一个可变的列表，使用elem可以引用其头部，使用next可以引用其尾部 // val l = scala.collection.mutable.LinkedList(1, 2, 3, 4, 5); l.elem; l.next // 7.3 Set // Set代表一个没有重复元素的集合，Set中的元素是乱序的 var s = Set(1, 2, 3) s += 4 println(s) // LinkedHashSet会用一个链表维护插入顺序 val ls = new scala.collection.mutable.LinkedHashSet[Int](); ls += 1; ls += 2; ls += 5 // SortedSet会自动根据key来进行排序 val ss = scala.collection.mutable.SortedSet(&quot;orange&quot;, &quot;apple&quot;, &quot;banana&quot;) // 7.4 Scala的高阶函数，Scala的集合类的map、flatMap、reduce、reduceLeft、foreach等这些函数，就是高阶函数，因为可以接收其他函数作为参数 // map案例实战：为List中每个元素都添加一个前缀 List(&quot;Leo&quot;, &quot;Jen&quot;, &quot;Peter&quot;, &quot;Jack&quot;).map(&quot;name is &quot; + _) // faltMap案例实战：将List中的多行句子拆分成单词 List(&quot;Hello World&quot;, &quot;You Me&quot;).flatMap(_.split(&quot; &quot;)) // foreach案例实战：打印List中的每个单词 List(&quot;I&quot;, &quot;have&quot;, &quot;a&quot;, &quot;beautiful&quot;, &quot;house&quot;).foreach(println(_)) // zip案例实战：对学生姓名和学生成绩进行关联 List(&quot;Leo&quot;, &quot;Jen&quot;, &quot;Peter&quot;, &quot;Jack&quot;).zip(List(100, 90, 75, 83)) // Set(1, 2, 3, 4) =&gt; Set((1,1), (2,1), (3,1), (4,1)) var sp = s.map((_, 1)) println(sp) var sp1 = sp.map(_._2) println(sp1) var sp2 = sp1.reduceLeft(_ + _) println(sp2) // 8.模式匹配 judgeGrade(&quot;JJW&quot;, &quot;dongdong&quot;) processException(new IOException(&quot;报错啦...&quot;)) matchArray(Array(&quot;Leo&quot;, &quot;JJW&quot;, &quot;SS&quot;)) matchList(List(&quot;Leo&quot;, &quot;JJW&quot;, &quot;SS&quot;)) // 9.泛型 // 泛型类 val st = new StudentD[Int](33) println(st.getSchoolId(52)) // 泛型函数 println(st.getCard[String](&quot;身份证&quot;)) // 上下边界 val steA = new StudentE(&quot;JJW&quot;) val steB = new StudentE(&quot;SS&quot;) val pa = new PartyA(steA, steB) pa.play val pb = new PartyB(steA, steB) pb.play // 10.协变和逆变 // enterMeetA(new CardA[Master](&quot;JJW&quot;)) 报错，因为方法形参定义的是CardA[Professional] CardA[+T]，所以在这里只能是比Professional更子级的类 enterMeetA(new CardA[Professional](&quot;JJW&quot;)) enterMeetB(new CardB[Master](&quot;JJW&quot;)) // enterMeetB(new CardB[Professional](&quot;JJW&quot;)) 报错，因为方法形参定义的是CardA[Master] CardA[-T]，所以在这里只能是比Master更父级的类 // 11.隐式转换 // Scala的隐式转换，其实最核心的就是定义隐式转换函数，即implicit conversion function。 // 定义的隐式转换函数，只要在编写的程序内引入，就会被Scala自动使用。Scala会根据隐式转换函数的签名，在程序中使用到隐式转换函数接收的参数类型定义的对象时，会自动将其传入隐式转换函数，转换为另外一种类型的对象并返回。 // 隐式转换的发生时机 // 1、调用某个函数，但是给函数传入的参数的类型，与函数定义的接收参数类型不匹配（案例：特殊售票窗口） // 2、使用某个类型的对象，调用某个方法，而这个方法并不存在于该类型时（案例：超人变身） // 3、使用某个类型的对象，调用某个方法，虽然该类型有这个方法，但是给方法传入的参数类型，与方法定义的接收参数的类型不匹配（案例：特殊售票窗口加强版） val stF = new StudentF(&quot;JJW&quot;) println(buySpecialTicket(stF)) // 隐式转换-装饰器模式 val leo = new Man(&quot;leo&quot;) leo.emitLaser // 隐式转换-隐式参数 // 定义隐式参数 implicit val signPen = new SignPen signForExam(&quot;JJW&quot;) // 12.Actor // Scala提供了Actor trait来让我们更方便地进行actor多线程编程，就Actor trait就类似于Java中的Thread和Runnable一样，是基础的多线程基类和接口。我们只要重写Actor trait的act方法，即可实现自己的线程执行体，与Java中重写run方法类似 // 使用start()方法启动actor；使用!符号，向actor发送消息；actor内部使用receive和模式匹配接收消息 // Scala的Actor模型与Java的多线程模型之间，很大的一个区别就是，Scala Actor天然支持线程之间的精准通信；即一个actor可以给其他actor直接发送消息。这个功能是非常强大和方便的。 val userManageActor = new UserManageActor userManageActor.start() userManageActor ! Register(&quot;JJW&quot;, &quot;5233&quot;) // 默认情况下，消息都是异步的；但是如果希望发送的消息是同步的，即对方接受后，一定要给自己返回结果，那么可以使用!?的方式发送消息。即val reply = actor !? message。 // 如果要异步发送一个消息，但是在后续要获得消息的返回值，那么可以使用Future。即!!语法。val future = actor !! message。val reply = future()。 &#125; // Scala中的函数是一等公民，可以独立定义，独立存在，而且可以直接将函数作为值赋值给变量 // Scala的语法规定，将函数赋值给变量时，必须在函数后面加上空格和下划线 def sayHello(name: String) &#123; println(&quot;Hello, &quot; + name) &#125; val sayHelloFunc = sayHello _ // 可以直接定义函数之后，将函数赋值给某个变量；也可以将直接定义的匿名函数传入其他函数之中 // Scala定义匿名函数的语法规则就是，(参数名: 参数类型) =&gt; 函数体 val sayHelloFuncA = (name: String) =&gt; println(&quot;Hello, &quot; + name) // 直接将某个函数传入其他函数，作为参数，这种函数叫做高阶函数 def greeting(func: (String) =&gt; Unit, name: String): Unit = &#123; func(name) &#125; // Scala通过为每个函数创建对象来实现闭包，实际上对于getGreetingFunc函数创建的函数，msg是作为函数对象的变量存在的，因此每个函数才可以拥有不同的msg def getGreetingFunc(msg: String) = (name: String) =&gt; println(msg + &quot;, &quot; + name) // Curring函数 def sum1(a: Int, b: Int) = a + b def sum2(a: Int) = (b: Int) =&gt; a + b def sum3(a: Int)(b: Int) = a + b // 模式匹配 // Scala的match case可以匹配各种情况，比如变量的类型、集合的元素、有值或无值 // match case中，只要一个case分支满足并处理了，就不会继续判断下一个case分支了 def judgeGrade(name: String, grade: String) &#123; grade match &#123; case &quot;A&quot; =&gt; println(name + &quot;, you are excellent&quot;) case &quot;B&quot; =&gt; println(name + &quot;, you are good&quot;) case &quot;C&quot; =&gt; println(name + &quot;, you are just so so&quot;) // 在case后的条件判断中，不仅仅只是提供一个值，而是可以在值后面再加一个if守卫，进行双重过滤 case _grade if name == &quot;leo&quot; =&gt; println(name + &quot;, you are a good boy, come on, your grade is &quot; + _grade) case _grade =&gt; println(&quot;you need to work harder, your grade is &quot; + _grade) // 如果值为下划线，则代表了不满足以上所有情况下的默认情况如何处理 case _ =&gt; println(&quot;you need to work harder&quot;) &#125; &#125; // 模式匹配-类型匹配 // 语法：case 变量: 类型 =&gt; 代码 def processException(e: Exception): Unit = &#123; e match &#123; case e1: IndexOutOfBoundsException =&gt; println(&quot;IndexOutOfBoundsException: &quot; + e1) case e2: IOException =&gt; println(&quot;IOException: &quot; + e2) case _e: Exception =&gt; println(&quot;Exception: &quot; + _e) &#125; &#125; // 对Array进行模式匹配，分别可以匹配带有指定元素的数组、带有指定个数元素的数组、以某元素打头的数组 def matchArray(arr: Array[String]): Unit = &#123; arr match &#123; case Array(&quot;Leo&quot;) =&gt; println(&quot;Hi, Leo!&quot;) case Array(girl1, girl2, girl3) =&gt; println(&quot;Hi, girls, nice to meet you. &quot; + girl1 + &quot; and &quot; + girl2 + &quot; and &quot; + girl3) case Array(&quot;Leo&quot;, _*) =&gt; println(&quot;Hi, Leo, please introduce your friends to me.&quot;) case _ =&gt; println(&quot;hey, who are you?&quot;) &#125; &#125; def matchList(list: List[String]): Unit = &#123; list match &#123; case &quot;Leo&quot; :: Nil =&gt; println(&quot;Hi, Leo!&quot;) case girl1 :: girl2 :: girl3 :: Nil =&gt; println(&quot;Hi, girls, nice to meet you. &quot; + girl1 + &quot; and &quot; + girl2 + &quot; and &quot; + girl3) case &quot;Leo&quot; :: tail =&gt; println(&quot;Hi, Leo, please introduce your friends to me.&quot;) case _ =&gt; println(&quot;hey, who are you?&quot;) &#125; &#125; // Scala有一种特殊的类型，叫做Option。Option有两种值，一种是Some，表示有值，一种是None，表示没有值 // Option通常会用于模式匹配中，用于判断某个变量是有值还是没有值，这比null来的更加简洁明了 val grades = Map((&quot;JJW&quot;, &quot;A&quot;), (&quot;SS&quot;, &quot;A&quot;)) def matchOption(name: String): Unit = &#123; val grade = grades.get(name) grade match &#123; // 有值 case Some(grade) =&gt; println(&quot;你的成绩是：&quot; + grade) case None =&gt; println(&quot;Sorry, your grade information is not in the system&quot;) &#125; &#125; // 斜边和逆变示例 def enterMeetA(card: CardA[Professional]) &#123; println(&quot;welcome to have this meeting!&quot;) &#125; def enterMeetB(card: CardB[Master]) &#123; println(&quot;welcome to have this meeting!&quot;) &#125; /** * 隐式转换函数 * * Scala默认会使用两种隐式转换，一种是源类型，或者目标类型的伴生对象内的隐式转换函数；一种是当前程序作用域内的可以用唯一标识符表示的隐式转换函数 * 如果隐式转换函数不在上述两种情况下的话，那么就必须手动使用import语法引入某个包下的隐式转换函数，比如import test._ */ implicit def object2SpecialPerson(obj: Object): SpecialPerson = &#123; if (obj.getClass == classOf[StudentF]) &#123; val stu = obj.asInstanceOf[StudentF]; new SpecialPerson(stu.name) &#125; else if (obj.getClass == classOf[Older]) &#123; val older = obj.asInstanceOf[Older]; new SpecialPerson(older.name) &#125; else Nil &#125; var ticketNumber = 0 def buySpecialTicket(p: SpecialPerson) = &#123; ticketNumber += 1 &quot;T-&quot; + ticketNumber &#125; /** * 隐式转换-装饰器模式 */ implicit def man2superman(man: Man): Superman = new Superman(man.name) /** * 隐式转换-隐式参数的使用示例 */ def signForExam(name: String) (implicit signPen: SignPen) &#123; signPen.write(name + &quot; come to exam in time.&quot;) &#125;&#125;// 泛型类class StudentD[T](val localId: T) &#123; def getSchoolId(id: T) = &quot;S-&quot; + id + &quot;-&quot; + localId // 泛型函数 def getCard[E](content: E) = &#123; if (content.isInstanceOf[Int]) &#123; &quot;card: 001, &quot; + content &#125; else if (content.isInstanceOf[String]) &#123; &quot;card: this is your card, &quot; + content &#125; else &#123; &quot;card: &quot; + content &#125; &#125;&#125;// 上边界 &lt;: 符号// 在指定泛型类型的时候，有时，我们需要对泛型类型的范围进行界定，而不是可以是任意的类型。class PersonF(val name: String) &#123; def sayHello = println(&quot;Hello, I&apos;m &quot; + name) def makeFriends(p: PersonF) &#123; sayHello p.sayHello &#125;&#125;class StudentE(name: String) extends PersonF(name)class PartyA[T &lt;: PersonF](p1: T, p2: T) &#123; def play = p1.makeFriends(p2)&#125;// 下边界 &gt;: 符号// 下边界，即指定泛型类型必须是某个类的父类class PartyB[T &gt;: StudentE](p1: T, p2: T) &#123; def play = &#123; if (p1.getClass == classOf[PersonF]) println(&quot;PersonF&quot;) else if (p1.getClass == classOf[StudentE]) println(&quot;StudentE&quot;) else println(&quot;error&quot;) &#125;&#125;/** * Scala的协变和逆变是非常有特色的！完全解决了Java中的泛型的一大缺憾！ * * 举例来说，Java中，如果有Professional是Master的子类，那么Card[Professionnal]是不是Card[Master]的子类？答案是：不是。因此对于开发程序造成了很多的麻烦。 */class Masterclass Professional extends Master// 大师以及大师级别以下的名片都可以进入会场class CardA[+T](val name: String)// 只要专家级别的名片就可以进入会场，如果大师级别的过来了，当然可以了！class CardB[-T](val name: String)/** * 隐式转换 * * 基础示例 */class SpecialPerson(val name: String)class StudentF(val name: String)class Older(val name: String)/** * 隐式转换-增强类型（装饰器模式） */class Man(val name: String)class Superman(val name: String) &#123; def emitLaser = println(&quot;emit a laster!&quot;)&#125;/** * 隐式参数 */class SignPen &#123; def write(content: String) = println(content)&#125;/** * Actor * 在scala中，通常建议使用样例类，即case class来作为消息进行发送。然后在actor接收消息之后，可以使用scala强大的模式匹配功能来进行不同消息的处理。 */case class Login(username: String, password: String)case class Register(username: String, password: String)class UserManageActor extends Actor &#123; def act(): Unit = &#123; while (true) &#123; receive &#123; case Login(username, password) =&gt; println(&quot;login, username is &quot; + username + &quot;, password is &quot; + password) case Register(username, password) =&gt; println(&quot;Register, username is &quot; + username + &quot;, password is &quot; + password) &#125; &#125; &#125;&#125;/** * 两个Actor之间要互相收发消息 * 一个actor向另外一个actor发送消息时，同时带上自己的引用；其他actor收到自己的消息时，直接通过发送消息的actor的引用，即可以给它回复消息。 */case class Message(content: String, sender: Actor)class JJWTelephoneActor extends Actor &#123; def act(): Unit = &#123; while (true) &#123; receive &#123; case Message(content, sender) =&gt; &#123; println(&quot;JJW telephone: &quot; + content) sender ! &quot;I&apos;m JJW, please call me after 10 minutes.&quot; &#125; &#125; &#125; &#125;&#125;class SSTelephoneActor(val jjwTelephoneActor: Actor) extends Actor &#123; def act(): Unit = &#123; jjwTelephoneActor ! Message(&quot;Hello JJW, , I&apos;m SS.&quot;, this) receive &#123; case resp: String =&gt; println(&quot;ss telephone: &quot; + resp) &#125; &#125;&#125;","categories":[{"name":"Scala","slug":"Scala","permalink":"https://jjw-story.github.io/categories/Scala/"}],"tags":[{"name":"Scala","slug":"Scala","permalink":"https://jjw-story.github.io/tags/Scala/"},{"name":"高阶","slug":"高阶","permalink":"https://jjw-story.github.io/tags/高阶/"}],"author":"JJW"},{"title":"MySQL-实践二","slug":"MySQL-实践二","date":"2020-07-31T08:17:46.000Z","updated":"2020-08-14T06:18:41.060Z","comments":true,"path":"2020/07/31/MySQL-实践二/","link":"","permalink":"https://jjw-story.github.io/2020/07/31/MySQL-实践二/","excerpt":"","text":"binlog 和 redo log详解binlog 的写入机制binlog 的写入逻辑比较简单：事务执行过程中，先把日志写到 binlog cache，事务提交的时候，再把 binlog cache 写到 binlog 文件中。一个事务的 binlog 是不能被拆开的，因此不论这个事务多大，也要确保一次性写入。 系统给 binlog cache 分配了一片内存，每个线程一个，参数 binlog_cache_size 用于控制单个线程内 binlog cache 所占内存的大小。如果超过了这个参数规定的大小，就要暂存到磁盘。事务提交的时候，执行器把 binlog cache 里的完整事务写入到 binlog 中，并清空 binlog cache。每个线程有自己 binlog cache，但是共用同一份 binlog 文件。 binlog cache写入binlog也要经历两步： write，指的就是指把日志写入到文件系统的 page cache，并没有把数据持久化到磁盘，所以速度比较快。 fsync，才是将数据持久化到磁盘的操作。一般情况下，我们认为 fsync 才占磁盘的 IOPS。 write 和 fsync 的时机，是由参数 sync_binlog 控制的： sync_binlog=0 的时候，表示每次提交事务都只 write，不 fsync； sync_binlog=1 的时候，表示每次提交事务都会执行 fsync； sync_binlog=N(N&gt;1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync。 因此，在出现 IO 瓶颈的场景里，将 sync_binlog 设置成一个比较大的值，可以提升性能。在实际的业务场景中，考虑到丢失日志量的可控性，一般不建议将这个参数设成 0，比较常见的是将其设置为 100~1000 中的某个数值。但是，将 sync_binlog 设置为 N，对应的风险是：如果主机发生异常重启，会丢失最近 N 个事务的 binlog 日志。 redo log 的写入机制事务在执行过程中，生成的 redo log 是要先写到 redo log buffer 的。redo log 可能存在的三种状态： 存在 redo log buffer 中，物理上是在 MySQL 进程内存中； 写到磁盘 (write)，但是没有持久化（fsync)，物理上是在文件系统的 page cache 里面； 持久化到磁盘，对应的是 hard disk。 日志写到 redo log buffer 是很快的，wirte 到 page cache 也差不多，但是持久化到磁盘的速度就慢多了。 为了控制 redo log 的写入策略，InnoDB 提供了 innodb_flush_log_at_trx_commit 参数，它有三种可能取值： 设置为 0 的时候，表示每次事务提交时都只是把 redo log 留在 redo log buffer 中; 设置为 1 的时候，表示每次事务提交时都将 redo log 直接持久化到磁盘； 设置为 2 的时候，表示每次事务提交时都只是把 redo log 写到 page cache。 InnoDB 有一个后台线程，每隔 1 秒，就会把 redo log buffer 中的日志，调用 write 写到文件系统的 page cache，然后调用 fsync 持久化到磁盘。 注意，事务执行中间过程的 redo log 也是直接写在 redo log buffer 中的，这些 redo log 也会被后台线程一起持久化到磁盘。也就是说，一个没有提交的事务的 redo log，也是可能已经持久化到磁盘的。 还有两种场景会让一个没有提交的事务的 redo log 写入到磁盘中: 一种是，redo log buffer 占用的空间即将达到 innodb_log_buffer_size 一半的时候，后台线程会主动写盘。注意，由于这个事务并没有提交，所以这个写盘动作只是 write，而没有调用 fsync，也就是只留在了文件系统的 page cache。 另一种是，并行的事务提交的时候，顺带将这个事务的 redo log buffer 持久化到磁盘。假设一个事务 A 执行到一半，已经写了一些 redo log 到 buffer 中，这时候有另外一个线程的事务 B 提交，如果 innodb_flush_log_at_trx_commit 设置的是 1，那么按照这个参数的逻辑，事务 B 要把 redo log buffer 里的日志全部持久化到磁盘。这时候，就会带上事务 A 在 redo log buffer 里的日志一起持久化到磁盘。 通常我们说 MySQL 的双1配置，指的就是 sync_binlog 和 innodb_flush_log_at_trx_commit 都设置成 1。也就是说，一个事务完整提交前，需要等待两次刷盘，一次是 redo log（prepare 阶段），一次是 binlog。 日志逻辑序列号（log sequence number，LSN）LSN 是单调递增的，用来对应 redo log 的一个个写入点。每次写入长度为 length 的 redo log， LSN 的值就会加上 length。LSN 也会写到 InnoDB 的数据页中，来确保数据页不会被多次执行重复的 redo log。 组提交例如我们有三个并发事务 (trx1, trx2, trx3) 在 prepare 阶段，都写完 redo log buffer，持久化到磁盘的过程，对应的 LSN 分别是 50、120 和 160，等 trx1 要开始写盘的时候，这个组里面已经有了三个事务，这时候 LSN 也变成了 160；trx1 去写盘的时候，带的就是 LSN=160，因此等 trx1 返回时，所有 LSN 小于等于 160 的 redo log，都已经被持久化到磁盘；这时候 trx2 和 trx3 就可以直接返回了。 所以，一次组提交里面，组员越多，节约磁盘 IOPS 的效果越好。在并发更新场景下，第一个事务写完 redo log buffer 以后，接下来这个 fsync 越晚调用，组员可能越多，节约 IOPS 的效果就越好。 为了让一次 fsync 带的组员更多，MySQL 有一个很有趣的优化：拖时间，具体流程就是： 1.redo log perpare write -&gt; 2.binlog write -&gt; 3.redo log perpare fsync -&gt; 4.binlog fsync -&gt; 5.redo log commit write; 注意-重点：上述流程都是在redo log 和 binlog 已经写入对应的 cache 中，并且在事务的提交阶段发生的流程，redo log perpare也是在提交阶段。 这么一来，binlog 也可以组提交了。在执行第 4 步把 binlog fsync 到磁盘时，如果有多个事务的 binlog 已经写完了，也是一起持久化的，这样也可以减少 IOPS 的消耗。通常情况下第 3 步执行得会很快，所以 binlog 的 write 和 fsync 间的间隔时间短，导致能集合到一起持久化的 binlog 比较少，因此 binlog 的组提交的效果通常不如 redo log 的效果那么好。 如果你想提升 binlog 组提交的效果，可以通过设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 来实现。 binlog_group_commit_sync_delay 参数，表示延迟多少微秒后才调用 fsync; binlog_group_commit_sync_no_delay_count 参数，表示累积多少次以后才调用 fsync。 这两个条件是或的关系，也就是说只要有一个满足条件就会调用 fsync。所以，当 binlog_group_commit_sync_delay 设置为 0 的时候，binlog_group_commit_sync_no_delay_count 也无效了。 MySQL IO 性能瓶颈提升方法 设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 参数，减少 binlog 的写盘次数。这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间，但没有丢失数据的风险。 将 sync_binlog 设置为大于 1 的值（比较常见是 100~1000）。这样做的风险是，主机掉电时会丢 binlog 日志。 将 innodb_flush_log_at_trx_commit 设置为 2。这样做的风险是，主机掉电的时候会丢数据。 不建议你把 innodb_flush_log_at_trx_commit 设置成 0。因为把这个参数设置成 0，表示 redo log 只保存在内存中，这样的话 MySQL 本身异常重启也会丢数据，风险太大。而 redo log 写到文件系统的 page cache 的速度也是很快的，所以将这个参数设置成 2 跟设置成 0 其实性能差不多，但这样做 MySQL 异常重启时就不会丢数据了，相比之下风险会更小。 总结为什么 binlog cache 是每个线程自己维护的，而 redo log buffer 是全局共用的？回答：MySQL 这么设计的主要原因是，binlog 是不能“被打断的”。一个事务的 binlog 必须连续写，因此要整个事务完成后，再一起写到文件里。而 redo log 并没有这个要求，中间有生成的日志可以写到 redo log buffer 中。redo log buffer 中的内容还能“搭便车”，其他事务提交的时候可以被一起写到磁盘中。 事务执行期间，还没到提交阶段，如果发生 crash 的话，redo log 肯定丢了，这会不会导致主备不一致呢？回答：不会。因为这时候 binlog 也还在 binlog cache 里，没发给备库。crash 以后 redo log 和 binlog 都没有了，从业务角度看这个事务也没有提交，所以数据是一致的。（对应上述组提交流程） 什么情况下会使用双非1配置？ 业务高峰期。一般如果有预知的高峰期，DBA 会有预案，把主库设置成“非双 1”。 备库延迟，为了让备库尽快赶上主库。 批量导入数据的时候。 MySQL主备一致原理主备原理M-S结构假设MySQL集群有两个节点，节点A和节点B。客户端的读写都直接访问节点 A，而节点 B 是 A 的备库，只是将 A 的更新都同步过来，到本地执行。这样可以保持节点 B 和 A 的数据是相同的。需要切换的时候，我们就将客户端读写访问的节点改为 B，而节点 A 是 B 的备库。 这就是主库和备库的使用原理。 一般情况下：我们都将备库设置为只读readonly）模式，原因有如下几点： 有时候一些运营类的查询语句会被放到备库上去查，设置为只读可以防止误操作； 防止切换逻辑有 bug，比如切换过程中出现双写，造成主备不一致； 可以用 readonly 状态，来判断节点的角色。 备库设置成只读，还怎么跟主库保持同步更新呢？readonly 设置对超级 (super) 权限用户是无效的，而用于同步更新的线程，就拥有超级权限。 双M结构双 M 结构和 M-S 结构，其实区别只是多了一条线，即：节点 A 和 B 之间总是互为主备关系。这样在切换的时候就不用再修改主备关系。（区别就是没有备库，不需要将其中一个节点设置为 readonly模式）。 但是，双 M 结构还有一个问题需要解决，业务逻辑在节点 A 上更新了一条语句，然后再把生成的 binlog 发给节点 B，节点 B 执行完这条更新语句后也会生成 binlog。那么，如果节点 A 同时是节点 B 的备库，相当于又把节点 B 新生成的 binlog 拿过来执行了一次，然后节点 A 和 B 间，会不断地循环执行这个更新语句，也就是循环复制了。这个要怎么解决呢？这里归结为循环复制的问题，答案在下面小节解释。 主备数据同步的内部流程主库接收到客户端的更新请求后，执行内部事务的更新逻辑，同时写 binlog。 备库 B 跟主库 A 之间维持了一个长连接。主库 A 内部有一个线程，专门用于服务备库 B 的这个长连接。一个事务日志同步的完整过程是这样的： 在备库 B 上通过 change master 命令，设置主库 A 的 IP、端口、用户名、密码，以及要从哪个位置开始请求 binlog，这个位置包含文件名和日志偏移量。 在备库 B 上执行 start slave 命令，这时候备库会启动两个线程，就是 io_thread 和 sql_thread。其中 io_thread 负责与主库建立连接。 主库 A 校验完用户名、密码后，开始按照备库 B 传过来的位置，从本地读取 binlog，发给 B。 备库 B 拿到 binlog 后，写到本地文件，称为中转日志（relay log）。 sql_thread 读取中转日志，解析出日志里的命令，并执行。 注意：由于多线程复制方案的引入，sql_thread 演化成为了多个线程 binlog的三种格式statement当 binlog_format=statement 时，binlog 里面记录的就是 SQL 语句的原文。 你可以用 show binlog events in ‘master.000001’; 命令看 binlog 中的内容。 statement 格式下，记录到 binlog 里的是语句原文，这样写是有风险的。因为我们执行一条语句，在主库和备库上执行结果又可能是不一样的（例如我们之前学的，MySQL为什么会选错索引，删除的时候用 limit = 1 限制，就会删除的数据不一样），这样就会出现问题。 rowrow格式的binlog记录了非常详细的内容，有server id：事务是在 server_id=xxx 的这个库上执行的。Table_map event：用于说明要操作的表。以及我们插入更新删除数据的所有字段信息，字段值信息，新旧数据信息等，非常全面。 这样就保证了，我们每操作一个数据，读不会出现操作错误的问题，因为我们有数据的所有信息。 mixed为什么会有 mixed 这种 binlog 格式的存在场景？ 因为有些 statement 格式的 binlog 可能会导致主备不一致，所以要使用 row 格式。 但 row 格式的缺点是，很占空间。比如你用一个 delete 语句删掉 10 万行数据，用 statement 的话就是一个 SQL 语句被记录到 binlog 中，占用几十个字节的空间。但如果用 row 格式的 binlog，就要把这 10 万条记录都写到 binlog 中。这样做，不仅会占用更大的空间，同时写 binlog 也要耗费 IO 资源，影响执行速度。 所以，MySQL 就取了个折中方案，也就是有了 mixed 格式的 binlog。mixed 格式的意思是，MySQL 自己会判断这条 SQL 语句是否可能引起主备不一致，如果有可能，就用 row 格式，否则就用 statement 格式。 也就是说，mixed 格式可以利用 statment 格式的优点，同时又避免了数据不一致的风险。 现在越来越多的场景要求把 MySQL 的 binlog 格式设置成 row。原因如下： 比如我们现在执行了一个删除语句，因为row 格式的 binlog 也会把被删掉的行的整行信息保存起来。所以，如果你在执行完一条 delete 语句以后，发现删错数据了，可以直接把 binlog 中记录的 delete 语句转成 insert，把被错删的数据插入回去就可以恢复了。 如果执行的是 update 语句的话，binlog 里面会记录修改前整行的数据和修改后的整行数据。所以，如果你误执行了 update 语句的话，只需要把这个 event 前后的两行信息对调一下，再去数据库里面执行，就能恢复这个更新操作了。 上述循环复制问题解决MySQL 在 binlog 中记录了这个命令第一次执行时所在实例的 server id。因此，我们可以用下面的逻辑，来解决两个节点间的循环复制的问题： 规定两个库的 server id 必须不同，如果相同，则它们之间不能设定为主备关系； 一个备库接到 binlog 并在重放的过程中，生成与原 binlog 的 server id 相同的新的 binlog； 每个库在收到从自己的主库发过来的日志后，先判断 server id，如果跟自己的相同，表示这个日志是自己生成的，就直接丢弃这个日志。 按照这个逻辑，如果我们设置了双 M 结构，日志的执行流就会变成这样： 从节点 A 更新的事务，binlog 里面记的都是 A 的 server id； 传到节点 B 执行一次以后，节点 B 生成的 binlog 的 server id 也是 A 的 server id； 再传回给节点 A，A 判断到这个 server id 与自己的相同，就不会再处理这个日志。所以，死循环在这里就断掉了。 MySQL是如何保证高可用的主备延迟主备切换可能是一个主动运维动作，比如软件升级、主库所在机器按计划下线等，也可能是被动操作，比如主库所在机器掉电。 先说明一个概念，即“同步延迟”。与数据同步有关的时间点主要包括以下三个： 主库 A 执行完成一个事务，写入 binlog，我们把这个时刻记为 T1; 之后传给备库 B，我们把备库 B 接收完这个 binlog 的时刻记为 T2; 备库 B 执行完成这个事务，我们把这个时刻记为 T3。 所谓主备延迟，就是同一个事务，在备库执行完成的时间和主库执行完成的时间之间的差值，也就是 T3-T1。 可以在备库上执行 show slave status 命令，它的返回结果里面会显示 seconds_behind_master，用于表示当前备库延迟了多少秒。 seconds_behind_master 的计算方法是这样的： 每个事务的 binlog 里面都有一个时间字段，用于记录主库上写入的时间； 备库取出当前正在执行的事务的时间字段的值，计算它与当前系统时间的差值，得到 seconds_behind_master。 可以看到，其实 seconds_behind_master 这个参数计算的就是 T3-T1。所以，我们可以用 seconds_behind_master 来作为主备延迟的值，这个值的时间精度是秒。在网络正常的时候，日志从主库传给备库所需的时间是很短的。 所以，主备延迟最直接的表现是，备库消费中转日志（relay log）的速度，比主库生产 binlog 的速度要慢。 主备延迟的来源 备库所在机器的性能要比主库所在的机器性能差。 备库的压力大（由于主库直接影响业务，大家使用起来会比较克制，反而忽视了备库的压力控制。结果就是，备库上的查询耗费了大量的 CPU 资源，影响了同步速度，造成主备延迟。这种情况我们可以使用一主多从。除了备库外，可以多接几个从库，让这些从库来分担读的压力）。 大事务。因为主库上必须等事务执行完成才会写入 binlog，再传给备库。所以，如果一个主库上的语句执行 10 分钟，那这个事务很可能就会导致从库延迟 10 分钟。（一次性地用 delete 语句删除太多数据，这就是一个大事务典型场景。另一种典型的大事务场景，就是大表 DDL） 备库的并行复制能力（下一章节的重点内容）。 可靠性优先策略在双M的架构下，我们可以这样保证数据的可靠性： 判断备库 B 现在的 seconds_behind_master，如果小于某个值（比如 5 秒）继续下一步，否则持续重试这一步； 把主库 A 改成只读状态，即把 readonly 设置为 true； 判断备库 B 的 seconds_behind_master 的值，直到这个值变成 0 为止； 把备库 B 改成可读写状态，也就是把 readonly 设置为 false； 把业务请求切到备库 B。 这个切换流程中是有不可用时间的。因为在步骤 2 之后，主库 A 和备库 B 都处于 readonly 状态，也就是说这时系统处于不可写状态，直到步骤 5 完成后才能恢复。试想如果一开始主备延迟就长达 30 分钟，而不先做判断直接切换的话，系统的不可用时间就会长达 30 分钟，这种情况一般业务都是不可接受的。 可用性优先策略如果强行把上面可靠性优先步骤 4、5 调整到最开始执行，也就是说不等主备数据同步，直接把连接切到备库 B，并且让备库 B 可以读写，那么系统几乎就没有不可用时间了。我们把这个切换流程，暂时称作可用性优先流程。这个切换流程的代价，就是可能出现数据不一致的情况。 大多数情况下，都建议使用可靠性优先策略。毕竟对数据服务来说的话，数据的可靠性一般还是要优于可用性的。 备库并行复制能力为什么要有多线程复制呢？这是因为单线程复制的能力全面低于多线程复制，对于更新压力较大的主库，备库是可能一直追不上主库的。从现象上看就是，备库上 seconds_behind_master 的值越来越大。 日志在备库上的执行，就是主备数据同步流程中备库上 sql_thread 更新数据 (DATA) 的逻辑。如果是用单线程的话，就会导致备库应用日志不够快，造成主备延迟。在官方的 5.6 版本之前，MySQL 只支持单线程复制，由此在主库并发高、TPS 高时就会出现严重的主备延迟问题。 MariaDB 的并行复制策略MariaDB 的并行复制策略利用的是 redo log 组提交 (group commit) 优化 的特性： 能够在同一组里提交的事务，一定不会修改同一行；（重点理解） 主库上可以并行执行的事务，备库上也一定是可以并行执行的。 在实现上，MariaDB 是这么做的： 在一组里面一起提交的事务，有一个相同的 commit_id，下一组就是 commit_id+1； commit_id 直接写到 binlog 里面； 传到备库应用的时候，相同 commit_id 的事务分发到多个 worker 执行； 这一组全部执行完成后，coordinator 再去取下一批。 但是，这个策略有一个问题，它并没有实现“真正的模拟主库并发度”这个目标。在主库上，一组事务在 commit 的时候，下一组事务是同时处于“执行中”状态的。在备库上执行的时候，要等第一组事务完全执行完成后，第二组事务才能开始执行，这样系统的吞吐量就不够。另外，这个方案很容易被大事务拖后腿，例如有三个事务（trx1， trx2， trx3），这一组事务需要全部执行都完成后，coordinator 再去取下一批，假设 trx2 是一个超大事务，那么在备库应用的时候，trx1 和 trx3 执行完成后，就只能等 trx2 完全执行完成，下一组才能开始执行。这段时间，只有一个 worker 线程在工作，是对资源的浪费。 MySQL 5.7 的并行复制策略在 MariaDB 并行复制实现之后，官方的 MySQL5.7 版本也提供了类似的功能，由参数 slave-parallel-type 来控制并行复制策略： 配置为 DATABASE，表示使用 MySQL 5.6 版本的按库并行策略； 配置为 LOGICAL_CLOCK，表示的就是类似 MariaDB 的策略。不过，MySQL 5.7 这个策略，针对并行度做了优化。这个优化的思路也很有趣儿。 同时处于“执行状态”的所有事务，是不是可以并行？答案是，不能。因为，这里面可能有由于锁冲突而处于锁等待状态的事务。如果这些事务在备库上被分配到不同的 worker，就会出现备库跟主库不一致的情况。而上面提到的 MariaDB 这个策略的核心，是“所有处于 commit”状态的事务可以并行。事务处于 commit 状态，表示已经通过了锁冲突的检验了。 其实，不用等到 commit 阶段，只要能够到达 redo log prepare 阶段，就表示事务已经通过锁冲突的检验了。因此，MySQL 5.7 并行复制策略的思想是： 同时处于 prepare 状态的事务，在备库执行时是可以并行的； 处于 prepare 状态的事务，与处于 commit 状态的事务之间，在备库执行时也是可以并行的。 MySQL 5.7.22 的并行复制策略在 2018 年 4 月份发布的 MySQL 5.7.22 版本里，MySQL 增加了一个新的并行复制策略，基于 WRITESET 的并行复制。相应地，新增了一个参数 binlog-transaction-dependency-tracking，用来控制是否启用这个新策略。这个参数的可选值有以下三种： COMMIT_ORDER，表示的就是前面介绍的，根据同时进入 prepare 和 commit 来判断是否可以并行的策略。 WRITESET，表示的是对于事务涉及更新的每一行，计算出这一行的 hash 值，组成集合 writeset。如果两个事务没有操作相同的行，也就是说它们的 writeset 没有交集，就可以并行。（为了唯一标识，这个 hash 值是通过“库名 + 表名 + 索引名 + 值”计算出来的。如果一个表上除了有主键索引外，还有其他唯一索引，那么对于每个唯一索引，insert 语句对应的 writeset 就要多增加一个 hash 值。） WRITESET_SESSION，是在 WRITESET 的基础上多了一个约束，即在主库上同一个线程先后执行的两个事务，在备库执行的时候，要保证相同的先后顺序。 MySQL 官方的这个实现还是有很大的优势： writeset 是在主库生成后直接写入到 binlog 里面的，这样在备库执行的时候，不需要解析 binlog 内容（event 里的行数据），节省了很多计算量； 不需要把整个事务的 binlog 都扫一遍才能决定分发到哪个 worker，更省内存； 由于备库的分发策略不依赖于 binlog 内容，所以 binlog 是 statement 格式也是可以的。 主备切换今天我们要讨论的就是，在一主多从架构下，主库故障后的主备切换问题。 假设我们有一个MySQL集群，主备关系： A 和 A’互为主备， 从库 B、C、D 指向的是主库 A。一主多从的设置，一般用于读写分离，主库负责所有的写入和一部分读，其他的读请求则由从库分担。 基于位点的主备切换当我们把节点 B 设置成节点 A’的从库的时候，需要执行一条 change master 命令： 1234567CHANGE MASTER TOMASTER_HOST=$host_nameMASTER_PORT=$portMASTER_USER=$user_nameMASTER_PASSWORD=$passwordMASTER_LOG_FILE=$master_log_nameMASTER_LOG_POS=$master_log_pos 这条命令有这么 6 个参数：MASTER_HOST、MASTER_PORT、MASTER_USER 和 MASTER_PASSWORD 四个参数，分别代表了主库 A’的 IP、端口、用户名和密码。最后两个参数 MASTER_LOG_FILE 和 MASTER_LOG_POS 表示，要从主库的 master_log_name 文件的 master_log_pos 这个位置的日志继续同步。而这个位置就是我们所说的同步位点，也就是主库对应的文件名和日志偏移量。 节点 B 要设置成 A’的从库，就要执行 change master 命令，就不可避免地要设置位点的这两个参数，但是这两个参数到底应该怎么设置呢？原来节点 B 是 A 的从库，本地记录的也是 A 的位点。但是相同的日志，A 的位点和 A’的位点是不同的。因此，从库 B 要切换的时候，就需要先经过“找同步位点”这个逻辑。这个位点很难精确取到，只能取一个大概位置。 考虑到切换过程中不能丢数据，所以我们找位点的时候，总是要找一个“稍微往前”的，然后再通过判断跳过那些在从库 B 上已经执行过的事务。例如我们找到的位点，但是我们需要稍微往前一点，正好这里面包了了A’库和B库都执行过了的一条插入语句，这样B库在执行的时候，就会把插入 R 这一行数据的 binlog 又同步到从库 B 去执行。这时候，从库 B 的同步线程就会报告 Duplicate entry ‘id_of_R’ for key ‘PRIMARY’ 错误，提示出现了主键冲突，然后停止同步。 通常情况下，我们在切换任务的时候，要先主动跳过这些错误，有两种常用的方法： 主动跳过一个事务。跳过命令的写法是： 12set global sql_slave_skip_counter=1;start slave; 因为切换过程中，可能会不止重复执行一个事务，所以我们需要在从库 B 刚开始接到新主库 A’时，持续观察，每次碰到这些错误就停下来，执行一次跳过命令，直到不再出现停下来的情况，以此来跳过可能涉及的所有事务. 通过设置 slave_skip_errors 参数，直接设置跳过指定的错误: 121062 错误是插入数据时唯一键冲突；1032 错误是删除数据时找不到行 这里需要注意的是，这种直接跳过指定错误的方法，针对的是主备切换时，由于找不到精确的同步位点，所以只能采用这种方法来创建从库和新主库的主备关系。等到主备间的同步关系建立完成，并稳定执行一段时间之后，我们还需要把这个参数设置为空，以免之后真的出现了主从数据不一致，也跳过了。 GTID通过 sql_slave_skip_counter 跳过事务和通过 slave_skip_errors 忽略错误的方法，虽然都最终可以建立从库 B 和新主库 A’的主备关系，但这两种操作都很复杂，而且容易出错。所以，MySQL 5.6 版本引入了 GTID，彻底解决了这个困难。 GTID 的全称是 Global Transaction Identifier，也就是全局事务 ID，是一个事务在提交的时候生成的，是这个事务的唯一标识。它由两部分组成，格式是：GTID=server_uuid:gno server_uuid 是一个实例第一次启动时自动生成的，是一个全局唯一的值； gno 是一个整数，初始值是 1，每次提交事务的时候分配给这个事务，并加 1。 GTID 模式的启动也很简单，我们只需要在启动一个 MySQL 实例的时候，加上参数 gtid_mode=on 和 enforce_gtid_consistency=on 就可以了。 在 GTID 模式下，每个事务都会跟一个 GTID 一一对应。这个 GTID 有两种生成方式，而使用哪种方式取决于 session 变量 gtid_next 的值（重点）。 如果 gtid_next=automatic，代表使用默认值。这时，MySQL 就会把 server_uuid:gno 分配给这个事务。a. 记录 binlog 的时候，先记录一行 SET @@SESSION.GTID_NEXT=‘server_uuid:gno’; b. 把这个 GTID 加入本实例的 GTID 集合。 如果 gtid_next 是一个指定的 GTID 的值，比如通过 set gtid_next=’current_gtid’指定为 current_gtid，那么就有两种可能：a. 如果 current_gtid 已经存在于实例的 GTID 集合中，接下来执行的这个事务会直接被系统忽略；b. 如果 current_gtid 没有存在于实例的 GTID 集合中，就将这个 current_gtid 分配给接下来要执行的事务，也就是说系统不需要给这个事务生成新的 GTID，因此 gno 也不用加 1。 这样，每个 MySQL 实例都维护了一个 GTID 集合，用来对应“这个实例执行过的所有事务”。 基于 GTID 的主备切换在 GTID 模式下，备库 B 要设置为新主库 A’的从库的语法如下： 123456CHANGE MASTER TOMASTER_HOST=$host_nameMASTER_PORT=$portMASTER_USER=$user_nameMASTER_PASSWORD=$passwordmaster_auto_position=1 其中，master_auto_position=1 就表示这个主备关系使用的是 GTID 协议。可以看到，前面让我们头疼不已的 MASTER_LOG_FILE 和 MASTER_LOG_POS 参数，已经不需要指定了。 我们把现在这个时刻，实例 A’的 GTID 集合记为 set_a，实例 B 的 GTID 集合记为 set_b。接下来，我们就看看现在的主备切换逻辑。我们在实例 B 上执行 start slave 命令，取 binlog 的逻辑是这样的： 实例 B 指定主库 A’，基于主备协议建立连接。 实例 B 把 set_b 发给主库 A’。 实例 A’算出 set_a 与 set_b 的差集，也就是所有存在于 set_a，但是不存在于 set_b 的 GTID 的集合，判断 A’本地是否包含了这个差集需要的所有 binlog 事务。a. 如果不包含，表示 A’已经把实例 B 需要的 binlog 给删掉了，直接返回错误；b. 如果确认全部包含，A’从自己的 binlog 文件里面，找出第一个不在 set_b 的事务，发给 B； 之后就从这个事务开始，往后读文件，按顺序取 binlog 发给 B 去执行。 由于不需要找位点了，所以从库 B、C、D 只需要分别执行 change master 命令指向实例 A’即可。其实，严谨地说，主备切换不是不需要找位点了，而是找位点这个工作，在实例 A’内部就已经自动完成了。但由于这个工作是自动的，所以对 HA 系统的开发人员来说，非常友好。 GTID 和在线 DDL业务高峰期的慢查询性能问题时，分析到如果是由于索引缺失引起的性能问题，我们可以通过在线加索引来解决。但是，考虑到要避免新增索引对主库性能造成的影响，我们可以先在备库加索引，然后再切换。 假设，这两个互为主备关系的库还是实例 X 和实例 Y，且当前主库是 X，并且都打开了 GTID 模式。这时的主备切换流程可以变成下面这样： 在实例 X 上执行 stop slave。 在实例 Y 上执行 DDL 语句。注意，这里并不需要关闭 binlog。 执行完成后，查出这个 DDL 语句对应的 GTID，并记为 server_uuid_of_Y:gno。 到实例 X 上执行以下语句序列： 12345set GTID_NEXT=&quot;server_uuid_of_Y:gno&quot;;begin;commit;set gtid_next=automatic;start slave; 这样做的目的在于，既可以让实例 Y 的更新有 binlog 记录，同时也可以确保不会在实例 X 上执行这条更新。 接下来，执行完主备切换，然后照着上述流程再执行一遍即可。 读写分离的主从延迟读写分离的主要目标就是分摊主库的压力。一种架构是：客户端（client）主动做负载均衡，这种模式下一般会把数据库的连接信息放在客户端的连接层。也就是说，由客户端来选择后端数据库进行查询。第二种架构是：在 MySQL 和客户端之间有一个中间代理层 proxy，客户端只连接 proxy， 由 proxy 根据请求类型和上下文决定请求的分发路由。 客户端直连和带 proxy 的读写分离架构，各有哪些特点： 客户端直连方案，因为少了一层 proxy 转发，所以查询性能稍微好一点儿，并且整体架构简单，排查问题更方便。但是这种方案，由于要了解后端部署细节，所以在出现主备切换、库迁移等操作的时候，客户端都会感知到，并且需要调整数据库连接信息。你可能会觉得这样客户端也太麻烦了，信息大量冗余，架构很丑。其实也未必，一般采用这样的架构，一定会伴随一个负责管理后端的组件，比如 Zookeeper，尽量让业务端只专注于业务逻辑开发。 带 proxy 的架构，对客户端比较友好。客户端不需要关注后端细节，连接维护、后端信息维护等工作，都是由 proxy 完成的。但这样的话，对后端维护团队的要求会更高。而且，proxy 也需要有高可用架构。因此，带 proxy 架构的整体就相对比较复杂。 不论使用哪种架构，都会碰到问题：由于主从可能存在延迟，客户端执行完一个更新事务后马上发起查询，如果查询选择的是从库的话，就有可能读到刚刚的事务更新之前的状态。“在从库上会读到系统的一个过期状态”的现象，称为过期读。 处理过期读的方案处理过期读包括以下6种方案： 强制走主库方案； sleep 方案； 判断主备无延迟方案； 配合 semi-sync 方案； 等主库位点方案； 等 GTID 方案 强制走主库方案强制走主库方案其实就是，将查询请求做分类。通常情况下，我们可以将查询请求分为这么两类： 对于必须要拿到最新结果的请求，强制将其发到主库上。 对于可以读到旧数据的请求，才将其发到从库上。 这个方案最大的问题在于，有时候你会碰到“所有查询都不能是过期读”的需求，比如一些金融类的业务。这样的话，你就要放弃读写分离，所有读写压力都在主库，等同于放弃了扩展性。 Sleep 方案主库更新后，读从库之前先 sleep 一下。具体的方案就是，类似于执行一条 select sleep(1) 命令。这个方案的假设是，大多数情况下主备延迟在 1 秒之内，做一个 sleep 可以有很大概率拿到最新的数据。 这个方案比较麻瓜，个人觉得还是不要用了。 判断主备无延迟方案要确保备库无延迟，通常有三种做法： 判断seconds_behind_master 参数的值确保无延迟:每次从库执行查询请求前，先判断 seconds_behind_master 是否已经等于 0。如果还不等于 0 ，那就必须等到这个参数变为 0 才能执行查询请求(seconds_behind_master 的单位是秒，存在精度不够的问题)。 对比位点确保主备无延迟： 12Master_Log_File 和 Read_Master_Log_Pos，表示的是读到的主库的最新位点；Relay_Master_Log_File 和 Exec_Master_Log_Pos，表示的是备库执行的最新位点。 如果 Master_Log_File 和 Relay_Master_Log_File、Read_Master_Log_Pos 和 Exec_Master_Log_Pos 这两组值完全相同，就表示接收到的日志已经同步完成。 对比 GTID 集合确保主备无延迟： 123Auto_Position=1，表示这对主备关系使用了 GTID 协议。Retrieved_Gtid_Set，是备库收到的所有日志的 GTID 集合；Executed_Gtid_Set，是备库所有已经执行完成的 GTID 集合。 如果这两个集合相同，也表示备库接收到的日志都已经同步完成。可见，对比位点和对比 GTID 这两种方法，都要比判断 seconds_behind_master 是否为 0 更准确。 我们上面判断主备无延迟的逻辑，是备库收到的日志都执行完成了。但是，从 binlog 在主备之间状态的分析中，不难看出还有一部分日志，处于客户端已经收到提交确认，而备库还没收到日志的状态。这种情况下，我们去备库做查询，按照我们上面的逻辑，从库认为已经没有同步延迟，但还是没有查到主库上最新的事务，严格地说，就是出现了过期读。所以还是有有几率出现问题。 配合 semi-sync引入半同步复制，也就是 semi-sync replication。semi-sync 做了这样的设计： 事务提交的时候，主库把 binlog 发给从库； 从库收到 binlog 以后，发回给主库一个 ack，表示收到了； 主库收到这个 ack 以后，才能给客户端返回“事务完成”的确认。 也就是说，如果启用了 semi-sync，就表示所有给客户端发送过确认的事务，都确保了备库已经收到了这个日志。这样，semi-sync 配合前面关于位点的判断，就能够确定在从库上执行的查询请求，可以避免过期读。 但是，semi-sync+ 位点判断的方案，只对一主一备的场景是成立的。在一主多从场景中，主库只要等到一个从库的 ack，就开始给客户端返回确认。这时，在从库上执行查询请求，就有两种情况： 如果查询是落在这个响应了 ack 的从库上，是能够确保读到最新数据； 但如果是查询落到其他从库上，它们可能还没有收到最新的日志，就会产生过期读的问题。 判断同步位点的方案还有另外一个潜在的问题，即：如果在业务更新的高峰期，主库的位点或者 GTID 集合更新很快，那么上面的两个位点等值判断就会一直不成立，很可能出现从库上迟迟无法响应查询请求的情况，主库事务一直在发生，GTIO一直在更新，导致从库一直得不到ack结束的状态。 到这里，我们小结一下，semi-sync 配合判断主备无延迟的方案，存在两个问题： 一主多从的时候，在某些从库执行查询请求会存在过期读的现象； 在持续延迟的情况下，可能出现过度等待的问题。 等主库位点方案要理解等主库位点方案，需要介绍一条命令：select master_pos_wait(file, pos[, timeout]); 这条命令的逻辑如下：它是在从库执行的；参数 file 和 pos 指的是主库上的文件名和位置；timeout 可选，设置为正整数 N 表示这个函数最多等待 N 秒。 这个命令正常返回的结果是一个正整数 M，表示从命令开始执行，到应用完 file 和 pos 表示的 binlog 位置，执行了多少事务。除了正常返回一个正整数 M 外，这条命令还会返回一些其他结果，包括： 如果执行期间，备库同步线程发生异常，则返回 NULL； 如果等待超过 N 秒，就返回 -1； 如果刚开始执行的时候，就发现已经执行过这个位置了，则返回 0。 此方案我们执行一个事务然后执行查询语句的具体逻辑如下： trx1 事务更新完成后，马上执行 show master status 得到当前主库执行到的 File 和 Position； 选定一个从库执行查询语句； 在从库上执行 select master_pos_wait(File, Position, 1)； 如果返回值是 &gt;=0 的正整数，则在这个从库执行查询语句； 否则，到主库执行查询语句。 这里我们假设，这条 select 查询最多在从库上等待 1 秒。那么，如果 1 秒内 master_pos_wait 返回一个大于等于 0 的整数，就确保了从库上执行的这个查询结果一定包含了 trx1 的数据。步骤 5 到主库执行查询语句，是这类方案常用的退化机制。因为从库的延迟时间不可控，不能无限等待，所以如果等待超时，就应该放弃，然后到主库去查。你可能会说，如果所有的从库都延迟超过 1 秒了，那查询压力不就都跑到主库上了吗？确实是这样。 GTID 方案MySQL 中同样提供了一个类似的命令：select wait_for_executed_gtid_set(gtid_set, 1); 这条命令的逻辑是：等待，直到这个库执行的事务中包含传入的 gtid_set，返回 0；超时返回 1。 在前面等位点的方案中，我们执行完事务后，还要主动去主库执行 show master status。而 MySQL 5.7.6 版本开始，允许在执行完更新类事务后，把这个事务的 GTID 返回给客户端，这样等 GTID 的方案就可以减少一次查询。这时，等 GTID 的执行流程就变成了： trx1 事务更新完成后，从返回包直接获取这个事务的 GTID，记为 gtid1； 选定一个从库执行查询语句； 在从库上执行 select wait_for_executed_gtid_set(gtid1, 1)； 如果返回值是 0，则在这个从库执行查询语句； 否则，到主库执行查询语句。 跟等主库位点的方案一样，等待超时后是否直接到主库查询，需要业务开发同学来做限流考虑。 MySQL 在执行事务后，返回包中带上 GTID，只需要将参数 session_track_gtids 设置为 OWN_GTID，然后通过 API 接口 mysql_session_track_get_first 从返回包解析出 GTID 的值即可。 小结上述几种方案中，有的方案看上去是做了妥协，有的方案看上去不那么靠谱儿，但都是有实际应用场景的，你需要根据业务需求选择。即使是最后等待位点和等待 GTID 这两个方案，虽然看上去比较靠谱儿，但仍然存在需要权衡的情况。如果所有的从库都延迟，那么请求就会全部落到主库上，这时候会不会由于压力突然增大，把主库打挂了呢？ 在实际应用中，这几个方案是可以混合使用的。比如，先在客户端对请求做分类，区分哪些请求可以接受过期读，而哪些请求完全不能接受过期读；然后，对于不能接受过期读的语句，再使用等 GTID 或等位点的方案。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://jjw-story.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://jjw-story.github.io/tags/MySQL/"},{"name":"实践一","slug":"实践一","permalink":"https://jjw-story.github.io/tags/实践一/"}],"author":"JJW"},{"title":"Spark-入门","slug":"Spark-入门","date":"2020-07-20T09:21:43.000Z","updated":"2020-08-14T02:21:53.327Z","comments":true,"path":"2020/07/20/Spark-入门/","link":"","permalink":"https://jjw-story.github.io/2020/07/20/Spark-入门/","excerpt":"","text":"Spark介绍Spark，是一种通用的大数据计算框架，正如传统大数据技术Hadoop的MapReduce、Hive引擎，以及Storm流式实时计算引擎等。 Spark使用Spark RDD、Spark SQL、Spark Streaming、MLlib、GraphX成功解决了大数据领域中，离线批处理、交互式查询、实时流计算、机器学习与图计算等最重要的任务和问题。 Spark主要用于大数据的计算，而Hadoop以后主要用于大数据的存储（比如HDFS、Hive、HBase等），以及资源调度（Yarn）。Spark+Hadoop的组合，是未来大数据领域最热门的组合，也是最有前景的组合！ Spark除了一站式的特点之外，另外一个最重要的特点，就是基于内存进行计算，从而让它的速度可以达到MapReduce、Hive的数倍甚至数十倍！ Spark特点 速度快：Spark基于内存进行计算（当然也有部分计算基于磁盘，比如shuffle）。 容易上手开发：Spark的基于RDD的计算模型，比Hadoop的基于Map-Reduce的计算模型要更加易于理解，更加易于上手开发，实现各种复杂功能，比如二次排序、topn等复杂操作时，更加便捷。 超强的通用性：Spark提供了Spark RDD、Spark SQL、Spark Streaming、Spark MLlib、Spark GraphX等技术组件，可以一站式地完成大数据领域的离线批处理、交互式查询、流式计算、机器学习、图计算等常见的任务。 集成Hadoop：Spark并不是要成为一个大数据领域的“独裁者”，一个人霸占大数据领域所有的“地盘”，而是与Hadoop进行了高度的集成，两者可以完美的配合使用。Hadoop的HDFS、Hive、HBase负责存储，YARN负责资源调度；Spark复杂大数据计算。实际上，Hadoop+Spark的组合，是一种“double win”的组合。Spark本身并不提供大数据的存储。 极高的活跃度：Spark目前是Apache基金会的顶级项目，全世界有大量的优秀工程师是Spark的committer。并且世界上很多顶级的IT公司都在大规模地使用Spark。 Spark与Hadoop对比Spark，是分布式计算平台，是一个用scala语言编写的计算框架，基于内存的快速、通用、可扩展的大数据分析引擎。 Hadoop，是分布式管理、存储、计算的生态系统；包括HDFS，Hive，HBase（存储）、MapReduce（计算）、Yarn（资源调度） MapReduce：我们要数图书馆中的所有书。你数1号书架，我数2号书架。这就是“Map”。我们人越多，数书就更快。现在我们到一起，把所有人的统计数加在一起。这就是“Reduce”。 Hadoop和Spark都是并行计算，两者都是用MR模型进行计算。Hadoop一个作业称为一个Job，Job里面分为Map Task和Reduce Task阶段，每个Task都在自己的进程中运行，当Task结束时，进程也会随之结束；Spark用户提交的任务称为application，一个application对应一个SparkContext，app中存在多个job，每触发一次action操作就会产生一个job。这些job可以并行或串行执行，每个job中有多个stage，stage是shuffle过程中DAGScheduler通过RDD之间的依赖关系划分job而来的，每个stage里面有多个task，组成taskset，由TaskScheduler分发到各个executor中执行；executor的生命周期是和app一样的，即使没有job运行也是存在的，所以task可以快速启动读取内存进行计算。 ps：一个Application -&gt; 多个job -&gt;一个job多个stage -&gt; 一个stage多个task 两者的各方面比较 Spark对标于Hadoop中的计算模块MR，但是速度和效率比MR要快得多； Spark没有提供文件管理系统，所以，它必须和其他的分布式文件系统进行集成才能运作，它只是一个计算分析框架，专门用来对分布式存储的数据进行计算处理，它本身并不能存储数据； Spark可以使用Hadoop的HDFS或者其他云数据平台进行数据存储，但是一般使用HDFS； Spark可以使用基于HDFS的HBase数据库，也可以使用HDFS的数据文件，还可以通过jdbc连接使用Mysql数据库数据；Spark可以对数据库数据进行修改删除，而HDFS只能对数据进行追加和全表删除； Spark数据处理速度秒杀Hadoop中MR； Spark处理数据的设计模式与MR不一样，Hadoop是从HDFS读取数据，通过MR将中间结果写入HDFS；然后再重新从HDFS读取数据进行MR，再刷写到HDFS，这个过程涉及多次落盘操作，多次磁盘IO，效率并不高；而Spark的设计模式是读取集群中的数据后，在内存中存储和运算，直到全部运算完毕后，再存储到集群中； Spark是由于Hadoop中MR效率低下而产生的高效率快速计算引擎，批处理速度比MR快近10倍，内存中的数据分析速度比Hadoop快近100倍（源自官网描述）； Spark中RDD一般存放在内存中，如果内存不够存放数据，会同时使用磁盘存储数据；通过RDD之间的血缘连接、数据存入内存中切断血缘关系等机制，可以实现灾难恢复，当数据丢失时可以恢复数据；这一点与Hadoop类似，Hadoop基于磁盘读写，天生数据具备可恢复性； Spark引进了内存集群计算的概念，可在内存集群计算中将数据集缓存在内存中，以缩短访问延迟，对7的补充； Spark中通过DAG图可以实现良好的容错。 部分基本组件对比与MapReduce对比MapReduce能够完成的各种离线批处理功能，以及常见算法（比如二次排序、topn等），基于Spark RDD的核心编程，都可以实现，并且可以更好地、更容易地实现。而且基于Spark RDD编写的离线批处理程序，运行速度是MapReduce的数倍，速度上有非常明显的优势。Spark速度快的原因是：MapReduce的计算模型太死板，必须是map-reduce模式，有时候即使完成一些诸如过滤之类的操作，也必须经过map-reduce过程，这样就必须经过shuffle过程。而MapReduce的shuffle过程是最消耗性能的，因为shuffle中间的过程必须基于磁盘来读写。而Spark的shuffle虽然也要基于磁盘，但是其大量transformation操作，比如单纯的map或者filter等操作，可以直接基于内存进行pipeline操作，速度性能自然大大提升。Spark的劣势是：由于Spark基于内存进行计算，虽然开发容易，但是真正面对大数据的时候（比如一次操作针对10亿以上级别），在没有进行调优的情况下，可能会出现各种各样的问题，比如OOM内存溢出等等。导致Spark程序可能都无法完全运行起来，就报错挂掉了，而MapReduce即使是运行缓慢，但是至少可以慢慢运行完。 Spark SQL与Hive 对比Spark SQL实际上并不能完全替代Hive，因为Hive是一种基于HDFS的数据仓库，并且提供了基于SQL模型的，针对存储了大数据的数据仓库，进行分布式交互查询的查询引擎。严格的来说，Spark SQL能够替代的，是Hive的查询引擎，而不是Hive本身，实际上即使在生产环境下，Spark SQL也是针对Hive数据仓库中的数据进行查询，Spark本身自己是不提供存储的，自然也不可能替代Hive作为数据仓库的这个功能。 Spark SQL的一个优点，相较于Hive查询引擎来说，就是速度快，同样的SQL语句，可能使用Hive的查询引擎，由于其底层基于MapReduce，必须经过shuffle过程走磁盘，因此速度是非常缓慢的。很多复杂的SQL语句，在hive中执行都需要一个小时以上的时间。而Spark SQL由于其底层基于Spark自身的基于内存的特点，因此速度达到了Hive查询引擎的数倍以上。而Spark SQL相较于Hive的另外一个优点，就是支持大量不同的数据源，包括hive、json、parquet、jdbc等等。此外，Spark SQL由于身处Spark技术堆栈内，也是基于RDD来工作，因此可以与Spark的其他组件无缝整合使用，配合起来实现许多复杂的功能。比如Spark SQL支持可以直接针对hdfs文件执行sql语句！ Spark Streaming与Storm对比Spark Streaming与Storm都可以用于进行实时流计算。但是他们两者的区别是非常大的。其中区别之一，就是，Spark Streaming和Storm的计算模型完全不一样，Spark Streaming是基于RDD的，因此需要将一小段时间内的，比如1秒内的数据，收集起来，作为一个RDD，然后再针对这个batch的数据进行处理。而Storm却可以做到每来一条数据，都可以立即进行处理和计算。因此，Spark Streaming实际上严格意义上来说，只能称作准实时的流计算框架；而Storm是真正意义上的实时计算框架。 此外，Storm支持的一项高级特性，是Spark Streaming暂时不具备的，即Storm支持在分布式流式计算程序（Topology）在运行过程中，可以动态地调整并行度，从而动态提高并发处理能力。而Spark Streaming是无法动态调整并行度的。但是Spark Streaming也有其优点，首先Spark Streaming由于是基于batch进行处理的，因此相较于Storm基于单条数据进行处理，具有数倍甚至数十倍的吞吐量。 此外，Spark Streaming由于也身处于Spark生态圈内，因此Spark Streaming可以与Spark Core、Spark SQL，甚至是Spark MLlib、Spark GraphX进行无缝整合。流式处理完的数据，可以立即进行各种map、reduce转换操作，可以立即使用sql进行查询，甚至可以立即使用machine learning或者图计算算法进行处理。这种一站式的大数据处理功能和优势，是Storm无法匹敌的。 对于Storm来说，如果仅仅要求对数据进行简单的流式计算处理，那么选择storm或者spark streaming都无可厚非。但是如果需要对流式计算的中间结果（RDD），进行复杂的后续处理，则使用Spark更好，因为Spark本身提供了很多原语，比如map、reduce、groupByKey、filter等等。","categories":[{"name":"Spark","slug":"Spark","permalink":"https://jjw-story.github.io/categories/Spark/"}],"tags":[{"name":"入门","slug":"入门","permalink":"https://jjw-story.github.io/tags/入门/"},{"name":"Spark","slug":"Spark","permalink":"https://jjw-story.github.io/tags/Spark/"}],"author":"JJW"},{"title":"MySQL-实践一","slug":"MySQL-实践一","date":"2020-07-12T03:09:01.000Z","updated":"2020-08-14T06:19:03.787Z","comments":true,"path":"2020/07/12/MySQL-实践一/","link":"","permalink":"https://jjw-story.github.io/2020/07/12/MySQL-实践一/","excerpt":"","text":"普通索引和唯一索引的选择普通索引和唯一索引的查询过程对比例如：我们查询一个 where k=5 条件的SQL语句，这个查询语句在索引树上查找的过程，先是通过 B+ 树从树根开始，按层搜索到叶子节点，然后可以认为数据页内部通过二分法来定位记录。 对于普通索引来说，查找到满足条件的第一个记录 (5,500) 后，需要查找下一个记录，直到碰到第一个不满足 k=5 条件的记录。 对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。 InnoDB 的数据是按数据页为单位来读写的。也就是说，当需要读一条记录的时候，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整体读入内存。在 InnoDB 中，每个数据页的大小默认是 16KB。因为引擎是按页读写的，所以说，当找到 k=5 的记录的时候，它所在的数据页就都在内存里了。那么，对于普通索引来说，要多做的那一次“查找和判断下一条记录”的操作，就只需要一次指针寻找和一次计算。当然，如果 k=5 这个记录刚好是这个数据页的最后一个记录，那么要取下一个记录，必须读取下一个数据页，这个操作会稍微复杂一些。但是，我们之前计算过，对于整型字段，一个数据页可以放近千个 key，因此出现这种情况的概率会很低。所以，我们计算平均性能差异时，仍可以认为这个操作成本对于现在的 CPU 来说可以忽略不计。 结论：这个索引不同查询带来的性能差距会有多少呢？答案是，微乎其微。 普通索引和唯一索引的更新过程对比change buffer当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InnoDB 会将这些更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。 需要说明的是，虽然名字叫作 change buffer，实际上它是可以持久化的数据。也就是说，change buffer 在内存中有拷贝，也会被写入到磁盘上。将 change buffer 中的操作应用到原数据页，得到最新结果的过程称为 merge。除了访问这个数据页会触发 merge 外，系统有后台线程会定期 merge。在数据库正常关闭（shutdown）的过程中，也会执行 merge 操作。显然，如果能够将更新操作先记录在 change buffer，减少读磁盘，语句的执行速度会得到明显的提升。而且，数据读入内存是需要占用 buffer pool 的，所以这种方式还能够避免占用内存，提高内存利用率。 唯一索引和普通索引对于change buffer的应用特点对比对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。比如我们要插入一条数据，而这必须要将数据页读入内存才能判断。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用 change buffer 了。 对于普通索引来说，则是将更新记录在 change buffer，语句执行就结束了。 因此，唯一索引的更新就不能使用 change buffer，实际上也只有普通索引可以使用。 change buffer 用的是 buffer pool 里的内存，因此不能无限增大。change buffer 的大小，可以通过参数 innodb_change_buffer_max_size 来动态设置。这个参数设置为 50 的时候，表示 change buffer 的大小最多只能占用 buffer pool 的 50%。 change buffer 的使用场景因为 merge 的时候是真正进行数据更新的时刻，而 change buffer 的主要目的就是将记录的变更动作缓存下来，所以在一个数据页做 merge 之前，change buffer 记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大。 因此，对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时 change buffer 的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。对于写少读多的业务，将更新先记录在 change buffer，但之后由于马上要访问这个数据页，会立即触发 merge 过程。这样随机访问 IO 的次数不会减少，反而增加了 change buffer 的维护代价。 普通索引和唯一索引的选择结论：这两类索引在查询能力上是没差别的，主要考虑的是对更新性能的影响。所以，我建议你尽量选择普通索引。如果所有的更新后面，都马上伴随着对这个记录的查询，那么你应该关闭 change buffer。而在其他情况下，change buffer 都能提升更新性能。 change buffer 和 redo logredo log 主要节省的是随机写磁盘的 IO 消耗（转成顺序写），而 change buffer 主要节省的则是随机读磁盘的 IO 消耗。(这块还是有点不太理解，个人理解就是：WAL是数据页已经在内存中了，这时我们修改或插入此数据页数据，直接更新内存中的数据，然后写入redo log，系统在空闲的时候进行将操作更新到磁盘。 而 change buffer 主要解决的是数据页本身就不在内存中，这时候我们更新或者添加数据，就直接写入到change buffer中，等到需要读此数据页的数据时，才将此数据读入内存中，然后合并 change buffer中的修改) MySQL为什么有时候会选错索引1：MySQL选错索引，啥意思？ 我们认为使用K索引检索的速度会更快的，但是MySQL没有使用，决定使用什么索引是由Server层的优化器来决定的，她也是想选择最佳的方案来检索数据的，不过他也是人写的程序也是存在bug的。 2：MySQL为啥会选错索引？ 优化器选择索引的目的，是找到一个最优的执行方案，并用最小的代价去执行语句。在数据库里面，扫描行数是影响执行代价的因素之一。扫描的行数越少，意味着访问磁盘数据的次数越少，消耗的 CPU 资源越少。优化器认为使用那个索引检索数据的速度比较快是一个需要各种因素综合评估的事情，比如：是否使用临时表、是否排序、扫描的行数多少、回表的次数等。 索引的创建是非常的耗时的，因为需要真正的建索引的过程，但是删除索引却不需要耗费太多时间，因为是标记删除，这个是以空间换时间的思路。优化器采用采样评估出现误差的原因也在于，索引的标记删除影响的。 3：mysql如何判断一个查询的扫描行数? MySQL 在真正开始执行语句之前，并不能精确地知道满足这个条件的记录有多少条，而只能根据统计信息来估算记录数。这个统计信息就是索引的“区分度”。显然，一个索引上不同的值越多，这个索引的区分度就越好。而一个索引上不同的值的个数，我们称之为“基数”（cardinality）。也就是说，这个基数越大，索引的区分度越好。我们可以使用 show index 方法，看到一个索引的基数。 4：索引基数如何计算? 为什么要采样统计呢？因为把整张表取出来一行行统计，虽然可以得到精确的结果，但是代价太高了，所以只能选择“采样统计”。采样统计的时候，InnoDB 默认会选择 N 个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数。当变更的数据行数超过 1/M 的时候，会自动触发重新做一次索引统计。 5：可以重新统计索引信息的命令是什么? analyze table t 命令，可以用来重新统计索引信息 6： 索引选择异常的问题可以有哪几种处理方式? 强制指定使用某个索引，不常用不推荐用 调整SQL语句，使优化器选择的和我们想的一样，不具有通用性 新建更合适的索引或者删除不合适的索引，是一个思路 使用analyze table可以解决索引统计信息不准确导致的索引选错的问题 怎么给字符串字段加索引MySQL 是支持前缀索引的，也就是说，你可以定义字符串的一部分作为索引。默认地，如果你创建索引的语句不指定前缀长度，那么索引就会包含整个字符串。 前缀索引使用示例： 12345# 正常默认索引-包含了每个记录的整个字符串alter table SUser add index index1(email);# 前缀索引-对于每个记录都是只取前 6 个字节alter table SUser add index index2(email(6)); 两种索引的数据结构和存储区别前缀索引因为只取整个字段的前几个字节，所以占用空间会更少，这就是使用前缀索引的优势，这同时带来的损失是，可能会增加额外的记录扫描次数，具体来说主要是使用索引检索的过程如下进行分析： 如果我们用的是整个字符串的索引，首先我们直接根据索引定位要查询的字符串，然后回表，取出数据，然后检索对比下一条，发现不满足条件，就查询结束。 如果使用前缀索引，因为前缀相同的记录可能会有多条，这样的情况也很正常，它就需要每一条都扫描，然后回表去查询具体的数据来进行对比，一直找到前缀不能匹配的记录，所以这就是前缀索引会增加额外的扫描次数的原因。 但是：如果我们通过分析业务，使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本（通过前缀就能很快的区分出大部分的数据）。 前缀索引对覆盖索引的影响如下一条查询语句： 1select id,email from SUser where email=&apos;zhangssxyz@xxx.com&apos;; 如果我们直接使用普通索引（email），我们因为有覆盖索引的机理，所以一次就能返回所有的数据而不需要进行回表，但是如果我们使用了覆盖索引，每一次都需要回表判断email字段是不是对应的具体记录，这样就增加了回表的逻辑，而事实上，即使我们的前缀索引长度设置的足够长，能包含所有的字段长度，它还是需要回表进行判断，因为系统并不知道前缀索引的定义是否截断了完整的信息。 综上所述：使用前缀索引就用不上覆盖索引对查询性能的优化了 前缀索引使用的其他方式对于类似于邮箱这样的字段来说，使用前缀索引的效果可能还不错。但是，遇到前缀的区分度不够好的情况时，我们要怎么办呢？要知道，索引选取的越长，占用的磁盘空间就越大，相同的数据页能放下的索引值就越少，搜索的效率也就会越低。 方式一：倒序存储：倒序存储就是针对一些前缀区别度不大，但是后缀区别比较大的字段类型，我们可以使用倒序存储来创建前缀索引。 方式二：使用hash字段：你可以在表上再创建一个整数字段，来保存你所要的业务字段的校验码，同时在这个字段上创建校验码。 使用倒序存储和使用 hash 字段这两种方法的异同点: 相同点是，都不支持范围查询 不同点： 从占用的额外空间来看，倒序存储方式在主键索引上，不会消耗额外的存储空间，而 hash 字段方法需要增加一个字段。当然，倒序存储方式使用 4 个字节的前缀长度应该是不够的，如果再长一点，这个消耗跟额外这个 hash 字段也差不多抵消了。 在 CPU 消耗方面，倒序方式每次写和读的时候，都需要额外调用一次 reverse 函数，而 hash 字段的方式需要额外调用一次 crc32() 函数。如果只从这两个函数的计算复杂度来看的话，reverse 函数额外消耗的 CPU 资源会更小些。 从查询效率上看，使用 hash 字段方式的查询性能相对更稳定一些。因为 crc32 算出来的值虽然有冲突的概率，但是概率非常小，可以认为每次查询的平均扫描行数接近 1。而倒序存储方式毕竟还是用的前缀索引的方式，也就是说还是会增加扫描行数。 总结 直接创建完整索引，这样可能比较占用空间； 创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引； 倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题； 创建 hash 字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描。 为什么MySQL会“抖一下”抖一下：一条SQL语句正常执行的时候非常的快，但有时突然就会变得特别慢，而且很难复现，它不止是随机的，而且持续时间很短。 脏页当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。 InnoDB 在处理更新语句的时候，只做了写日志这一个磁盘操作。这个日志叫作 redo log（重做日志），在更新内存写完 redo log 后，就返回给客户端，本次更新成功（WAL）。 内存里的数据总是要找时间写入磁盘的，这个过程术语就是 flush。在这个 flush 操作执行之前，内存中的数据跟磁盘上的数据是不一致的，因为还没有将redo log中的记录刷新到磁盘上。 所以我们就能够想象，我们的MySQL突然抖一下，就是因为在刷脏页，平时执行很快的更新操作，其实就是写了内存和日志。 数据库flush过程的触发点 InnoDB 的 redo log 写满了。这时候系统会停止所有更新操作，把 checkpoint 往前推进，redo log 留出空间可以继续写（环形链表结构）。checkpoint 可不是随便往前修改一下位置就可以的。它需要将两个点之间的日志，对应的所有脏页都 flush 到磁盘上。 系统内存不足。当需要新的内存页，而内存不够用的时候，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是“脏页”，就要先将脏页写到磁盘。为什么刷脏页一定会写盘，这是为了保证每个数据页只有两种状态： 一种是内存里存在，内存里就肯定是正确的结果，直接返回； 另一种是内存里没有数据，就可以肯定数据文件上是正确的结果，读入内存后返回。这样的效率最高。 MySQL 认为系统“空闲”的时候。当然MySQL及时忙的时候，也会见缝插针的找时间，只要有机会就会刷一点脏页。 MySQL 正常关闭的情况。这时候，MySQL 会把内存的脏页都 flush 到磁盘上，这样下次 MySQL 启动的时候，就可以直接从磁盘上读数据，启动速度会很快。 触发点的具体分析我们着重分析第一种和第二种情况，因为第三种和第四种都是正常的情况，我们不需要关注它的性能问题。 第一种是“redo log 写满了，要 flush 脏页”，这种情况是 InnoDB 要尽量避免的。因为出现这种情况的时候，整个系统就不能再接受更新了，所有的更新都必须堵住。如果你从监控上看，这时候更新数会跌为 0。 第二种是“内存不够用了，要先将脏页写到磁盘”，这种情况其实是常态。InnoDB 用缓冲池（buffer pool）管理内存，缓冲池中的内存页有三种状态： 第一种是，还没有使用的； 第二种是，使用了并且是干净页； 第三种是，使用了并且是脏页。 InnoDB 的策略是尽量使用内存，因此对于一个长时间运行的库来说，未被使用的页面很少。而当要读入的数据页没有在内存的时候，就必须到缓冲池中申请一个数据页。这时候只能把最久不使用的数据页从内存中淘汰掉：如果要淘汰的是一个干净页，就直接释放出来复用；但如果是脏页呢，就必须将脏页先刷到磁盘，变成干净页后才能复用。 所以，刷脏页虽然是常态，但是出现以下这两种情况，都是会明显影响性能的： 一个查询要淘汰的脏页个数太多，会导致查询的响应时间明显变长； 日志写满，更新全部堵住，写性能跌为 0，这种情况对敏感业务来说，是不能接受的。 InnoDB 刷脏页的控制策略 首先，你要正确地告诉 InnoDB 所在主机的 IO 能力，这样 InnoDB 才能知道需要全力刷脏页的时候，可以刷多快。这就要用到 innodb_io_capacity 这个参数了，它会告诉 InnoDB 你的磁盘能力。这个值我建议你设置成磁盘的 IOPS。因为没能正确地设置 innodb_io_capacity 参数，而导致的性能问题也比比皆是。 innodb_flush_neighbors：MySQL 中的一个机制，可能让你的查询会更慢：在准备刷一个脏页的时候，如果这个数据页旁边的数据页刚好是脏页，就会把这个“邻居”也带着一起刷掉；而且这个把“邻居”拖下水的逻辑还可以继续蔓延，也就是对于每个邻居数据页，如果跟它相邻的数据页也还是脏页的话，也会被放到一起刷。innodb_flush_neighbors 参数就是用来控制这个行为的，值为 1 的时候会有上述的“连坐”机制，值为 0 时表示不找邻居，自己刷自己的。SSD的时代，建议设置为0，MySQL8 已经默认设置为0了。 总结WAL这个机制后续需要的刷脏页操作和执行时机。利用 WAL 技术，数据库将随机写转换成了顺序写，大大提升了数据库的性能。但是，由此也带来了内存脏页的问题。脏页会被后台线程自动 flush，也会由于数据页淘汰而触发 flush，而刷脏页的过程由于会占用资源，可能会让你的更新和查询语句的响应时间长一些。 重点的重点淘汰的时候，刷脏页过程不用动redo log文件的，直接将脏页数据刷到磁盘中就完成了。而在redo log重放的过程中，有个额外的保证，如果一个数据页已经是刷过的，会识别出来并跳过。这个保证的具体实现机制是：innodb的每个数据页头部有LSN，8字节，每次修改都会变大，对比这个LSN跟checkpoint 的LSN，比checkpoint小的一定是干净页。这样解决的问题是：当内存不够用了，要将脏页写到磁盘，会有一个数据页淘汰机制（最久不使用），假设淘汰的是脏页，则此时脏页所对应的redo log的位置是随机的，当有多个不同的脏页需要刷，则对应的redo log可能在不同的位置，这样就需要把redo log的多个不同位置刷掉，这样对于redo log的处理不是就会很麻烦（合并间隙，移动位置） 现在我们对 WAL、change buffer、脏页、flush串起来一下，首先我们来了一条更新数据的语句，如果此数据所在页已经在内存中，那么MySQL直接更新内存数据，然后写redo log，如果此数据页没有再内存中，那么MySQL会写change buffer（前提不是添加数据，或者修改的列没有建立唯一索引，如果建立了，就需要将数据页加载到内存中进行判断唯一，这样就直接更新内存了），然后写redo log，这样我们的更新就完成了。下面我们说flush的过程，1. 在我们内存满了后需要淘汰脏页，这是就会将脏页的数据在内存中直接刷到磁盘上，WAL进行redo log重放的时候，会判断此数据是否被之前已有脏页刷过盘了，如果刷过了就跳过，没有刷过就重放更新磁盘数据。2. change buffer中的数据加载是看数据有没有被读取过，如果数据被读取，那么数据就会从磁盘读取到内存中，然后从change buffer中取出更改更新到内存中，那么此时内存中就是脏页，脏页在淘汰或者刷盘中就走了正常逻辑，如果没有被读取，change buffer 的后台也会有自己的合并行为，在一定的时机就会将change buffer中的数据刷新到磁盘中（这里重点注意：如果change buffer中的数据被丢了，那么它还是可以通过 redo log 进行重放进行恢复）。3. redo log 的重放，重放会将我们所有的更改持久化到磁盘数据中，这里重放的时候会判断当前数据有没有被脏页刷盘过，有没有被change buffer的后台自动持久化过，如果有，就跳过，如果没有，就通过redo log进行重放（LSN）。 redo log 的重放：redo log 并没有记录数据页的完整数据，所以它并没有能力自己去更新磁盘数据页，也就不存在“数据最终落盘，是由 redo log 更新过去”的情况。 如果是正常运行的实例的话，数据页被修改以后，跟磁盘的数据页不一致，称为脏页。最终数据落盘，就是把内存中的数据页写盘。这个过程，甚至与 redo log 毫无关系。 在崩溃恢复场景中，InnoDB 如果判断到一个数据页可能在崩溃恢复的时候丢失了更新，就会将它读到内存，然后让 redo log 更新内存内容。更新完成后，内存页变成脏页，就回到了第一种情况的状态。 数据库表的空间回收一个 InnoDB 表包含两部分，即：表结构定义和数据。在 MySQL 8.0 版本以前，表结构是存在以.frm 为后缀的文件里。而 MySQL 8.0 版本，则已经允许把表结构定义放在系统数据表中了。因为表结构定义占用的空间很小。 参数 innodb_file_per_table表数据既可以存在共享表空间里，也可以是单独的文件。这个行为是由参数 innodb_file_per_table 控制的： 这个参数设置为 OFF 表示的是，表的数据放在系统共享表空间，也就是跟数据字典放在一起； 这个参数设置为 ON 表示的是，每个 InnoDB 表数据存储在一个以 .ibd 为后缀的文件中。从 MySQL 5.6.6 版本开始，它的默认值就是 ON 了。 建议你不论使用 MySQL 的哪个版本，都将这个值设置为 ON。因为，一个表单独存储为一个文件更容易管理，而且在你不需要这个表的时候，通过 drop table 命令，系统就会直接删除这个文件。而如果是放在共享表空间中，即使表删掉了，空间也是不会回收的。 数据删除流程InnoDB 里的数据都是用 B+ 树的结构组织的，假设我们有一个数据页PageA，数据页中存的数据ID有（3、5、6），现在我们把 ID为5 的这条记录删除，InnoDB 引擎只会把 5 这个记录标记为删除，如果之后要再插入一个 ID 在 3 和 6 之间的记录时，可能会复用这个位置。但是，磁盘文件的大小并不会缩小。如果我们删掉了一个数据页上的所有记录，那么整个数据页就可以被复用了，但是，数据页的复用跟记录的复用是不同的。记录的复用，只限于符合范围条件的数据，比如上面这个例子，我们删除 5 记录之后，如果插入一个 ID 为8 的记录，就不能复用这个位置了。而当整个页从 B+ 树里面摘掉以后，可以复用到任何位置。如果将数据页 page A 上的所有记录删除以后，page A 会被标记为可复用。这时候如果要插入一条 ID=50 的记录需要使用新页的时候，page A 是可以被复用的。 如果相邻的两个数据页利用率都很小，系统就会把这两个页上的数据合到其中一个页上，另外一个数据页就被标记为可复用。 进一步地，如果我们用 delete 命令把整个表的数据删除，所有的数据页都会被标记为可复用。但是磁盘上，文件不会变小。 空洞上述我们了解到，delete 命令其实只是把记录的位置，或者数据页标记为了“可复用”，但磁盘文件的大小是不会变的。也就是说，通过 delete 命令是不能回收表空间的。这些可以复用，而没有被使用的空间，看起来就像是“空洞”。 插入数据也可以产生空洞：如果数据是按照索引递增顺序插入的，那么索引是紧凑的。但如果数据是随机插入的，就可能造成索引的数据页分裂。如果我们某个Page页满了，向此页中插入数据就不得不再申请一个新的数据页，来保存数据，页分裂完成后，旧页的末尾就留下了空洞。 更新索引上的值也可以产生空洞：更新索引上的值，可以理解为删除一个旧的值，再插入一个新值。不难理解，这也是会造成空洞的（比如将一个索引的值 10 改为 1000）。 重建表经过大量增删改的表，都是可能是存在空洞的。所以，如果能够把这些空洞去掉，就能达到收缩表空间的目的。而重建表，就可以达到这样的目的。 可以使用 alter table A engine=InnoDB 命令来重建表。在 MySQL 5.5 版本之前，这个命令的执行流程大致是： 1新建一个与表 A 结构相同的表 B，然后按照主键 ID 递增的顺序，把数据一行一行地从表 A 里读出来再插入到表 B 中。 由于表 B 是新建的表，所以表 A 主键索引上的空洞，在表 B 中就都不存在了。用表 B 替换 A，从效果上看，就起到了收缩表 A 空间的作用。 MySQL 会自动完成转存数据、交换表名、删除旧表的操作。 Online DDL上述流程中，显然，花时间最多的步骤是往临时表插入数据的过程，如果在这个过程中，有新的数据要写入到表 A 的话，就会造成数据丢失。因此，在整个 DDL 过程中，表 A 中不能有更新。也就是说，这个 DDL 不是 Online 的。在 MySQL 5.6 版本开始引入的 Online DDL，对这个操作流程做了优化。下面描述一下引入了 Online DDL 之后，重建表的流程： 建立一个临时文件，扫描表 A 主键的所有数据页； 用数据页中表 A 的记录生成 B+ 树，存储到临时文件中； 生成临时文件的过程中，将所有对 A 的操作记录在一个日志文件（row log）中； 临时文件生成后，将日志文件中的操作应用到临时文件，得到一个逻辑数据上与表 A 相同的数据文件； 用临时文件替换表 A 的数据文件。 此过程与上述重建表过程不同的是，由于日志文件记录和重放操作这个功能的存在，这个方案在重建表的过程中，允许对表 A 做增删改操作。这也就是 Online DDL 名字的来源。alter 语句在启动的时候需要获取 MDL 写锁，但是这个写锁在真正拷贝数据之前就退化成读锁了。对于一个大表来说，Online DDL 最耗时的过程就是拷贝数据到临时表的过程，这个步骤的执行期间可以接受增删改操作。所以，相对于整个 DDL 过程来说，锁的时间非常短。对业务来说，就可以认为是 Online 的。 Online 和 inplaceinplace：上述我们在讲MySQL 5.5 以前的版本重建表的流程，我们把表 A 中的数据导出来的存放位置叫作 tmp_table。这是一个临时表，是在 server 层创建的，而5.5之后，根据表 A 重建出来的数据是放在“tmp_file”里的，这个临时文件是 InnoDB 在内部创建出来的。整个 DDL 过程都在 InnoDB 内部完成。对于 server 层来说，没有把数据挪动到临时表，是一个“原地”操作，这就是“inplace”名称的来源。 inplace重建表的语句： 1alter table t engine=innodb,ALGORITHM=inplace; (ALGORITHM=inplace 可以不加，因为它是默认的) copy重建表的语句： 1alter table t engine=innodb,ALGORITHM=copy; 当你使用 ALGORITHM=copy 的时候，表示的是强制拷贝表，对应的就是类似上述5.5版本重建表的逻辑流程。 Online 和 inplace的区别 DDL 过程如果是 Online 的，就一定是 inplace 的； 反过来未必，也就是说 inplace 的 DDL，有可能不是 Online 的。截止到 MySQL 8.0，添加全文索引（FULLTEXT index）和空间索引 (SPATIAL index) 就属于这种情况。 optimize table、analyze table 和 alter table 这三种方式重建表的区别 从 MySQL 5.6 版本开始，alter table t engine = InnoDB（也就是 recreate）默认的就是上面 Online重建表的 流程了； analyze table t 其实不是重建表，只是对表的索引信息做重新统计，没有修改数据，这个过程中加了 MDL 读锁； optimize table t 等于 recreate+analyze。 count函数应用剖析count(*) 的实现方式在不同的 MySQL 引擎中，count(*) 有不同的实现方式： MyISAM 引擎把一个表的总行数存在了磁盘上，因此执行 count(*) 的时候会直接返回这个数，效率很高； 而 InnoDB 引擎就麻烦了，它执行 count(*) 的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数。 这里需要注意的是，我们在这篇文章里讨论的是没有过滤条件的 count(*)，如果加了 where 条件的话，MyISAM 表也是不能返回得这么快的。 为什么 InnoDB 不跟 MyISAM 一样，也把数字存起来呢？这是因为即使是在同一个时刻的多个查询，由于多版本并发控制（MVCC）的原因，InnoDB 表“应该返回多少行”也是不确定的。 InnoDB 是索引组织表，主键索引树的叶子节点是数据，而普通索引树的叶子节点是主键值。所以，普通索引树比主键索引树小很多。对于 count(*) 这样的操作，遍历哪个索引树得到的结果逻辑上都是一样的。因此，MySQL 优化器会找到最小的那棵树来遍历。在保证逻辑正确的前提下，尽量减少扫描的数据量，是数据库系统设计的通用法则之一。 小结 MyISAM 表虽然 count(*) 很快，但是不支持事务； show table status 命令虽然返回很快，但是不准确； InnoDB 表直接 count(*) 会遍历全表，虽然结果准确，但会导致性能问题。 不同的 count 用法count() 的语义：count() 是一个聚合函数，对于返回的结果集，一行行地判断，如果 count 函数的参数不是 NULL，累计值就加 1，否则不加。最后返回累计值。所以，count(*)、count(主键 id) 和 count(1) 都表示返回满足条件的结果集的总行数；而 count(字段），则表示返回满足条件的数据行里面，参数“字段”不为 NULL 的总个数。 对于 count(主键 id) 来说，InnoDB 引擎会遍历整张表，把每一行的 id 值都取出来，返回给 server 层。server 层拿到 id 后，判断是不可能为空的（这里这个判断虽然是多余的，主键不可能为空，但是MySQL代码确实是这么做的），就按行累加。 对于 count(1) 来说，InnoDB 引擎遍历整张表，但不取值。server 层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。 单看这两个用法的差别的话，你能对比出来，count(1) 执行得要比 count(主键 id) 快。因为从引擎返回 id 会涉及到解析数据行，以及拷贝字段值的操作。 对于 count(字段) 来说： 如果这个“字段”是定义为 not null 的话，一行行地从记录里面读出这个字段，判断不能为 null，按行累加； 如果这个“字段”定义允许为 null，那么执行的时候，判断到有可能是 null，还要把值取出来再判断一下，不是 null 才累加。 对于 count(*) 来说：并不会把全部字段取出来，而是专门做了优化，不取值。count(*) 肯定不是 null，按行累加。 结论：按照效率排序的话，count(字段) &lt; count(主键 id) &lt; count(1) ≈ count()，所以我建议你，尽量使用 count(\\)。 order by 的工作原理这里用一条SQL语句举例说明： select city,name,age from t where city=’杭州’ order by name limit 1000; （city字段建立了索引） 全字段排序MySQL 会给每个线程分配一块内存用于排序，称为 sort_buffer。通常情况下，全字段排序上述语句执行流程如下： 初始化 sort_buffer，确定放入 name、city、age 这三个字段； 从索引 city 找到第一个满足 city=’杭州’ 条件的主键 id； 到主键 id 索引取出整行，取 name、city、age 三个字段的值，存入 sort_buffer 中； 从索引 city 取下一个记录的主键 id； 重复步骤 3、4 直到 city 的值不满足查询条件为止； 对 sort_buffer 中的数据按照字段 name 做快速排序； 按照排序结果取前 1000 行返回给客户端。 排序这个动作，可能在内存中完成，也可能需要使用外部排序，这取决于排序所需的内存和参数 sort_buffer_size。sort_buffer_size，就是 MySQL 为排序开辟的内存（sort_buffer）的大小。如果要排序的数据量小于 sort_buffer_size，排序就在内存中完成。但如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序，外部排序一般使用归并排序算法。（一般是将数据分为多个小临时文件排好顺序，然后归并排序到一个大文件中） rowid 排序在上面这个算法过程里面，只对原表的数据读了一遍，剩下的操作都是在 sort_buffer 和临时文件中执行的。但这个算法有一个问题，就是如果查询要返回的字段很多的话，那么 sort_buffer 里面要放的字段数太多，这样内存里能够同时放下的行数很少，要分成很多个临时文件，排序的性能会很差。 我们可以通过配置参数max_length_for_sort_data，控制用于排序的行数据的长度，如果单行的长度超过这个值，MySQL 就认为单行太大，要换一个算法。使用如下： 1SET max_length_for_sort_data = 16; city、name、age 这三个字段的定义总长度是 36，我把 max_length_for_sort_data 设置为 16，新的算法放入 sort_buffer 的字段，只有要排序的列（即 name 字段）和主键 id，这时，排序的结果就因为少了 city 和 age 字段的值，不能直接返回，具体执行流程如下： 初始化 sort_buffer，确定放入两个字段，即 name 和 id； 从索引 city 找到第一个满足 city=’杭州’条件的主键 id； 到主键 id 索引取出整行，取 name、id 这两个字段，存入 sort_buffer 中； 从索引 city 取下一个记录的主键 id； 重复步骤 3、4 直到不满足 city=’杭州’条件为止； 对 sort_buffer 中的数据按照字段 name 进行排序； 遍历排序结果，取前 1000 行，并按照 id 的值回到原表中取出 city、name 和 age 三个字段返回给客户端。 对比全字段排序，rowid 排序多访问了一次表 t 的主键索引，就是步骤 7。 全字段排序 VS rowid 排序如果 MySQL 实在是担心排序内存太小，会影响排序效率，才会采用 rowid 排序算法，这样排序过程中一次可以排序更多行，但是需要再回到原表去取数据。如果 MySQL 认为内存足够大，会优先选择全字段排序，把需要的字段都放到 sort_buffer 中，这样排序后就会直接从内存里面返回查询结果了，不用再回到原表去取数据。如果内存够，就要多利用内存，尽量减少磁盘访问。 不用排序算法的 order by 场景如果我们对上述查询语句的 city 和 name 建立联合索引，这时，对于 city 字段的值相同的行来说，还是按照 name 字段的值递增排序的，此时的查询语句也就不再需要排序了。这样整个查询语句的执行流程就变成了： 从索引 (city,name) 找到第一个满足 city=’杭州’条件的主键 id； 到主键 id 索引取出整行，取 name、city、age 三个字段的值，作为结果集的一部分直接返回； 从索引 (city,name) 取下一个记录主键 id； 重复步骤 2、3，直到查到第 1000 条记录，或者是不满足 city=’杭州’条件时循环结束。 在我们这个例子里，只需要扫描 1000 次，不需要经历排序算法。 我们还可以建立(city,name,age)的联合索引，这样上述步骤中的的回表操作就可以完全省略，因为在索引中已经包含了我们需要的所有字段（覆盖索引的原理），这样性能会更快。 当然，这里并不是说要为了每个查询能用上覆盖索引，就要把语句中涉及的字段都建上联合索引，毕竟索引还是有维护代价的。这是一个需要权衡的决定。 explain 中 Extra 字段返回结果Using filesort：表示的就是需要排序 Using temporary表示的是需要使用临时表 order by内部会使用归并排序，根据sort buffer size决定是否需要使用外部（磁盘）排序，根据max_length_for_sort_data决定使用全字段排序还是rowid排序，不同点是rowid排序，只使用排序字段和主键，会在原有的基础上，多进行回表查询，多了磁盘操作，为此可以使用复合查询，这样从索引中查询出来的数据，就是有序的，可以直接进行回表，返回result，也可以考虑是否使用覆盖索引，直接返回值，如果order by后面加上limit num，num是小值，在5.6以上会使用优先队列进行排序。 rowid详解如果把一个 InnoDB 表的主键删掉，是不是就没有主键，就没办法回表了？其实不是的。 如果你创建的表没有主键，或者把一个表的主键删掉了，那么 InnoDB 会自己生成一个长度为 6 字节的 rowid 来作为主键。这也就是排序模式里面，rowid 名字的来历。实际上它表示的是： 每个引擎用来唯一标识数据行的信息。对于有主键的 InnoDB 表来说，这个 rowid 就是主键 ID； 对于没有主键的 InnoDB 表来说，这个 rowid 就是由系统生成的； MEMORY 引擎不是索引组织表，你可以认为它就是一个数组。因此，这个 rowid 其实就是数组的下标。 本章节注意：内存临时表、磁盘临时表的概念 SQL语句执行性能分析条件字段函数操作对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。 例如，对于一个查询语句，t_modified字段类型为datetime类型： 1select count(*) from tradelog where month(t_modified)=7; 上述语句就不会走索引，因为对索引字段做了month()函数操作 例如，对于 select * from tradelog where id + 1 = 10000 这个 SQL 语句，这个加 1 操作并不会改变有序性，但是 MySQL 优化器还是不能用 id 索引快速定位到 9999 这一行。所以，需要你在写 SQL 语句的时候，手动改写成 where id = 10000 -1 才可以。 隐式类型转换例如如下查询语句，tradeid 这个字段上建立了索引，字段类型是 varchar(32)，但是此语句却没有走索引： 1mysql&gt; select * from tradelog where tradeid=110717; 这里的原因就是，tradeid 的字段类型是 varchar(32)，而输入的参数却是整型，所以需要做类型转换，所以对于优化器来说，上述语句相当于： 1select * from tradelog where CAST(tradid AS signed int) = 110717; 也就是说，这条语句触发了我们上面说到的规则：对索引字段做函数操作，优化器会放弃走树搜索功能。 注意重点：当字符串和数字比较时会把字符串转化为数字 隐式字符编码转换例如我们有如下查询语句，此两个表的tradeid 这个字段上都建立了索引 1select d.* from tradelog l, trade_detail d where d.tradeid=l.tradeid and l.id=2; 在这条语句中，tradelog 为驱动表，trade_detail为被驱动表，具体的查询逻辑如下： 我们首先通过tradelog驱动表的主键索引找到id = 2的记录； 然后找出tradeid字段的值； 然后根据 tradeid 值到 trade_detail 表中查找条件匹配的行。 这里我们通过explain结果集发现，trade_detail 的 tradeid 值匹配并没有走索引，这是因为：这两个表的字符集不同，一个是 utf8mb4，一个是 utf8，所以做表连接查询的时候用不上关联字段的索引。所以我们在做上述第三步的时候，具体查询逻辑类似如下SQL： 123select * from trade_detail where tradeid=$L2.tradeid.value;也就是：select * from trade_detail where CONVERT(traideid USING utf8mb4)=$L2.tradeid.value; $L2.tradeid.value 的字符集是 utf8mb,。字符集 utf8mb4 是 utf8 的超集，所以当这两个类型的字符串在做比较的时候，MySQL 内部的操作是，先把 utf8 字符串转成 utf8mb4 字符集，再做比较。 这个设定很好理解，utf8mb4 是 utf8 的超集。类似地，在程序设计语言里面，做自动类型转换的时候，为了避免数据在转换过程中由于截断导致数据错误，也都是“按数据长度增加的方向”进行转换的。 所以优化此查询语句，就可以修改为： 1select d.* from tradelog l , trade_detail d where d.tradeid=CONVERT(l.tradeid USING utf8) and l.id=2; 这里，我主动把 l.tradeid 转成 utf8，就避免了被驱动表上的字符编码转换，从 explain 结果可以看到，这次索引走对了。 本节总结索引字段不能进行函数操作，但是索引字段的参数可以玩函数，一言以蔽之。 SQL语句执行慢分析查询长时间不返回等 MDL 锁例如我们执行一条很简单的语句：select * from t where id=1; 结果长时间不返回，一般出现这种情况大概率是表被锁住了，分析时我们一般执行 show processlist 命令，查看当前语句处于什么状态。 使用 show processlist 命令查看语句出现 Waiting for table metadata lock 的状态，说明现在有一个线程正在表 t 上请求或者持有 MDL 写锁，把 select 语句堵住了。场景是:session A 通过 lock table 命令持有表 t 的 MDL 写锁，而 session B 的查询需要获取 MDL 读锁。所以，session B 进入等待状态。这类问题的处理方式，就是找到谁持有 MDL 写锁，然后把它 kill 掉。(通过查询 sys.schema_table_lock_waits 这张表，我们就可以直接找出造成阻塞的 process id，把这个连接用 kill 命令断开即可。) 等 flush我们使用select * from information_schema.processlist查询结果，发现状态有 Waiting for table flush，这个状态表示的是，现在有一个线程正要对表 t 做 flush 操作。MySQL 里面对表做 flush 操作的用法，一般有以下两个： flush tables t with read lock; flush tables with read lock; 这两个 flush 语句，如果指定表 t 的话，代表的是只关闭表 t；如果没有指定具体的表名，则表示关闭 MySQL 里所有打开的表。但是正常这两个语句执行起来都很快，除非它们也被别的线程堵住了。所以，出现 Waiting for table flush 状态的可能情况是：有一个 flush tables 命令被别的语句堵住了，然后它又堵住了我们的 select 语句，这个别的语句可能是一个耗时很长的查询操作，或者耗时很长的更新操作。 等行锁例如：一条更新语句占用了写锁，并且事务一直没有提交，另一条查询语句如下 select * from t where id=1 lock in share mode; 或是使用了for update都表示需要当前读，这样就需要给当前数据加写锁，这时因为上一条执行事务没有提交，锁一直没有释放，就导致本条查询语句一直被阻塞。 我们可以通过SQL语句查看具体是被什么被锁住了：select * from t sys.innodb_lock_waits where locked_table=’[schema.tablename]’。查找到 blocking_pid，然后 kill [pid] 即可完成释放。 查询慢扫描行数多例如有如下语句：select * from t where c=50000 limit 1; 这条语句慢是因为字段c上没有索引，所以只能走主键ID顺序扫描，然后取出行记录进行对比，因此需要扫描50000行。扫描行数越多，执行越慢 一致性读 undo log 回放比如我们会遇到一种现象，执行SQL语句 select * from t where id=1； 这条SQL只扫描一行，但是执行时间确很长，如果我们执行语句是 select * from t where id=1 lock in share mode，执行时扫描行数也是 1 行，执行时间确非常短，看上去非常奇怪，按理说 lock in share mode 还要加锁，时间应该更长才对啊，具体说明如下，如下SQL流程： session A session B start transaction with consistent snapshot; update t set c = c + 1 where id = 1;// 执行100万次 select * from t where id = 1; select * from t where id = 1 lock in share mode; 你看到了，session A 先用 start transaction with consistent snapshot 命令启动了一个事务，之后 session B 才开始执行 update 语句，session B 更新完 100 万次，生成了 100 万个回滚日志 (undo log)。带 lock in share mode 的 SQL 语句，是当前读，因此会直接读到 1000001 这个结果，所以速度很快；而 select * from t where id=1 这个语句，是一致性读，因此需要从 1000001 开始，依次执行 undo log，执行了 100 万次以后，才将 1 这个结果返回。所以这就是上述现象的原因。 幻读和间隙锁幻读什么是幻读？ 在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。因此，幻读在“当前读”下才会出现。 上面 session B 的修改结果，被 session A 之后的 select 语句用“当前读”看到，不能称为幻读。幻读仅专指“新插入的行”。 幻读带来的问题？ 对行锁语义的破坏 破坏了数据一致性 为啥会出现幻读？ 行锁只能锁定存在的行，针对新插入的操作没有限定 间隙锁产生幻读的原因是，行锁只能锁住行，但是新插入记录这个动作，要更新的是记录之间的“间隙”。因此，为了解决幻读问题，InnoDB 只好引入新的锁，也就是间隙锁 (Gap Lock)。顾名思义，间隙锁，锁的就是两个值之间的空隙。 注意：间隙锁是在可重复读隔离级别（RR）下才会生效的。 数据行是可以加上锁的实体，数据行之间的间隙，也是可以加上锁的实体。但是间隙锁跟我们之前碰到过的锁都不太一样。跟间隙锁存在冲突关系的，是“往这个间隙中插入一个记录”这个操作。间隙锁之间都不存在冲突关系。 间隙锁和行锁合称 next-key lock，每个 next-key lock 是前开后闭区间。也就是说，我们有一个表 t 初始化以后，如果用 select * from t for update 要把整个表所有记录锁起来，就形成了 next-key lock，分别是 (-∞, id1]、(id2, id3]、… 、(idn, +supremum]。supremum从哪儿来的呢？这是因为 +∞是开区间。实现上，InnoDB 给每个索引加了一个不存在的最大值 supremum，这样才符合我们前面说的“都是前开后闭区间”。 注意：间隙锁本身是前开后开的区间锁，next-key lock 才是前开后闭区间。 间隙锁的引入，可能会导致同样的语句锁住更大的范围，这其实是影响了并发度的。 非索引字段update或者delete对于非索引字段进行update或select .. for update操作，代价极高。所有记录上锁，以及所有间隔的锁。对于索引字段进行上述操作，代价一般。只有索引字段本身和附近的间隔会被加锁。（个人理解：锁是加在主键索引上的） MySQL加锁规则MySQL加锁规则里面，包含了两个“原则”、两个“优化”和一个“bug”。 原则 1：加锁的基本单位是 next-key lock。希望你还记得，next-key lock 是前开后闭区间。 原则 2：查找过程中访问到的对象才会加锁。 优化 1：索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁。 优化 2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。 一个 bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。 注意： 只有访问到的对象才会加锁，比如我们访问一个普通索引的字段，使用覆盖索引就可以查询出来数据，这时我们是不会给主键索引来加锁的。（lock in share mode 只锁覆盖索引，但是如果是 for update 就不一样了。 执行 for update 时，系统会认为你接下来要更新数据，因此会顺便给主键索引上满足条件的行加上行锁。如果你要用 lock in share mode 来给行加读锁避免数据被更新的话，就必须得绕过覆盖索引的优化，在查询字段中加入索引中不存在的字段。） 申请锁的顺序是 先申请间隙锁，然后再申请行锁。（有的时候我们一条更新语句加锁的时候我们先加了间隙锁，然后加行锁的时候发现行被占用，因为间隙锁之间不是互斥的，这是行锁申请失败被阻塞住等待其他事务释放行锁，但间隙锁已经加成功，也会导致一些其他的操作被此间隙锁所阻塞住）。 在删除数据的时候尽量加 limit。这样不仅可以控制删除数据的条数，让操作更安全，还可以减小加锁的范围。 “有行”才会加行锁。如果查询条件没有命中行，那就加 next-key lock。 范围查询：无论是否是唯一索引，范围查询都需要访问到不满足条件的第一个值为止。 例如有一个表有数据如下： 1(0,0,0),(5,5,5),(10,10,10),(15,15,15),(20,20,20),(25,25,25); 对应字段为(id, c, d)，c 建立了普通索引，我们有如下查询语句： 12beginselect * from t where t.c &gt;= 15 and c &lt; 20 order by c desc lock in share mode; 这里的加锁逻辑如下: 由于是 order by c desc，第一个要定位的是索引 c 上“最右边的”c=20 的行，所以会加上间隙锁 (20,25) 和 next-key lock (15,20]。 在索引 c 上向左遍历，要扫描到 c=10 才停下来，所以 next-key lock 会加到 (5,10]。 注意这里是重点：为什么会加(5,10]，因为我们的desc向左扫描的时候，我们需要扫描到10才能停下来，而我们的 next-key lock 是前开后闭区间，为了保证10这行本身也被锁住，所以我们需要正向的加 (5,10] 的 next-key lock，所以这就是为什么这个锁的范围这么广的原因。而如果我们是asc，这样就不会存在这种问题，就是正常的加锁逻辑，不会多出来一个锁区间。 在扫描过程中，c=20、c=15、c=10 这三行都存在值，由于是 select *，所以会在主键 id 上加三个行锁。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://jjw-story.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://jjw-story.github.io/tags/MySQL/"},{"name":"实践一","slug":"实践一","permalink":"https://jjw-story.github.io/tags/实践一/"}],"author":"JJW"},{"title":"MySQL-基础","slug":"MySQL-基础","date":"2020-07-10T12:37:48.000Z","updated":"2020-07-28T03:27:38.833Z","comments":true,"path":"2020/07/10/MySQL-基础/","link":"","permalink":"https://jjw-story.github.io/2020/07/10/MySQL-基础/","excerpt":"","text":"SQL查询语句的执行过程MySQL 可以分为 Server 层和存储引擎层两部分 Server 层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。 而存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等多个存储引擎。现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始成为了默认存储引擎。我们可以在 create table 语句中使用 engine=memory, 来指定使用内存引擎创建表。 不同的存储引擎共用一个 Server 层，也就是从连接器到执行器的部分。 连接器连接器负责跟客户端建立连接、获取权限、维持和管理连接。一个用户成功建立连接后，即使你用管理员账号对这个用户的权限做了修改，也不会影响已经存在连接的权限。修改完成后，只有再新建的连接才会使用新的权限设置。连接完成后，如果你没有后续的动作，这个连接就处于空闲状态，你可以在 show processlist 命令中看到它，如果其中的 Command 列显示为“Sleep”的这一行，就表示现在系统里面有一个空闲连接。客户端如果太长时间没动静，连接器就会自动将它断开。这个时间是由参数 wait_timeout 控制的，默认值是 8 小时。 数据库里面，长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。短连接则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。建立连接的过程通常是比较复杂的，所以我建议你在使用中要尽量减少建立连接的动作，也就是尽量使用长连接。 但是全部使用长连接后，你可能会发现，有些时候 MySQL 占用内存涨得特别快，这是因为 MySQL 在执行过程中临时使用的内存是管理在连接对象里面的。这些资源会在连接断开的时候才释放。所以如果长连接累积下来，可能导致内存占用太大，被系统强行杀掉（OOM），从现象看就是 MySQL 异常重启了.怎么解决这个问题呢: 定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。 可以在每次执行一个比较大的操作后，通过执行 mysql_reset_connection 来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。 查询缓存MySQL 拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以 key-value 对的形式，被直接缓存在内存中。如果语句不在查询缓存中，就会继续后面的执行阶段。执行完成后，执行结果会被存入查询缓存中。 但是大多数情况下我会建议你不要使用查询缓存，为什么呢？因为查询缓存往往弊大于利。 查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。因此很可能你费劲地把结果存起来，还没使用呢，就被一个更新全清空了。对于更新压力大的数据库来说，查询缓存的命中率会非常低。除非你的业务就是有一张静态表，很长时间才会更新一次。比如，一个系统配置表，那这张表上的查询才适合使用查询缓存。 可以将参数 query_cache_type 设置成 DEMAND，这样对于默认的 SQL 语句都不使用查询缓存。而对于你确定要使用查询缓存的语句，可以用 SQL_CACHE 显式指定，如下查询语句： 1select SQL_CACHE * from T where ID=10; 需要注意的是，MySQL 8.0 版本直接将查询缓存的整块功能删掉了。 分析器如果没有命中查询缓存，就要开始真正执行语句了。 分析器先会做“词法分析”。你输入的是由多个字符串和空格组成的一条 SQL 语句，MySQL 需要识别出里面的字符串分别是什么，代表什么。做完了这些识别以后，就要做“语法分析”。根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法。 优化器经过了分析器，MySQL 就知道你要做什么了。在开始执行之前，还要先经过优化器的处理。优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。 执行器优化器阶段完成后，这个语句的执行方案就确定下来了，然后进入执行器阶段。开始执行的时候，要先判断一下你对这个表 T 有没有执行查询的权限，如果没有，就会返回没有权限的错，如果命中查询缓存，会在查询缓存返回结果的时候，做权限验证。 具体的执行查询会一行一行的扫描，扫描到满足条件的行就返回，如果没有就直到扫描到最后一行，对于有索引的表，执行的逻辑也差不多。第一次调用的是“取满足条件的第一行”这个接口，之后循环取“满足条件的下一行”这个接口，这些接口都是引擎中已经定义好的。 你会在数据库的慢查询日志中看到一个 rows_examined 的字段，表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。 SQL更新语句的执行过程可以确定的说，查询语句的那一套流程，更新语句也是同样会走一遍。 你执行语句前要先连接数据库，这是连接器的工作。在一个表上有更新的时候，跟这个表有关的查询缓存会失效，所以这条语句就会把表 T 上所有缓存结果都清空。这也就是我们一般不建议使用查询缓存的原因。接下来，分析器会通过词法和语法解析知道这是一条更新语句。优化器决定要使用 ID 这个索引。然后，执行器负责具体执行，找到这一行，然后更新。 与查询流程不一样的是，更新流程还涉及两个重要的日志模块：redo log 和 binlog redo logWAL 技术:Write-Ahead Logging，它的关键点就是先写日志，再写磁盘。具体来说，当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log 里面，并更新内存，这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做。 InnoDB 的 redo log 是固定大小的，比如可以配置为一组 4 个文件，每个文件的大小是 1GB，那么总共就可以记录 4GB 的操作。从头开始写，写到末尾就又回到开头循环写，类似于循环链表的一个数据结构。write pos 是当前记录的位置的一个指针，一边写一边后移，checkpoint 是当前要擦除的位置的指针，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。如果 write pos 追上 checkpoint，表示“粉板”满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint 推进一下。 有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为 crash-safe。 redo log buffer开启一个事务有多个操作，我们将里面的各种操作一个一个执行完后日志写入到redo log buffer，真正把日志写到 redo log 文件（文件名是 ib_logfile+ 数字），是在执行 commit 语句的时候做的。 redo log buffer 就是一块内存，用来先存 redo 日志的。 binlog前面我们讲过，MySQL 整体来看，其实就有两块：一块是 Server 层，它主要做的是 MySQL 功能层面的事情；还有一块是引擎层，负责存储相关的具体事宜。上面我们聊到的 redo log 是 InnoDB 引擎特有的日志（重做日志），而 Server 层也有自己的日志，称为 binlog（归档日志），他们的不同之处有如下三点: redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。 redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”。 redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。 一条更新语句的流程如下： 1234567891. 取ID=2这一行2. 数据是否在内存中2 -&gt; true: 返回行数据； 2 -&gt; false:从磁盘读入内存3. 内存中的行数据C值+14. 写入新行5. 新行更新到内存6. 写入redo log - 处于prepare阶段7. 写binlog8. 提交事务，处于commit状态，同时提交 redo log。（两阶段提交） 最后三步看上去有点“绕”，将 redo log 的写入拆成了两个步骤：prepare 和 commit，这就是”两阶段提交”。 两阶段提交上述我们记录演示了redo log的两阶段提交，但是我们为什么要使用两阶段提交，具体如下。 binlog 会记录所有的逻辑操作，并且是采用“追加写”的形式。怎样让数据库恢复到半个月内任意一秒的状态: 首先，找到最近的一次全量备份，如果你运气好，可能就是昨天晚上的一个备份，从这个备份恢复到临时库。 然后，从备份的时间点开始，将备份的 binlog 依次取出来，重放到中午误删表之前的那个时刻。 如果我们执行一条更新语句，不使用两阶段提交，会出现什么情况： 先写 redo log 后写 binlog。假设在 redo log 写完，binlog 还没有写完的时候，MySQL 进程异常重启。由于我们前面说过的，redo log 写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行 c 的值是 1。但是由于 binlog 没写完就 crash 了，这时候 binlog 里面就没有记录这个语句。因此，之后备份日志的时候，存起来的 binlog 里面就没有这条语句。然后你会发现，如果需要用这个 binlog 来恢复临时库的话，由于这个语句的 binlog 丢失，这个临时库就会少了这一次更新，恢复出来的这一行 c 的值就是 0，与原库的值不同。 先写 binlog 后写 redo log。如果在 binlog 写完之后 crash，由于 redo log 还没写，崩溃恢复以后这个事务无效，所以这一行 c 的值是 0。但是 binlog 里面已经记录了“把 c 从 0 改成 1”这个日志。所以，在之后用 binlog 来恢复的时候就多了一个事务出来，恢复出来的这一行 c 的值就是 1，与原库的值不同。 可以看到，如果不使用“两阶段提交”，那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。简单说，redo log 和 binlog 都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致。 两阶段提交日志相关问题 在两阶段提交的不同时刻，MySQL 异常重启会出现什么现象，如果 binlog 写完，redo log 还没 commit 前发生 crash，那崩溃恢复的时候 MySQL 会怎么处理： 如果 redo log 里面的事务是完整的，也就是已经有了 commit 标识，则直接提交； 如果 redo log 里面的事务只有完整的 prepare，则判断对应的事务 binlog 是否存在并完整：a. 如果是，则提交事务；b. 否则，回滚事务。 MySQL 怎么知道 binlog 是完整的： 一个事务的 binlog 是有完整格式的：statement 格式的 binlog，最后会有 COMMIT；row 格式的 binlog，最后会有一个 XID event。 redo log 和 binlog 是怎么关联起来的? 它们有一个共同的数据字段，叫 XID。崩溃恢复的时候，会按顺序扫描 redo log： 如果碰到既有 prepare、又有 commit 的 redo log，就直接提交； 如果碰到只有 parepare、而没有 commit 的 redo log，就拿着 XID 去 binlog 找对应的事务。 总结redo log 用于保证 crash-safe 能力。innodb_flush_log_at_trx_commit 这个参数设置成 1 的时候，表示每次事务的 redo log 都直接持久化到磁盘。这个参数我建议你设置成 1，这样可以保证 MySQL 异常重启之后数据不丢失。 sync_binlog 这个参数设置成 1 的时候，表示每次事务的 binlog 都持久化到磁盘。这个参数我也建议你设置成 1，这样可以保证 MySQL 异常重启之后 binlog 不丢失。 事务隔离事务就是要保证一组数据库操作，要么全部成功，要么全部失败。提到事务，我们会想到 ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性），今天我们就来说说其中 I，也就是“隔离性”。 当数据库上有多个事务同时执行的时候，就可能出现脏读（dirty read）、不可重复读（non-repeatable read）、幻读（phantom read）的问题，为了解决这些问题，就有了“隔离级别”的概念。 SQL 标准的事务隔离级别包括： 读未提交是指，一个事务还没提交时，它做的变更就能被别的事务看到。 读提交是指，一个事务提交之后，它做的变更才会被其他事务看到。 可重复读是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。 串行化，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。 隔离级别相关SQL： 12345# 查看当前事务隔离级别show variables like &apos;transaction_isolation&apos;;# 修改隔离级别将启动参数 transaction-isolation 的值设置成 对应的级别 如：READ-COMMITTED 隔离级别的实现原理实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。在“读提交”隔离级别下，这个视图是在每个 SQL 语句开始执行的时候创建的。这里需要注意的是，“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；而“串行化”隔离级别下直接用加锁的方式来避免并行访问。 这里展开说明”可重复读”：在 MySQL 中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。假设一个值从 1 被按顺序改成了 2、3、4，他们创建的视图分别是read-view A、read-view B、read-view C，在视图 A、B、C 里面，这一个记录的值分别是 1、2、3，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）。对于 read-view A，要得到 1，就必须将当前值依次执行图中所有的回滚操作得到。同时你会发现，即使现在有另外一个事务正在将 4 改成 5，这个事务跟 read-view A、B、C 对应的事务是不会冲突的。 事务回滚日志只有再在不需要的时候才删除。也就是说，系统会判断，当没有事务再需要用到这些回滚日志时，回滚日志会被删除。什么时候才不需要了呢？就是当系统里没有比这个回滚日志更早的 read-view 的时候。 基于上面的说明，我们来讨论一下为什么建议你尽量不要使用长事务。长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。 怎么避免使用长事务： 确认是否使用了 set autocommit=0。这个确认工作可以在测试环境中开展，把 MySQL 的 general_log 开起来，然后随便跑一个业务逻辑，通过 general_log 的日志来确认。一般框架如果会设置这个值，也就会提供参数来控制行为，你的目标就是把它改成 1。 确认是否有不必要的只读事务。有些框架会习惯不管什么语句先用 begin/commit 框起来。我见过有些是业务并没有这个需要，但是也把好几个 select 语句放到了事务中。这种只读事务可以去掉。 业务连接数据库的时候，根据业务本身的预估，通过 SET MAX_EXECUTION_TIME 命令，来控制每个语句执行的最长时间，避免单个语句意外执行太长时间 事务的启动方式 显式启动事务语句， begin 或 start transaction。配套的提交语句是 commit，回滚语句是 rollback。 set autocommit=0，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个 select 语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行 commit 或 rollback 语句，或者断开连接。在 autocommit 为 1 的情况下，用 begin 显式启动的事务，如果执行 commit 则提交事务。如果执行 commit work and chain，则是提交事务并自动启动下一个事务，这样也省去了再次执行 begin 语句的开销。同时带来的好处是从程序开发的角度明确地知道每个语句是否处于事务中。 查询长事务的SQL语句： 12# 查找持续时间超过 60s 的事务select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))&gt;60 索引索引的出现其实就是为了提高数据查询的效率，就像书的目录一样。 索引的常见模型 哈希表：哈希表这种结构适用于只有等值查询的场景，但是对于区间查找，因为Hash表示无序的，这样就需要全部都扫描一遍进行对比。 有序数组：在等值查询和范围查询场景中的性能就都非常优秀。但是，在需要更新数据的时候就麻烦了，你往中间插入一个记录就必须得挪动后面所有的记录，成本太高。 二叉搜索树：二叉树为了维持 O(log(N)) 的查询复杂度，你就需要保持这棵树是平衡二叉树。为了做这个保证，更新的时间复杂度也是 O(log(N))。你可以想象一下一棵 100 万节点的平衡二叉树，树高 20。一次查询可能需要访问 20 个数据块。在机械硬盘时代，从磁盘随机读一个数据块需要 10 ms 左右的寻址时间，这样就会使用很长的时间。 为了让一个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块。那么，我们就不应该使用二叉树，而是要使用“N 叉”树。这里，“N 叉”树中的“N”取决于数据块的大小。 InnoDB 的索引模型在 InnoDB 中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。又因为前面我们提到的，InnoDB 使用了 B+ 树索引模型，所以数据都是存储在 B+ 树中的。 主键索引的叶子节点存的是整行数据。在 InnoDB 里，主键索引也被称为聚簇索引（clustered index）。非主键索引的叶子节点内容是主键的值。在 InnoDB 里，非主键索引也被称为二级索引（secondary index）。 基于主键索引和普通索引的查询有什么区别？基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量使用主键查询。 索引维护B+ 树为了维护索引有序性，在插入新值的时候需要做必要的维护。B+树每个节点维护的都是数据页，当我们需要插入一条记录的时候，只需要将这条记录找到索引应该对应的数据页，放入行中即可，但是我们插入的位置需要挪动数据页相对位置后面的数据的时候，就比较麻烦了（比如：数据页中原数据是 …3,5… ，但是我们插入的数据是4，则需要将5以及5后面的内容都移动一下空出位置），而更糟的情况是，如果 R5 所在的数据页已经满了，根据 B+ 树的算法，这时候需要申请一个新的数据页，然后挪动部分数据过去。这个过程称为页分裂。在这种情况下，性能自然会受影响。除了性能外，页分裂操作还影响数据页的利用率。原本放在一个页的数据，现在分到两个页中，整体空间利用率降低大约 50%。当然有分裂就有合并。当相邻两个页由于删除了数据，利用率很低之后，会将数据页做合并。合并的过程，可以认为是分裂过程的逆过程。 哪些场景应该使用自增主键，哪些场景不应该使用： 使用自增主键的好处：插入新记录的时候可以不指定 ID 的值，系统会获取当前 ID 最大值加 1 作为下一条记录的 ID 值。也就是说，自增主键的插入数据模式，正符合了我们前面提到的递增插入的场景。每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。而有业务逻辑的字段做主键，则往往不容易保证有序插入，这样写数据成本相对较高。 从存储空间来考虑：设你的表中确实有一个唯一字段，比如字符串类型的身份证号，那应该用身份证号做主键，还是用自增字段做主键呢？由于每个非主键索引的叶子节点上都是主键的值。如果用身份证号做主键，那么每个二级索引的叶子节点占用约 20 个字节，而如果用整型做主键，则只要 4 个字节，如果是长整型（bigint）则是 8 个字节。显然，主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。所以，从性能和存储空间方面考量，自增主键往往是更合理的选择。 适合用业务字段作为主键的场景： 只有一个索引; 该索引必须是唯一索引; 由于没有其他索引，所以也就不用考虑其他索引的叶子节点大小的问题。 普通索引的查询逻辑普通索引使用的查询逻辑是，先在普通索引上找到符合要求的索引节点，从节点拿到主键的值，然后我们通过主键的值去主键索引上拿到所有数据的值，这个过程叫做回表。 由于查询结果所需要的数据只在主键索引上有，所以不得不回表。那么，有没有可能经过索引优化，避免回表过程呢？ 覆盖索引如果执行的语句是 select ID from T where k between 3 and 5，这时只需要查 ID 的值，而 ID 的值已经在 k 索引树上了，因此可以直接提供查询结果，不需要回表。也就是说，在这个查询里面，索引 k 已经“覆盖了”我们的查询需求，我们称为覆盖索引。 由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。 很多时候，我们建立联合索引就是利用的覆盖索引这一个概念，比如我们要查询 a &gt; 0 AND b &gt; 1，这时候我们如果只对a建立索引，那么b的值判断我们就需要通过回表的方式，去主键索引中拿到b的值，然后判断，这就耗费了大量的时间，但是我们建立了联合索引，就可以直接在此联合索引上先判断a的值，然后判断b的值，不需要通过回表，能大量提升效率。 最左前缀原则B+ 树这种索引结构，可以利用索引的“最左前缀”，来定位记录，包括联合索引。 示例： （如果你要查的是所有名字第一个字是“张”的人，你的 SQL 语句的条件是”where name like ‘张 %’”。这时，你也能够用上这个索引，查找到第一个符合条件的记录是 ID3，然后向后遍历，直到不满足条件为止。） 在建立联合索引的时候，如何安排索引内的字段顺序： 上一节覆盖索引的示例中，我们建立的a b联合索引，如果单独只查询b，这样是不走索引的，因为最左匹配原则 第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。 索引下推索引下推其实就是我们上述联合索引覆盖索引的具体应用原理，就是联合索引 a b，然后查询a &gt; 0 AND b &gt; 1，减少回表次数，这就是索引下推的原理。 锁数据库锁设计的初衷是处理并发问题。作为多用户共享的资源，当出现并发访问的时候，数据库需要合理地控制资源的访问规则。而锁就是用来实现这些访问规则的重要数据结构。 根据加锁的范围，MySQL 里面的锁大致可以分成全局锁、表级锁和行锁三类。 全局锁全局锁就是对整个数据库实例加锁。MySQL 提供了一个加全局读锁的方法，命令是 Flush tables with read lock (FTWRL)。当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。 全局锁的典型使用场景是，做全库逻辑备份。也就是把整库每个表都 select 出来存成文本。 但是让整库都只读，听上去就很危险： 如果你在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆。 如果你在从库上备份，那么备份期间从库不能执行主库同步过来的 binlog，会导致主从延迟。 但是我们在全库备份的时候，如果不加全局锁，备份系统备份的得到的库不是一个逻辑时间点，这个视图是逻辑不一致的。 官方自带的逻辑备份工具是 mysqldump。当 mysqldump 使用参数–single-transaction的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于 MVCC 的支持，这个过程中数据是可以正常更新的。 一致性读是好，但前提是引擎要支持这个隔离级别，如果是一些不支持这个隔离级别的引擎，就还是需要全局锁来实现全库备份，所以，single-transaction 方法只适用于所有的表使用事务引擎的库。 既然要全库只读，为什么不使用 set global readonly=true 的方式呢？确实 readonly 方式也可以让全库进入只读状态，但我还是会建议你用 FTWRL 方式，主要有两个原因： 一是，在有些系统中，readonly 的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。因此，修改 global 变量的方式影响面更大，我不建议你使用。 二是，在异常处理机制上有差异。如果执行 FTWRL 命令之后由于客户端发生异常断开，那么 MySQL 会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为 readonly 之后，如果客户端发生异常，则数据库就会一直保持 readonly 状态，这样会导致整个库长时间处于不可写状态，风险较高。 表级锁MySQL 里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL)。 表锁：语法是 lock tables … read/write。与 FTWRL 类似，可以用 unlock tables 主动释放锁，也可以在客户端断开的时候自动释放。需要注意，lock tables 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。举个例子, 如果在某个线程 A 中执行 lock tables t1 read, t2 write; 这个语句，则其他线程写 t1、读写 t2 的语句都会被阻塞。同时，线程 A 在执行 unlock tables 之前，也只能执行读 t1、读写 t2 的操作。连写 t1 都不允许，自然也不能访问其他表。 元数据锁：MDL 不需要显式使用，在访问一个表的时候会被自动加上。MDL 的作用是，保证读写的正确性。当对一个表做增删改查操作的时候，加 MDL 读锁；当要对表做结构变更操作的时候，加 MDL 写锁。 读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。 读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。 虽然 MDL 锁是系统默认会加的，但却是你不能忽略的一个机制。所有对表的增删改查操作都需要先申请 MDL 读锁，就都被锁住，等于这个表现在完全不可读写了。 表锁一般是在数据库引擎不支持行锁的时候才会被用到的。如果你发现你的应用程序里有 lock tables 这样的语句，你需要追查一下，比较可能的情况是： 要么是你的系统现在还在用 MyISAM 这类不支持事务的引擎，那要安排升级换引擎； 要么是你的引擎升级了，但是代码还没升级。我见过这样的情况，最后业务开发就是把 lock tables 和 unlock tables 改成 begin 和 commit，问题就解决了。 Online DDL: Online DDL的过程是这样的： 拿MDL写锁 降级成MDL读锁 真正做DDL 升级成MDL写锁 释放MDL锁 1、2、4、5如果没有锁冲突，执行时间非常短。第3步占用了DDL绝大部分时间，这期间这个表可以正常读写数据，是因此称为“online ” 行锁MySQL 的行锁是在引擎层由各个引擎自己实现的。但并不是所有的引擎都支持行锁，比如 MyISAM 引擎就不支持行锁。不支持行锁意味着并发控制只能使用表锁，对于这种引擎的表，同一张表上任何时刻只能有一个更新在执行，这就会影响到业务并发度。 两阶段锁的概念：在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。所以我们在使用锁的时候需要注意：如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。 死锁和死锁检测当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。 死锁的解决策略： 一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置。innodb_lock_wait_timeout 的默认值是 50s，意味着如果采用第一个策略，当出现死锁以后，第一个被锁住的线程要过 50s 才会超时退出，然后其他线程才有可能继续执行。 另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。正常情况下我们还是要采用第二种策略，即：主动死锁检测，而且 innodb_deadlock_detect 的默认值本身就是 on。主动死锁检测在发生死锁的时候，是能够快速发现并进行处理的，但是它也是有额外负担的。每当一个事务被锁的时候，就要看看它所依赖的线程有没有被别人锁住，如此循环，最后判断是否出现了循环等待，也就是死锁，这个负担在高并发的时候是很大的 事务和行锁的关系事务的启动时机begin/start transaction 命令并不是一个事务的起点，在执行到它们之后的第一个操作 InnoDB 表的语句，事务才真正启动。如果你想要马上启动一个事务，可以使用 start transaction with consistent snapshot 这个命令。 第一种启动方式，一致性视图是在执行第一个快照读语句时创建的； 第二种启动方式，一致性视图是在执行 start transaction with consistent snapshot 时创建的。 一致性视图：是 InnoDB 在实现 MVCC 时用到的一致性读视图，即 consistent read view，用于支持 RC（Read Committed，读提交）和 RR（Repeatable Read，可重复读）隔离级别的实现。 “快照”在 MVCC 里的工作原理在可重复读隔离级别下，事务在启动的时候就“拍了个快照”。注意，这个快照是基于整库的，实际上，这个快照并不需要拷贝出全库的数据，它的实现如下： InnoDB 里面每个事务有一个唯一的事务 ID，叫作 transaction id。它是在事务开始的时候向 InnoDB 的事务系统申请的，是按申请顺序严格递增的。而每行数据也都是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本，并且把 transaction id 赋值给这个数据版本的事务 ID，记为 row trx_id。同时，旧的数据版本要保留，并且在新的数据版本中，能够有信息可以直接拿到它。也就是说，数据表中的一行记录，其实可能有多个版本 (row)，每个版本有自己的 row trx_id。 注意：*事务启动的时候还要保存“现在正在执行的所有事物ID列表”，如果一个row trx_id在这列表中，也要不可见，这就保证了一个事务的row trx_id比较大，还有比它小的row trx_id还未提交，这样比它小的row trx_id的数据同样不可见。 按照可重复读的定义，一个事务启动的时候，能够看到所有已经提交的事务结果。但是之后，这个事务执行期间，其他事务的更新对它不可见。因此，一个事务只需要在启动的时候声明说，“以我启动的时刻为准，如果一个数据版本是在我启动之前生成的，就认；如果是我启动以后才生成的，我就不认，我必须要找到它的上一个版本”。在实现上， InnoDB 为每个事务构造了一个数组，用来保存这个事务启动瞬间，当前正在“活跃”的所有事务 ID。“活跃”指的就是，启动了但还没提交。数组里面事务 ID 的最小值记为低水位，当前系统里面已经创建过的事务 ID 的最大值加 1 记为高水位。这个视图数组和高水位，就组成了当前事务的一致性视图（read-view），这个视图数组把所有的 row trx_id 分成了几种不同的情况。 已提交事务 - （低水位） - 未提交事务集合 - （高水位） - 未开始事务 InnoDB 利用了“所有数据都有多个版本”的这个特性，实现了“秒级创建快照”的能力。（具体来说就是，一致性读会读取到当前数据的真实值，然后通过这个水位，找到当前事务之后提交的数据的 undo log，然后回放 undo log 获取到当时的数据，这样来保证一致性读） 一个数据版本，对于一个事务视图来说，除了自己的更新总是可见以外，有三种情况： 版本未提交，不可见； 版本已提交，但是是在视图创建后提交的，不可见； 版本已提交，而且是在视图创建前提交的，可见； 更新逻辑一个非常非常重要的概念更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）。意味着我们更新数据的时候，读的数据就不能从事务视图中拿了，必须直接拿当前的值，否则其他事务所更新的数据就有可能被丢失。 基于此逻辑，我们的写锁就与事务结合了起来：如果我们在写数据的时候不通过当前读，那就会导致每个事务都只更新自己的数据，还要锁干什么，只有通过当前读，我们才会对当前内存中的数据进行加锁，这样保证每个事务在更新数据的时候都是串行的，两阶段锁协议保证每个事务的修改只有再提交或者回滚后，下一个事务的更新操作才能获取到锁，才能进行更新数据，每个事务更新的数据才不会丢失，到这里，我们把一致性读、当前读和行锁就串起来了。 事务的可重复读的能力是怎么实现的？可重复读的核心就是一致性读（consistent read）；而事务更新数据的时候，只能用当前读。如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。 而读提交的逻辑和可重复读的逻辑类似，它们最主要的区别是： 在可重复读隔离级别下，只需要在事务开始的时候创建一致性视图，之后事务里的其他查询都共用这个一致性视图； 在读提交隔离级别下，每一个语句执行前都会重新算出一个新的视图。 为什么表结构不支持“可重复读”？这是因为表结构没有对应的行数据，也没有 row trx_id，因此只能遵循当前读的逻辑。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://jjw-story.github.io/categories/MySQL/"}],"tags":[{"name":"入门","slug":"入门","permalink":"https://jjw-story.github.io/tags/入门/"},{"name":"MySQL","slug":"MySQL","permalink":"https://jjw-story.github.io/tags/MySQL/"}],"author":"JJW"},{"title":"Kebernetes-进阶","slug":"Kebernetes-进阶","date":"2020-06-30T12:12:20.000Z","updated":"2020-07-10T12:50:14.601Z","comments":true,"path":"2020/06/30/Kebernetes-进阶/","link":"","permalink":"https://jjw-story.github.io/2020/06/30/Kebernetes-进阶/","excerpt":"","text":"Kubectl连接K8s集群配置（Cluster配置）在我们搭建好K8s集群后，需要通过Kubectl 客户端连接集群并进行相关集群管控操作，一般我们只需要安装kubectl工具，然后将集群中生成的config文件，拷贝到我们需要连接集群的电脑的 ${HOME}/.kube/config 目录下，这样就可以操作K8s集群了。 但是有的时候我们一台客户端电脑需要连接多个K8s集群，这时我们就需要将不同的config文件合并在一起，以方便我们操作。 本节核心命令： kubectl config get-contexts:获取客户端链接的所有上下文 kubectl config get-clusters:获取客户端连接的所有配置cluster kubectl config use-context [context的名称]：切换当前集群的连接 kubectl get node -o wide:查看集群节点的详细信息 kubectl describe node [上述命令查询出的节点名称]:查看某个节点的详细信息 例如我们原有的minikube集群中的config文件如下： 12345678910111213141516171819apiVersion: v1clusters:- cluster: certificate-authority: /home/jjw/.minikube/ca.crt server: https://172.17.0.3:8443 name: minikubecontexts:- context: cluster: minikube user: minikube name: minikubecurrent-context: minikubekind: Configpreferences: &#123;&#125;users:- name: minikube user: client-certificate: /home/jjw/.minikube/profiles/minikube/client.crt client-key: /home/jjw/.minikube/profiles/minikube/client.key 我们现在合并另外一个集群的配置文件如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344# 指定版本apiVersion: v1# 配置clusters，这里就是可以配置连接多个K8s的集群clusters:- cluster: certificate-authority: /home/jjw/.minikube/ca.crt server: https://172.17.0.3:8443 name: minikube- cluster: certificate-authority-data: DATA+OMITTED server: https://172.19.8.113:6443 name: jplocal# 配置context，contexts:# 第一个- context: cluster: minikube user: minikube name: minikube# 第二个- context: cluster: jplocal user: kube-admin-local name: local# 配置默认的连接current-context: minikubekind: Configpreferences: &#123;&#125;# 配置连接集群的uers信息，包含身份认证信息等users:- name: minikube user: client-certificate: /home/jjw/.minikube/profiles/minikube/client.crt client-key: /home/jjw/.minikube/profiles/minikube/client.key- name: kube-admin-local user: client-certificate-data: REDACTED client-key-data: REDACTED 配置完成后我们就可以通过命令查看我们的配置上下文等信息，如下： 12345678910# 注意：带*号表示是我们当前使用连接的contextjjw@jjw-PC:~/.kube$ kubectl config get-contextsCURRENT NAME CLUSTER AUTHINFO NAMESPACE local jplocal kube-admin-local * minikube minikube minikube jjw@jjw-PC:~/.kube$ kubectl config get-clustersNAMEminikubejplocal 切换连接到名称为local的集群： 123456789# 切换jjw@jjw-PC:~/.kube$ kubectl config use-context localSwitched to context &quot;local&quot;.# 查看切换结果，发现切换成功jjw@jjw-PC:~/.kube$ kubectl config get-contextsCURRENT NAME CLUSTER AUTHINFO NAMESPACE* local jplocal kube-admin-local minikube minikube minikube 这样我们就可以操作我们的K8s集群了，例如完整如下： 123456789101112# 获取当前local集群的节点信息，获取不到是因为这个配置是我瞎写的jjw@jjw-PC:~/.kube$ kubectl get nodeerror: tls: failed to find any PEM data in certificate input# 切换成之前的minikube集群jjw@jjw-PC:~/.kube$ kubectl config use-context minikubeSwitched to context &quot;minikube&quot;.# 能够获取到节点信息jjw@jjw-PC:~/.kube$ kubectl get nodeNAME STATUS ROLES AGE VERSIONminikube Ready master 15d v1.18.3 K8s集群网络（Cluster Networking）K8s集群间网络现象及原理当我们搭建了一套K8s集群后，我们在节点中创建Pod，并且查询出此Pod的IP地址，这时我们在任何一个节点或者任何一个节点的Pod中，我们ping这个IP地址，我们发现是都可以ping通的，这就是K8s集群中我们要讲的网络。 在之前的Swarm集群中，我们也有同样的现象，我们知道原理是它们通过一个Overlay的Network实现的，其实K8s集群也是这样，只不过这里是通过某个插件来实现的Overlay网络，远离同样是将Pod的网络代理到机器网关上，类似eth1，然后通过此网关来解析代理。 具体的插件有很多种（例如flannal网络插件），我们可以去K8s官网上查看，这些插件都需要遵循K8s网络的规定或者说协议： 所有的容器跟其他所有的容器之间可以直接通信，并且不需要NAT的转化 所有的Node都可以直接与其他Node的容器进行直接通信，并且不需要NAT的转化 我们的这个容器的IP地址是什么，那么其他容器或者节点就可以直接通过这个IP来访问这个容器 本节核心命令： kubectl get svc:获取集群上所有的Services信息 kubectl get pods –show-labels:查看集群中所有Pod的Label kubectl expose pods [pod名称]:将已有Pod导出创建Service kubectl expose depolyment [depolyment名称]：将已有depolyment导出创建为Service kubectl create -f [service的yml文件名称]：通过yml文件创建service kubectl edit depolyment [depolyment名称]：创建service后，直接编辑此depolymet升级此depolyment kubectl apply -f [新的depolyment yml文件] –record:创建service滚动升级depolyment kubectl delete svc/[service名称]:删除service kubectl delete -f [service的yml文件名称]:通过文件删除service K8s集群中应用对外提供网络Service在上述现象中，我们所描述的Pod提供的IP都只是在K8s集群中可以互访，但是我们部署应用后，需要对外界提供服务，这样我们就需要将网络暴露给外界，这时应该怎么做呢？ 首先我们看看在K8s集群中直接使用和管理Pod的缺点： 当我们使用ReplicaSet或者ReplicationController做水平扩展scale的时候，Pods就有可能被终止掉 当我们使用Depolyment的时候，我们去更新Docker Image Version ，旧的Pod就会被终止，然后创建新的Pod 当我们使用上述两种方式做扩展，如果我们直接管理的是Pod，对外提供的是Pod的IP，那么我们在扩展后，Pod的IP地址就会发生变化，这时我们外界再通过之前的IP就不能访问我们的Pod中提供的服务了。或者是说我们在Pod中部署了数据库服务，其他集群中的Pod可以访问，但是我们对数据库进行升级的时候，这样其他集群中的服务就不能访问数据库了，因为在升级的过程中，数据库的IP地址就发生了变化 为了解决上述问题，我们同样可以使用之前学习过的Service来解决，K8s中管理最常用的也是Service，使用Service我们可以管理多个Pod，并且将这些Pod集中管理起来，可以随意扩展或降级升级，并且保证我们对外提供的IP地址是一个，且不发生变化，而且有负载均衡的作用。 Service主要有三种类型： ClusterIP：这个IP地址是Cluster可以访问的，及K8s集群中任何一个节点都可以访问，但是外界不能访问，这个IP是不会变的，是Service所对应的IP地址，它会代理到我们service中的Pod上，Pod的IP地址是可以变化的，一般应用与只在系统间内部可以访问，比如数据库服务 NodePort：这个Service是对外提供IP地址，这是与ClusterIP类型的Service最大的不同 LoadBalancer：这个一般需要云服务商提供，我们通过这个LoadBalancer就可以访问集群中的Pod，并且提供负载均衡 Service的创建方式： 通过kubectl expose 命令，会给我们的Pod创建一个service，供外部访问 定义一个yml文件，我们在此文件中描述Service的具体信息及资源 创建ClusterIP类型Servcice示例 通过Pod直接创建Service 1234567891011121. 首先创建好Podkubectl create -f [yml文件的路径名称]2. 查看我们创建的Pod的具体信息，包括pod的名称和IP等kubectl get pods -o wide3. 根据pod的名称，创建servicekubectl expose pods [pod名称]4. 查看我们创建的service的具体信息，这里会查看到我们创建的service的IP地址和端口，这里我们查看到的Service的IP地址是不会变化的，而上面我们查看到的Pod的IP地址是会随着服务的扩展升级等发生变化注意：这里查询出的ServiceIP只能在K8s集群内部访问，因为我们创建的是一个ClusterIP类型的Servicekubectl get svc 通过Depolyment创建Service，测试升级或者扩展此应用，Service IP不发生变化 12345678910111213141516171819202122232425262728293031323334353637381. 首先我们创建一个Depolyment，此Depolyment中Pod的个数可以是多个kubectl create -f [deployment的yml文件]jjw@jjw-PC:~$ kubectl create -f deployment_nginx.yml deployment.apps/nginx-deployment created2. 查看我们创建好的pod的具体信息kubectl get pods -o widejjw@jjw-PC:~$ kubectl get pods -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESnginx-deployment-5cc6c7559b-j5v57 1/1 Running 0 16s 172.18.0.5 minikube &lt;none&gt; &lt;none&gt;nginx-deployment-5cc6c7559b-t5z92 1/1 Running 0 16s 172.18.0.4 minikube &lt;none&gt; &lt;none&gt;nginx-deployment-5cc6c7559b-wfbts 1/1 Running 0 16s 172.18.0.6 minikube &lt;none&gt; &lt;none&gt;3. 查看我们此depolyment的具体信息，包括depolyment的名称kubectl get depolyment4. 通过此depolyment创建Servicekubectl expose depolyment [depolyment名称]jjw@jjw-PC:~$ kubectl expose deployment nginx-deploymentservice/nginx-deployment exposed5. 查看我们创建的service，这时，我们的Service的IP信息也就被查看到了kubectl get svcjjw@jjw-PC:~$ kubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 19dnginx-deployment ClusterIP 10.96.161.226 &lt;none&gt; 80/TCP 26s6. 然后我们访问此IP，发现是可以访问到我们Pod提供的服务的，并且它还实现了负载均衡的功能7. 升级此depoluyment，我们可以直接编辑此depolyment来实现升级，使用命令kubectl edit depolyment [depolyment名称]8. 编辑完此depolyment要升级的内容后，我们的服务就会自动升级9. 查看现在的Pod信息，发现pod已经不是我们之前创建的了，而是新的，但是这时我们的Service IP还是没有变化，还是可以通过此IP访问到服务kubectl get pods -o wide 这里我们的升级它不是零宕机的升级，它还是会中断一会，我们可以通过其他方法实现滚动升级，即优雅上下线升级 滚动升级的实现其实就是我们重新定义一个yml，及针对与之前depolyment的yml的升级后的yml，然后通过命令： kubectl apply -f [新的depolyment yml文件] –record 这样就可以实现滚动升级，如果不加 –record 参数，则旧的depolymeng不会被删除，它还会存在，只是Pod数变成了0 创建NodePort类型Servcice示例 通过Pod直接创建Service 1234567891011121. 首先创建好Podkubectl create -f [yml文件的路径名称]2. 查看我们创建的Pod的具体信息，包括pod的名称和IP等kubectl get pods -o wide3. 根据pod的名称，指定参数，创建NodePort类型Servicekubectl expose pods [pod名称] --type=NodePort4. 查看我们创建的service的具体信息注意：这里也会查询出ClusterIP，但是在端口信息上，与ClusterIP类型的Service不同，它会指定一个IP映射（80:31404/TCP），这里就表示我们将Pod的端口映射到了主机上，我们可以通过此映射及Port通过主机的IP来访问此Pod服务。这样如果我们的主机是有公网IP的，那么我们这个服务就可以直接暴露给外界来使用kubectl get svc 通过Depolyment创建NodePort类型的Service 创建方式与上述创建ClusterIP类型的Service一样，不同的是在创建的命令中指定–type=NodePort即可 kubectl expose depolyment [depolyment名称] –type=NodePort即可 通过Service.yml文件创建Service 通过yml文件创建service，我们首先要创建好Pod，然后指定Pod的Label，如下Pod的yml文件，nginx-pod.yml 123456789101112131415apiVersion: v1kind: Podmetadata: name: nginx-pod # 注意：这里我们指明了Pod的Label labels: app: nginxspec: containers: - name: nginx-container image: nginx ports: - name: nginx-port containerPort: 80 创建service的yml文件，如下service_nginx.yml 1234567891011121314151617apiVersion: v1kind: Servicemetadata: name: nginx-servicespec: # 指定端口映射，这里表示将Pod的端口映射为本地的8080和NodePort的8080 ports: - port: 32333 nodePort: 32333 # 这里就表示我们创建service要引用的Pod的，这里指定的是Pod的Label，所以我们创建service的文件是用Label来确定具体Pod的 targetPort: nginx-port protocol: TCP selector: app: nginx type: NodePort 创建service 1kubectl create -f service_nginx.yml 创建LoadBalance类型Servcice示例创建LoadBalance类型的Servcie需要借助于云服务，所以这里不再演示，比较复杂，具体用的时候查资料或者视频即可 具体创建命令： kubectl expose pods [pod名称] –type=LoadBalance kubectl expose depolyment [depolyment名称] –type=LoadBalance secret使用secret的使用与Swarm很类似，具体就是先在集群中创建secret，然后在service的yml文件中要使用的地方引入此secret名称即可 创建secret： kubectl create secret generic [secret名称] –from-literal=[key]=[value]：通过命令直接指定创建 kubectl create secret generic [secret名称] –from-file=[file路径]：通过编辑好的文件创建 示例如下： 12# 创建一个名称为mysql-pass的 键为password 值为jjw0923的secretkubectl create secret generic mysql-pass --from-literal=password=jjw0923 然后在service的yml文件引入即可，具体使用查资料","categories":[],"tags":[{"name":"Kebernetes","slug":"Kebernetes","permalink":"https://jjw-story.github.io/tags/Kebernetes/"},{"name":"进阶","slug":"进阶","permalink":"https://jjw-story.github.io/tags/进阶/"}],"author":"JJW"},{"title":"Kubernetes","slug":"Kubernetes","date":"2020-06-14T05:14:20.000Z","updated":"2020-07-10T12:50:14.433Z","comments":true,"path":"2020/06/14/Kubernetes/","link":"","permalink":"https://jjw-story.github.io/2020/06/14/Kubernetes/","excerpt":"","text":"Kubernetes介绍Kubernetes（k8s）是自动化容器操作的开源平台，这些操作包括部署，调度和节点集群间扩展。它与Swarm是类似的，并且是竞争产品。Swarm是Docker公司开发内置的，K8s是一个专门的社区，在2017年的时候，Docker公司宣布支持K8s，因为K8s的社区等都比较活跃及完善，所以这场竞争中，是K8s胜利了。 使用Kubernetes可以： 自动化容器的部署和复制 随时扩展或收缩容器规模 将容器组织成组，并且提供容器间的负载均衡 很容易地升级应用程序容器的新版本 提供容器弹性，如果容器失效就替换它，等等… Kubernetes解决的问题： 调度 - 容器应该在哪个机器上运行 生命周期和健康状况 - 容器在无错的条件下运行 服务发现 - 容器在哪，怎样与它通信 监控 - 容器是否运行正常 认证 - 谁能访问容器 容器聚合 - 如何将多个容器合并成一个工程 Kubernetes架构及组件Kubernetes属于主从分布式架构，主要由Master Node和Worker Node组成，以及包括客户端命令行工具kubectl和其它附加项（Add on）。 Master Node作为控制节点，对集群进行调度管理（它类似于Swarm的Manager节点），它是K8s集群的大脑。Master Node由API Server、Scheduler、Cluster State Store和Controller-Manger Server所组成。 API ServerAPI Server是暴露给外接访问的，我们可以通过UI或者CLI通过API Server去跟集群进行交互。 API Server主要用来处理REST的操作，确保它们生效，并执行相关业务逻辑，以及更新etcd（或者其他存储）中的相关对象。API Server是所有REST命令的入口，它的相关结果状态将被保存在etcd（或其他存储）中。 另外，API Server也作为集群的网关。默认情况，客户端通过API Server对集群进行访问，客户端需要通过认证，并使用API Server作为访问Node和Pod（以及service）的堡垒和代理/通道。 SchedulerScheduler是一个调度模块，比如我们通过API Server创建一个应用，这个应用有两个容器，那么这两个容器到底要部署在哪个节点上，这就是通过Scheduler模块来进行一些算法来确认的。 scheduler组件为容器自动选择运行的主机。依据请求资源的可用性，服务请求的质量等约束条件，scheduler监控未绑定的pod，并将其绑定至特定的node节点。Kubernetes也支持用户自己提供的调度器，Scheduler负责根据调度策略自动将Pod部署到合适Node中，调度策略分为预选策略和优选策略，Pod的整个调度过程分为两步： 预选Node：遍历集群中所有的Node，按照具体的预选策略筛选出符合要求的Node列表。如没有Node符合预选策略规则，该Pod就会被挂起，直到集群中出现符合要求的Node。 优选Node：预选Node列表的基础上，按照优选策略为待选的Node进行打分和排序，从中获取最优Node。 Controller-Manager Server控制管理服务器，主要是控制容器的负载均衡，或者对容器的横向扩展，比如增加节点等。 它用于执行大部分的集群层次的功能，它既执行生命周期功能(例如：命名空间创建和生命周期、事件垃圾收集、已终止垃圾收集、级联删除垃圾收集、node垃圾收集)，也执行API业务逻辑（例如：pod的弹性扩容）。控制管理提供自愈能力、扩容、应用生命周期管理、服务发现、路由、服务绑定和提供。Kubernetes默认提供Replication Controller、Node Controller、Namespace Controller、Service Controller、Endpoints Controller、Persistent Controller、DaemonSet Controller等控制器。 etcd（Cluster state store）集群状态存储，Kubernetes默认使用etcd作为集群整体存储，当然也可以使用其它的技术。etcd是一个简单的、分布式的、一致的key-value存储，主要被用来共享配置和服务发现。etcd提供了一个CRUD操作的REST API，以及提供了作为注册的接口，以监控指定的Node。集群的所有状态都存储在etcd实例中，并具有监控的能力，因此当etcd中的信息发生变化时，就能够快速的通知集群中相关的组件。 Worker Node作为真正的工作节点，运行业务应用的容器；Worker Node包含kubelet、kube proxy和Fluented、Container Runtime。 Pod在Kubernets中，Pod作为基本的执行单元，在Kubernetes中，最小的管理元素不是一个个独立的容器，而是Pod，Pod是最小的，管理，创建，计划的最小单元。Pod指的是具有相同的Name Space（这里的Name Space包含了所有的，最重要的是Network Name Space）的一些Container的组合，容器可能有多个，如果是多个，它们之间共享一个Network Name Space所以它可以拥有多个容器和存储数据卷，能够方便在每个容器中打包一个单一的应用，从而解耦了应用构建时和部署时的所关心的事项，已经能够方便在物理机/虚拟机之间进行迁移。 KubeletKubelet是Kubernetes中最主要的控制器，它是Pod和Node API的主要实现者，Kubelet负责驱动容器执行层。在Kubernetes中，应用容器彼此是隔离的，并且与运行其的主机也是隔离的，这是对应用进行独立解耦管理的关键点。 API准入控制可以拒绝或者Pod，或者为Pod添加额外的调度约束，但是Kubelet才是Pod是否能够运行在特定Node上的最终裁决者，而不是scheduler或者DaemonSet。kubelet默认情况使用cAdvisor进行资源监控。负责管理Pod、容器、镜像、数据卷等，实现集群（Manager）对节点的管理，并将容器的运行状态汇报给Kubernetes API Server。 kube proxy它是跟网络有关的，（总结就是例如一个service有多个容器，我们对这个service的所有容器提供一个公共的IP，并且实现负载均衡），基于一种公共访问策略（例如：负载均衡），服务提供了一种访问一群pod的途径。此方式通过创建一个虚拟的IP来实现，客户端能够访问此IP，并能够将服务透明的代理至Pod。每一个Node都会运行一个kube-proxy，kube proxy通过iptables规则引导访问至服务IP，并将重定向至正确的后端应用，通过这种方式kube-proxy提供了一个高可用的负载均衡解决方案。服务发现主要通过DNS实现。 在Kubernetes中，kube proxy负责为Pod创建代理服务；引到访问至服务；并实现服务到Pod的路由和转发，以及通过应用的负载均衡。 Container Runtime每一个Node都会运行一个Container Runtime，其负责下载镜像和运行容器。这里容器我们一般选择Docker，当然也可以选择其他产品。 Fluented主要是用于日志的采集、存储、查询等。 Add-onAdd-on是对Kubernetes核心功能的扩展，例如增加网络和网络策略等能力，在Kunbernetes中可以以附加项的方式扩展Kubernetes的功能，目前主要有网络、服务发现和可视化这三大类的附加项。 kubectlkubectl是Kubernetes集群的命令行工具，通过kubectl能够对集群本身进行管理，并能够在集群上进行容器化应用的安装部署。它用于通过命令行与API Server进行交互，而对Kubernetes进行操作，实现在集群中进行各种资源的增删改查等操作。命令的语法如下所示：kubectl [command] [TYPE] [NAME] [flags] Kubernates安装 Kubernates-the-hard-way：最基础的方式，一步一步的安装各种组件，然后安装完成K8s集群，困难度很高 minikube：是一个工具，它能快速在我们本地创建一个只有一个节点的K8s集群 kuberadm：是一个工具，它能快速在我们本地搭建一个有多个节点的K8s集群 kops：快速的在云上创建K8s集群，比如AWS等，操作比较简单 Tectonic：企业版的一个工具，节点数量比较少，免费，大于十个节点是收费的 Play Way Kubernates：在云上快速搭建一个K8s集群，但是它有时间限制，四个小时后会自动销毁 具体的搭建方法可以Google或者Baidu 我们这里使用minikube的方式来创建。 安装完成我们就可以通过一些基础命令开查看K8s集群的状态了，例如： kubectl config view：查看当前config的基本情况，包括Api的IP地址和端口，以及认证信息，context的名字等 kubectl config get-contexts：查看当前的context kubectl cluster-info：查看当前K8s集群的基本情况，节点信息，类似于swarm中的 docker node 命令 使用minikube创建的k8s集群我们可以通过 minikube ssh 命令进入到虚拟机中，在这里面我们可以做具体的操作，比如直接操作docker等 Pod详解及基本操作命令K8s我们不直接对container进行操作，pod是我们的基本操作单元。之前我们说过，一个Pod中的容器是共享一个Namespace的，他们之间是可以直接通信的。 基础操作创建Pod，K8s中我们创建Pod需要通过一个yml文件来创建，这个yml文件有点类似于我们之前学习docker-compose和swarm的stack的文件，以下是一个示例文件： 12345678910111213141516171819202122# api的版本apiVersion: v1# yml锁定义的内容的类型，这里是一个Podkind: Pod# 一些基本的元数据metadata: name: nginx-pod labels: app: nginx# 最重要的部分，它是直接定义容器的spec: # containers表示我们可以定义多个容器，这里只写了一些 containers: - name: nginx-container image: nginx ports: - name: nginx-port containerPort: 80 kubectl create -f [yml文件的路径名称]： 创建Pod kubectl delete -f [yml文件的路径名称]： 删除已经创建的Pod kubectl get pods：查看当前集群中所有的Pod及状态信息等 kubectl get pods -o wide：查看当前集群中所有的Pod及状态信息，包含的信息更全面一些，包含了容器的IP信息和运行的节点等 kubectl delete pods [Pod名称]：删除指定的Pod kubectl describe [Pod名称]：查看Pod的详细信息，包含名称，节点信息，Namespace，所有的Container的详细信息，我们的Pod中的具体容器信息也能显示出来，这里我们就能够查到容器的Iamge、IP、端口、容器ID、状态等信息 kubectl exec -it [Pod名称] -c [Pod中Container名称] /bin/bash：进入Pod中的具体某一个容器，如果我们这里不使用 -c 参数，默认是进入第一个容器中 kubectl port-forward [Pod名称] [本地端口:Pod端口]：端口映射，类似于将容器的端口映射到宿主机上，此命令如果停止我们就无法访问 kubectl get nodes: 查询K8s集群中所有的节点信息 ReplicationControllerReplication Controller简称RC，RC是Kubernetes系统中的核心概念之一，简单来说，RC可以保证在任意时间运行Pod的副本数量，能够保证Pod总是可用的。如果实际Pod数量比指定的多那就结束掉多余的，如果实际数量比指定的少就新启动一些Pod，当Pod失败、被删除或者挂掉后，RC都会去自动创建新的Pod来保证副本数量，所以即使只有一个Pod，我们也应该使用RC来管理我们的Pod。可以说，通过ReplicationController，Kubernetes实现了集群的高可用性。 核心命令： kubectl create -f [rc的yml路径名称]：根据yml文件创建ReplicationController应用 kubectl get rc：查看我们K8s集群所有的rc的简单信息 kubectl get rc -o wide：查看我们K8s集群所有的rc的详细一些信息 kubectl scala rc [rc名称] –replicas=[要扩展后或回收后的Pod总数量]：扩展或者回收rc应用的pod kubectl delete -f [rc的yml路径名称]：根据yml文件删除ReplicationController应用 ReplicationController和Pod一样，都是Kubernetes中的对象，因此创建方式类似。通过yaml或json描述文件来定义一个ReplicationController对象。一个最简单的ReplicationController的定义如下 rc-nginx.yml文件： 12345678910111213141516171819apiVersion: v1kind: ReplicationControllermetadata: name: nginxspec: # 指定副本数，这里指定为3，那么K8s就会创建三个Pod replicas: 3 template: metadata: name: nginx labels: app: nginx spec: containers: - name: nginx image: nginx ports: - containerPort: 80 基于此文件，我们就可以通过命令： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364# 1.通过rc-nginx.yml来创建我们的应用jjw@jjw-PC:~$ kubectl create -f rc-nginx.ymlreplicationcontroller/nginx created# 2.查看我们K8s集群创建的此rc的简单信息jjw@jjw-PC:~$ kubectl get rcNAME DESIRED CURRENT READY AGEnginx 3 3 0 32s# 3.查看集群中所有Pod的具体信息，这里有三个Pod，因为我们在rc-nginx.yml文件中指定了replicas为3个jjw@jjw-PC:~$ kubectl get podsNAME READY STATUS RESTARTS AGEnginx-5p7s2 1/1 Running 0 61snginx-ckph9 1/1 Running 0 61snginx-rs8qk 1/1 Running 0 61s# 4.我们尝试通过命令删除上述查询出的其中一个Podjjw@jjw-PC:~$ kubectl delete pods nginx-5p7s2pod &quot;nginx-5p7s2&quot; deleted# 5.删除之后我们再次查看所有Pod，发现有四个，其中一个的状态为Terminating，然后新增了一个，一共三个是Runnig的状态，说明我们通过rc创建的Pod，它能帮我们维持Pod的数目，这里与Swarm中的stack是一样的jjw@jjw-PC:~$ kubectl get podsNAME READY STATUS RESTARTS AGEnginx-ckph9 1/1 Running 0 51snginx-rs8qk 1/1 Running 0 51snginx-6w6zs 1/1 Running 0 4m1s# 6.我们通过scala将此rc的Pod数量降为2个jjw@jjw-PC:~$ kubectl scale rc nginx --replicas=2replicationcontroller/nginx scaled# 7.然后查看rc的具体信息，发现该nginx rc只有两个了jjw@jjw-PC:~$ kubectl get rcNAME DESIRED CURRENT READY AGEnginx 2 2 2 7m22s# 8.我们查看每一个Pod的具体信息，它们的IP地址是不同的jjw@jjw-PC:~$ kubectl get pods -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESnginx-ckph9 1/1 Running 0 7m45s 172.18.0.6 minikube &lt;none&gt; &lt;none&gt;nginx-rs8qk 1/1 Running 0 7m45s 172.18.0.5 minikube &lt;none&gt; &lt;none&gt;# 9.我们将其中一个pod的端口映射到当前机器上jjw@jjw-PC:~$ kubectl port-forward nginx-ckph9 8080:80Forwarding from 127.0.0.1:8080 -&gt; 80Forwarding from [::1]:8080 -&gt; 80# 10.通过在外部访问，发现我们的8080端口能正确访问映射到pod的80端口jjw@jjw-PC:~$ curl 127.0.0.1:8080&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;&lt;style&gt; body &#123; width: 35em; margin: 0 auto; font-family: Tahoma, Verdana, Arial, sans-serif; &#125;&lt;/style&gt;# 11.删除此ReplicationControllerjjw@jjw-PC:~$ kubectl delete -f rc-nginx.ymlreplicationcontroller &quot;nginx&quot; deleted ReplicaSet在新版本的 Kubernetes 中建议使用 ReplicaSet（简称为RS ）来取代 ReplicationController。ReplicaSet 跟 ReplicationController 没有本质的不同，只是名字不一样，并且 ReplicaSet 支持集合式的 selector（ReplicationController 仅支持等式） 核心命令（与ReplicationController的核心命令大概相同）： kubectl create -f [rs的yml路径名称]：根据yml文件创建ReplicaSet应用 kubectl get rs：查看我们K8s集群所有的rs的简单信息 kubectl get rs -o wide：查看我们K8s集群所有的rs的详细一些信息 kubectl scale rs [rs名称] –replicas=[要扩展后或回收后的Pod总数量]：扩展或者回收rs应用的pod kubectl delete -f [rs的yml路径名称]：根据yml文件删除ReplicaSet应用 下面是rs文件示例，rs-nginx.yml: 123456789101112131415161718192021222324apiVersion: apps/v1kind: ReplicaSetmetadata: name: nginx # 注意 labels的定义与RC有所不同 labels: tier: frontendspec: replicas: 3 selector: matchLabels: tier: frontend template: metadata: name: nginx labels: tier: frontend spec: containers: - name: nginx image: nginx ports: - containerPort: 80 具体的操作我们发现与RC是没有什么区别的，我们可以通过上面的示例，替换一下命令来测试一下，如下： 12345678910111213141516171819202122232425262728jjw@jjw-PC:~$ kubectl create -f rs-nginx.yml replicaset.apps/nginx createdjjw@jjw-PC:~$ kubectl get rsNAME DESIRED CURRENT READY AGEnginx 3 3 0 10sjjw@jjw-PC:~$ kubectl get podsNAME READY STATUS RESTARTS AGEnginx-7zzbg 1/1 Running 0 28snginx-nzsrh 1/1 Running 0 28snginx-zhzbk 1/1 Running 0 28sjjw@jjw-PC:~$ kubectl scale rs nginx --replicas=4replicaset.apps/nginx scaledjjw@jjw-PC:~$ kubectl get podsNAME READY STATUS RESTARTS AGEnginx-7zzbg 1/1 Running 0 91snginx-kp4fz 1/1 Running 0 15snginx-nzsrh 1/1 Running 0 91snginx-zhzbk 1/1 Running 0 91sjjw@jjw-PC:~$ kubectl delete -f rs-nginx.yml replicaset.apps &quot;nginx&quot; deletedjjw@jjw-PC:~$ kubectl get podsNo resources found in default namespace. DeploymentDeployment为Pod和Replica Set提供声明式更新。（个人理解最大的作用就是更新我们的应用用的，它用来替换我们上面学习的三种创建Pod的方式，它底层使用的还是ReplicaSet，类似与对ReplicaSet又做了一层高级的封装）你只需要在 Deployment 中描述您想要的目标状态是什么，Deployment controller 就会帮您将 Pod 和ReplicaSet 的实际状态改变到您的目标状态。您可以定义一个全新的 Deployment 来创建 ReplicaSet 或者删除已有的 Deployment 并创建一个新的来替换。注意：不能手动管理由 Deployment 创建的 Replica Set，否则就篡越了 Deployment controller 的职责！ 核心命令（与ReplicaSet的核心命令大概相同）： kubectl create -f [deployment的yml路径名称]：根据yml文件创建deployment应用 kubectl get deployment：查看我们K8s集群所有的deployment：的简单信息 kubectl get deployment -o wide：查看我们K8s集群所有的deployment的详细一些信息 kubectl set image deployment [deployment名称] [要升级的image名称]=[升级的image版本]：通过命令行直接指定升级的image来升级我们的deployment pod应用 kubectl rollout history deployment [deployment名称]：查看我们的deployment的历史版本，这里默认只有当前和上一个两个版本 kubectl rollout undo deployment [deployment名称]：回滚deployment应用的版本至上一个版本 kubectl delete -f [deployment的yml路径名称]：根据yml文件删除Deployment应用 下面我们通过一个示例来讲解： 首先定义deployment的yml文件，文件内容如下（deployment-nginx.yml） 123456789101112131415161718192021222324252627# 定义的版本，因为它底层使用的是Replica SetapiVersion: apps/v1# 定义类型为Deploymentkind: Deploymentmetadata: name: nginx-deployment labels: app: nginxspec: replicas: 3 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx # 定义我们nginx的版本，这里故意使用一个低版本，便于我们演示升级Pod image: nginx:1.12.2 ports: - containerPort: 80 下面演示具体的操作： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970# 通过此yml文件创建deploymentjjw@jjw-PC:~$ kubectl create -f deployment_nginx.yml deployment.apps/nginx-deployment created# 查看我们K8s集群创建的deployment的简单信息jjw@jjw-PC:~$ kubectl get deploymentNAME READY UP-TO-DATE AVAILABLE AGEnginx-deployment 3/3 3 3 50s# 通过命令查看k8s集群中的所有ReplicaSet，我们发现有一个，而且它的名字是我们deployment的名字加上一段字符jjw@jjw-PC:~$ kubectl get rsNAME DESIRED CURRENT READY AGEnginx-deployment-5cc6c7559b 3 3 3 3m44s# 查看所有的Pod信息，我们发现pod的名称又是rs的名称加上一段字符jjw@jjw-PC:~$ kubectl get podsNAME READY STATUS RESTARTS AGEnginx-deployment-5cc6c7559b-c8l5c 1/1 Running 0 5m8snginx-deployment-5cc6c7559b-cqdzg 1/1 Running 0 5m8snginx-deployment-5cc6c7559b-llzgk 1/1 Running 0 5m8s# 查看我们K8s集群创建的deployment的详细信息，这里我们的image版本是1.12.2jjw@jjw-PC:~$ kubectl get deployment -o wideNAME READY UP-TO-DATE AVAILABLE AGE CONTAINERS IMAGES SELECTORnginx-deployment 3/3 3 3 11m nginx nginx:1.12.2 app=nginx# 通过命令行指定image的版本，升级我们的deployment应用jjw@jjw-PC:~$ kubectl set image deployment nginx-deployment nginx=nginx:1.13deployment.apps/nginx-deployment image updated# 再次查看我们K8s集群创建的deployment的详细信息，发现这里我们的image版本已经升级为1.13jjw@jjw-PC:~$ kubectl get deployment -o wideNAME READY UP-TO-DATE AVAILABLE AGE CONTAINERS IMAGES SELECTORnginx-deployment 3/3 3 3 14m nginx nginx:1.13 app=nginx# 然后我们查看ReplicaSet信息，发现之前的rs DESIRED 已经变成了0个，我们又新创建了一个rsjjw@jjw-PC:~$ kubectl get rsNAME DESIRED CURRENT READY AGEnginx-deployment-5cc6c7559b 0 0 0 15mnginx-deployment-76d7bfdc99 3 3 3 2m12s# 查看pod信息，发现在运行的有三个，但是都是全新的与之前不一样jjw@jjw-PC:~$ kubectl get podsNAME READY STATUS RESTARTS AGEnginx-deployment-76d7bfdc99-9rkbg 1/1 Running 0 3m18snginx-deployment-76d7bfdc99-fhm5f 1/1 Running 0 3m38snginx-deployment-76d7bfdc99-zprtj 1/1 Running 0 3m12s# 查看历史版本信息jjw@jjw-PC:~$ kubectl rollout history deployment nginx-deploymentdeployment.apps/nginx-deployment REVISION CHANGE-CAUSE1 &lt;none&gt;2 &lt;none&gt;# 使用命令回滚到上一个版本jjw@jjw-PC:~$ kubectl rollout undo deployment nginx-deploymentdeployment.apps/nginx-deployment rolled back# 查看deployment的信息，发现image的版本恢复到了1.12.2jjw@jjw-PC:~$ kubectl get deployment -o wideNAME READY UP-TO-DATE AVAILABLE AGE CONTAINERS IMAGES SELECTORnginx-deployment 3/3 3 3 22m nginx nginx:1.12.2 app=nginx# 再次查看历史版本信息，发现序号是递增的jjw@jjw-PC:~$ kubectl rollout history deployment nginx-deploymentdeployment.apps/nginx-deployment REVISION CHANGE-CAUSE2 &lt;none&gt;3 &lt;none&gt; 上述升级方式并不是滚动升级的，即不是优雅升级，期间会有一段时间服务处于宕机状态，实现滚动升级，我们只需要重新定义depolyment.yml文件，升级后的depolyment.yml文件中添加如下内容： 1234567891011121314151617181920212223242526272829303132333435# 定义的版本，因为它底层使用的是Replica SetapiVersion: apps/v1# 定义类型为Deploymentkind: Deploymentmetadata: name: nginx-deployment labels: app: nginxspec: replicas: 3 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx # 定义我们nginx的版本，这里故意使用一个低版本，便于我们演示升级Pod image: nginx:1.12.2 ports: - containerPort: 80 #滚动升级策略 minReadySeconds: 5 strategy: # indicate which strategy we want for rolling update type: RollingUpdate rollingUpdate: maxSurge: 1 maxUnavailable: 1 具体添加内容解释如下： minReadySeconds: Kubernetes在等待设置的时间后才进行升级 如果没有设置该值，Kubernetes会假设该容器启动起来后就提供服务了 如果没有设置该值，在某些极端情况下可能会造成服务不正常运行maxSurge: 升级过程中最多可以比原先设置多出的POD数量 例如：maxSurage=1，replicas=5,则表示Kubernetes会先启动1一个新的Pod后才删掉一个旧的POD，整个升级过程中最多会有5+1个POD。maxUnavaible: 升级过程中最多有多少个POD处于无法提供服务的状态 当maxSurge不为0时，该值也不能为0 例如：maxUnavaible=1，则表示Kubernetes整个升级过程中最多会有1个POD处于无法服务的状态。 然后执行命令： kubectl apply -f [新的depolyment的yml文件] 这样就实现了滚动升级 升级可以暂停和继续，使用如下命令： kubectl rollout pause deployment &lt;deployment名称&gt;:暂停升级 kubectl rollout resume deployment &lt;deployment名称&gt;:继续升级","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://jjw-story.github.io/categories/Kubernetes/"}],"tags":[{"name":"入门","slug":"入门","permalink":"https://jjw-story.github.io/tags/入门/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://jjw-story.github.io/tags/Kubernetes/"}],"author":"JJW"},{"title":"Docker-Swarm","slug":"Docker-Swarm","date":"2020-06-06T08:30:37.000Z","updated":"2020-06-14T06:51:21.608Z","comments":true,"path":"2020/06/06/Docker-Swarm/","link":"","permalink":"https://jjw-story.github.io/2020/06/06/Docker-Swarm/","excerpt":"","text":"容器编排介绍（Swarm Mode）我们之前的学习创建的容器都是在一台机器上的，但是实际生产环境中，我们创建的容器不可能都是在一台机器上的，而是在多台物理机器上。在生产环境中我们要部署一个应用，可能涉及很多个容器，而且这些容器不可能都部署在一台机器上，那么我们就需要解决一系列问题，比如： 怎么去管理这么多容器 怎么方便的横向扩展 如果容器down了，怎么自动恢复 如何去更新容器而不影响业务 如何去监控追踪这些容器 如何去调度容器的创建 如何保护隐私数据 Swarm介绍Swarm就是做容器编排的一个工具，用于容器服务的创建删除等操作和调度，它用来解决上述问题，它是Docker内置的一个工具，但是我们要注意，容器编排的工具并不是Swarm一个，只是Docker内置的是这个，不需要安装任何其他的东西。 Swarm是一个集群的架构，它有两种角色，Manager和Worker。Manager是整个集群的大脑，一般至少要有两个机器，Worker就是实际容器的运行的节点，当然Manager节点也可以运行我们的业务容器，但是一般我们都是部署在Worker节点。 Service：Swarm中一个非常重要的概念，我们Swarm环境下的Service的概念基本和Compose中的Service是一样的，一个Service就代表了一个容器。 Replicas：作为容器横向扩展时的概念，就是我们部署一个service时，通过scale指定部署的容器个数时，我们每一个容器就是作为了一个Replica，可以理解为同一个容器的多个副本，但是这里不存在主分片的概念。 Swarm的应用创建Swarm集群我们这里只讲述生产环境中多个机器的Swarm的创建方式。 创建Swarm节点，方法是在一个安装了Docker环境的机器上通过命令： docker swarm init –advertise=[本机IP地址] 我们先运行此命令的节点将会成为Manager节点，运行此命令后，终端会输出如果要添加Manager节点和添加Worker节点的命令，我们要添加此集群的节点，就复制此对应的命令，然后到另外的机器上执行即可 创建Worker节点，将上述输出的添加Worker命令粘贴，进入另外的机器（可以是多个），执行即可 我们可以在Manager节点通过命令：docker node ls 查看此集群下的所有节点信息 在swarm集群环境service操作 我们docker service的创建有点类似于docker run，但是我们在searm模式下就不用docker run命令了，因为docker run只是用于在本地创建docker容器，创建命令如下： docker service create –name [service名称] [Image名称] 我们可以通过命令查看创建的容器信息，此信息会展示容器的Replicas数量等： docker service ls 查看到service信息后，我们可以查看每个容器具体的部署信息，比如部署在哪个节点，状态等，通过如下命令： docker service ps [service名称] 我们创建完成后就可以通过scale来进行容器数量的横向扩展，使用命令： docker service scale [service名称]=[容器的总数量] 执行完成后，我们通过ls命令，查看到的service信息，Replicas的数量就是我们设置的容器总数量了，并且我们通过ps命令查看到每个容器的部署是平均的分配在了不同的机器上 上述创建的容器我们说会平均分布在不同的机器上，如果此时我们有一个机器down掉了或者我们手动将容器给停止了，我们发现过一会在通过ls命令查看的容器数量还是5，这是因为它又新扩展了一个容器在其他的机器上。这就证明scale它不仅仅是横向扩展的功能，而且它能保证横向扩展的数目是稳定有效的，当其中容器down掉之后，他们 检测到然后立即创建新的容器保证扩展的数量 service的删除，我们service的删除使用如下命令，删除后会将此service下所有的容器都回收掉： docker service rm [service名称] Swarm网络示例及现象介绍首先我们搭建一个三台机器的swarm集群，有一个Manager节点和两个Worker节点，然后我们部署wordpress和mysql应用，我们在部署前创建驱动类型为 overlay 的Network Namespace，然后创建mysql和wordpress的service，并且在创建的时候通过 -p 参数指定wordpress的端口映射，使得我们可以向外部提供服务，在创建的时候指定此两个service使用的Network Namespace（具体方式与run启动指定参数一样），使他们之间可以直接通过service名称就能实现网络互通，完成我们的应用部署。 注意：我们如果要保证本机之间的容器通信，需要使用bridge驱动类型的Network，但是如果是多机之间的通信，需要使用overlay驱动类型的Network 以上出现的现象是： 我们之前挨Manager节点上创建的驱动类型为 overlay 的Network Namespace，在其他的两个Worker机器节点上也能看到并且存在 我们的mysql service容器部署在了manager机器上，wordpress service容器部署在了其中一台Worker节点上，但是我们通过我们映射好的端口，通过任何一个swarm集群机器的ip加此映射好的端口，都能访问到我们的workpress服务 Rounting Mesh的两种体现Docker Swarm的网络技术 Internal Network针对于Swarm service之间的访问及负载均衡，我们同一个Swarm中的容器之间是怎么通信的，他们是用过service名称来进行通信的，我们service名称对应的IP地址并不是容器的具体地址，因为我们某一个service下可能会通过scale创建多个容器，并且容器扩增或删除都会造成service下容器IP地址的变化，所以我们肯定不是直接通过容器的IP地址进行通信的，我们service名称对应的IP地址是一个VIP，就是一个虚拟IP，如果我们的横向容器扩展了之后，VIP是不会变化的，并且它会对我们的访问做负载均衡，这就是VIP的主要作用和Swarm的网络访问实现。 Internal Load Balancing，既我们通过service名称访问的容器它是通过VIP访问的，VIP会自动负载均衡到请求的不同的容器节点上去，它是基于LVS来实现的，LVS是一个很牛的中国大佬写的，已经加入到Linux内核中了，详细google或baidu了解。 Ingress Network针对于外部访问的负载均衡，我们某个service绑定了对外的端口，这个service可能只是部署在了我们Swarm集群中的部分节点，但是我们在Swarm中的任何一个机器节点都可以通过此机器IP加端口都能访问到此容器的服务，它就是使用了Ingress网络。 Docker StackDocker Stack及对于一个应用包含的多个容器进行统一管理的工具，它与Docker Compose的作用及使用类似，不同的是compose是应用于单机环境的，而Stack是应用于Swarm下的多机环境的。 Docker Stack的使用也是使用docker-compose.yml文件来定义的，此文件的格式与之前介绍的compose定义一样，只不过添加了deploy参数，此参数下定义的内容有非常多，包括service部署更新等策略，容器的数量、内存CPU的使用限制等非常多，具体我们可以通过官网去查看。 docker stack 命令参数说明： deploy：部署或更新stack，使用示例：docker stack depoly [指定stack名称] –compose-file=docker-compose.yml ls：列举出当前所有stack及每个stack中包含的services个数，使用示例：docker stack ls ps：查询指定stack的详细信息，包括容器部署的节点、状态、使用的image等信息，使用示例：docker stack ps [指定stack名称] rm：删除指定的stack，使用示例：docker stack rm [指定stack名称] services：列举出当前stack中包含的所有service，以及service的副本数量等信息，使用示例：docker stack services [指定stack名称] docker-compose.yml文件示例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071version: &apos;3&apos;services: web: image: wordpress ports: - 8080:80 environment: WORDPRESS_DB_HOST: mysql WORDPRESS_DB_PASSWORD: root networks: - my-network depends_on: - mysql # web的service stack配置 deploy: # 部署模式-多例 mode: replicated # 容器分片数量 replicas: 3 # 重启策略 restart_policy: condition: on-failure delay: 5s max_attempts: 3 # 更新策略 update_config: # 更新时同时进行的容器数量 parallelism: 1 delay: 10s mysql: image: mysql environment: MYSQL_ROOT_PASSWORD: root MYSQL_DATABASE: wordpress volumes: - mysql-data:/var/lib/mysql networks: - my-network # mysql的service stack配置 deploy: # 部署模式-单例 mode: global placement: # 容器部署的节点位置，指定部署在manager机器上 constraints: - node.role == manager # 一个可视化的stack工具，访问此端口可以通过可视化的界面查看具体的stack信息 visualizer: image: dockersamples/visualizer:stable ports: - &quot;8080:8080&quot; stop_grace_period: 1m30s volumes: - &quot;/var/run/docker.sock:/var/run/docker.sock&quot; deploy: placement: constraints: [node.role == manager]volumes: mysql-data:# 指定使用的网络驱动networks: my-network: driver: overlay Docker Secret管理什么是Secret，主要是指一下内容： 用户名密码 SSH Key TLS认证 任何不想让别人看到的数据 我们之前在讲Swarm时说过，在Manager节点之间，它们有一个内置的分布式存储， 它们是基于Raft协议来同步数据的，保证他们之间的信息时实时共享同步的。 Secret Management Secret都是存储在Swarm 的 Manager节点，存储在Raft database中的，都是加密的 Secret可以assign给一个service，在这个service中就可以看到这个secret 在container内部Secret看起来像文件，但实际是在内存中的 Secret的具体操作使用Secret的创建首先介绍查看Secret的命令： docker secret ls，表示查看当前环境中的Secret 创建有两种方式，一种是从一个文件中创建，一种是从标准的输入中创建。 我们首先创建一个文件，然后再文件中写入我们的Secret内容，例如密码等内容，然后我们通过命令：docker secret create [secret名称] [文件路径名称]，这样我们就创建完成，一般我们通过文件创建好secret后，就把我们的文件删除掉，这是为了保护我们的隐私数据。创建完成我们就可以通过ls命令来查看创建的Secret。 通过标准输入创建，使用示例如下：echo “secret具体内容” | docker secret create [secret名称] -，这样我们就创建完成了，可以通过ls命令查看了 Secret的删除使用命令：docker secret rm [secret名称] 将Secret暴露给Service容器来使用我们在创建service容器时，指定一下即可，例如： 123456789# 1.创建容器并指定要应用的Searetdocker service create --name [service名称] --secret [要使用的之前在Manager节点创建好的secret名称] [image名称]# 2.进入创建好的容器docker exec -it [容器ID] /bin/bash# 3.进入 /run/secret 目录并查看文件，我们发现有一个文件跟我们指定的Secret名称一样，查看后发现内部的内容就是我们之前定义好的内容cd /run/secretls 具体使用例如我们创建一个MySQL容器，并且创建时指定root用户的密码，具体使用命令如下： 1docker service create --name [mysql service 名称] --secret [要使用的之前在Manager节点创建好的secret名称] -e MYSQL_ROOT_PASSWORD_FILE=/run.secret/[之前在Manager节点创建好的secret名称] [mysql image名称] Searct在stack中的应用应用原理其实与上述暴露给service中一样，只不过我们将一些命令直接写在了docker-compose.yml文件中，例如： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869# 1.首先通过上述方式在Manager节点创建好Secret# 2.docker-compose.yml文件中引入应用version: &apos;3&apos;services: web: image: wordpress ports: - 8080:80 # 定义我们要引入的secret secrets: - my-pw # 环境变量应用我们引入的secret environment: WORDPRESS_DB_HOST: mysql WORDPRESS_DB_PASSWORD_FILE: /run/secrets/my-pw networks: - my-network depends_on: - mysql deploy: mode: replicated replicas: 3 restart_policy: condition: on-failure delay: 5s max_attempts: 3 update_config: parallelism: 1 delay: 10s mysql: image: mysql # 定义我们要引入的secret secrets: - my-pw # 环境变量应用我们引入的secret environment: MYSQL_ROOT_PASSWORD_FILE: /run/secrets/my-pw MYSQL_DATABASE: wordpress volumes: - mysql-data:/var/lib/mysql networks: - my-network deploy: mode: global placement: constraints: - node.role == managervolumes: mysql-data:networks: my-network: driver: overlay# 我们可以不再先前就创建好secret，可以定义一个文件在创建service时引入文件创建，但是这种做法不安全，所以我们不推荐（一般还是先创建好）# secrets:# my-pw:# file: ./password Service的更新本节讲述的是对Swarm中运行的service进行升级，我们需要实现的是不宕机的升级，参照现在的生产环境服务升级。 Service的更新可以更新很多内容，例如Secret，暴露的端口，image等。 普通方式更新 更新image，当我们的servcie使用scale创建了多个实例的时候，我们使用如下命令更新服务，发现容器更新是逐个进行的，可以表述为优雅上下线，命令如下： 更新服务使用命令： docker service update –image [更新的新的image名称] [service名称] 更新端口，命令如下(同理更新secret)： docker service update –pulish-rm 8080:5000 –pulish-add 8088:5000 [service名称] stack模式下的更新stack模式下的更新我们只需要修改 docker-compose.yml 文件的内容，然后重新发布就自动完成了更新，而且更新的过程更上述一样，都是优雅的。 例如我们要升级服务更新image，只需要修改 docker-compose.yml 中对应的serivce中对应的iamge即可，更新其他内容也一样，只需要修改此文件，然后直接 depoly 即可。","categories":[{"name":"Docker","slug":"Docker","permalink":"https://jjw-story.github.io/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://jjw-story.github.io/tags/Docker/"},{"name":"Swarm","slug":"Swarm","permalink":"https://jjw-story.github.io/tags/Swarm/"}],"author":"JJW"},{"title":"Docker-Compose","slug":"Docker-Compose","date":"2020-06-03T14:34:23.000Z","updated":"2020-06-03T14:33:07.000Z","comments":true,"path":"2020/06/03/Docker-Compose/","link":"","permalink":"https://jjw-story.github.io/2020/06/03/Docker-Compose/","excerpt":"","text":"Docker Compose介绍如果我们有一个APP是由多个容器组成，那我们在部署这个APP的时候就会非常的繁琐，我们要去维护多个Docker image，基于这些image我们还要创建多个container，要管理这些container会非常麻烦，比如启动停止删除等，需要分别一个个的操作，Compose就是来解决这个问题的，它所赋予的使命就是“批处理”，如果我们一个应用有十个容器，那我们利用compose，只需要执行一条命令就可以完成这些容器的启动停止等操作。 Docker Compose是一个工具，这个工具可以通过一个yml文件定义多个容器的Docker应用，通过一条命令就可以根据yml文件的定义去创建或者管理这些多个容器。 docker-compose.yml文件compose的yml文件默认名称是Docker-compose.yml，我们可以根据需要更改名称。此文件有三大概念，Services、Networks、Volumes。 docker-compose的文件格式版本经历了三个版本，分别时version-1、2、3，我们现在基本使用3版本，但是1版本现在不要用，基本淘汰了，2版本定义虽然变化不大，但是2版本只能应用在单机，3版本就可以管理多机的场景（多个容器部署在不同的物理机器上） Services一个services代表一个container，这个container可以从dockerhub的image来创建，或者从本地的Dockerfile build出image然后创建 Service的启动类似与docker run命令，所以我们docker run命令可以指定的参数我们都可以通过compose文件指定出来，可以给其指定network和volume，所以可以给service指定network和volume的引用 yml配置语法如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# 固定声明文件版本version: &apos;3&apos;# 固定声明servicesservices: # worker是表示这个services的名称 worker: # （注意此两项只需要写一项） # 声明要创建的容器的image，来源为DockerHub image:mysql：5.7 # 声明要创建的容器的image，来源为此配置目录下的Dockerfile build: ./worker # 声明端口映射，将容器的端口映射到本地 ports: - 8080:80 # 声明环境变量 environment: WORDPRESS_DB_HOST: mysql # 声明映射的volume volumes： - db-data:/var/lib/mysql/data # 声明我们的容器会与那几个容器做link，实际应用不广泛，我们在link时都是直接指定network的bridge，多个容器链接在同一个bridges上，它们自然是互通的 links: - redis - mysql # 生命容器使用的network networks: - back-tier# 固定生命volumesvolumes: # 与上述services中声明对应 db-data: # 固定声明networksnetworks: # 与services中声明对应，这里详细具体定义 back-tier: # 声明此命名空间使用的驱动 driver: bridge 以下是一个实际应用的示例，这个示例中我们一个APP应用了两个容器，并对它们做关联，具体的yml文件如下： 123456789101112131415161718192021222324252627282930version: &apos;3&apos;services: wordpress: image: wordpress ports: - 8080:80 environment: WORDPRESS_DB_HOST: mysql WORDPRESS_DB_PASSWORD: root networks: - my-bridge mysql: image: mysql environment: MYSQL_ROOT_PASSWORD: root MYSQL_DATABASE: wordpress volumes: - mysql-data:/var/lib/mysql networks: - my-bridgevolumes: mysql-data:networks: my-bridge: driver: bridge docker-compose的具体使用首先需要安装docker-compose，在Windows等版本的Docker安装中默认就会安装compose，但是Linux中不会，所以需要我们手动安装一下，安装步骤如下： curl -L “https://github.com/docker/compose/releases/download/1.23.2/docker-compose-$(uname -s)-$(uname -m)” -o /usr/local/bin/docker-compose chmod +x /usr/local/bin/docker-compose 安装完成，运行： docker-compose –version 就可以看到compose的具体信息 docker-compose 命令具体使用我们可以通过：docker-compose –help 命令来查看帮助 docker-compose up命令 前面我们讲了yml文件，定义好此文件后，我们可以通过此命令来创建容器了，一般我们就在yml文件所在的目录执行：dokker-compose up命令即可，但是我们之前说此yml文件的名称是可以自定义的，如果修改为其他名称就需要：docker-compose -f [文件名称] up 来创建我们的容器了，我们也可以添加 -d 参数来后台启动，即不打印日志 docker-compose stop命令 停止我们通过 docker-compose up 命令一次启动的各个容器 docker-compose start 重启我们之前通过 docker-compose up 命令一次启动的各个容器 docker-compose down 停止并删除之前通过 docker-compose up 命令一次启动的各个容器，并且删除container，以及network，但是它并不会删除image和volume docker-compose ps 查看我们通过yml创建的所有容器 docker-compose iamge 查看我们通过yml创建container，以及定义它的image docker-compose exec docker-compose exec [yml文件service定义的容器名称] bash，等同于docker exec it [容器名称] /bin/bash 水平扩展和伏在均衡（scale）有时候我们线上的服务机器数量较少，但遇到大并发机器处理不过来的时候，我们需要横向扩展机器，这时我们compose就遇到大用处了 通过：docker-compose up -scala [yml文件services中定义的容器名称]=[容器的总数量] -d 就可以迅速的扩展机器 注意：如过本身我们已经有2个容器，我们指定容器的总数量为5,那么它会新添加3个，一共5个，而不是新添加5个 扩展后我们通过：docker-compose ps，就可以查看到扩展后的容器 注意：如果我们在yml文件中指定了端口映射，那么如果一个机器上扩展的多个容器都映射到本机一个端口上，就会造成端口冲突，所以我们需要在yml文件中去除端口映射的代码，让它自己生成。这个时候我们只需要在添加一个负载均衡的容器，让它来监听各个容器内部的端口，一般都是我们在容器服务代码中指定好的端口，然后请求打在这个负载均衡的容器上，就完成了一个完美的横向扩展。（这里我们需要了解到，Spring Cloud Eurka它天生就是这个作用，我们启动服务自己就注册到了Eurka上，可以快速的横向扩展） 当我们使用此命令设置的容器的总数量小于实际在运行的容器总数量时，它会自动回收停止掉一些，完成闲时资源释放 注意：上述命令我们指定了要扩展数量的容器名称，如果我们的yml中定义了多个容器，我们只会扩展指定的容器的数量，不会扩展其中定义的其他容器","categories":[{"name":"Docker","slug":"Docker","permalink":"https://jjw-story.github.io/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://jjw-story.github.io/tags/Docker/"},{"name":"Compose","slug":"Compose","permalink":"https://jjw-story.github.io/tags/Compose/"}],"author":"JJW"},{"title":"Docker-数据持久化","slug":"Docker数据持久化","date":"2020-05-23T13:32:39.000Z","updated":"2020-06-02T14:08:49.000Z","comments":true,"path":"2020/05/23/Docker数据持久化/","link":"","permalink":"https://jjw-story.github.io/2020/05/23/Docker数据持久化/","excerpt":"","text":"Docker数据持久化简介我们创建的容器里面是可以写数据的,image是只读的,但是container是可以写数据的,但是我们在container里面写的数据仅限于存在于这个容器,如果我们将这个容器停掉或者删除掉,那么我们创建的文件或存储的数据就都没了,所以容器的存储是临时的. 但是有的时候我们就需要将一些数据保存起来,必须我们的数据库容器,这个我们就需要利用Docker的数据持久化技术. Docker持久化数据的方案 基于本地文件系统的Volume:可以在执行docker create 或者 docker run时,通过 -v 参数将主机的目录作为容器的数据卷.这部分功能便是基于本地文件系统的voloum管理. 基于plugin的Volume:支持第三方的存储方案,比如NAS,aws Volume的类型: 受管理的Volume(data Volume):它是受管理的data volume,由docker后台自动创建,不需要我们通过 -v 参数指定,它的位置是固定的,但是名字是随机的 绑定挂载的Volume(bind Volume):具体的挂载位置可以由用户来指定,这样的好处是方便用户来管理 Data Volume这节主要讲述第一种的数据持久化方案,通过指定主机的目录作为容器的数据卷,我们主要是使用-v参数来指定volume的名称,然后发现不同的容器是可以复用一个volume 我们通过安装一个MySQL容器并且指定数据持久化的位置(MySQL的Dockerfile中是有指定Volume的,我们只是通过 -v 参数来指定一个Volume名称),然后在此MySQL中创建一个表,然后删除此容器,重新创建一个新的MySQL容器,然后指定Volume是上一次创建的那个Volume,通过进入容器,发现上个容器中创建的表还是存在的,来说明数据持久化的方案是生效的. 主要命令: -v 指定容器的数据存储位置及位置名称: docker run -d -v [volume名称]:[具体宿主机文件位置绝对路径] –name [容器名称] [image名称] 查看所有的Volume: docker volume ls 查看指定Volume的具体信息: docker volume inspect [volume名称] 删除指定的Volume: docker volume rm [volume名称] 下面是演示示例: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107# 1.docker hub上下载MySQL5.7版本的Image# 2.查看Dockerfile发现由如下代码,表明指定了MySQL数据存储的具体宿主机位置VOLUME /var/lib/mysql# 3.启动此Docker容器, -e 指定了环境变量,设置此MySQL的ROOT用户密码. -v 指定了volume的名称地址jjw@jjw-PC:~$ docker run -d -v mysql:/var/lib/mysql --name mysql01 -e MYSQL_ROOT_PASSWORD=123456 mysql:5.728e8bb72065bb5417936b098952dc741969420e80de22d177c3cb50cfe538101# 4.查看我们创建的mysql Volume是否创建成功jjw@jjw-PC:~$ docker volume lsDRIVER VOLUME NAMElocal mysql# 5.查看此volume的具体信息docker volume inspect [volume名称]jjw@jjw-PC:~$ docker volume inspect mysql[ &#123; &quot;CreatedAt&quot;: &quot;2020-06-02T21:34:14+08:00&quot;, &quot;Driver&quot;: &quot;local&quot;, &quot;Labels&quot;: null, &quot;Mountpoint&quot;: &quot;/var/lib/docker/volumes/mysql/_data&quot;, &quot;Name&quot;: &quot;mysql&quot;, &quot;Options&quot;: null, &quot;Scope&quot;: &quot;local&quot; &#125;]# 6.我们进入此MySQL容器中docker exec -it mysql01 /bin/bashjjw@jjw-PC:~$ docker exec -it mysql01 /bin/bashroot@28e8bb72065b:/# # 7.查看当前数据库中的表并创建一个新的表叫dockerroot@c1afa5e97468:/# mysql -u root -pEnter password: Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 11Server version: 5.7.30 MySQL Community Server (GPL)show databasesmysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || sys |+--------------------+4 rows in set (0.00 sec)create database dockermysql&gt; create database docker;Query OK, 1 row affected (0.00 sec)show databasemysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || docker || mysql || performance_schema || sys |+--------------------+5 rows in set (0.00 sec)# 8.退出容器并删除此容器jjw@jjw-PC:~$ docker rm -f mysql01mysql01# 9.查看volume,发现容器创建的volume还是在的jjw@jjw-PC:~$ docker volume lsDRIVER VOLUME NAMElocal mysql# 10.我们重新去创建一个MySQL的容器,指定Volume还是上一次的那个Volumedocker run -d -v mysql:/var/lib/mysql --name mysql02 -e MYSQL_ALLOW_EMPTY_PASSWORD=true mysql# 11.创建完成我们进入此新的容器中,并查看数据库总所有的表,发现我们之前mysql01创建的表还在,说明我们的数据持久化是成功的jjw@jjw-PC:~$ docker run -d -v mysql:/var/lib/mysql --name mysql02 -e MYSQL_ROOT_PASSWORD=123456 mysql:5.7881ba147a8b1804edab835d268fd70bb6974a1e643f595d9ff98fff684868e3djjw@jjw-PC:~$ docker exec -it mysql02 /bin/bashroot@881ba147a8b1:/# mysql -u root -pEnter password: Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 3Server version: 5.7.30 MySQL Community Server (GPL)show databases;mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || docker || mysql || performance_schema || sys |+--------------------+5 rows in set (0.00 sec) bind volume上一种方式我们创建的Volume需要在Dockerfile中使用 VOLUME 参数指定具体的位置,我们虽然可以通过-v参数修改volume的名称,但是不能修改具体位置.而这一节的这种方式我们是通过绑定的方式,不需要在Dockerfile中去定义,我们只需要在启动docker容器时指定容器的存储目录和本地的目录做一个绑定关系,这样我们当容器的目录中数据发生变化时,会同步到本地的目录中,因为其实它们使用的是同一个目录文件. 以下我们通过示例来演示,示例内容主要是利用一个Dockerfile,然后在Dockerfile中使用 WORKDIR 指定工作目录,我们不使用 VOLUME 参数指定数据存储目录,然后我们启动容器时使用-v参数绑定一个本机目录,然后再容器中创建文件及修改文件,我们发现在本地的目录中也会创建这样的文件并跟随修改,并且我们在本机修改次文件内容,进入容器发现容器中的文件也跟随修改,因为它们是同一个文件 12345678910111213# 1.修改Dockerfile,添加WORKDIR参数WORKDIR /usr/share/test# 2.根据此Dockerfile构建image# 3.启动容器并指定绑定的目录docker run -d -v [本机目录绝对路径]:[容器中需要映射的目录] --name [容器名称] [image名称]# 4.进入容器内部在被bind的目录下创建一个文件# 5.退出容器进入本机绑定的目录发现由我们刚才在容器中创建的目录# 6.在本机修改此文件,然后进入容器内部,发现容器内的文件也被修改(因为他们是同一个文件)","categories":[{"name":"Docker","slug":"Docker","permalink":"https://jjw-story.github.io/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://jjw-story.github.io/tags/Docker/"},{"name":"数据持久化","slug":"数据持久化","permalink":"https://jjw-story.github.io/tags/数据持久化/"}],"author":"JJW"},{"title":"Docker-Network","slug":"Docker-Network","date":"2020-05-13T13:32:39.000Z","updated":"2020-05-23T11:49:27.000Z","comments":true,"path":"2020/05/13/Docker-Network/","link":"","permalink":"https://jjw-story.github.io/2020/05/13/Docker-Network/","excerpt":"","text":"Dcocker网络-现象容器与宿主机的网络隔离首先我们创建一个容器，然后进入此容器查询容器的网关，然后退出口查看宿主机的网关，查看可以发现它们是完全不一样的，由此可见容器的Network Namespace与宿主机是隔离开的，演示如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344# 1.启动容器jjw@jjw-PC:~$ docker run -d --name demo01 jjw-story/flask-hello-world645a63e0a07637efcd5fe85813d30eb5d92b4533b7c7a1458d2c4db5d6142cda# 2.进入容器查看网关jjw@jjw-PC:~$ docker exec -it demo01 /bin/bashroot@645a63e0a076:/app# ip a1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever5: eth0@if6: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0 valid_lft forever preferred_lft forever# 3.查看宿主机网关jw@jjw-PC:~$ ip a1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever2: enp2s0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc pfifo_fast state DOWN group default qlen 1000 link/ether d8:d0:90:00:dd:94 brd ff:ff:ff:ff:ff:ff3: wlp3s0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000 link/ether 48:5f:99:ce:dc:3b brd ff:ff:ff:ff:ff:ff inet 192.168.1.9/24 brd 192.168.1.255 scope global dynamic noprefixroute wlp3s0 valid_lft 603108sec preferred_lft 603108sec inet6 2409:8a00:78ce:bb0:eaf5:3d9b:3a9d:dfd0/64 scope global dynamic noprefixroute valid_lft 259159sec preferred_lft 172759sec inet6 fe80::d29c:f72a:7c51:83cc/64 scope link noprefixroute valid_lft forever preferred_lft forever4: docker0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default link/ether 02:42:ca:69:08:5a brd ff:ff:ff:ff:ff:ff inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0 valid_lft forever preferred_lft forever inet6 fe80::42:caff:fe69:85a/64 scope link valid_lft forever preferred_lft forever6: veth531bf01@if5: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master docker0 state UP group default link/ether ae:ba:05:48:45:07 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet6 fe80::acba:5ff:fe48:4507/64 scope link valid_lft forever preferred_lft forever 容器与容器之间网络是互通的我们创建第二个容器，然后进入第二个容器查看网关，发现与第一个容器是不一样的，然后我们在第二个容器中ping第一个容器的ip，发现是可以ping通的 12345678910111213141516171819202122232425262728# 1.创建第二个容器jjw@jjw-PC:~$ docker run -d --name demo02 jjw-story/flask-hello-worldf6606faba1d160e78e4fb1accadadbb4cf61df5feddeabc1b3ef0d25f229fa3d# 2.进入容器查看第二个容器的网管jjw@jjw-PC:~$ docker exec -it demo02 /bin/bashroot@f6606faba1d1:/app# ip a1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever7: eth0@if8: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default link/ether 02:42:ac:11:00:03 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet 172.17.0.3/16 brd 172.17.255.255 scope global eth0 valid_lft forever preferred_lft forever# 3.ping第一个容器的ip地址root@f6606faba1d1:/app# ping 172.17.0.2PING 172.17.0.2 (172.17.0.2) 56(84) bytes of data.64 bytes from 172.17.0.2: icmp_seq=1 ttl=64 time=0.169 ms64 bytes from 172.17.0.2: icmp_seq=2 ttl=64 time=0.111 ms64 bytes from 172.17.0.2: icmp_seq=3 ttl=64 time=0.106 ms64 bytes from 172.17.0.2: icmp_seq=4 ttl=64 time=0.103 ms^C--- 172.17.0.2 ping statistics ---4 packets transmitted, 4 received, 0% packet loss, time 73msrtt min/avg/max/mdev = 0.103/0.122/0.169/0.028 ms 下面一节我们讲述一下原理 Namespace-网络命名空间我们通过在Linux上创建一个可用的Network Namespace来说明它的原理 查看当前机器的Network Namespace： sudo ip netns list 删除指定的Network Namespace： sudo ip netns delete [namespace名称] 创建Network Namespace： sudo ip netns add [namespace名称] 查看Network Namespace的网关及ip地址：sudo ip netns exec [namespace名称] ip a 查询各个网口当前的状态： ip link，注意 DOWN表示未启动，UP表示正在与运行，UNKNOWN表示未知 修改指定网口的状态： sudo ip netns exec [namespace名称] ip link set dev [网口名称] up l0：每次我们查询网关的时候都会发现有这样的一个网关，它代表的是localback0，本地回环口 我们的网口需要UP起来，它必须是要与另外一个网口成为一对的，也就是说它必须是要两端直连起来的，也就是单个端口是没有办法UP起来的，这个是硬性限制，网络的基础知识，需要注意 创建自己的网口并且是UP状态示例 添加自定义的Namespace，然后查询此Namespace中网口的ip和状态 1234567jjw@jjw-PC:~$ sudo ip netns add test1jjw@jjw-PC:~$ sudo ip netns listtest1jjw@jjw-PC:~$ sudo ip netns exec test1 ip a1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 我们发现此网口没有IP地址，并且状态是DOWN 修改此网口的状态为UP，并查看修改结果 1234jjw@jjw-PC:~$ sudo ip netns exec test1 ip link set dev lo upjjw@jjw-PC:~$ sudo ip netns exec test1 ip link1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 我们发现这里设置为UP之后，它并不是直接成为UP状态，而是成为了UNKNOWN状态，这是因为我们此端口并没有与另外一个端口成为一对并且直连，所以它并不会UP起来 我们创建一对相互配对的网口（为了创建出一个UP的端口） 123456789101112131415161718jw@jjw-PC:~$ sudo ip link add veth-test1 type veth peer name veth-test2jjw@jjw-PC:~$ ip link1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:002: enp2s0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc pfifo_fast state DOWN mode DEFAULT group default qlen 1000 link/ether d8:d0:90:00:dd:94 brd ff:ff:ff:ff:ff:ff3: wlp3s0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP mode DORMANT group default qlen 1000 link/ether 48:5f:99:ce:dc:3b brd ff:ff:ff:ff:ff:ff4: docker0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP mode DEFAULT group default link/ether 02:42:ca:69:08:5a brd ff:ff:ff:ff:ff:ff6: veth531bf01@if5: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master docker0 state UP mode DEFAULT group default link/ether ae:ba:05:48:45:07 brd ff:ff:ff:ff:ff:ff link-netnsid 08: veth973fc89@if7: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master docker0 state UP mode DEFAULT group default link/ether f6:6d:60:62:80:cf brd ff:ff:ff:ff:ff:ff link-netnsid 19: veth-test2@veth-test1: &lt;BROADCAST,MULTICAST,M-DOWN&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/ether 62:55:74:b2:2f:11 brd ff:ff:ff:ff:ff:ff10: veth-test1@veth-test2: &lt;BROADCAST,MULTICAST,M-DOWN&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/ether 22:c8:a4:b3:f4:b2 brd ff:ff:ff:ff:ff:ff 创建后我们发现我们已经创建成功，并且他们的名称都是 veth-test2@veth-test1 和 veth-test1@veth-test2，它们有mac地址，但是没有ip地址，状态都为DOWN 将我们创建的网口添加到我们之前创建的Namespace中 123456jjw@jjw-PC:~$ sudo ip link set veth-test1 netns test1jjw@jjw-PC:~$ sudo ip netns exec test1 ip link1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:0010: veth-test1@if9: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/ether 22:c8:a4:b3:f4:b2 brd ff:ff:ff:ff:ff:ff link-netnsid 0 我们发现我们新创建的网口已经被添加到我们之前创建的Namespace中了 同理我们创建test2的Namespace，然后将veth-test2这个网口添加到test2这个Namespace中 12345678910jjw@jjw-PC:~$ sudo ip netns add test2jjw@jjw-PC:~$ sudo ip netns listtest2test1 (id: 2)jjw@jjw-PC:~$ sudo ip link set veth-test2 netns test2jjw@jjw-PC:~$ sudo ip netns exec test2 ip link1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:009: veth-test2@if10: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/ether 62:55:74:b2:2f:11 brd ff:ff:ff:ff:ff:ff link-netns test1 查看本机的ip link，我们发现已经没有了刚才的veth-test2@veth-test1 和 veth-test1@veth-test2，说明我们已经将此两个端口放到了我们创建的两个Namespace中 给我们刚刚创建的两个Namespace的端口分配IP地址 12jjw@jjw-PC:~$ sudo ip netns exec test1 ip addr add 192.168.1.1/24 dev veth-test1jjw@jjw-PC:~$ sudo ip netns exec test2 ip addr add 192.168.1.2/24 dev veth-test2 这时如果我们去查看这两个Namespace的ip和状态，发现我们的网口还是没有ip地址，并且状态还是DOWN，这时我们需要设置将这两个网口启动起来 12jjw@jjw-PC:~$ sudo ip netns exec test1 ip link set dev veth-test1 upjjw@jjw-PC:~$ sudo ip netns exec test2 ip link set dev veth-test2 up 这时我们再去查看这两个Namespace中的新创建网口状态和IP发现就都是正常的了 1234567891011121314151617181920212223242526272829jjw@jjw-PC:~$ sudo ip netns exec test1 ip a1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:0012: veth-test1@if11: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000 link/ether 16:af:b8:ee:76:02 brd ff:ff:ff:ff:ff:ff link-netns test2 inet 192.168.1.1/24 scope global veth-test1 valid_lft forever preferred_lft forever inet6 fe80::14af:b8ff:feee:7602/64 scope link valid_lft forever preferred_lft foreverjjw@jjw-PC:~$ sudo ip netns exec test1 ip link1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:0012: veth-test1@if11: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP mode DEFAULT group default qlen 1000 link/ether 16:af:b8:ee:76:02 brd ff:ff:ff:ff:ff:ff link-netns test2jjw@jjw-PC:~$ sudo ip netns exec test2 ip a1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:0011: veth-test2@if12: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000 link/ether 36:f9:03:cb:ef:e1 brd ff:ff:ff:ff:ff:ff link-netns test1 inet 192.168.1.2/24 scope global veth-test2 valid_lft forever preferred_lft forever inet6 fe80::34f9:3ff:fecb:efe1/64 scope link valid_lft forever preferred_lft foreverjjw@jjw-PC:~$ sudo ip netns exec test2 ip link1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:0011: veth-test2@if12: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP mode DEFAULT group default qlen 1000 link/ether 36:f9:03:cb:ef:e1 brd ff:ff:ff:ff:ff:ff link-netns test1 现在我们就终于创建好了我们自己的正常的Namespace和互联互通的网口，我们就可以在其中一个Namespace中去ping另外一个Namespace的这个网口，发现就可以通了 互相ping IP地址 123456789jjw@jjw-PC:~$ sudo ip netns exec test1 ping 192.168.1.2PING 192.168.1.2 (192.168.1.2) 56(84) bytes of data.64 bytes from 192.168.1.2: icmp_seq=1 ttl=64 time=0.031 ms64 bytes from 192.168.1.2: icmp_seq=2 ttl=64 time=0.058 ms64 bytes from 192.168.1.2: icmp_seq=3 ttl=64 time=0.058 ms^C--- 192.168.1.2 ping statistics ---3 packets transmitted, 3 received, 0% packet loss, time 49msrtt min/avg/max/mdev = 0.031/0.049/0.058/0.012 ms 综上就是我们Namespace的使用方法及具体作用，如第一节中我们所示，Docker创建的容器他们之间ip能互通，基本使用的就是此原理，与我们的示例原理是一致的 Docker BridgeDocker的默认网络，上述我们发现在创建容器后发现容器之间ip是互通的，并且在容器内部是可以ping通外部网络的，并且在我们每次启动一个容器，就会在宿主机器上多出一个网口，如下： 1234567891011121314151617181920212223242526272829303132# 1.查询原本宿主机网口jw@jjw-PC:~$ ip a1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 ...2: enp2s0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc pfifo_fast state DOWN group default qlen 1000 ...3: wlp3s0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000 ...4: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN group default ...# 2.启动一个容器jjw@jjw-PC:~$ docker start demo01demo01# 3.查看现在宿主机网口1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 ...2: enp2s0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc pfifo_fast state DOWN group default qlen 1000 ...3: wlp3s0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000 ...4: docker0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default link/ether 02:42:5b:44:0a:01 brd ff:ff:ff:ff:ff:ff inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0 valid_lft forever preferred_lft forever inet6 fe80::42:5bff:fe44:a01/64 scope link valid_lft forever preferred_lft forever8: veth54021aa@if7: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master docker0 state UP group default link/ether 72:40:50:33:72:99 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet6 fe80::7040:50ff:fe33:7299/64 scope link valid_lft forever preferred_lft forever 我们发现在上述启动一个容器后，宿主机新添加了一个网口veth54021aa@if7，并且它是与docker0网口相关联的，我们说这个新的网口就是第一节示例中的Network Namespace的一对peer，它们链接了容器的ip和docker0，docker0网口就是我们说的 Docker Bridge 我们没创建一个容器，它都会创建这样的一个peer，然后与docker0相关联，这就是容器之间ip是互通的原理，也是容器内访问外网的原因 Docker Bridge是Docker网络最重要的部分 容器之间的link–link的使用本章注意下面命令： docker network ls: 查看docker上存在的所有Network Namespace docker network create -d bridge [自定义bridge名称]： 创建自定义bridge docker network connect [自定义bridge名称] [容器名称]： 将容器链接到自定义bridge docker network inspect [bridge ID]：查看bridge的具体信息，ID通过上述 ls 命令查看 前面我们说过，容器之间的网络是互通的，但是很多时候我们容器之间需要链接，但是我们并不知道另一方容器的ip地址，比如一个服务容器需要链接一个数据库容器，这时候我们就可以利用docker的link，我们可以不通过ip地址而是通过容器名称来进行链接 下面我们通过link使用示例来说明，我们创建两个容器，然后用第二个容器link到第一个容器，然后ping第一个容器的名称 123456789101112131415161718192021222324# 1.创建第一个容器jjw@jjw-PC:~$ docker run -d --name test1 jjw-story/flask-hello-world968f4e9fafe3fb2662e457515010c3cfedd57dc91d89839d7d091de753ef7e4a# 2.创建第二个容器并链接到第一个容器（使用 --link 参数）jjw@jjw-PC:~$ docker run -d --name test2 --link test1 jjw-story/flask-hello-worldec56c76cc2e38daca937672582d9451758d98566f510d2d7212ec4a9ea8eea4f# 3.进入第二个容器通过ping第一个容器的名称jjw@jjw-PC:~$ docker exec -it test2 /bin/bashroot@ec56c76cc2e3:/app# ping test1PING test1 (172.17.0.2) 56(84) bytes of data.64 bytes from test1 (172.17.0.2): icmp_seq=1 ttl=64 time=0.234 ms64 bytes from test1 (172.17.0.2): icmp_seq=2 ttl=64 time=0.105 ms64 bytes from test1 (172.17.0.2): icmp_seq=3 ttl=64 time=0.104 ms^C--- test1 ping statistics ---3 packets transmitted, 3 received, 0% packet loss, time 52msrtt min/avg/max/mdev = 0.104/0.147/0.234/0.062 ms# 4.进入第一个容器ping第二个容器的名称，我们发现是ping不通的，因为我们创建test1容器并没有link test2这个容器jjw@jjw-PC:~$ docker exec -it test1 /bin/bashroot@968f4e9fafe3:/app# ping test2ping: test2: Temporary failure in name resolution 以上示例就是link的使用方法，生产中我们链接数据库时就可以通过数据库容器名称:3601来直接访问数据库服务。 创建自己的bridge我们发现link是单向的，必须在创建容器时就指定好，不然是ping不通的，所以正式用的时候我们很少使用这种方式，而是使用第二种方式，创建自定义的bridge，将容器链接到此bridge上，这两链接的多个容器就都是互通的，可以通过容器名称互访 一般我们创建容器会链接到Docker的默认的bridge，我们也可以在创建容器时指定链接的bridge，或者在容器运行时添加链接到新的bridge，每个容器都可以链接多个bridge 以下我们通过示例创建一个自定义bridge，然后将服务挂载实现服务间名称访问网络互通 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071# 1.创建自定义的bridgejjw@jjw-PC:~$ docker network create -d bridge my-bridge714b9b2f827ee434b7ecbc08ad792d34cf9e298e2cbc42339d697317087bf157jjw@jjw-PC:~$ docker network lsNETWORK ID NAME DRIVER SCOPE413d667b89f6 bridge bridge localcfcb7ba38694 host host local714b9b2f827e my-bridge bridge local7a8a158e3c19 none null local# 2.创建第三个容器，指定链接到此自定义的bridgejjw@jjw-PC:~$ docker run -d --name test3 --network my-bridge jjw-story/flask-hello-world811ddcb7a6fbff14f3c18e7f09d93df9df23c90c4b1f162a4bd0e3d182619aa0# 3.将之前已经存在的容器test2链接到此自定义的bridge上jjw@jjw-PC:~$ docker network connect my-bridge test2# 4.查看此自定义bridge信息，发现此自定义bridge上挂载了两个容器jjw@jjw-PC:~$ docker network inspect 714b9b2f827e[ &#123; &quot;Name&quot;: &quot;my-bridge&quot;, &quot;Id&quot;: &quot;714b9b2f827ee434b7ecbc08ad792d34cf9e298e2cbc42339d697317087bf157&quot;, ... &quot;Containers&quot;: &#123; &quot;811ddcb7a6fbff14f3c18e7f09d93df9df23c90c4b1f162a4bd0e3d182619aa0&quot;: &#123; &quot;Name&quot;: &quot;test3&quot;, &quot;EndpointID&quot;: &quot;3dabecb55602d042563ac700343ac06a6f5221fa713caa521ff3eb75460b1aa7&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:12:00:02&quot;, &quot;IPv4Address&quot;: &quot;172.18.0.2/16&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125;, &quot;ec56c76cc2e38daca937672582d9451758d98566f510d2d7212ec4a9ea8eea4f&quot;: &#123; &quot;Name&quot;: &quot;test2&quot;, &quot;EndpointID&quot;: &quot;1e9dcad5b2f800d440a53f39fe809e671b5bfbe72f46820bbe9ad51daa12fe32&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:12:00:03&quot;, &quot;IPv4Address&quot;: &quot;172.18.0.3/16&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125; &#125; ... &#125;]# 5.分别进入两个容器，互相ping test2 和 test3,我们发现是可以通的jjw@jjw-PC:~$ docker exec -it test2 /bin/bashroot@ec56c76cc2e3:/app# ping test3PING test3 (172.18.0.2) 56(84) bytes of data.64 bytes from test3.my-bridge (172.18.0.2): icmp_seq=1 ttl=64 time=0.056 ms64 bytes from test3.my-bridge (172.18.0.2): icmp_seq=2 ttl=64 time=0.112 ms^C--- test3 ping statistics ---2 packets transmitted, 2 received, 0% packet loss, time 3msrtt min/avg/max/mdev = 0.056/0.084/0.112/0.028 msroot@ec56c76cc2e3:/app# exitexitjjw@jjw-PC:~$ docker exec -it test3 /bin/bashroot@811ddcb7a6fb:/app# ping test2PING test2 (172.18.0.3) 56(84) bytes of data.64 bytes from test2.my-bridge (172.18.0.3): icmp_seq=1 ttl=64 time=0.040 ms64 bytes from test2.my-bridge (172.18.0.3): icmp_seq=2 ttl=64 time=0.132 ms^C--- test2 ping statistics ---2 packets transmitted, 2 received, 0% packet loss, time 3msrtt min/avg/max/mdev = 0.040/0.086/0.132/0.046 ms# 6. ping test1 我们发现是不通的，因为我们test1没有加入自定义的bradgeroot@811ddcb7a6fb:/app# ping test1ping: test1: Temporary failure in name resolution 由此我们可以发现，我们没创建一个容器，它都会加入默认的bridge，这是容器之间虽然通过ip是互通的，但是不能通过容器名称互通访问网络但是我们通过创建自己的bridge，然后将两个或多个容器加入此bridge，容器之间就可以通过名称网络互通（注意默认bridge和自定义bridge的区别） Docker容器的端口映射注意：本章内容是一个重点 通常我们创建的Docker容器，需要对外提供服务时，我们需要将容器的ip地址和端口暴露出去，但是我们容器的ip和端口都只能在宿主机上访问，不能被外界访问，只有宿主机关联的公网ip才可以被外网访问，这个时候我们就需要将容器的端口映射到宿主机的ip端口，这时我们通过访问宿主机的ip加我们映射好的端口，就可以访问到我们Docker容器内部的服务 具体命令如下： docker run -d -p [容器服务端口]:[宿主机需要被映射的端口] –name [容器的名称] [image名称] 使用示例如下：docker run -d -p 80:80 –name nignxweb nginx 这样，我们访问宿主机的ip加80端口，就可以映射到容器内部的80端口，从而访问服务 Docker host和none Network Namespace上面我们通过命令docker network ls查看docker的网络命名空间，发现有三个，bridge是默认链接的，host和none没有介绍，下面我们介绍这两种命名空间 none命名空间这个命名空间很少使用，因为此命名空间是非常孤立的，它不跟外界任何网络有联通，所以它的应用场景很局限，我们可以创建一个容器然后挂在到此命名空间上观察一下，它一般就是我们的容器非常机密，里面保存了各种密码必须只能进入容器内部才能查看这些信息，这种场景比较适合使用此none网络命名空间 host命名空间此命名空间我们可以创建一个容器然后关联到此命名空间，然后进入容器内部使用ip a查看网口信息，发现与宿主机上查看的信息一模一样，也就是说它是直接关联宿主机的网络命名空间，host使用也非常少，因为我们容器这样关联的话，Network Namespace就和宿主机的没有隔离，容易出现端口冲突等问题","categories":[{"name":"Docker","slug":"Docker","permalink":"https://jjw-story.github.io/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://jjw-story.github.io/tags/Docker/"},{"name":"Network","slug":"Network","permalink":"https://jjw-story.github.io/tags/Network/"}],"author":"JJW"},{"title":"Docker镜像的构建和发布及容器操作","slug":"Docker镜像的构建和发布","date":"2020-04-28T13:05:38.000Z","updated":"2020-05-08T15:42:03.000Z","comments":true,"path":"2020/04/28/Docker镜像的构建和发布/","link":"","permalink":"https://jjw-story.github.io/2020/04/28/Docker镜像的构建和发布/","excerpt":"","text":"Docker镜像的构建Docker镜像的构建有两种方式，第一种是通过Container来构建，第二种是通过Dockerfile来构建，我们一般推荐通过第二种方式来构建，因为第一种我们将此镜像发不出去，我们是黑盒的，我们不知道它内部是不是有什么不安全的东西在里面，所以推荐使用第二种方式来创建 通过Container构建Docker镜像在通常的使用中，我们会在已经创建的容器中添加各种文件或操作，这样我们就希望在添加了这些文件或操作后的容器能形成一个新的容器，以便我们移植使用，这个时候我们就可以基于当前已经有的容器来构建一个Docker镜像，以便我们移植。具体步骤如下： 首先通过命令：docker container ls -a 查询出我们添加了操作的要构建镜像的Container 通过命令创建新的镜像：docker commit [旧的Container名称] [tag/新的镜像名称] 通过命令查看我们创建的新的镜像：docker image ls 通过命令查看容器分层情况：docker history [Container ID]，通过此命令查看我们旧的容器和新的容器，发现它们之间共享了很多底层容器，由此可见，我们新的容器是基于旧的容器分层之上创建的 通过Dockerfile来构建镜像这种方式我们是通过编写Dockerfile来构建镜像，使用命令：Docker build -t [tag/镜像名称] 通过docker image ls，就可以查看到我们新创建的镜像 推荐使用这种方式来构建镜像，因为这种方式我们要给别人这个镜像的时候，我们只需要把Dockerfile共享给其他人就行，而且其他人能看到这个镜像中道理有什么东西，也比较放心 Dockerfile语法FromFrom关键字是一般Dockerfile最开头的语句，它指定了我们要build的image它的 Base image 是什么，也就是它在我们哪个Base Image之上来构建我们的Image，示例如下： From scratch # scratch表示我们不需要任何的Base Image，直接从头来制作的 From centos 或者 From ubuntu：14.04 # 表示我们的Image是基于centos或者ubuntu之上来构建的 LABEL它定义的是我们的Image的 Mate data，一般Dockerfile中此信息不能少，它是帮助其他人来了解我们的Image的重要信息来源，示例如下： LABEL maintainer=”jjw-story.china@gmail.com“ # Image的作者 LABEL version=”1.0” # Image的版本 LABEL description=”描述信息“ # Image的描述信息 RUNRUN就是我们要执行的命令，一般在构建Image时，我们都需要安装一些软件，它的定义是：执行命令并创建新的 Image Layer，这个时候就需要使用RUN来实现，示例如下： RUN yum update &amp;&amp; yum install -y vim \\ yum install python 这里有一点需要注意，我们每运行一次RUN，对于我们的Image都会生成新的一层，每生成新的一层，我们在构建的时候就会新生成一层新的Container，然后基于此基础上构建新的Iamge，所以，为了美观，复杂的RUN使用反斜线换行，避免无用分层，合并多条命令成一行，合并多条命令为一行，可以使用 &amp;&amp; 符号 WORKDIRWORKDIR是设定当前工作目录的，这个有点类似在linux中通过cd来改变当前的工作目录，示例如下： WORKDIR /root WORKDIR /testWORKDIR /demoRUN pwd # 这里会输出的是 /test/demo 我们变更工作目录，尽量使用 WORKDIR，不要使用 RUN cd ，尽量是哟过绝对目录，不要使用相对目录，绝对目录更加清晰 如果我们没有此目录，Docker对自动创建 AND 和 COPYADD 和 COPY非常像，都是将本地的文件添加到Image中，使用示例： ADD test.tar.gz # 会自动解压 WORKDIR /rootADD demo.tar.gz test/ # 这里会将文件添加到 /root/test/demo 目录下 WORKDIR /rootCOPY demo.tar.gz test/ # 这里会将文件添加到 /root/test/demo 目录下 ADD 和 COPY不同的点在于，使用 ADD 会将压缩文件添加并解压掉 大部分情况，COPY由于ADD，添加远程文件/目录，使用 curl 或者 wget 来实现 ENVENV作为设置常量或环境变量之用，示例如下： ENV MYSQL_VERSION 5.6 # 设置常量RUN apt-get install -y mysql-server=”${MYSQL_VERSION}” # 引用常量 对于我们Dockerfile中上下文中有多处使用此常量，推荐使用ENV，因为我们修改的时候只需要改一次env即可 CMD 和 ENTRYPOINTCMD：设置容器启动后默认执行的命令和参数 ENTRYPOINT：设置容器启动时运行的命令 Shell格式和Exec格式首先我们了解两种格式，Shell格式和Exec格式 Shell格式是说把我们要运行的命令当成Shell的格式去运行，第一个是命令，后面的都是命令的参数等，使用示例如下： 123RUN apt-get install -y vimCMD ehco &quot;hello docker&quot;ENTRYPOINT echo &quot;hello docker&quot; Exec格式需要通过特定的格式去指明需要运行的命令，以及命令所跟的参数，使用示例如下： 123RUN [ &quot;apt-get&quot;, &quot;install&quot;, &quot;-y&quot;, &quot;vim&quot; ]CMD [ &quot;ehco&quot;, &quot;hello docker&quot; ]ENTRYPOINT [ &quot;echo&quot;, &quot;hello docker&quot;] Exec格式需要指定可执行命令的具体文件 两种方式的区别在于，例如如下示例： 1234567# 第一种Dockerfile定义，其他省略ENV name &quot;docker&quot;ENTRYPOINT [ &quot;/bin/echo&quot;, &quot;hello $&#123;name&#125;&quot;]# 第二种Dockerfile定义，其他省略ENV name &quot;docker&quot;ENTRYPOINT &quot;echo&quot;, &quot;hello $&#123;name&#125;&quot; 当我们分别通过两种格式去build Image，并且创建Container时，第一种方式打印出来的是 hello ${name}, 第二种方式打印的是 hello docker，由此可见，第一种Exec的方式它并没有解析ENV的配置，这是因为第二种Shell格式，他会默认铜鼓shell来执行命令echo，而Exec方式，它只是单纯的去执行/bin/echo这个命令，它并没有在shell环境中，所以它解析不了，如何让Exec格式也能解析呢，可以通过如下方法： 12ENV name &quot;docker&quot;ENTRYPOINT [ &quot;/bin/bash&quot;, &quot;-c&quot;, &quot;echo hello $&#123;name&#125;&quot;] 这样就可以保证后面的echo命令实在shell环境中执行的，就能正常的解析占位符和变量 这两种方式都可以在RUN CMD ENTRYPOINT中使用 CMDCMD是容器启动时默认执行的命令，如果docker run指定的其他命令，CMD命令会被忽略，如果定义了多个CMD,只有最后一个会执行，如下示例： docker run -it jjw-story/hello-docker /bin.bash 如此：我们可以进入容器中，但是并不会打印我们在hello-docker中定义的CMD命令执行的东西，因为，我们在run命令后指定了其他命令， /bin/bash ENTRYPOINT让容器以应用程序或者服务的形式与运行，比如说我们启动一个数据的服务，让他作为一个后台进程一直在运行。它不会被忽略，一定会被执行，这是与CMD不同的地方，这里可以写一个shell脚本作为entrypoint启动的脚本 ENTRYPOINT是使用比较广泛的，比CMD应用的多 EXPOSE我们的容器中很多时候部署的是需要常驻内存的服务，这时我们就需要对外提供端口，此选项就是指定容器对外暴露的端口的，使用方式如下，暴露 5000 的端口 EXPOSE 5000 镜像的发布很多时候我们自己创建的镜像需要push到我们自己的仓库里以便与别人共享，这时就可以通过早docker hub上创建我们自己的仓库，来把我们创建好的镜像上传上去 首先需要在Docker Hub上创建我们自己的帐号，登陆上去之后，就可以看到我们自己的仓库，这里面都是我们自己上传的镜像 在本地找到我们的Docker Image，如果我们要上传此Image，那么我们在build我们自己的Image时，tag一定是我们在Docker Hub上创建的帐号的名称，否则我们在push时，会报没有权限的错误 本地上传首先我们使用命令在本地登陆Docker Hub，命令： docker login，然后输入我们的用户名和密码 使用命令上传：docker image push [用户名/Imag名称:tag]，注意这里tag一般是latest push完成后，就可以在Docker Hub上仓库中看到我们上传的Image 下次我们想下载此Image就可以通过命令：docker pull [用户名/Imag名称] 来下载此Image 上述方式下载的Image比较黑盒，我们不知道这里面究竟有没有其他东西，我们可以通过Docker Hub关联GitHub，将Dockerfile上传到GitHub上，然后关联起来，每次我们上传Dockerfile时，DockerHub会自动的检测到，然后build出新的Image，这样我们在下载时，就可以看到具体的Dockerfile，这里使用时我们自己百度就可以的。 上述方式DockerHub是公有的，所有人都能看到，有些公司私密的我们不需要别人看到，这时我们就需要自己搭建一个私密或者个人的Docker Hub，具体如下： 在本地使用命令搭建私有的Docker Hub，命令：docker run -d -p [端口号：端口号] –restart always –name regestry registry:2，使用示例如下：docker run -d -p [5000: 5000] –restart always –name regestry registry:2，这样我们就在本地搭建好了一个私有的Docker Hub，我们通过 docker ps 就可以查看此启动的容器 push我们自己的Image，这个时候我们Image的用户名就不能是DOckerHub的用户名了，应该是我们私有的DockerHub的IP和端口，例如：192.168.26.112:5000/hello-world，push命令同上，docker push 192.168.26.112:5000/hello-world，这样就完成了push image到本地私有库。第一次push使用可能会出现错误，因为它会认为我们是不安全的，这里我们通过百度一下来找解决方案，就是创建一个文件加入配置即可 push完成后，下次我们想下载此Image就可以通过命令：docker pull [IP：端口/Imag名称] 来下载此Image 镜像构建问题排查方法有的时候我们构建一些镜像会出现错误，这时我们就需要通过一些方式来进行具体查看问题原因，例如如下Dockerfile构建示例： Dockerfile： 1234567FROM python:2.7LABEL maintainer=&quot;JJW-STORY&quot;RUN pip install flaskCOPY app.py /appWORKDIR /appEXPOSE 5000CMD [&quot;python&quot;, &quot;app.py&quot;] 首先我们通过命令构建：docker build -t jjw-story/flask-hello-world . 发现发生如下错误： 1234Step 4/7 : COPY app.py /app ---&gt; 89f35be7aac8Step 5/7 : WORKDIR /appCannot mkdir: /app is not a directory 前面说过，docker镜像构建是基于分层的，我们构建时，每一层都会创建一个临时的container，然后基于此container来创建新的image，比如这里出现了此问题，我们就可以通过查看创建的临时container来查看内部具体错误原因 通过命令查看所有image，找到我们出现错误的上一层创建的临时image，然后基于此image启动容器 12345678910111213# 1.查找image，对应上述第四步创建的分层镜像jjw@jjw-PC:~/AppBoot/flask-hello-world$ docker image lsREPOSITORY TAG IMAGE ID CREATED SIZE&lt;none&gt; &lt;none&gt; 89f35be7aac8 2 minutes ago 906MBjjw-story/helloworld-java latest 3c378e4f1c1d 8 days ago 682Bjjw-story/hello-docker-c latest 73404f3002a9 11 days ago 756kB# 2.基于此临时镜像启动容器并使用base进入此容器~/AppBoot/flask-hello-world$ docker run -it 89f35be7aac8 /bin/bash# 3.进入容器内部后查看根目录中不存在 /app 文件夹，所以我们定位到了问题root@e9599f7da1aa:/# lsapp bin boot dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var 重点命令： docker run -it 89f35be7aac8 /bin/bash 修改Dcokerfile中的错误，将 COPY app.py /app 修改为 COPY app.py /app/ 此问题即可解决 重新构建构建镜像，发现已经可以了，并可以启动容器 容器的操作exec进入正在运行的docker容器，我们有的时候需要进入正在运行的docker容器中，来查看容器服务运行的状态，日志等，就需要此操作，使用命令： docker exec -it [运行的container ID] /bin/bash 使用示例： 1234567891011jjw@jjw-PC:~$ docker exec -it 80e308651aee /bin/bashroot@80e308651aee:/app# lsapp.pyroot@80e308651aee:/# ps -ef | grep pythonroot 1 0 0 14:08 ? 00:00:00 python app.pyroot@80e308651aee:/# pythonPython 2.7.18 (default, Apr 20 2020, 19:27:10) [GCC 8.3.0] on linux2Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; stop停止容器命令： docker container stop [运行的container ID/容器名称] 或者直接 docker stop [运行的container ID/容器名称] 这里可以使用容器名称来停止容器，因为docker中容器名称是唯一的 1234jjw@jjw-PC:~$ docker container stop 80e308651aee80e308651aeejjw@jjw-PC:~$ docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES run（启动容器指定容器名称）启动容器并指定容器名称使用 –name 参数来实现，具体命令如下： docker run -d –name=[容器名称] image名称，使用示例： 1234567891011jjw@jjw-PC:~$ docker run -d --name=demo jjw-story/flask-hello-world2e9940a72f76168232e1f9bfbc560c69007a240a4ff85da9fff58e78dde5185bjjw@jjw-PC:~$ docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES2e9940a72f76 jjw-story/flask-hello-world &quot;python app.py&quot; 11 seconds ago Up 8 seconds 5000/tcp demojw@jjw-PC:~$ docker stop demo demojjw@jjw-PC:~$ docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES start（启动已有容器或者说启动被停止的容器）已有的容器我们可以直接通过名称来启动它，默认就是后台启动，使用命令如下： docker start [容器名称]，使用示例： 12345jjw@jjw-PC:~$ docker start demo demojjw@jjw-PC:~$ docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES2e9940a72f76 jjw-story/flask-hello-world &quot;python app.py&quot; 5 minutes ago Up 3 seconds 5000/tcp demo inspect（查看容器的详细信息）可以通过此命令来查看我们启动的或者未启动的容器信息，使用命令如下： docker inspece [容器ID]，使用示例： 123456789101112131415161718192021222324252627282930jjw@jjw-PC:~$ docker inspect 2e9940a72f76[ &#123; &quot;Id&quot;: &quot;2e9940a72f76168232e1f9bfbc560c69007a240a4ff85da9fff58e78dde5185b&quot;, &quot;Created&quot;: &quot;2020-05-07T14:35:16.815307467Z&quot;, &quot;Path&quot;: &quot;python&quot;, &quot;Args&quot;: [ &quot;app.py&quot; ],... &quot;Networks&quot;: &#123; &quot;bridge&quot;: &#123; &quot;IPAMConfig&quot;: null, &quot;Links&quot;: null, &quot;Aliases&quot;: null, &quot;NetworkID&quot;: &quot;ce37397299d77a4de06125c0443f242cdad381acb35f4abece69c00e68b63643&quot;, &quot;EndpointID&quot;: &quot;5c9e31916c947b9c8ef29452ab80eeb075a7c3f6ca048d669b93848f431902b1&quot;, &quot;Gateway&quot;: &quot;172.17.0.1&quot;, &quot;IPAddress&quot;: &quot;172.17.0.2&quot;, &quot;IPPrefixLen&quot;: 16, &quot;IPv6Gateway&quot;: &quot;&quot;, &quot;GlobalIPv6Address&quot;: &quot;&quot;, &quot;GlobalIPv6PrefixLen&quot;: 0, &quot;MacAddress&quot;: &quot;02:42:ac:11:00:02&quot;, &quot;DriverOpts&quot;: null &#125; &#125; &#125; &#125;] 可以看到信息非常详细，中间省略，具体可以在使用时查看 logs（查看容器运行的log）使用命令：docker logs [容器ID]，使用示例： 1234567jw@jjw-PC:~$ docker logs 2e9940a72f76 * Serving Flask app &quot;app&quot; (lazy loading) * Environment: production WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead. * Debug mode: off * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit) 容器的资源控制我们可以对容器进行资源限制，虚拟化的技术就是我们一个在一个物理机器上创建多个虚拟机，然后对每个虚拟机进行不同的资源划分，同样对于容器技术来讲，我们的container也是运行在Linux的机器上的，机器的资源也是有限的，如果我们不对容器进行资源限制，那我们创建的这个容器就会尽可能的去占用更多的资源，直到占用满整个机器的内存，所以我们就需要限制容器所占用的资源，比如内存、CPU个数等 具体限制的类型有很多中，我们可以通过： docker run –help 命令来具体查看，这里我们只介绍重要的几种 内存和交换分区的限制内存和交换分区的限制一般是并行出现的，使用 –memory 和 –memory-swap 参数来指定，需要注意，如果我们只限制 –memory 不限制 –memory-swap，那么默认交换分区的容量和我们限制的内存容量大小是一样的，使用方式如下： docker run –memory=[自定义大小] –memory-swap=[自定义大小] -d [image名称] 123jjw@jjw-PC:~$ docker run --memory=200M -d jjw-story/flask-hello-worldWARNING: Your kernel does not support swap limit capabilities or the cgroup is not mounted. Memory limited without swap.30f8d4297cc49d1bf7fee1f1d53bad77f3ebfcfc44eafbf0c789515cb814380e 当我们的容器占用内存超过我们的限制，容器就会宕机自动退出 限定CPU资源CPU资源的限定我们一般使用的是 –cpu-shares 参数，此参数限定的不是说占用CPU的个数，而是一个相对的权重，意思就是：日如我们有两个容器，一个容器我们设置此参数值为10,一个容器我们设置此参数值为5,如果物理CPU已经被占用满了，那么他们其实占用的是一个比例，而且是 2:1 的比例 使用方法： docker run –cpu-shares [image名称] 1234567jjw@jjw-PC:~$ docker run --cpu-shares=10 jjw-story/flask-hello-world * Serving Flask app &quot;app&quot; (lazy loading) * Environment: production WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead. * Debug mode: off * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)","categories":[{"name":"Docker","slug":"Docker","permalink":"https://jjw-story.github.io/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://jjw-story.github.io/tags/Docker/"},{"name":"镜像的构建和发布及容器操作","slug":"镜像的构建和发布及容器操作","permalink":"https://jjw-story.github.io/tags/镜像的构建和发布及容器操作/"}],"author":"JJW"},{"title":"Docker入门","slug":"Docker入门","date":"2020-04-20T13:05:38.000Z","updated":"2020-05-07T01:51:50.956Z","comments":true,"path":"2020/04/20/Docker入门/","link":"","permalink":"https://jjw-story.github.io/2020/04/20/Docker入门/","excerpt":"","text":"Docker入门容器技术介绍原始方式的应用程序部署有以下不足： 部署非常慢（需要找机房，安装操作系统及各种环境等） 成本非常高（有些应用程序占用的资源非常少，但是我们还是要部署一个机器，成本很高） 资源浪费（应用程序使用资源很少，导致我们的机器很多资源都在空置，造成浪费） 难于迁移和扩展（我们迁移应用的时候需要重新找机器安装各种环境，扩展同理，也需要我们准备各种环境，有的时候可以通过扩展机器配置来完成，但这样也很麻烦） 虚拟化技术出现以后： 一个物理机可以部署多个APP，每个APP可以运行在单独的一个VM中，虚拟化的优点： 资源池：一个物理机的资源分配到了不同的虚拟机中，可以节约资源 很容易扩展：在扩展的时候我们可以通过添加物理机或加虚拟机的方式来实现 虚拟化的局限性： 每个虚拟机都是一个完整的操作系统，需要给其分配资源，当虚拟机数量增多时，操作系统本身消耗的资源势必增多 容器技术解决了什么问题： 对软件和其依赖的标准化自动化打包和发布 能实现应用之间的相互隔离，类似于上述虚拟化技术的隔离，但是它的隔离没有虚拟化技术隔离的那么好 容器可以共享同一个OS（实现多个应用程序运行在一个OS上） 可以运行在很多主流的操作系统上 容器是APP层面的隔离，虚拟化是物理资源层面的隔离，我们也可以将虚拟化技术与容器技术结合使用，既对物理机器划分为不同的VM，每个VM上运行多个容器 Docker介绍Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从 Apache2.0 协议开源。 Docker 可以让开发者打包他们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。 容器是完全使用沙箱机制，相互之间不会有任何接口（类似 iPhone 的 app），更重要的是容器性能开销极低。 Docker的优点Docker 是一个用于开发，交付和运行应用程序的开放平台。Docker 使您能够将应用程序与基础架构分开，从而可以快速交付软件。借助 Docker，您可以与管理应用程序相同的方式来管理基础架构。通过利用 Docker 的方法来快速交付，测试和部署代码，您可以大大减少编写代码和在生产环境中运行代码之间的延迟。 1、快速，一致地交付您的应用程序 Docker 允许开发人员使用您提供的应用程序或服务的本地容器在标准化环境中工作，从而简化了开发的生命周期。 容器非常适合持续集成和持续交付（CI / CD）工作流程，请考虑以下示例方案： 您的开发人员在本地编写代码，并使用 Docker 容器与同事共享他们的工作。他们使用 Docker 将其应用程序推送到测试环境中，并执行自动或手动测试。当开发人员发现错误时，他们可以在开发环境中对其进行修复，然后将其重新部署到测试环境中，以进行测试和验证。测试完成后，将修补程序推送给生产环境，就像将更新的镜像推送到生产环境一样简单。 2、响应式部署和扩展 Docker 是基于容器的平台，允许高度可移植的工作负载。Docker 容器可以在开发人员的本机上，数据中心的物理或虚拟机上，云服务上或混合环境中运行。 Docker 的可移植性和轻量级的特性，还可以使您轻松地完成动态管理的工作负担，并根据业务需求指示，实时扩展或拆除应用程序和服务。 3、在同一硬件上运行更多工作负载 Docker 轻巧快速。它为基于虚拟机管理程序的虚拟机提供了可行、经济、高效的替代方案，因此您可以利用更多的计算能力来实现业务目标。Docker 非常适合于高密度环境以及中小型部署，而您可以用更少的资源做更多的事情。 Docker架构和底层技术实现docker的前生LXCLXC为Linux Container的简写。可以提供轻量级的虚拟化，以便隔离进程和资源，而且不需要提供指令解释机制以及全虚拟化的其他复杂性。相当于C++中的NameSpace。容器有效地将由单个操作系统管理的资源划分到孤立的组中，以更好地在孤立的组之间平衡有冲突的资源使用需求。与传统虚拟化技术相比，它的优势在于： 与宿主机使用同一个内核，性能损耗小； 不需要指令级模拟； 不需要即时(Just-in-time)编译； 容器可以在CPU核心的本地运行指令，不需要任何专门的解释机制； 避免了准虚拟化和系统调用替换中的复杂性； 轻量级隔离，在隔离的同时还提供共享机制，以实现容器与宿主机的资源共享。 总结：Linux Container是一种轻量级的虚拟化的手段。Linux Container提供了在单一可控主机节点上支持多个相互隔离的server container同时执行的机制。Linux Container有点像chroot，提供了一个拥有自己进程和网络空间的虚拟环境，但又有别于虚拟机，因为lxc是一种操作系统层次上的资源的虚拟化。 docker并不是LXC替代品，docker底层使用了LXC来实现，LXC将linux进程沙盒化，使得进程之间相互隔离，并且能够控制各进程的资源分配。 Docker架构Docker架构可以分为三个部分 Docker Client：这个就是我们平时操作Docker的主要入口，我们输入各种命令都是通过Client来操作的，客户端可以与Docker在同一个服务 Docker Host：是我们启动了docker的机器，也就是Docker所在的服务器，这上面主要有两个重要的概念，Containers（镜像）和images（容器） Image镜像：docker镜像就是一个只读模板，比如，一个镜像可以包含一个完整的centos，里面仅安装apache或用户的其他应用，镜像可以用来创建docker容器，另外docker提供了一个很简单的机制来创建镜像或者更新现有的镜像，用户甚至可以直接从其他人那里下载一个已经做好的镜像来直接使用。 Image是文件和meta data的集合，Linux分为内核空间和用户空间，内核空间就是Linux Kernel，也称为bootfs，用户空间其实就是基于此内核空间我们创建了各种Linux的发行版本，比如Ubuntu，CentOS，Debian等，这些其实就是一个Image，被称为Base Image，在此基础上，我们可以创建更高一级的Image，Base Image是不包含Liunx内核的，所以我们这些不同的Image可以共享Linux内核，也就是bootfs。我们可以在此Base Image上安装各种不同的软件，然后就形成了新的Image，个人理解Image就是基于内核安装各种不同的软件，然后形成不同的镜像，成为Image。所以Image是可以分层的，我们可以在每一层添加和删除文件，形成新的Image。 Image的获取有两种方式，1.我们的Docker Image，可以通过手动创建Dockerfile，然后根据它的语法来写入指令，实现自己的Dockerfile。2.Pull from Registry，其实就是类似于GitHub，我们通过Pull命令来此远程仓库拉取公开的各种Dockerfile，一般是通过Docker Hub来拉取，它是一个官方的仓库，我们可以去此仓库找到我们需要的Dockerfile，下载到本地，来创建我们的专用的Docker容器。 container容器：docker利用容器来运行应用，容器是从镜像创建的运行实例，它可以被启动，开始、停止、删除、每个容器都是互相隔离的，保证安全的平台，可以把容器看做是要给简易版的linux环境（包括root用户权限、镜像空间、用户空间和网络空间等）和运行再其中的应用程序。 container是通过image创建的。container是在image之上建立的一个container layer（可读写），image是一个只读的东西，container要去运行程序或者安装软件，所以它是可写的。container和image类似与我们Java中类和实例的关系，container就是实例，image是负责app的存储和分发的，Container负责运行App。 Registry：是一个存储容器镜像的仓库。而容器镜像是在容器被创建时，被加载用来初始化容器的文件架构与目录。它可以理解为我们的GitHUb，仓库是集中存储镜像文件的，registry是仓库主从服务器，实际上参考注册服务器上存放着多个仓库，每个仓库中又包含了多个镜像，每个镜像有不同的标签（tag），仓库分为两种，公有参考，和私有仓库，最大的公开仓库是docker Hub，存放了数量庞大的镜像供用户下周，国内的docker pool，这里仓库的概念与Git类似，registry可以理解为github这样的托管服务 底层技术支持 Namespace docker是通过namespace实现资源隔离，它可以实现六项资源的隔离， UTS：主机与域名 IPS：信号量和消息队列和共享内容 PID：进程编号 NETWORK：网络设备、网络栈、端口等 MOUNT：挂载点，既文件系统 USER：用户和用户组 Control Group CGroup它是用来做资源限制的，主要有四大功能： 资源限制：可以对任务使用的资源总额进行限制 优先级分配：通过分配的cpu时间片数量以及磁盘IO带宽大小，实际上相当于控制了任务运行优先级 资源统计：可以统计系统的资源使用量，如cpu时长，内存用量等 任务控制：cgroup可以对任务执行挂起、恢复等操作 Union file systems Container和image的分层，Docker的存储驱动的实现是基于Union File System，简称UnionFS，他是一种为Linux 、FreeBSD 和NetBSD 操作系统设计的，把其他文件系统联合到一个联合挂载点的文件系统服务。它用到了一个重要的资源管理技术,叫写时复制。写时复制（copy-on-write），也叫隐式共享，是一种对可修改资源实现高效复制的资源管理技术。对于一个重复资源，若不修改，则无需立刻创建一个新的资源，该资源可以被共享使用。当发生修改的时候，才会创建新资源。这会大大减少对于未修改资源复制的消耗。Docker正式基于此去创建images和containers 入门使用及基本命令Image操作 查询当前所有的image：docker image ls 或者 docker images 删除image：docker image rm ‘Image ID’ 或者 docker rmi ‘Image ID’， ‘Image ID‘是通过ls命令查出的，有时候我们一个Dockerfile被build成了多个image，这时我们不能直接删除，可以加 -f 参数来强制删除，示例： 12345678910111213141516171819202122# 1.查看所有的imagejw@jjw-PC:~$ docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEjjw-story/hello-docker-c latest 73404f3002a9 47 minutes ago 756kBjjw-story/hello-docker-copy latest f982998b02d3 49 minutes ago 682Bjjw-story/hello-docker latest ad1e583a2447 51 minutes ago 682B# 第一种删除方案# 2.删除失败jjw@jjw-PC:~$ docker image rm f982998b02d3Error response from daemon: conflict: unable to delete f982998b02d3 (must be forced) - image is being used by stopped container 88443ef588b1# 3.强制删除jjw@jjw-PC:~$ docker image rm -f f982998b02d3Untagged: jjw-story/hello-docker-copy:latestDeleted: sha256:f982998b02d382876511b156632c77d795a8155103e4a7e2c4d67703a16be89c# 4.查看结果jjw@jjw-PC:~$ docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEjjw-story/hello-docker-c latest 73404f3002a9 About an hour ago 756kBjjw-story/hello-docker latest ad1e583a2447 About an hour ago 682B 如上示例，COMMAND 列展示的其实是我们在 Dockerfile CMD项 指定的命令 Container操作 创建container即实例化Image：docker run ‘Image tag’，image tag就是我们使用Dockerfile构建image时指定的tag 交互式运行container，及后台运行不自动关闭，以便我们可以再次container中进行一些操作：docker run -it ‘Image name’，如下示例： 12jjw@jjw-PC:~$ docker run -it jjw-story/hello-docker-chello docker 后台运行container：docker run -d ‘Image name’ 查看当前所有正在运行的container：docker container ls，如下示例： 查看所有的container，包括历史运行的：docker container ls -a 或者 docker ps -a，如下示例： 1234jjw@jjw-PC:~$ docker container ls -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES979454ee2253 jjw-story/hello-docker-c &quot;/hello&quot; 4 minutes ago Exited (0) 4 minutes ago sweet_davinciad4051fc47ed jjw-story/hello-docker &quot;java /HelloWorld&quot; 4 minutes ago Created clever_goodall 上述查询结果中，COMMAND 展示的就是我们在编写Dockerfile时制定的 CMD 所对应的命令内容 删除container： docker container rm ‘Container ID’ 或者直接 docker rm ‘Container ID’ 效果是一样的，默认删除的就是container，Container ID是通用 container ls 命令查询出来的，这里的ID我们也可以只写ID的前几位，只要能区分出唯一即可，例如： 12345678910jw@jjw-PC:~$ docker container ls -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESd4d452d8cf2c jjw-story/hello-docker-c &quot;/hello&quot; 3 minutes ago Exited (0) 3 minutes ago competent_varahamihira6f40251fb684 jjw-story/hello-docker-c &quot;/hello&quot; 4 minutes ago Exited (0) 4 minutes ago jovial_keldyshjw@jjw-PC:~$ docker container rm 6f6fjjw@jjw-PC:~$ docker container ls -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESd4d452d8cf2c jjw-story/hello-docker-c &quot;/hello&quot; 5 minutes ago Exited (0) 5 minutes ago competent_varahamihira 查看当前所有的container，并只显示id：docker container ls -aq，此命令会显示标题。去除标题：docker container ls -a | awk {‘print$1’} 基于上述命令删除所有的container：docker rm $(docker container ls -aq) 查看所有已经退出的容器：docker container ls -f “status=exited”, 只列出ID：docker container ls -f “status=exited” -q 删除所有已退出的容器：docker rm $(docker container ls -f “status=exited” -q)","categories":[{"name":"Docker","slug":"Docker","permalink":"https://jjw-story.github.io/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://jjw-story.github.io/tags/Docker/"},{"name":"入门","slug":"入门","permalink":"https://jjw-story.github.io/tags/入门/"}],"author":"JJW"},{"title":"分布式消息队列","slug":"分布式消息队列","date":"2020-04-05T04:11:21.000Z","updated":"2020-04-26T03:04:11.347Z","comments":true,"path":"2020/04/05/分布式消息队列/","link":"","permalink":"https://jjw-story.github.io/2020/04/05/分布式消息队列/","excerpt":"","text":"MQ应用详解分布式消息队列的应用思考点 生产端的消息可靠性投递 就是有些业务场景我们需要消息是百分之百投递成功的，或者与我们的数据库一定是一个原子性的操作 消费端幂等 在生产端为了保证消息投递可靠的时候，可能会出现重复发送消息的情况，我们的消费端一定要做好消费的幂等，杜绝出现消息重复消费的情况 MQ的高可用 我们要保证MQ的节点在挂掉一个或多个，MQ还是可用的状态 MQ的低延迟 在流量非常大的时候，我们如何保证消息的低延迟 MQ的消息的可靠性 就是如果我们的消息落到了MQ中，如何保证消息肯定不会丢失，比如某个磁盘出现问题，还能使消息不丢失（一般都是使用分片、副本的概念解决） MQ消息的堆积能力 当消息量非常大，消费者消费速度跟不上的时候，我们的MQ能否堆积一个很大的消息量 扩展性等 主流的分布式消息队列目前业界主流的消息中间件有： ActiveMQ、RabbitMQ、RocketMQ、Kafka 如何进行技术选型 各个MQ的性能、优缺点、响应的业务场景、 集群架构模式，分布式、可扩展性、高可用、可维护性 综合成本问题，集群规模，人员成本（既看公司的技术栈，公司整体比较熟悉哪种MQ的使用等等的综合考虑） 未来的方向、规划、思考 JMS及其专业术语JMS（Java Message Service）规范，也就是Java消息服务，它定义了Java中访问消息中间件的接口的规范。在这里注意，JMS只是接口，并没有给予实现，实现JMS接口的消息中间件称为 “JMS Provider”，目前知名的开源 MOM （Message Oriented Middleware，也就是消息中间件）系统包括Apache的ActiveMQ、RocketMQ、Kafka，以及RabbitMQ，可以说他们都 “基本遵循” 或 “参考” JMS规范，都有自己的特点和优势 专业术语： JMS（Java Message Service）：实现JMS 接口的消息中间件； Provider（MessageProvider）：消息的生产者； Consumer（MessageConsumer）：消息的消费者； PTP（Point to Point）：即点对点的消息模型，这也是非常经典的模型； Pub / Sub（Publish/Subscribe）：，即发布/订阅的消息模型； Queue：队列目标，也就是我们常说的消息队列，一般都是会真正的进行物理存储； Topic：主题目标； ConnectionFactory：连接工厂，JMS 用它创建连接； Connection：JMS 客户端到JMS Provider 的连接； Destination：消息的目的地； Session：会话，一个发送或接收消息的线程（这里Session可以类比Mybatis的Session）； ActiveMQActiveMQ介绍ActiveMQ 是一个完全支持JMS1.1和J2EE 1.4规范的 JMS Provider实现，尽管JMS规范出台已经是很久的事情了，但是JMS在早些年的 “J2EE应用” 时期扮演着特殊的地位，可以说那个年代ActiveMQ在业界应用最广泛，当然如果现在想要有更强大的性能和海量数据处理能力，ActiveMQ还需要不断的升级版本，不断的提升性能和架构设计的重构。 就算现在我们 80% 以上的业务我们使用ActiveMQ已经足够满足需求，其丰富的API、多种集群构建模式使得他成为业界老牌消息中间件，在中小型企业中应用广泛！ 当然如果你想针对大规模、高并发应用服务做消息中间件技术选型，譬如淘宝、京东这种大型的电商网站，尤其是双11这种特殊时间，ActiveMQ可能就显得力不从心了 ActiveMQ消息投递模式 点对点：生产者向队列投递一条消息，只有一个消费者能够监听得到这条消息（PTP) 发布订阅：生产者向队列投递一条消息，所有监听该队列的消费者都能够监听得到这条消息（P/S) ActiveMQ各项指标衡量一个MOM，我们主要从三方面考虑即可，即服务性能、存储堆积能力、可扩展性。 服务性能：ActiveMQ的性能一般，在早期传统行业为王的时代还是比较流行的，但现如今面对高并发、大数据的业务场景，往往力不从心！ 数据存储：默认采用kahadb存储（索引文件形式存储），也可以使用高性能的google leveldb（内存数据库存储）， 或者可以使用MySql、Oracle进程消息存储（关系型数据库存储）。 集群架构：ActiveMQ 可以与zookeeper进行构建 主备集群模型，并且多套的主备模型直接可以采用Network的方式构建分布式集群。 ActiveMQ集群架构模式ActiveMQ最经典的两种集群架构模式，Master-Slave 、Network 集群模式 Master-Slave: 顾名思义，就是主从方式，当然这里要理解为主备的方式，也就是双机热备机制；Master Slave 背后的想法是，消息被复制到slave broker，因此即使master broker遇到了像硬件故障之类的错误，你也可以立即切换到slave broker而不丢失任何消息。 Master Slave是目前ActiveMQ推荐的高可靠性和容错的解决方案。 zookeeper的作用就是为了当绿色的主节点宕机时，进行及时切换到备份的灰色节点上去，使其进行主从角色的互换，用于实现高可用性的方案。 Master-Slave集群模型的缺点也显而易见，就是不能做到分布式的topic、queue，当消息量巨大时，我们的MQ集群压力过大，没办法满足分布式的需求 Network：这里可以理解为网络通信方式，也可以说叫Network of brokers。这种方式真正解决了分布式消息存储和故障转移、broker切换的问题。可以理解消息会进行均衡；从ActiveMQ1.1版本起，ActiveMQ支持networks of brokers。它支持分布式的queues和topics。一个broker会相同对待所有的订阅（subscription）：不管他们是来自本地的客户连接，还是来自远程broker，它都会递送有关的消息拷贝到每个订阅。远程broker得到这个消息拷贝后，会依次把它递送到其内部的本地连接上。（说白了就是部署多套MQ集群，以每个集群为单位进行通信，每个集群有自己的主从节点，有自己的zookeeper节点） Network集群模型的关键点： 这种方案需要两套或多套（Master-Slave）的集群模型才可以搞定，部署非常麻烦，需要两套或多套集群直接相互交叉配置，相互间能够感知到彼此的存在 Network虽然解决了分布式消息队列这个难题，但是还有很多潜在的问题，最典型的就是资源浪费问题，并且也可能达不到所预期的效果；通常采用Master-Slave模型是传统型互联网公司的首选，作为互联网公司往往会选择开箱即用的消息中间件，从运维、部署、使用各个方面都要优于ActiveMQ，当然ActiveMQ毕竟是 “老牌传统强Q”，Apache的顶级项目之一，目前正在进行新版本的重构（对于5.X版本）与落地。 RibbitMQRibbitMQ四种集群模式 主备模式warren（兔子窝）：经典的主备模式，正常情况由主节点提供服务，从节点只是备份数据，当主节点挂掉，从节点会代替主节点提供服务。与Active不同的是，主从实现不是通过zookeeper来实现的，它使用Haproxy实现的，Haproxy跟Nginx有点类似 远程模式早起版本提供的一种多活的模式，主要是服务异地的容灾，与上述ActiveMQ的NetWork模式非常类似，主要是在不同的地方部署不同的集群，可以提高容灾能力及处理性能，现在的版本已经不推荐使用 远距离通信和复制，可以实现多活的一种模式，简称Shovel模式，就是我们可以把消息进行不同的数据中心的复制工作，可以让跨地域的两个MQ集群互联，当其中的某一个集群处理消息处理不过来的时候，可以把消息转发到另外一个集群进行处理。集群之间的通信使用MQ的amqp协议来做通信的。此模式的配置非常麻烦，现在已经很少使用，只做了解就行。 镜像模式业界使用最为广泛的模型，非常经典的Mirror镜像模式，保证数据100%的不丢失，镜像模式其实就是数据的备份。可靠性非常高，因为数据发过来之后，它需要将数据同步到MQ镜像集群中所有的节点，所有节点都会对数据做备份存储，它的模型跟ES的很像，但是它的副本是在所有的节点上。但是缺点也很明显，就是每个节点都存储了所有的数据，如果我们要扩容的话只能增加所有节点的磁盘大小，而不能通过增加机器来实现 多活模型这种模式也是实现异地数据复制的主流模式，因为Shovel模式配置比较复杂，所以一般实现异地集群都是使用这种多活模型。这种模型需要依赖RabbitMQ的federation插件，可以实现持续可靠的AMQP数据通信，配置与应用很简单。 部署架构采用多中心模式，在两套或多套数据中心中各部署一套Rabbit集群，各中心的RabbitMQ服务除了为业务提供正常消息服务外，中心之间需要实现部分队列消息共享。集群可以是不同RibbitMQ版本的集群 RocketMQ概述RocketMQ是一款分布式、队列模型的消息中间件，由阿里巴巴自主研发的一款适用于高并发、高可靠性、海量数据场景的消息中间件。早期开源2.x版本名为MetaQ；15年迭代3.x版本，更名为RocketMQ，16年开始贡献到Apache，经过1年多的孵化，最终成为Apache顶级的开源项目，更新非常频繁，社区活跃度也非常高；RocketMQ参考借鉴了优秀的开源消息中间件Apache Kafka，其消息的路由、存储、集群划分都借鉴了Kafka优秀的设计思路，并结合自身的 “双十一” 场景进行了合理的扩展和API丰富。 优秀的能力与支持 支持集群模型、负载均衡、水平扩展能力 亿级别的消息堆积能力 采用零拷贝的原理、顺序写盘、随机读（索引文件） 丰富的API使用 代码优秀，底层通信框架采用Netty NIO框架 NameServer 代替 Zookeeper 强调集群无单点，可扩展，任意一点高可用，水平可扩展 消息失败重试机制、消息可查询 开源社区活跃度、是否足够成熟（经过双十一考验） 专业术语 Producer：消息生产者，负责产生消息，一般由业务系统负责产生消息。 Consumer：消息消费者，负责消费消息，一般是后台系统负责异步消费。 Push Consumer：Consumer的一种，需要向Consumer对象注册监听。 Pull Consumer：Consumer的一种，需要主动请求Broker拉取消息。 Producer Group：生产者集合，一般用于发送一类消息。 Consumer Group：消费者集合，一般用于接受一类消息进行消费。 Broker ： MQ消息服务（中转角色，用于消息存储与生产消费转发） 集群架构模型RocketMQ为我们提供了丰富的集群架构模型，包括单点模式、主从模式、双主模式、以及生产上使用最多的双主双从模式（或者说多主多从模式） Producer集群就是生产者集群（他们在同一个生产者组 Producer Group） Consumer集群就是消费者集群（他们在同一个消费者组 Consumer Group） NameServer集群作为超轻量级的配置中心，只做集群元数据存储和心跳工作，不必保障节点间数据强一致性，也就是说NameServer集群是一个多机热备的概念。 对于Broker而言，通常Master与Slave为一组服务，他们互为主从节点，通过NameServer与外部的Client端暴露统一的集群入口。Broker就是消息存储的核心MQ服务了。 RocketMQ作为国内顶级的消息中间件，其性能主要依赖于天然的分布式Topic/Queue，并且其内存与磁盘都会存储消息数据，借鉴了Kafka的 “空中接力” 概念，所谓 “空中接力” 就是指数据不一定要落地，RocketMQ提供了同步/异步双写、同步/异步复制的特性。在真正的生产环境中应该选择符合自己业务的配置。下面针对于RocketMQ的高性能及其瓶颈在这里加以说明： RocketMQ目前其主要瓶颈最终会落在IOPS上面，当高峰期来临的时候，磁盘读写能力是主要的性能瓶颈，为什么瓶颈在IOPS? 根本原因还是因为云环境导致的问题，云环境的SSD物理存储显然和自建机房SSD会有不小的差距，这一点我们无论是从数据库的磁盘性能、还是搜索服务（ElasticSearch）的磁盘性能，都能给出准确的瓶颈点，单机IOPS达到1万左右就是云存储SSD的性能瓶颈，这个也解释了 “木桶短板原理” 的效应，在真正的生产中，CPU的工作主要在等待IO操作，高并发下 CPU资源接近极限，但是IOPS还是达不到我们想要的效果。 与KAFKA对比既然RocketMQ有Kafka所有的优点，那么它两的区别在哪呢？ 消息投递实时性 Kafka使用短轮询方式，实时性取决于轮询间隔时间 RocketMQ使用长轮询，同Push方式实时性一致，消息的投递延时通常在几个毫秒。 严格的消息顺序 Kafka支持消息顺序，但是一台Broker宕机后，就会产生消息乱序 RocketMQ支持严格的消息顺序，在顺序消息场景下，一台Broker宕机后，发送消息会失败，但是不会乱序 namesrv VS zk kafka和rocketMq在协调节点选择上的差异，kafka通过zookeeper来进行协调，而rocketMq通过自身的namesrv进行协调。 kafka在具备选举功能，在Kafka里面，Master/Slave的选举，有2步：第1步，先通过ZK在所有机器中，选举出一个KafkaController；第2步，再由这个Controller，决定每个partition的Master是谁，Slave是谁。因为有了选举功能，所以kafka某个partition的master挂了，该partition对应的某个slave会升级为主对外提供服务。 rocketMQ不具备选举，Master/Slave的角色也是固定的。当一个Master挂了之后，你可以写到其他Master上，但不能让一个Slave切换成Master。那么rocketMq是如何实现高可用的呢，其实很简单，rocketMq的所有broker节点的角色都是一样，上面分配的topic和对应的queue的数量也是一样的，Mq只能保证当一个broker挂了，把原本写到这个broker的请求迁移到其他broker上面，而并不是这个broker对应的slave升级为主。 吞吐量 kafka在消息存储过程中会根据topic和partition的数量创建物理文件，也就是说我们创建一个topic并指定了3个partition，那么就会有3个物理文件目录，也就说说partition的数量和对应的物理文件是一一对应的。 rocketMq在消息存储方式就一个物流问题，也就说传说中的commitLog，rocketMq的queue的数量其实是在consumeQueue里面体现的，在真正存储消息的commitLog其实就只有一个物理文件。 kafka的多文件并发写入 VS rocketMq的单文件写入，性能差异kafka完胜可想而知。 kafka的大量文件存储会导致一个问题，也就说在partition特别多的时候，磁盘的访问会发生很大的瓶颈，毕竟单个文件看着是append操作，但是多个文件之间必然会导致磁盘的寻道。 在性能上Kafka是完胜的 KAFKA介绍Kafka是LinkedIn开源的分布式消息系统，目前归属于Apache顶级项目 主要特点是基于Pull的模式来处理消息消费，追求高吞吐量，一开始就是用于日志收集 0.8版本开始支持复制，不支持事务，对消息的重复、丢失、错误没有严格要求，适合产生大量数据的互联网服务的数据收集业务 特点 有分布式的特性，就是支持分区的概念，一个主题下可以有多个分区 有跨平台的特性，支持不同语言的客户端 堆积能力特别强，且并不影响消息的接收和发送 实时性非常强 高性能的原因（重点）顺序写就是顺序写盘，可以提高磁盘的利用率，就是一个一个的写，而不是随机写，这样会大大提高写的性能。 每个topic有不同的分区，而每个分区下包含若干个只能追加写的提交日志：新消息被追加到文件的最末端。最直接的证明就是Kafka源码中只调用了FileChannel.write(ByteBuffer)，而没有调用过带offset参数的write方法，说明它不会执行随机写操作。 Page Cache首先，Kafka重度依赖底层操作系统提供的PageCache功能。当上层有写操作时，操作系统只是将数据写入PageCache，同时标记Page属性为Dirty。当读操作发生时，先从PageCache中查找，如果发生缺页才进行磁盘调度，最终返回需要的数据。实际上PageCache是把尽可能多的空闲内存都当做了磁盘缓存来使用。同时如果有其他进程申请内存，回收PageCache的代价又很小，所以现代的OS都支持PageCache。 使用PageCache功能同时可以避免在JVM内部缓存数据，JVM为我们提供了强大的GC能力，同时也引入了一些问题不适用与Kafka的设计。 如果在Heap内管理缓存，JVM的GC线程会频繁扫描Heap空间，带来不必要的开销。如果Heap过大，执行一次Full GC对系统的可用性来说将是极大的挑战。 所有在在JVM内的对象都不免带有一个Object Overhead(千万不可小视)，内存的有效空间利用率会因此降低。 所有的In-Process Cache在OS中都有一份同样的PageCache。所以通过只在PageCache中做缓存至少可以提高一倍的缓存空间。 如果Kafka重启，所有的In-Process Cache都会失效，而OS管理的PageCache依然可以继续使用。 零拷贝首先介绍一下传统的网络I/O操作流程，大体上分为以下4步： OS从硬盘把数据读到内核区的PageCache。 用户进程把数据从内核区Copy到用户区。 然后用户进程再把数据写入到Socket，数据流入内核区的Socket Buffer上。 OS再把数据从Buffer中Copy到网卡的Buffer上，这样完成一次发送。 整个过程一共经历了四次拷贝，同一份数据在内核Buffer与用户Buffer之间重复拷贝，效率低下。其中2、3两步没有必要，完全可以直接在内核区完成数据拷贝。 零拷贝技术就是省略了第2、3步，不难看出，Kafka的设计初衷是尽一切努力在内存中完成数据交换，无论是对外作为一整个消息系统，或是内部同底层操作系统的交互。如果Producer和Consumer之间生产和消费进度上配合得当，完全可以实现数据交换零I/O。这也就是我为什么说Kafka使用“硬盘”并没有带来过多性能损失的原因。 主要特点 同时为发布和订阅提供高吞吐量。据了解，Kafka每秒可以生产约25万消息（50 MB），每秒处理55万消息（110 MB）。 可进行持久化操作。将消息持久化到磁盘，因此可用于批量消费，例如ETL，以及实时应用程序。通过将数据持久化到硬盘以及replication防止数据丢失。 分布式系统，易于向外扩展。所有的producer、broker和consumer都会有多个，均为分布式的。无需停机即可扩展机器。 消息被处理的状态是在consumer端维护，而不是由server端维护。当失败时能自动平衡。 支持online和offline的场景。 Kafka的架构Kafka的整体架构非常简单，是显式分布式架构，producer、broker（kafka）和consumer都可以有多个。Producer，consumer实现Kafka注册的接口，数据从producer发送到broker，broker承担一个中间缓存和分发的作用。broker分发注册到系统中的consumer。broker的作用类似于缓存，即活跃的数据和离线处理系统之间的缓存。客户端和服务器端的通信，是基于简单，高性能，且与编程语言无关的TCP协议。 基本概念 Topic：特指Kafka处理的消息源（feeds of messages）的不同分类。 Partition：Topic物理上的分组，一个topic可以分为多个partition，每个partition是一个有序的队列。partition中的每条消息都会被分配一个有序的id（offset）。 Message：消息，是通信的基本单位，每个producer可以向一个topic（主题）发布一些消息。 Producers：消息和数据生产者，向Kafka的一个topic发布消息的过程叫做producers。 Consumers：消息和数据消费者，订阅topics并处理其发布的消息的过程叫做consumers。 Broker：缓存代理，Kafka集群中的一台或多台服务器统称为broker。 发送消息的流程 Producer根据指定的partition方法（round-robin、hash等），将消息发布到指定topic的partition里面 kafka集群接收到Producer发过来的消息后，将其持久化到硬盘，并保留消息指定时长（可配置），而不关注消息是否被消费。 Consumer从kafka集群pull数据，并控制获取消息的offset kafka的优秀设计从kafka的吞吐量、负载均衡、消息拉取、扩展性来说一说kafka的优秀设计。 高吞吐高吞吐是kafka需要实现的核心目标之一，为此kafka做了以下一些设计： 内存访问：直接使用 linux 文件系统的cache，来高效缓存数据，对数据进行读取和写入。 数据磁盘持久化：消息不在内存中cache，直接写入到磁盘，充分利用磁盘的顺序读写性能。 zero-copy：减少IO操作步骤，采用linux Zero-Copy提高发送性能。传统的数据发送需要发送4次上下文切换，采用sendfile系统调用之后，数据直接在内核态交换，系统上下文切换减少为2次。根据测试结果，可以提高60%的数据发送性能。Zero-Copy详细的技术细节可以参考：https://www.ibm.com/developerworks/linux/library/j-zerocopy/ 对消息的处理：支持数据批量发送、支持数据压缩机制 主题分区：Topic划分为多个partition，提高生产/消费端处理消息的parallelism（并行度），数据在磁盘上存取代价为O(1)。kafka以topic来进行消息管理，每个topic包含多个part（ition），每个part对应一个逻辑log，有多个segment组成。每个segment中存储多条消息，消息id由其逻辑位置决定，即从消息id可直接定位到消息的存储位置，避免id到位置的额外映射。每个part在内存中对应一个index，记录每个segment中的第一条消息偏移。发布者发到某个topic的消息会被均匀的分布到多个part上（随机或根据用户指定的回调函数进行分布），broker收到发布消息往对应part的最后一个segment上添加该消息，当某个segment上的消息条数达到配置值或消息发布时间超过阈值时，segment上的消息会被flush到磁盘，只有flush到磁盘上的消息订阅者才能订阅到，segment达到一定的大小后将不会再往该segment写数据，broker会创建新的segment。 负载均衡 producer根据用户指定的算法，将消息发送到指定的partition 存在多个partiiton，每个partition有自己的replica，每个replica分布在不同的Broker节点上 多个partition需要选取出lead partition，lead partition负责读写，并由zookeeper负责fail over 通过zookeeper管理broker与consumer的动态加入与离开 消息的拉取 简化kafka设计（由于kafka broker会持久化数据，broker没有内存压力，因此，consumer非常适合采取pull的方式消费数据） consumer根据消费能力自主控制消息拉取速度 consumer根据自身情况自主选择消费模式，例如批量，重复消费，从尾端开始消费等 可扩展性当需要增加broker结点时，新增的broker会向zookeeper注册，而producer及consumer会根据注册在zookeeper上的watcher感知这些变化，并及时作出调整。 KAFKA应用场景 消息队列：比起大多数的消息系统来说，Kafka有更好的吞吐量，内置的分区，冗余及容错性，这让Kafka成为了一个很好的大规模消息处理应用的解决方案。消息系统一般吞吐量相对较低，但是需要更小的端到端延时，并常常依赖于Kafka提供的强大的持久性保障。在这个领域，Kafka足以媲美传统消息系统，如ActiveMQ或RabbitMQ。 行为跟踪：Kafka的另一个应用场景是跟踪用户浏览页面、搜索及其他行为，以发布-订阅的模式实时记录到对应的topic里。那么这些结果被订阅者拿到后，就可以做进一步的实时处理，或实时监控，或放到hadoop/离线数据仓库里处理。 元信息监控：作为操作记录的监控模块来使用，即汇集记录一些操作信息，可以理解为运维性质的数据监控吧。 日志收集：日志收集方面，其实开源产品有很多，包括Scribe、Apache Flume。很多人使用Kafka代替日志聚合（log aggregation）。日志聚合一般来说是从服务器上收集日志文件，然后放到一个集中的位置（文件服务器或HDFS）进行处理。然而Kafka忽略掉文件的细节，将其更清晰地抽象成一个个日志或事件的消息流。这就让Kafka处理过程延迟更低，更容易支持多数据源和分布式数据处理。比起以日志为中心的系统比如Scribe或者Flume来说，Kafka提供同样高效的性能和因为复制导致的更高的耐用性保证，以及更低的端到端延迟。 流处理：这个场景可能比较多，也很好理解。保存收集流数据，以提供之后对接的Storm或其他流式计算框架进行处理。很多用户会将那些从原始topic来的数据进行阶段性处理，汇总，扩充或者以其他的方式转换到新的topic下再继续后面的处理。例如一个文章推荐的处理流程，可能是先从RSS数据源中抓取文章的内容，然后将其丢入一个叫做“文章”的topic中；后续操作可能是需要对这个内容进行清理，比如回复正常数据或者删除重复数据，最后再将内容匹配的结果返还给用户。这就在一个独立的topic之外，产生了一系列的实时数据处理的流程。Strom和Samza是非常著名的实现这种类型数据转换的框架。 事件源：事件源是一种应用程序设计的方式，该方式的状态转移被记录为按时间顺序排序的记录序列。Kafka可以存储大量的日志数据，这使得它成为一个对这种方式的应用来说绝佳的后台。比如动态汇总（News feed） 持久性日志（commit log）：Kafka可以为一种外部的持久性日志的分布式系统提供服务。这种日志可以在节点间备份数据，并为故障节点数据回复提供一种重新同步的机制。Kafka中日志压缩功能为这种用法提供了条件。在这种用法中，Kafka类似于Apache BookKeeper项目。","categories":[{"name":"MQ","slug":"MQ","permalink":"https://jjw-story.github.io/categories/MQ/"}],"tags":[{"name":"MQ","slug":"MQ","permalink":"https://jjw-story.github.io/tags/MQ/"}],"author":"JJW"},{"title":"Shell","slug":"shell","date":"2020-03-22T09:58:31.000Z","updated":"2020-04-10T02:35:29.211Z","comments":true,"path":"2020/03/22/shell/","link":"","permalink":"https://jjw-story.github.io/2020/03/22/shell/","excerpt":"","text":"Shellshell介绍Shell 是一个用 C 语言编写的程序，它是用户使用 Linux 的桥梁。Shell 既是一种命令语言，又是一种程序设计语言Shell是命令解释器，用来解释用户对操作系统的操作，也就是将我们用户执行的命令，翻译给内核，内核根据命令执行的结果，将结果反馈给用户Shell 脚本（shell script），是一种为 shell 编写的脚本程序，业界所说的 shell 通常都是指 shell 脚本Shell有很多种，我们一般使用的都是 bash Linux的启动过程BLOS - MBR - BootLoader(grub) - kernel - systemd - 系统初始化 - shell BLOS：基本的输入输出系统，这个功能是在主板上的，通过BLOS来选择引导的介质，一般引导的介质有两种，一是早起使用到的光盘，二是硬盘。现在更多用的是网络的方式去引导 MBR：硬盘的主引导记录部分，硬盘是不是可以引导， 是通过这部分来确定的 BootLoader(grub)： 这里就是Linux的部分了，Linux的部分首先不是内核的工作引导，而是通过grub这样的一个软件来引导，grub我们在Linux中称为BootLoader，主要用来启动和引导内核的一个工具。我们可以简单理解为BootLoader是用来选择哪一个内核及选择指定内核版本的，选定后我们就要启动内核了 kernel：内核 systemd：Linux的一号进程，如果是CentOS7以下的版本，头号进程是 init 进程。在systemd中，系统初始化的过程一部分是通过配置文件完成的，一部分是通过shell完成的，init中，系统初始化过程都是通过shell完成的 Shell脚本的格式UNIX的哲学：一条命令只做一件事 为组合命令和多次执行，使用脚本文件来保存需要执行的命令 然后赋予该文件的执行权限（chmod u+rx filename） Shell脚本的作用就是将一系列的命令操作整合在一个文件里，然后再下次执行的时候可以直接执行此文件，而不需要我们一步一步的执行所有命令 一般我们都是使用bash的方式来执行我们的脚本文件，我们的shell脚本文件一般使用 .sh 作为文件的后缀 标准Shell脚本需要包含的元素 Sha-bang：就是每一个shell脚本文件的内容开头 以 #! 开头，是一个声明作用，如果我们使用 【bash 文件名.sh】 的方式来执行，那么此内容变不被识别，如果使用 【./文件名.sh】 的方式来执行，那么此文件头就表示告诉Linux系统，此文件需要使用 bash 脚本的，既告诉Linux，此文件是一个bash的脚本。下面是一般Sha-bang的内容： 1#!/bin/bash 命令：这里说的就是我们之前学习的那么多的Linux命令 “#” 开头的注释。在我们的shell脚本中，# 开头的行表示内容是注释 赋予文件可执行的权限。例如 chmod u+x aa.sh 执行命令的方式： bash ./filename.sh ./filename.sh source ./filename.sh .filename.sh 这里只需要注意：命令我们可以在一行中使用 ; 号隔开来写多个命令，但是一般我们是通过换行的方式来写多个命令","categories":[{"name":"Linux","slug":"Linux","permalink":"https://jjw-story.github.io/categories/Linux/"}],"tags":[{"name":"Shell","slug":"Shell","permalink":"https://jjw-story.github.io/tags/Shell/"}],"author":"JJW"},{"title":"逻辑卷管理","slug":"逻辑卷管理","date":"2020-03-15T07:37:55.000Z","updated":"2020-03-15T09:28:57.415Z","comments":true,"path":"2020/03/15/逻辑卷管理/","link":"","permalink":"https://jjw-story.github.io/2020/03/15/逻辑卷管理/","excerpt":"","text":"逻辑卷管理什么是逻辑卷许多Linux使用者安装操作系统时都会遇到这样的困境：如何精确评估和分配各个硬盘分区的容量，如果当初评估不准确，一旦系统分区不够用时可能不得不备份、删除相关数据，甚至被迫重新规划分区并重装操作系统，以满足应用系统的需要 LVM逻辑卷相当于在传统的硬盘的底层上面在叠一层，把上面的这一层也当做一个硬盘来对待，只是这个硬盘是一个虚拟的硬盘，RAID其实就是一个逻辑卷的应用，Linux中默认使用的就是根目录，逻辑卷去管理磁盘的 增加逻辑卷增加逻辑卷首先我们首先需要添加物理硬盘，然后对添加的物理硬盘做好分区，注意：这里可以添加多块硬盘，然后我们建立上层系统，将几块硬盘做一个整合，整合成一个物理卷，然后再上层查看磁盘状态的时候，我们发现这几个硬盘它是一个整体，只有一块硬盘，这样我们就可以通过上层的系统将这块硬盘划分成不同的逻辑卷（比如，给根目录划分挂载，给boot目录划分挂载，给usr划分挂载，将这些目录进行隔离开，这些隔离开的空间就称为逻辑卷） 下面是具体步骤： 12345678910111213141516171819202122232425262728293031323334# 1.将多块分区组成一个物理卷pvcreate /dev/sdb1 /dev/sdc1 /dev/sdd1# 注意这里可以使用简写，通配符pvcreate /dev/sd[b,c,d]1# 2.查看我们创建的物理卷，会发现我们添加的三块硬盘已经创建成了三个物理卷，但是他们的 VG 选项都是空的，VG选项表示他们属于哪个卷组，这里我们还没有对他们设置卷组pvs# 3.对物理卷设置卷组vgcreate vg1 /dev/sdb1 /dev/sdc1 /dev/sdd1-- 这里 vg1 表示卷组的名称# 4.创建成功后我们继续通过 pvs 命令查看，发现这三个分区的 VG 选项就有了值，是我们设置的vg1-- 注意一个分区只能属于一个卷组# 5.我们可以通过 vgs 命令来插件当前机器的卷组，来查看我们创建的卷组信息vgs-- 注意查询出来的 #LV 选项表述的就是此物理卷创建了几个逻辑卷，一般我们安装LINUX系统时，会默认创建一个逻辑卷，CENTOS，它里面会有两个逻辑卷，一般默认都是 / 和 boot 逻辑卷，我们先创建的物理卷这里会显示为0，表示还没有创建逻辑卷# 6.现在我们就可以创建逻辑卷了# 使用命令：lvcreate -L [逻辑卷大小] -n [逻辑卷名称] [物理卷名称]lvcreate -L 100M -n lv1 vg1# 7.现在通过lvs查看逻辑卷信息，我们发现里面已经有我们创建好的逻辑卷信息，然后通过vgs查看物理卷，发现vg1这个物理卷已经有了逻辑卷，既 #LV 选项值为1lvsvgs# 8.逻辑卷的使用，使用方法还是现将逻辑卷进行格式化，然后创建目录进行挂载# 8.1 创建文件夹mkdir /mnt/test# 8.2 格式化逻辑卷mkfs.xfs /dev/vg1/lv1# 8.3 mount挂载挂载成功后，此逻辑卷就可以正常使用 扩充逻辑卷很多时候当我们物理卷够用的情况下但是逻辑卷大小分配太小，我们可以直接从物理卷上扩充逻辑卷，有的情况是物理卷也太小，需要先扩充物理卷然后扩充逻辑卷，下面是扩充展示： 1234567891011121314151617181920212223242526# 1.扩充物理卷组首先添加磁盘，然后对新添加的磁盘进行分区，例如这里划分分区为 /dev/sde1# 2.将新的分区划分给需要扩充的物理卷组，下面命令 vg1 为物理卷组名称，后面是分区名称vgextend vg1 /dev/sde1# 3.使用pvs命令查看是否划分成功pvs# 4.使用vgs查看物理卷信息vgs-- 这里我们发现 vg1 物理卷的大小已经发生了变化，增大了我们新加入的磁盘分区大小# 5.扩充我们要扩充的逻辑卷, 下面命令 +10G 表示添加10G大小的空间给逻辑卷，后面是逻辑卷名称-- 注意：我们物理卷够用的时候，可以直接从这里开始扩充逻辑卷就好，不需要扩充物理卷lvextend -L +10G /dev/vg1/lv1# 6.使用lvs查看逻辑卷大小是否改变，这里发现已经被扩大lvs这里先不要着急，我们虽然看到逻辑卷已经被扩大，但是我们还没有告诉文件系统，文件系统还认为我们的大小没有变，这里需要告诉文件系统# 7.告诉文件系统xfs_growfs /dev/vg1/lv1# 8.使用 df -h 查看文件夹是否扩容成功df -h","categories":[{"name":"Linux","slug":"Linux","permalink":"https://jjw-story.github.io/categories/Linux/"}],"tags":[{"name":"command","slug":"command","permalink":"https://jjw-story.github.io/tags/command/"},{"name":"逻辑卷管理","slug":"逻辑卷管理","permalink":"https://jjw-story.github.io/tags/逻辑卷管理/"}],"author":"JJW"},{"title":"高效员工起航训练营","slug":"高效员工起航训练营","date":"2020-02-16T11:00:00.000Z","updated":"2020-02-18T03:37:47.358Z","comments":true,"path":"2020/02/16/高效员工起航训练营/","link":"","permalink":"https://jjw-story.github.io/2020/02/16/高效员工起航训练营/","excerpt":"","text":"高效员工起航训练营如何使执行效果达到预期（以终为始） 明确任务执行完成的目标，以任务实现达到的效果为目标，而不是以执行任务为目标 任务执行效果未达到预期，应以实际证据来支撑未达成目标的原因，而不是临时应付造原因 有效执行是第一有效的方案（积极主动） 接收到任务时，应该立即投入到执行中，不要拖拉，总在快要到交付时间的时候才开始，这样可以完成的记住任务所有的需求或要求，避免拖延执行而忘记某些需求点，导致目标实现效果不佳 即使在因为某些原因而不能立即执行，也应该将当时构思的方案及需求点记录下来，避免执行时丢失某些点 该吃吃该喝喝，该睡觉就好好睡，该玩就好好玩，拖延会造成在做任何事情都会顶着雷，并且随时会爆炸，导致每一种生活都受影响 如何在执行时获得有利帮助 及时汇报工作进展，当遇到个人无法解决的问题时，应及时向领导寻求帮助，使领导协调相应的资源及帮助，不要自己蒙头干，最后还完不成任务（重点：站会的目的，此处解释的淋漓尽致） 遇到问题一定要如实汇报，即使已解决的问题，也要即使汇报，汇报时要详细说明自己遇到的问题情况，并且如何解决的，可以汇报一些自己的收获，这是一种让领导认可你的方式 协调工作可以即使寻求领导帮助，自己协调完成也应该汇报给领导，得到领导的认可和指导 如何做到灵活执行 执行不是按照自己的意识就头脑发热立即开始执行，接到任务一定要分析任务，分析任务完成需要达到的目标，想清楚什么方式能达到最好的执行效果（重点：仔细分析，考虑到影响的结果及后期会产生的问题，全面考虑一下） 如何有效完成上司安排的日常任务（要事第一） 其实就是大石头，运用好的时间管理工具，任务要分清主次，紧急重要、紧急不重要、重要不紧急、不重要不紧急。 千万不要顾此失彼，重要的事情细心的办，分清主次，并且学会寻求帮助及遇到冲突及时反馈 如何明确有效倾听的内涵（知彼解己-同理心交流） 不要随意打断别人的话，保持眼神接触 在需要表达自己想法时，用请原谅来开头 及时察觉对方的情绪 重要内容记录笔记 社交行为风格与沟通技巧 与分析型人沟通:沟通时提供可靠的数据和信息，并且有条理的分析，尽量能有书面的提案，因为沟通者也需要时间思考和决定 与亲和型人沟通:有话好好说，有事好商量（发现我们组的人性格特性十分明显） 与干劲型人沟通:开门见山，态度真诚，少周旋，提供足够信息判断选择（与分析型不太好区分） 与表达型人沟通:这种类型人沟通时喜欢制造热烈与参与的气氛，乐于分享自己的梦想与激情，沟通喜欢激励、主动，比较关注他人对他的意见和看法。这这种类型人最好沟通，就是听他说，听他说，等他说的差不多了，然后你在绕回来直接问他最终的抉择 这一节有这些就够了（我非常确认我的领导们是什么样类型的） 如何与上司沟通？ 要有效的与领导沟通，需要我们仔细倾听，认真观察，理解上司的沟通风格，把握三个问题： 你的上司是倾听者还是阅读者？倾听者喜欢先听后度，阅读者喜欢先看到书面报告，再讨论 上司喜欢看详实材料和数据还是只看看概述？摸清楚之后，使用调整使用对应的策略 上司希望收到新消息的频率如何？了解上司是不是喜欢在某些特点点希望收到新消息，以及会不会不同的项目又不同的对待，摸清楚领导期望收到消息的频率，然后根据要求及时汇报 如何提高沟通效率 讨论期限要确切，避免尽快，或下周什么时候之类模糊的用语，给予确切的时间（重点注意） 坦陈自己能做到什么，做不到什么 要明确自己的目标 不明白就问，同时问清下次何时有机会沟通，因为之后可能还会想到其他问题（重点注意） 工作遇到问题，主动请教 遇到问题要正确面对，不要怕问，不懂的要及时请教别人，避免小问题拖成大问题 请教别人时需要注意： 确定请教对象，专业/专家，省时高效 选择合适的时间：不在别人忙碌时打扰别人 组织语言，确认重点：快速让别人清楚你要咨询什么 尽量一次问清楚：避免模棱相克和反复请教 请教问题时一定要礼貌客气：让别人感觉到你对他的尊重 这节是好东西，实际存在的问题（重点：一定要注意） 高效的与领导沟通 沟通前做好准备，沟通时做好确认（要准备好工作本身的相关资料，并且了解前因后果，这个是重点，遇到好几次了，一定要了解前因后果） 不能慌乱，实事求是。可以说目前是。。。情况，具体我会去核实一下 准备好方案，学会给领导做选择题（这个得慢慢来） 内容重点突出，直击要点，逻辑清晰（千万不要在自己都捋不清的情况下直接去找领导，这个也是重点） 先讲结论，再展开说明（这是一个技巧，要学习把握，重点） 注意沟通方式和态度，意见不一致不要发生激烈顶撞，先尊重和认可领导，在展开讨论 如何增加人脉建立的渠道 珍惜各种聚会及活动的机会，能增加个人曝光率 树立帮助观念这集不喜欢。。。 如何做好人脉的维护工作 有效打破规范（要注意礼仪礼貌，多听少说，尊重对方的想法和愿望，摸清楚对方的兴趣所在，意见不同的地方，要先肯定，再反问，后共识。要真诚赞美对方，发现对方的优点并赞美） 自己人脉圈内的人员要经常来往 如何与上级或同事保持良好的人际关系 如何与上级相处： 最大效率原则 最佳方式原则（开诚布公，表现自己的诚意） 最佳时机原则（选择合适的时间和地点） 及时性原则（及时与上级保持沟通，保证工作的时效性） 将心比心原则（站在领导角度替领导考虑） 尊敬原则（谦虚但不怯场） 道德原则（不说坏话） 特事特办原则（必要时可以越级） 与同事相处 三心两意（积极、知人、自信、主动、诚恳） 沟通合作只冲突处理 应对冲突的三个步骤 确定目标（是要坚持己见，还是满足对方，还是双赢） 选择策略 采取行动这里着重说采取策略： 坚持己见（运用的重点是要：1.坚定和明确立场。2.语气不可模棱两可。3.清晰果断表名自己的期望、观点。4.必要时说明不遵从的可能后果） 拖延回避（不表态、不退让、不采取行动）当局势不利于自己，对方比自己更着急，这样处理可以争取时间创造有利局面，并争取筹码 妥协退让（这里注意不要让对方感觉自己是经过长时间思考、放弃自己珍惜的事务后才做的决定。表明放弃自己的立场是为了想与对方维系长远关系、对方很重要等等） 寻求共赢（敞开心扉，齐心协力找最佳解决方式），双赢思想，这个不做赘述 如何确定问题根源理想工作八步法应该比这个更加详细","categories":[{"name":"高效员工起航训练营","slug":"高效员工起航训练营","permalink":"https://jjw-story.github.io/categories/高效员工起航训练营/"}],"tags":[{"name":"高效员工起航训练营","slug":"高效员工起航训练营","permalink":"https://jjw-story.github.io/tags/高效员工起航训练营/"}],"author":"JJW"},{"title":"Lamda","slug":"Lamda","date":"2019-12-29T08:57:11.000Z","updated":"2020-02-18T03:22:50.733Z","comments":true,"path":"2019/12/29/Lamda/","link":"","permalink":"https://jjw-story.github.io/2019/12/29/Lamda/","excerpt":"","text":"Lamda表达式基本语法函数式接口的应用函数式接口就是Java类型系统中的接口，是只包含一个接口方法的特殊接口，我们在定义函数式接口时，可以使用注解 @FunctionalInterface 来完成语义化的检测 以下是函数式接口的定义代码示例： 1234567891011121314151617181920212223242526272829303132// 定义函数式接口// 这里使用此注解来帮助我们实现一个正确的函数式接口@FunctionalInterfacepublic interface IUserCredential &#123; // 每一个函数式接口只能包含一个未实现的方法 String verifyUser(String username); // 这里注意，如果包含了两个就会报错，在编译期 // boolean test(); // 有一个特例，因为Java中的类都继承了Object，所以Object类中的方法可以写在这里不实现它 String toString(); // 注意：接口中可以包含实现的静态方法 static boolean verifyMessage(String msg) &#123; if (msg != null) &#123; return true; &#125; return false; &#125; // 1.8中可以在接口中定义默认的方法实现 default String getCredential(String username) &#123; // 模拟方法 if (&quot;admin&quot;.equals(username)) &#123; return &quot;admin + 系统管理员用户&quot;; &#125; else &#123; return &quot;commons + 普通会员用户&quot;; &#125; &#125;&#125; 以下是函数式接口的使用示例： 1234567891011121314151617181920212223// 首先是普通接口的调用实现// 1. 普通实现，直接初始化接口实现类IUserCredential ic = new UserCredentialImpl();System.out.println(ic.verifyUser(&quot;admin&quot;));// 2. 静态方法，直接调用String msg = &quot;hello world&quot;;IMessageFormat.verifyMessage(msg)// 3. 匿名内部类，实现接口的抽象方法IUserCredential ic2 = new IUserCredential() &#123; @Override public String verifyUser(String username) &#123; return &quot;admin&quot;.equals(username)?&quot;管理员&quot;:&quot;会员&quot;; &#125;&#125;;// 4. 使用Lamda的方式实现接口的抽象方法// 这里我们需要注意，Lamda是通过返回的接收对象确定它实现的是哪个接口的方法，所以当有多个函数式接口中都有相同的未实现方法参数列表时，我们是通过返回的接收对象来绑定实现的接口类型，，如此示例中，就是通过 IUserCredential ic3 这个返回的接收接口来类型推导，绑定实现的接口，所以不会有冲突的情况IUserCredential ic3 = (String username) -&gt; &#123; return &quot;admin&quot;.equals(username)?&quot;lbd管理员&quot;: &quot;lbd会员&quot;;&#125;; 以下是JDK8提供的常见的函数式接口 12345678910111213141516171819202122232425262728293031323334353637// 1. PredicatePredicate&lt;String&gt; pre = (String username) -&gt; &#123; return &quot;admin&quot;.equals(username);&#125;;System.out.println(pre.test(&quot;manager&quot;));// 2. ConsumerConsumer&lt;String&gt; con = (String message) -&gt; &#123; System.out.println(&quot;要发送的消息：&quot; + message); System.out.println(&quot;消息发送完成&quot;);&#125;;con.accept(&quot;hello 慕课网的学员们..&quot;);// 3. FunctionFunction&lt;String, Integer&gt; fun = (String gender) -&gt; &#123; return &quot;male&quot;.equals(gender)?1:0;&#125;;System.out.println(fun.apply(&quot;male&quot;));// 4. SupplierSupplier&lt;String&gt; sup = () -&gt; &#123; return UUID.randomUUID().toString();&#125;;System.out.println(sup.get());// 5. UnaryOperatorUnaryOperator&lt;String&gt; uo = (String img)-&gt; &#123; img += &quot;[100x200]&quot;; return img;&#125;;System.out.println(uo.apply(&quot;原图--&quot;));// 6. BinaryOperatorBinaryOperator&lt;Integer&gt; bo = (Integer i1, Integer i2) -&gt; &#123; return i1 &gt; i2? i1: i2;&#125;;System.out.println(bo.apply(12, 13)); java.util.function提供了大量的函数式接口，以上示例使用总结如下： Predicate 接收参数T对象，返回一个boolean类型结果 Consumer 接收参数T对象，没有返回值 Function 接收参数T对象，返回R对象 Supplier 不接受任何参数，直接通过get()获取指定类型的对象 UnaryOperator 接口参数T对象，执行业务处理后，返回更新后的T对象 BinaryOperator 接口接收两个T对象，执行业务处理后，返回一个T对象 lambda表达式的基本语法: 声明：就是和lambda表达式绑定的接口类型 参数：包含在一对圆括号中，和绑定的接口中的抽象方法中的参数个数及顺序一致 操作符：-&gt; 执行代码块：包含在一对大括号中，出现在操作符号的右侧 [接口声明] = (参数) -&gt; {执行代码块}; Lamda表达式的变量捕获首先我们查看原始代码风格中的变量捕获方式及存在的问题: 123456789101112131415161718192021222324252627public class App2 &#123; String s1 = &quot;全局变量&quot;; String s3 = &quot;全局变量s3&quot;; // 1. 匿名内部类型中对于变量的访问 public void testInnerClass() &#123; String s2 = &quot;局部变量&quot;; new Thread(new Runnable() &#123; String s3 = &quot;内部变量s3&quot;; @Override public void run() &#123; // 访问全局变量，这里用this访问到的是外部类中的全局变量s1，因为在内部类中并没有定义s1 System.out.println(this.s1); System.out.println(s1); System.out.println(s2); // 局部变量的访问，~不能对局部变量进行数据的修改[final] // s2 = &quot;hello&quot;; // 这里访问的就是内部类中定义的内部变量，因为就近原则，所以这里很多时候就会被初学者产生歧义 System.out.println(s3); System.out.println(this.s3); &#125; &#125;).start(); &#125; 我们再用lambda表达式变量捕获的方式来实现一遍： 12345678910111213141516171819202122232425public class App2 &#123; String s1 = &quot;全局变量&quot;; String s3 = &quot;全局变量s3&quot;; public void testLambda() &#123; String s2 = &quot;局部变量lambda&quot;; new Thread(() -&gt; &#123; String s3 = &quot;内部变量lambda&quot;; // 访问全局变量 System.out.println(this.s1);// this关键字，表示的就是所属方法所在类型的对象 // 访问局部变量 System.out.println(s2); // 这里不能进行数据修改，默认推导变量的修饰符：final，因为获取到的s2是在栈中的 s2 = &quot;hello&quot;; // 这里我们捕获到的变量就是外部定义的s3全局变量，这里就不会产生歧义 System.out.println(s3); // 这里获取到的s3变量是可以修改的，因为此外部的变量是存放在堆中的 s3 = &quot;labmda 内部变量直接修改&quot;; System.out.println(s3); &#125;).start(); &#125;&#125; 通过以上代码示例，我们就可以看出Lamda表达式对于变量捕获的影响 方法重载对于lmabda表达式的影响具体我们通过代码来查看： 12345678910111213141516171819202122232425262728293031323334353637383940414243public class App4 &#123; interface Param1 &#123; void outInfo(String info); &#125; interface Param2 &#123; void outInfo(String info); &#125; // 定义重载的方法 public void lambdaMethod(Param1 param) &#123; param.outInfo(&quot;hello param1 imooc!&quot;); &#125; public void lambdaMethod(Param2 param) &#123; param.outInfo(&quot;hello param2 imooc&quot;); &#125; // 这里我们通过匿名内部类来实现此重载方法，这样是没有任何问题的 public static void main(String[] args) &#123; App4 app = new App4(); app.lambdaMethod(new Param1() &#123; @Override public void outInfo(String info) &#123; System.out.println(info); &#125; &#125;); app.lambdaMethod(new Param2() &#123; @Override public void outInfo(String info) &#123; System.out.println(&quot;------&quot;); System.out.println(info); &#125; &#125;); // 这里我们通过lamda表达式来重载，发现是失败的， 会报错，因为它无法推导出具体要绑定的接口是哪个 // app.lambdaMethod( (String info) -&gt; &#123; // System.out.println(info); // &#125;); &#125;&#125; 以上示例说明，Lamda是存在类型推导的，lambda表达式存在类型检查-&gt; 自动推导lambda表达式的目标类型，具体推导流程如下 1234567lambdaMethod() -&gt; 方法 -&gt; 重载方法 -&gt; Param1 函数式接口 -&gt; Param2 函数式接口 调用方法-&gt; 传递Lambda表达式-&gt; 自动推导-&gt; -&gt; Param1 | Param2这里到了推导的最后一步，发现有两个接口满足此推导逻辑，导致产生了歧义，这样就出现了问题，导致无法编译 Lamda的方法引用的实现我们还是通过示例的代码来分析： 12345678910111213141516171819202122232425262728293031// 首次定义用于示例的实体类@Data@AllArgsConstructor@NoArgsConstructorclass Person &#123; private String name; // 姓名 private int age; // 年龄 // 这里使用lombox，有默认的构造方式 AllArgsConstructor // 静态方法 public static int compareByAge(Person p1, Person p2) &#123; return p1.getAge() - p2.getAge(); &#125; // 实例方法 public int compareByName(Person p1, Person p2) &#123; return p1.getName().hashCode() - p2.getName().hashCode(); &#125;&#125;// 静态方法调用Person::compareByAge// 实例方法调用Person pu = new Person();pu::compareByName// 构造方法引用：绑定函数式接口Person ip = Person::new; // 无参构造Person person = ip.initPerson(&quot;jerry&quot;, &quot;男&quot;, 22); // 有参构造 Stream常见操作API介绍Stream的获取 批量数据 -&gt; Stream对象 123456789101112131415161718192021222324// 多个数据Stream stream = Stream.of(&quot;admin&quot;, &quot;tom&quot;, &quot;damu&quot;);// 数组String [] strArrays = new String[] &#123;&quot;xueqi&quot;, &quot;biyao&quot;&#125;;Stream stream2 = Arrays.stream(strArrays);// 列表List&lt;String&gt; list = new ArrayList&lt;&gt;();list.add(&quot;少林&quot;);list.add(&quot;武当&quot;);Stream stream3 = list.stream();// 集合Set&lt;String&gt; set = new HashSet&lt;&gt;();set.add(&quot;武当长拳&quot;);set.add(&quot;青城剑法&quot;);Stream stream4 = set.stream();// MapMap&lt;String, Integer&gt; map = new HashMap&lt;&gt;();map.put(&quot;tom&quot;, 1000);map.put(&quot;jerry&quot;, 1200);Stream stream5 = map.entrySet().stream(); Stream对象对于基本数据类型的功能封装 注意，当前只支持 int / long / double 这三种数据类型 123IntStream.of(new int[] &#123;10, 20, 30&#125;).forEach(System.out::println);IntStream.range(1, 5).forEach(System.out::println); // 开区间IntStream.rangeClosed(1, 5).forEach(System.out::println); // 闭区间 Stream对象 –&gt; 转换得到指定的数据类型 注意：这里涉及到的都是终结操作，既每一个操作后stream流就被关闭了 123456789101112131415161718// 数组Object [] objx = stream.toArray(String[]::new);// 字符串String str = stream.collect(Collectors.joining()).toString();System.out.println(str);// 列表List&lt;String&gt; listx = (List&lt;String&gt;) stream.collect(Collectors.toList());System.out.println(listx);// 集合Set&lt;String&gt; setx = (Set&lt;String&gt;) stream.collect(Collectors.toSet());System.out.println(setx);// MapMap&lt;String, String&gt; mapx = (Map&lt;String, String&gt;) stream.collect(Collectors.toMap(x-&gt;x, y-&gt;&quot;value:&quot;+y));System.out.println(mapx); Stream常见API介绍 聚合操作 stream的处理流程 数据源 数据转换 获取结果 获取Stream对象 1234567891011121314* 1. 从集合或者数组中获取[**]* Collection.stream()，如accounts.stream()* Collection.parallelStream()* Arrays.stream(T t)* 2. BufferReader* BufferReader.lines()-&gt; stream()* 3. 静态工厂* java.util.stream.IntStream.range()..* java.nio.file.Files.walk()..* 4. 自定构建* java.util.Spliterator* 5. 更多的方式..* Random.ints()* Pattern.splitAsStream().. 中间操作API{intermediate} 操作结果是一个Stream，中间操作可以有一个或者多个连续的中间操作，需要注意的是，中间操作只记录操作方式，不做具体执行，直到结束操作发生时，才做数据的最终执行。 中间操作：就是业务逻辑处理。 中间操作过程：无状态：数据处理时，不受前置中间操作的影响，如下面所列操作： map/filter/peek/parallel/sequential/unordered 有状态：数据处理时，受到前置中间操作的影响，如下面所列操作： distinct/sorted/limit/skip 终结操作|结束操作{Terminal} 需要注意：一个Stream对象，只能有一个Terminal操作，这个操作一旦发生，就会真实处理数据，生成对应的处理结果。 终结操作：非短路操作：当前的Stream对象必须处理完集合中所有 数据，才能得到处理结果，如下面所列操作： forEach/forEachOrdered/toArray/reduce/collect/min/max/count/iterator 短路操作：当前的Stream对象在处理过程中，一旦满足某个条件，就可以得到结果。 anyMatch/allMatch/noneMatch/findFirst/findAny等 Short-circuiting，无限大的Stream-&gt; 有限大的Stream。 Stream常见的API操作 基本常用的操作支持 123456789101112131415161718192021// 定义一个集合数据List&lt;String&gt; accountList = new ArrayList&lt;&gt;();accountList.add(&quot;songjiang&quot;);accountList.add(&quot;lujunyi&quot;);accountList.add(&quot;wuyong&quot;);// 1.map() 中间操作，map()方法接收一个Functional接口accountList = accountList.stream().map(x-&gt;&quot;梁山好汉:&quot; + x).collect(Collectors.toList());// 2.filter() 添加过滤条件，过滤符合条件的用户accountList = accountList.stream().filter(x-&gt; x.length() &gt; 5).collect(Collectors.toList());// 3.forEach 增强型循环accountList.forEach(x-&gt; System.out.println(&quot;forEach-&gt;&quot; + x));// 4.peek() 中间操作，迭代数据完成数据的依次处理过程，这里只循环一次，但是能处理两件事情accountList.stream() .peek(x -&gt; System.out.println(&quot;peek 1: &quot; + x)) .peek(x -&gt; System.out.println(&quot;peek 2:&quot; + x)) .forEach(System.out::println); Stream中对于数字运算的支持 123456789101112131415161718192021222324252627282930// 定义一个数字集合List&lt;Integer&gt; intList = new ArrayList&lt;&gt;();intList.add(20);intList.add(19);intList.add(7);intList.add(12);intList.add(5);// 1.skip() 中间操作，有状态，跳过部分数据，示例跳过前三个数据intList.stream().skip(3).forEach(System.out::println);// 2.limit() 中间操作，有状态，限制输出数据量，示例跳过前三个数据，然后取跳过后的前两个数据intList.stream().skip(3).limit(2).forEach(System.out::println);// 3.distinct() 中间操作，有状态，剔除重复的数据intList.stream().distinct().forEach(System.out::println);// 4.sorted() 中间操作，有状态，排序// 5.max() 获取最大值Optional optional = intList.stream().max((x, y)-&gt; x-y);System.out.println(optional.get());// 6.min() 获取最小值Optional optional = intList.stream().min((x, y)-&gt; x-y);System.out.println(optional.get());// 7.reduce() 合并处理数据Optional optional2 = intList.stream().reduce((sum, x)-&gt; sum + x);System.out.println(optional2.get()); 补充 ParallelStreamParallelStream是一个并发多线程的Stream 使用示例： 12345678910111213141516171819202122Optional optional = list.parallelStream().max(Integer::compare);System.out.println(optional.get());// 整数列表，注意：下面示例是为了说明并行的Stream会出现线程安全问题List&lt;Integer&gt; lists = new ArrayList&lt;Integer&gt;();// 增加数据for (int i = 0; i &lt; 1000; i++)&#123; lists.add(i);&#125;// 串行StreamList&lt;Integer&gt; list2 = new ArrayList&lt;&gt;();lists.stream().forEach(x-&gt;list2.add(x));System.out.println(lists.size());System.out.println(list2.size());// 并行StreamList&lt;Integer&gt; list3 = new ArrayList&lt;&gt;();lists.parallelStream().forEach(x-&gt; list3.add(x));System.out.println(list3.size());//List&lt;Integer&gt; list4 = lists.parallelStream().collect(Collectors.toList());System.out.println(list4.size());","categories":[{"name":"Lamda","slug":"Lamda","permalink":"https://jjw-story.github.io/categories/Lamda/"}],"tags":[{"name":"Lamda","slug":"Lamda","permalink":"https://jjw-story.github.io/tags/Lamda/"}],"author":"JJW"},{"title":"内存与磁盘管理","slug":"内存与磁盘管理","date":"2019-11-10T06:22:53.000Z","updated":"2019-12-15T05:02:11.349Z","comments":true,"path":"2019/11/10/内存与磁盘管理/","link":"","permalink":"https://jjw-story.github.io/2019/11/10/内存与磁盘管理/","excerpt":"","text":"内存与磁盘管理内存查看命令free命令通过free命令可以查看当前内存的使用情况，使用方法： free [参数] 参数： -m 将数据按以MB为单位进行显示 -g 将数据按以GB为单位进行显示 注意我们一般不用 -g 参数，因为例如我们内存使用了1990M，但是-g会显示1g，将超出的都舍去了，所以会显示的不精准 下面是使用示例： 1234567891011121314151617181920# 1.直接查看[root@iZm5ehzqow4ijp2ya2g2drZ ~]# free total used free shared buffers cachedMem: 1019980 838124 181856 160 142184 337192-/+ buffers/cache: 358748 661232Swap: 0 0 0# 2.使用-m参数[root@iZm5ehzqow4ijp2ya2g2drZ ~]# free -m total used free shared buffers cachedMem: 996 818 177 0 138 329-/+ buffers/cache: 350 645Swap: 0 0 0# 3.使用-g参数[root@iZm5ehzqow4ijp2ya2g2drZ ~]# free -g total used free shared buffers cachedMem: 0 0 0 0 0 0-/+ buffers/cache: 0 0Swap: 0 0 0 以上查询结果我们需要注意的是，buffers/cache 项目查询的结果，有的时候我们查看内存发现我们 used 的内存已经非常大，free 的内存就剩一点点这个时候我们先不要着急去想办法加内存，我们首先查看 buffers/cache 下的内存有多少，如果这里显示的内存使用了很多，那么我们就不需要加内存，因为这里使用的内存是缓冲剂缓存使用的，这些都是可以被回收的内存，所以当内存真的撑不住的时候，会回收这一部分，当然，CentOS6没有查询出 available 的内容，如果可以看到这个的占用，这里是汇总的所有可释放的占用，我们可以直接查看这一块的占用，来判断需不需要加内存 还有要注意的就是Swap，它是交换分区的意思，它占用的并不是实际的内存，而是使用的磁盘空间，这里一般查看都是0，如果我们发现查询的时候这里的占用不是0，那么就真的该加内存了，这里就跟Windows中虚拟内存是一样的，指的是内存本身不够用了，我们需要将一些超出的使用转移到硬盘上，将硬盘的一些容量当做内存使用，但是磁盘的读写速度比内存慢十倍，所以一般我们看到交换分区被使用了，就该加内存了。这个交换分区大小一般默认为2G，可以手动指定。 如果我们不指定swap分区，既超出内存占用后不使用交换分区，那么系统会随机杀掉一些占用内存较大的进程，当然这样是不安全的，所以我们一般还是保留swap存在。还有一些Redies了，Memcache等内存数据库，它们不会使用swap分区，内存超出后就停止新增数据了 top命令top命令我们在进程管理中已经讲解完毕了，可以直接去进程管理章节查看 磁盘查看命令fdisk命令fdisk命令既可以查看磁盘的信息，又可以修改磁盘的分区，一般不要直接执行此命令进行分区，会有风险 使用方法： fdisk [参数] -l 查询磁盘信息，使用示例如下： 1234567891011[root@iZm5ehzqow4ijp2ya2g2drZ ~]# fdisk -lDisk /dev/vda: 42.9 GB, 42949672960 bytes255 heads, 63 sectors/track, 5221 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x0003a7b4 Device Boot Start End Blocks Id System/dev/vda1 * 1 5222 41940992 83 Linux Linux的磁盘都是用文件来表示的，磁盘文件所在的位置是:/dev目录下，vda表示是主机固有磁盘，我们有时候会见到很多 /dev/sda 的磁盘，这种表示的是可插拔的磁盘，类似于我们外接的移动硬盘等，磁盘一般表示都是 vda ~ vdb …这样按顺序往下排，同样挂载的硬盘也是，sda ~ sdb 等排列 上述命令查询出信息的第一行有磁盘总大小的表示方法，一种是以GB为单位，一种是换算为字节为单位，一般我们关注第一行的信息即可，还有就是最后的表格展示的项目，当我们有多快磁盘在机器中时，我们需要看到boot选项的 * 号在哪块磁盘上，* 号表示的就是我们系统启动的引导盘 我们可以直接进入 /dev 目录具体的查看硬盘的文件信息。如下示例： 12345[root@iZm5ehzqow4ijp2ya2g2drZ ~]# ls -l /dev/vd?brw-rw---- 1 root disk 252, 0 Sep 14 09:44 /dev/vda[root@iZm5ehzqow4ijp2ya2g2drZ ~]# ls -l /dev/vd??brw-rw---- 1 root disk 252, 1 Sep 14 09:44 /dev/vda1 如上查询，disk后跟的数字252表示磁盘的主设备号，第二个数字表示磁盘的从设备号，我们第二条命令查询出来的发现是 vda1，其中1表示这块磁盘的分区为1分区，如同我们Windows中一块磁盘可以划分为CDE几块不同的分区，Linux也有分区的概念，如果有多个分区，就是从 1 … n，这样的表示方法 df命令此命令也可以查询磁盘的具体大小，它可以作为fdsik命令的补充，因为fdisk命令只能查看到磁盘的大小，看不到磁盘具体挂载的目录以及目录的大小，这个时候我们就可以使用df命令来查看，一般我们会使用 -h 参数来具体查看，使用示例如下： 1234[root@iZm5ehzqow4ijp2ya2g2drZ ~]# df -hFilesystem Size Used Avail Use% Mounted on/dev/vda1 40G 2.5G 35G 7% /tmpfs 499M 0 499M 0% /dev/shm 如上我们就可以看到我们机器的分区挂载目录，以及此目录的大小，注意：此命令是我们最常用的 du命令上述命令都是直接查看磁盘大小的，我们还可以通过du命令查看具体文件夹的大小，但是注意，我们同样可以是用ls -l命令查看文件的大小，但是ls命令查询出的文件大小可能与du命令查出的文件大小是不一样的，这是因为，ls查询出的文件包含了文件占用的全部大小，而这全部大小可能包含了很多空洞文件，空洞文件表示的是可以理解为一块磁盘空间，我们只给空间头和尾加了标记，其他位置全部都是空的，这样的文件就叫做空洞文件，我们可以使用dd命令来创建空洞命令，这里不做详细解释 在查看文件的具体大小时我们可以使用此两种命令查看文件的具体大小，使用示例如下： 12345[root@iZm5ehzqow4ijp2ya2g2drZ balyu]# ls -lh SparrowNet-1.0-SNAPSHOT.jar -rw-r--r-- 1 root root 51M Oct 19 14:27 SparrowNet-1.0-SNAPSHOT.jar[root@iZm5ehzqow4ijp2ya2g2drZ balyu]# du -h SparrowNet-1.0-SNAPSHOT.jar 51M SparrowNet-1.0-SNAPSHOT.jar 以上两种命令所查出的文件大小是一样的，说明此文件中没有包含空洞文件 我们需要查看文件夹的大小时，我们就可以使用du命令，因为我们发现ls命令查看的文件夹大小并不包含文件夹中的内容，所以无法知道文件夹及其中内容的总大小，这时我们就可以使用 du -sh *命令，注意此命令是重点，要牢记，使用示例如下： 1234567891011121314151617181920# 首先使用 ls -lh 命令查看，这里只包含一级目录的大小，并没有包含子目录中文件的总大小[root@iZm5ehzqow4ijp2ya2g2drZ balyu]# ls -lhtotal 51Mdrwxrwxrwx 2 root root 4.0K Nov 15 01:02 datadrwxr-xr-x 2 root root 4.0K Nov 17 00:07 logsdrwxr-xr-x 2 root root 4.0K Oct 19 14:28 packagedrwxrwxrwx 5 root root 4.0K Sep 14 17:20 resources-rw-r--r-- 1 root root 51M Oct 19 14:27 SparrowNet-1.0-SNAPSHOT.jar# 使用 du 命令的 -sh 参数查询文件的总大小，包含了子目录中所有文件的大小[root@iZm5ehzqow4ijp2ya2g2drZ balyu]# du -sh84M .# 使用 du -sh * 命令分别查看一级目录中所有文件及子目录的总大小[root@iZm5ehzqow4ijp2ya2g2drZ balyu]# du -sh *60K data9.0M logs4.0K package24M resources51M SparrowNet-1.0-SNAPSHOT.jar 通过上述示例我们很容易能看出区别，所以此命令我们需要牢记 常见文件系统Linux支持多种文件系统，常见的有： ext4 xfs NTFS(需要安装额外转件) 目前比较流行的是前两种，CentOS7使用的xfs文件系统，之前的版本使用的都是ext4文件系统，这两个操作系统都是足够稳定的，NTFS文件系统Windows使用的文件系统，我们将这种格式的磁盘挂载到Linux系统上的时候，它会是只读状态，因为这种文件系统是有版权的，需要额外安装一个软件才能操作它 这里我们介绍最常用的ext4文件系统，它分为四个部分： 超级块 超级块副本 I节点(iNode) 数据块(datablock) 超级块是在文件系统最开始的部分的空间，它所存储的主要是磁盘的大小，磁盘中文件所占用的大小，包含了多少个文件，文件的总数，我们在使用df命令很快就能查看出文件的总数及大小，就是因为它查看的是超级块中的信息 超级块副本是超级块的备份，它不止有一份，当超级块出现故障的时候，可以在这里恢复 i节点记录的是每一个文件，它记录的是文件的大小，位置，创建时间，修改时间，文件的权限，编号等等信息，但是这里不包括文件的名称，注意：文件的名称是记录在自己文件的父目录的i节点中，当文件过多的时候，也会记录在父目录的数据块中 数据块就是记录的真实的文件数据，数据块是挂在i节点后的，我们只要能找到文件的i节点，就能找到文件的数据块，就可以通过挂的数据块的个数来知道文件的大小 所以我们使用ls查看文件的大小的时候，查看的是i节点里面文件的大小信息，而du统计的是i节点挂在的数据块的个数统计文件的大小信息，所以说du查看的是真实的文件大小 i节点和数据块操作我们首先观察cp和mv命令 12345678910111213141516171819202122232425# 首先我们创建一个文件并查看文件信息，发现它占用0k大小[root@iZm5ehzqow4ijp2ya2g2drZ test]# touch file1[root@iZm5ehzqow4ijp2ya2g2drZ test]# ls -litotal 01179654 -rw-r--r-- 1 root root 0 Dec 1 14:34 file1# 然后写入文件123字符，发现大小时4k[root@iZm5ehzqow4ijp2ya2g2drZ test]# echo &gt;file1 123[root@iZm5ehzqow4ijp2ya2g2drZ test]# ls -litotal 41179657 -rw-r--r-- 1 root root 4 Dec 1 14:34 file1# 然后copy这个文件，发现两个文件占用大小相同，复制的文件创建了一个新的i节点[root@iZm5ehzqow4ijp2ya2g2drZ test]# cp file1 file2[root@iZm5ehzqow4ijp2ya2g2drZ test]# ls -litotal 81179657 -rw-r--r-- 1 root root 4 Dec 1 14:34 file11179654 -rw-r--r-- 1 root root 4 Dec 1 14:35 file2# 然后我们移动file2到当前目录修改名称为file3，发现file2的节点没有发生变化，只是文件名称发生变化[root@iZm5ehzqow4ijp2ya2g2drZ test]# mv file2 file3[root@iZm5ehzqow4ijp2ya2g2drZ test]# ls -litotal 81179657 -rw-r--r-- 1 root root 4 Dec 1 14:34 file11179654 -rw-r--r-- 1 root root 4 Dec 1 14:35 file3 通过上述示例，我们发现，复制名称是创建了一个新的i节点及文件，而移动操作并不会创建新的i节点及数据块，只是修改了目中的文件的信息，比如上述文件名 注意：上述移动我们只是移动到当前目录下，所以只需要修改名称，这个过程是非常快的。如果我们将文件移动到此分区的其他目录，我们发现移动也非常快，通过原理我们知道，移动到其他目录，我们也并不需要创建新的i节点及数据块等，只需要将目录链接做修改即可。但是如果我们将文件移动到其他分区，这里因为发生了文件系统的变换，从一个文件系统移动到另一个文件系统，这里就需要在创建新的i节点和数据块，所以这个过程就比较慢了。 注意：一般我们创建文件，默认大小就是4K的大小，虽然上述示例我们只写入了三个数字，只占用102位，也就是12个字节，但是文件的大小还是4K，所以我们要创建很多小文件的时候，需要注意一下浪费空间，这个当然有办法解决，可以自行google 上述我们给文件写入数据使用的是echo命令，注意的是，如果我们使用vim来修改文件内容的话，文件的i节点及数据块都会发生变化，这里在CentOS6、7版本都是这样。如果i节点发生变化，那么此文件就已经不是原来的文件，这里主要是vim对于文件一致性的考虑，所以会有这样的操作机制，vim打开的文件实际是一个交换文件，具体可以自行google rm命令，其实也不是将文件直接删除，而是将i节点与数据块的链接给断开了，所以我们在删除文件的时候操作也是非常快，不管多大的文件 利用ext4和xfs文件系统的特性修改文件的权限我们之前知道原始的文件的权限就三种，rwx，原始修改文件权限的方式是一改全改，但是当我们有特殊的业务场景，比如我们需要一个文件，user1有读权限，user2有写权限，user3有执行权限，这个时候我们原始的设置权限的方式就不能满足我们的需求了，这个时候我们就可以利用ext4和xfs文件系统的特性来满足此需求，这两个文件系统支持了一个文件访问控制列表，叫facl的功能 getfacl命令我们可以使用getfacl命令来查看文件的控制访问列表，使用方法: getfacl 文件名，示例如下： 12345678910111213# 普通查看方式[root@iZm5ehzqow4ijp2ya2g2drZ test]# ll file1-rw-r--r-- 1 root root 4 Dec 1 14:34 file1[root@iZm5ehzqow4ijp2ya2g2drZ test]# lsfile1[root@iZm5ehzqow4ijp2ya2g2drZ test]# getfacl file1# file: file1# owner: root# group: rootuser::rw-group::r--other::r-- 这里我们使用faclget命令查看的文件控制访问列表跟我们使用ll查询出的信息一致，这是基本的一些控制信息，那我们怎么赋予指定用户或用户组的一些权限呢？使用setfacl命令 setfacl命令我们可以使用setfacl为指定的用户或用户组赋予权限，使用方法:setfacl -m u:用户名称:权限符号 文件名，具体使用示例如下： 123456# 设置[root@iZm5ehzqow4ijp2ya2g2drZ test]# setfacl -m u:user01:r file1# 查看文件权限[root@iZm5ehzqow4ijp2ya2g2drZ test]# ls -l file1-rw-r--r--+ 1 root root 4 Dec 1 14:34 file1 我们通过setfacl命令设置完权限之后，我们使用普通ll命令查看此文件权限的时候，发现权限列表中 -rw-r–r–+ 多了一个+号，这个+号表示除了我们标准权限之后，此文件还被设置了文件访问控制权限facl的权限，我们必须使用getfacl命令来查看，如下： 123456789[root@iZm5ehzqow4ijp2ya2g2drZ test]# getfacl file1# file: file1# owner: root# group: rootuser::rw-user:user01:r--group::r--mask::r--other::r-- 我们发现此文件user01用户有了读的权限，我们还可以给user02设置读和写的权限，设置示例如下： 12345678910111213141516[root@iZm5ehzqow4ijp2ya2g2drZ test]# setfacl -m u:user02:rw file1[root@iZm5ehzqow4ijp2ya2g2drZ test]# lltotal 4-rw-rw-r--+ 1 root root 4 Dec 1 14:34 file1[root@iZm5ehzqow4ijp2ya2g2drZ test]# getfacl file1# file: file1# owner: root# group: rootuser::rw-user:user01:r--user:user02:rw-group::r--mask::rw-other::r-- 如上我们就设置成功了，user02有了读写权限 我们还可以为指定的组赋予权限，使用的还是setfacl命令，使用方法：setfacl -m g:组名称:权限 文件名，使用示例如下： 1234567891011121314151617[root@iZm5ehzqow4ijp2ya2g2drZ test]# setfacl -m g:group01:x file1[root@iZm5ehzqow4ijp2ya2g2drZ test]# lltotal 4-rw-rwxr--+ 1 root root 4 Dec 1 14:34 file1[root@iZm5ehzqow4ijp2ya2g2drZ test]# getfacl file1# file: file1# owner: root# group: rootuser::rw-user:user01:r--user:user02:rw-group::r--group:group01:--xmask::rwxother::r-- 如上我们就为新建组group01分配了执行权限 收回权限我们只需要将setfacl命令参数中的 -m 修改为 -x，使用方法：setfacl -x u:用户名称 文件名，使用示例： 12345678910111213# 收回root@iZm5ehzqow4ijp2ya2g2drZ test]# setfacl -x u:user02 file1[root@iZm5ehzqow4ijp2ya2g2drZ test]# getfacl file1# file: file1# owner: root# group: rootuser::rw-user:user01:r--group::r--group:group01:--xmask::r-xother::r-- 注意：收回只能按照用户级别或者用户组级别，而不能收回单个权限编码，例如只收回某个用户的读权限，上述命令收回组权限使用用法与收回用户一样，直降u改为g即可，使用用法：setfacl -x g:用户组名称 文件名 这样我们就可以非常细粒度及灵活的设置文件的具体权限 磁盘分区和挂载这里我们不详细描述磁盘的分区和挂载，因为用的不会太多，即使使用可以网上自行百度一下，这里只列举一下步骤 首先第一种情况是需要分区的磁盘容量小于2T： 首先使用：fdisk 分区设备 命令，然后输入 m 查看帮助命令，这里我们输入 n 选择分区类型，一般我们都是将一个磁盘划分为一个主分区，所以这里再选择输入 p，这是会提示我们输入分区号及分区大小，选择完成后，我们就可以选择输入命令，选择是保存还是不保存删除刚才输入的分区信息，保存使用 w ，保存后，我们就可以使用 fdisk -l 查看我们刚才创建的分区了 注意:上述命令中分区设备示例： /dev/sdd 分好区后，路径是 /dev/sdd1 接下来使用：mkfs. 命令来格式化分区的文件系统类型，使用方法：mkfs.文件系统类型 分区位置，这里我们一般选择ext4文件系统，这样我们就给分区格式化好了磁盘格式 接下来:使用mkdir命令，创建一个目录 接下来：使用mount命令将刚刚分好区的磁盘挂载到此目录上，使用方法：mount 分区路径 目录 这样我们就可以使用mount来查看磁盘的挂载情况，发现我们新添加分好区的磁盘就挂载到了指定的目录上，这样我们操作此目录中的内容，最后就落在了我们挂载的磁盘上 第二种情况磁盘容量大有2T： 这时我们就不能使用fdisk命令来为磁盘分区了，我们需要使用parted命令来操作，同样我们可以对标fdisk来操作，使用help来查看具体使用，当然具体流程是一样的，只不过分区的命令不一样，其他流程及命令都一样 以上我们的操作都是保存在内存中的，如果我们的机器重启，配置就会丢失，如果我们需要固化下来，就需要修改一个配置文件，在此配置文件中进行指定挂载的配置，配置文件的位置：/etc/fstab, 配置说明： 磁盘分区 挂载目录 文件系统格式 default 0 0 示例： 1/dev/sdc1 /mnt/sdc1 ext4 default 0 0 将以上配置信息写入文件，就可以完成永久的挂载配置 创建交换分区swap是在硬盘中开辟的一块区域，之前我们介绍过，它的作用是临时的扩充内存的区域 新添加磁盘挂载为交换分区注意这种方式我们很少用，因为很少用新添加的磁盘作为内存使用。上面我们讲述了如何新添加磁盘然后分区、挂载，现在我们讲述如何新添加磁盘然后分区挂载为交换分区 查看交换分区大小使用free -m命令 首先我们对新添加的硬盘进行分区，命令与上述一样，首先使用：fdisk 分区设备 命令，然后我们输入 n 选择分区类型，然后输入 p 表示将一个磁盘划分为一个主分区，这是会提示我们输入分区号及分区大小，分区编号一般选择 1 ，从1开始，分区大小可以不选择，直接默认使用全部，选择完成后，我们 w 保存配置，这样我们就可以查看我们的分区了 如同使用正常的文件系统一样，我们将磁盘分区为交换分区，也需要对它进行格式化，格式化命令：mkswap 分区位置， 格式化命令使用示例： mkswap /dev/sdd1 格式化完成就需要对此分区进行挂载了，如果是文件系统使用的是mount命令，挂载为内存分区使用的是：swapon 分区位置，挂载命令使用示例：swapon /dev/sdd1 这样我们就对内存分区扩展完成，可以使用 free -m 命令查看了 如果我们想将此新挂载的swap分区关闭掉，使用命令：swapoff 分区位置，使用示例：swapoff /dev/sdd1，这是使用 free -m 命令再次查看，发现就已经被关闭掉了 使用文件挂载为交换分区上述我们是新添加了一块磁盘作为交换分区，但是一般很不常用，一般我们是在已有磁盘开辟一块空间，作为交换分区，挂载方式如下： 首先创建一个文件，文件创建未空洞文件形式，使用命令示例：dd if=/dev/zero bs=4M count=1024 of=/swapfile, 这里我们创建了一个每块为4M。一共1024块的大小的文件 下面我们需要格式化此文件，但是首先我们需要将此文件的权限处理好，负责可能会报关于权限的错误，所以这里首先：chmod 600 /swapfile 然后格式化此文件，使用命令：mkswap /swapfile 打开挂载此文件，使用命令：swapon /swapfile 这样我们就可以使用 free -m 命令来查看了 上述创建挂载方式跟我们普通磁盘文件系统挂载步骤差不多，所以一样都是保存在内存中的，如果我们的机器重启，配置就会丢失，如果我们需要固化下来，就需要修改一个配置文件，在此配置文件中进行指定挂载的配置，配置文件的位置：/etc/fstab 配置说明： 磁盘分区 挂载目录 文件系统格式 default 0 0 写入示例： 1234## 上述磁盘挂载配置/dev/sdc1 swap swap default 0 0## 上述文件挂载配置/swapfile swap swap default 0 0 将以上配置信息写入文件，就可以完成永久的挂载配置","categories":[{"name":"Linux","slug":"Linux","permalink":"https://jjw-story.github.io/categories/Linux/"}],"tags":[{"name":"command","slug":"command","permalink":"https://jjw-story.github.io/tags/command/"},{"name":"内存与磁盘管理","slug":"内存与磁盘管理","permalink":"https://jjw-story.github.io/tags/内存与磁盘管理/"}],"author":"JJW"},{"title":"Elasticsearch核心技术","slug":"Elasticsearch核心技术","date":"2019-10-20T08:17:09.000Z","updated":"2020-02-18T03:24:27.710Z","comments":true,"path":"2019/10/20/Elasticsearch核心技术/","link":"","permalink":"https://jjw-story.github.io/2019/10/20/Elasticsearch核心技术/","excerpt":"","text":"ElasticsearchElasticsearch简介Elasticsearch是分布式，高性能，高可用，可伸缩的全文检索和分析系统 什么是搜索，百度、谷歌等是我们接触到的最直接的搜索，还有垂直搜索（站内搜索），比如理想APP、OA了等等的搜索 如果用数据库做搜索有什么缺点？ （1、每次都搜索查找都需要对数据库中所有的记录进行扫描查找。2、不能将搜索词拆分，比如我搜索理想汽车但是却匹配搜索不出理想One。总的来说，效率会非常差） 什么是全文检索和lucene？（1、倒排索引的概念：传统数据库的检索，如果有几十万条数据，那么我们数据库检索就要扫描几十万次，而使用倒排索引，它可以把这几十万条数据拆分成单个的词或词语，可能会拆出来几百万条，但是我们在检索的时候，只要第一次匹配到检索的词语，就可以知道此词语在哪些文档中，并且在这些文档的什么位置，我们不必担心几十万的数据拆词后拆成几百万个词在极端情况下会需要检索到最后的几百万次才能检索到此词语，因为ES底层的算法及数据结构对此做了非常大的优化，所以我们并不需要担心。这里可以专门讲解一下倒排索引的数据结构。 2、lucene的概念：就是一些个jar包，里面包含了封装好的各种建立倒排索引，以及进行搜索的代码，包括各种算法。我们就用java开发的时候，引入lucene jar，然后基于lucene的api进行去进行开发就可以了。用lucene，我们就可以去将已有的数据建立索引，lucene会在本地磁盘上面，给我们组织索引的数据结构。另外的话，我们也可以用lucene提供的一些功能和api来针对磁盘上的索引数据进行搜索。 总之来讲：lucene非常优秀，以前玩过一个solr，也是建立在lucene上，ES同样也是，他们都是对lucene的封装） 什么是Elasticsearch？（我们说ES是基于lucene的封装，那他解决了什么问题呢？ 1、磁盘容量问题：基于磁盘容量的限制，比如我们有10TB的数据，如果我们使用10个1TB的计算机分别存储，数据散落在不同的机器上，那么每次查询我们都需要跟多台机器进行通信分别查询然后组织所有数据这个过程会非常麻烦。 这里我们就可以使用ES的集群来解决此问题，我们建立多个ES的节点，ES会自动维护数据并将数据均匀的分布在多个节点上，并且将搜索请求分布到各个节点上，然后把数据整体封装起来返回给调用方。 2、机器宕机的问题：我们的10个1TB的机器中有一个或多个挂掉，那么数据就会有丢失。这里ES会自动维护数据的冗余副本，可以保证如果一些机器宕机了，不会丢失任何的数据。 3、基于lucene的封装，提供了更多的高级功能，以便给我们提供更多的高级支持，使我们快速开发更复杂的应用，比如更复杂的查询，聚合查询分析等，地理位置的搜索等） 这就是Elasticsearch，以上已经将ES的分布式，高性能（ES的很多性能优化），高可用，可伸缩（可伸缩说的是集群扩容成本很低）的特性讲解了 Elastcsearch入门Elasticsearch功能 分布式的搜索引擎和数据分析引擎（1、搜索：百度，网站的站内搜索，IT系统的检索。 2、数据分析：电商网站，最近7天牙膏这种商品销量排名前10的商家有哪些；新闻网站，最近1个月访问量排名前3的新闻版块是哪些） 全文检索，结构化检索，数据分析等等（1、全文检索：类似模糊匹配。 2、结构化检索：精确匹配。 3、数据分析：统计分类总数，直方图了等等。还包括搜索纠错、数据分词等） 对海量数据进行近实时的处理（ES自动可以将海量数据分散到多台服务器上去存储和检索，分布式以后，就可以采用大量的服务器去存储和检索数据，自然而然就可以实现海量数据的处理了，在秒级别对数据进行搜索和分析） lucene，单机应用，只能在单台服务器上使用，最多只能处理单台服务器可以处理的数据量 Elasticsearch使用场景 维基百科，全文检索，高亮，搜索推荐 理想APP话题及帖子，对用户行为日志（点击、浏览、收藏、评论）数据分析，分析话题的热度，文章的反馈反响等 GitHub（开源代码管理），搜索上千亿行代码 淘宝京东商品检索 IT系统搜索（OA，CRM，ERP，等等），数据分析（ES热门的一个使用场景） Elasticsearch特点 可以作为一个大型分布式集群（数百台服务器）技术，处理PB级数据，服务大公司；也可以运行在单机上，服务小公司 Elasticsearch不是什么新技术，主要是将全文检索、数据分析以及分布式技术，合并在了一起，才形成了独一无二的ES；lucene（全文检索），商用的数据分析软件（也是有的），分布式数据库（mycat） 对用户而言，是开箱即用的，非常简单，作为中小型的应用，直接3分钟部署一下ES，就可以作为生产环境的系统来使用了，数据量不大，操作不是太复杂 数据库的功能面对很多领域是不够用的；特殊的功能，比如全文检索，同义词处理，相关度排名，复杂数据分析，海量数据的近实时处理；Elasticsearch作为传统数据库的一个补充，提供了数据库所不不能提供的很多功能 Elasticsearch核心概念通过上面的讲解我们知道lucene和elasticsearch之间的关系。 lucene：最先进、功能最强大的搜索库，直接基于lucene开发，非常复杂，api复杂（实现一些简单的功能，写大量的java代码），需要深入理解原理（各种索引结构） elasticsearch：基于lucene，隐藏复杂性，提供简单易用的restful api接口、java api接口（还有其他语言的api接口），lucene是单机的，ES有如下特点： 分布式的文档存储引擎 分布式的搜索引擎和分析引擎 分布式，支持PB级数据 开箱即用，优秀的默认参数，不需要任何额外设置，完全开源 关于elasticsearch的一个传说，有一个程序员失业了，陪着自己老婆去英国伦敦学习厨师课程。程序员在失业期间想给老婆写一个菜谱搜索引擎，觉得lucene实在太复杂了，就开发了一个封装了lucene的开源项目，compass。后来程序员找到了工作，是做分布式的高性能项目的，觉得compass不够，就写了elasticsearch，让lucene变成分布式的系统。 核心概念Near Realtime（NRT）：近实时，两个意思，1、从写入数据到数据可以被搜索到有一个小延迟（大概1秒）。 2、基于es执行搜索和分析可以达到秒级。一般说纯实时说的基本是毫秒级，秒或几十秒算是近实时。这里也遇到问题，比如我们搜索热词删除之后刷新快的话，数据还在。 Cluster：集群，包含多个节点，每个节点属于哪个集群是通过一个配置（集群名称，默认是elasticsearch）来决定的，对于中小型应用来说，刚开始一个集群就一个节点很正常 Node：节点，集群中的一个节点，节点也有一个名称（默认是随机分配的），节点名称很重要（在执行运维管理操作的时候），默认节点会去加入一个名称为“elasticsearch”的集群，如果直接启动一堆节点，那么它们会自动组成一个elasticsearch集群，当然一个节点也可以组成一个elasticsearch集群，一个局域网中的集群是通过集群的名称来分割的，节点也是通过集群名称匹配来加入集群的 Document&amp;field：文档，es中的最小数据单元，一个document可以是一条客户数据，一条商品分类数据，一条订单数据，通常用JSON数据结构表示，每个index下的type中，都可以去存储多个document。一个document里面有多个field，每个field就是一个数据字段。 Index：索引，包含一堆有相似结构的文档数据，比如可以有一个客户索引，商品分类索引，订单索引，索引有一个名称。一个index包含很多document，一个index就代表了一类类似的或者相同的document。比如说建立一个product index，商品索引，里面可能就存放了所有的商品数据，所有的商品document。 Type：类型，每个索引里都可以有一个或多个type，type是index中的一个逻辑数据分类，一个type下的document，都有相同的field，比如博客系统，有一个索引，可以定义用户数据type，博客数据type，评论数据type。（这里可以讲一下type已经不推荐使用了，它跟数据库表的区别，多个type类型的文档但是如果在同一个索引下，type的mapping既字段类型必须是一样的，现在还存在只是为了兼容） 注：以上三个类型可以现场打开kibana进行讲解分析一下 shard：单台机器无法存储大量数据，es可以将一个索引中的数据切分为多个shard，分布在多台服务器上存储。有了shard就可以横向扩展，存储更多数据，让搜索和分析等操作分布到多台服务器上去执行，提升吞吐量和性能。每个shard都是一个lucene index。 replica：任何一个服务器随时可能故障或宕机，此时shard可能就会丢失，因此可以为每个shard创建多个replica副本。replica可以在shard故障时提供备用服务，保证数据不丢失，多个replica还可以提升搜索操作的吞吐量和性能。primary shard（建立索引时一次设置，不能修改，默认5个），replica shard（随时修改数量，默认1个），默认每个索引10个shard，5个primary shard，5个replica shard，最小的高可用配置，是2台服务器。 注： 上述主分片和副本分片详细说明如下： 在ES中，index会被拆分成多个shard，每个shard会存放这个index一部分数据，这些shard会散落在多台服务器上面，shard其实叫primary shard，一般直接说shard，多个分片的好处主要有两个：1、横向扩展：比如说我们的数据量增大，现有的服务器已经无法承载，那我们就加机器，横向扩展，重新建立索引然后将数据重新索引导入就行。 2、数据分布在多个shard，多台服务器上，所有的操作，都会在多台服务器上并行分布式执行，提升吞吐量和性能 副本分片replice其实叫replice shard，它也是分片，并且跟主分片一样，一般简称为replice。上面讲过如果不使用ES，传统lucene多个机器，其中一个机器挂掉，那么搜索就会丢数据，ES能解决这个问题，就是通过副本分片来解决的，如果我们的集群中有一台机器宕机了，这个时候不会丢数据，因为还有一个replice，在另外一个节点上面，用户搜索的时候，还是可以搜索到的，请求直接被发送到replice上，这样数据就不会丢失。 总结分片好处： 1、高可用，一个shard宕机，数据不会丢，服务继续提供。 2、提升了搜索这类请求的吞吐量和性能 分片机制梳理： index包含多个shard 每个shard都是一个最小工作单元，承载部分数据，lucene实例，完整的建立索引和处理请求的能力 增减节点时，shard会自动在nodes中负载均衡 primary shard和replica shard，每个document肯定只存在于某一个primary shard以及其对应的replica shard中，不可能存在于多个primary shard replica shard是primary shard的副本，负责容错，以及承担读请求负载 primary shard的数量在创建索引的时候就固定了，replica shard的数量可以随时修改 primary shard的默认数量是5，replica默认是1，默认有10个shard，5个primary shard，5个replica shard primary shard不能和自己的replica shard放在同一个节点上（否则节点宕机，primary shard和副本都丢失，起不到容错的作用），但是可以和其他primary shard的replica shard放在同一个节点上 如果集群中某个节点宕掉了，那么此节点的主分片立刻失效，转移到其他存活的节点上的副本分片上，将其他节点的副本分片作为主节点。宕掉的节点重新启动后，其他节点会将数据同步到新起来的节点上，并且不是直接覆盖，而是只是将宕机的期间发生的新的数据变化的内容同步过来 注意（个人理解）：要保证服务器的高容错性，我们可以增加副本分片的数量，保证更多的机器有跟多的副本分片，容错性更高，当然，容错高是需要占用更多的磁盘空间。另外提升检索效率，可以适当增加主分片的个数，但是不要一味的高，各个集群机器之间的通信也非常耗费时间。 ES的特性透明隐藏性：ES将复杂的分布式机制，比如分片、副本、负载均衡等等全部隐藏了起来 扩容的透明性：两种方式，1、垂直扩容：直接扩展服务器的磁盘容量，但是这种方案的弊端就是，世界上最大的服务器磁盘容量也就只有10T。2、水平扩容：采购更多的服务，扩展到集群中。一般采取水平扩容的方式。 负载均衡：某个节点的分片或者数据量，及处理的请求量，明显比其他节点多，那么ES就会有负载均衡的特点，将压力分布到其他节点上 master节点：并不是必须存在，关键看集群的部署是那种方式，比如我们现在的项目，它就没有master节点，如果有的话，它的作用是：1、创建或删除索引。2、增加或删除节点 节点平等的分布式架构：1.节点对等，每个节点都能接收所有的请求。2、自动请求路由。3.响应收集。主要就是每一个节点接收到查询等的请求，都可以将每个节点上收集的数据汇总起来，由接收到的节点响应给用户 Elasticsearch基本使用集群状态既所有索引查看等API，待定是否讲解索引操作（PUT创建索引，DELETE删除操作）索引文档操作（增删改查，注意修改的时候，可以使用PUT直接替换，和使用POST修改），注意替换方式，必须带上所有的数据进行替换，修改可以只修改其中某一个字段，讲的时候可以演示一下PUT和POST的使用，注意，POST的使用最后要跟上”_update”在url上，DELETE演示直接使用ID删除就可以增加文档的时候，我们可以指定ID，也可以不指定ID，如果我们的数据是从SQL数据库中拉取过来，那么我们就使用数据中已有的ID，指定ID进行保存数据。如果我们的数据只是在ES库中存在，那么我们可以不指定ID，使用ES自带的主键生成策略，它使用一种GUID得算法生成主键，保证在分布式的系统中，同时插入数据生成的主键不会重复，不指定主键的插入数据需要使用POST，然后不指定主键即可，PUT式的插入数据需要指定主键 注意：ES全量替换是先将原来的数据删除，然后新添加进去，注意这里说的删除和我们主动的删除数据都是伪删除，只是给文档标记为了deleted的状态，并没有直接删除，它会在后面这种状态的数据多的时候或者其他情况下执行物理删除 注意：ES的并发控制是通过乐观锁CAS这种方式来控制的，它里面有_version这个字段，不过现在的版本已经改了，不是这个字段了。这个字段我们在对文档进行操作，不管是修改还是删除，都会给这个字段自动+1，即使我们是PUT形式覆盖数据，或者先删除数据，然后添加数据，ID一样，它的版本号都是存在并且直接++的，而不是重新从1开始（注意：主从同步时，只有版本号高的时候才同步数据，否则不同步） 注意：一般我们在修改数据的时候，还是尽量使用PUT式的全量替换，而不是使用POST式的部分替换，虽然POST修改只修改我们需要修改的字段，能够节省网络开销，但是其实我们内部的修改实现是和PUT是一样的，都是先删除在插入，而且POST式的修改，ES先把要修改的所有文档的内容找出来，然后将我们POST过来的数据中的部分字段内容替换，然后将原文档删除，插入此新的文档。所以我们发现虽然能节省网络开销，但是多了重新构建数据这一步，对于数据量很大的情况来说，还是会有损失效率，所以尽量使用PUT来修改。注意：如果我们是用的POST这种方式修改数据，我们内部也是有并发控制的，同样使用CAS，如果我们在拼装好新的数据后，发现_version已经不一样了，那么它内部会重新拉去doucment数据，然后重新拼装，然后再次CAS，一共可以重试五次，如果五次都失败了，则会抛弃此数据。 DSL语言演示讲解（Domain Specified Language）（注意一些高阶查询，聚合查询，可以查看视频中第八讲的笔记，这里讲了一点）Elasticsearch的分布式架构","categories":[{"name":"Linux","slug":"Linux","permalink":"https://jjw-story.github.io/categories/Linux/"}],"tags":[{"name":"Elasticsearch核心技术","slug":"Elasticsearch核心技术","permalink":"https://jjw-story.github.io/tags/Elasticsearch核心技术/"},{"name":"基础入门","slug":"基础入门","permalink":"https://jjw-story.github.io/tags/基础入门/"}],"author":"JJW"},{"title":"进程管理","slug":"进程管理","date":"2019-10-06T08:30:13.000Z","updated":"2019-11-02T09:51:14.163Z","comments":true,"path":"2019/10/06/进程管理/","link":"","permalink":"https://jjw-story.github.io/2019/10/06/进程管理/","excerpt":"","text":"进程管理进程可以理解为程序正在运行的过程，管理的内容主要包括程序什么时候启动，程序运行的整个生命周期需要多少资源，包括需要多少内存资源，运行是需要多少CPU资源，运行结束是需要自己结束还是被其他程序结束的，还有程序运行时我们需要让他结束应该怎么让它结束等等 进程的概念及进程查看进程是运行中的程序，从程序开始运行到终止的整个生命周期是可管理的 C程序的启动时从main函数开始的，包括Java等，终止的方式并不唯一，分为正常终止和异常终止： 正常终止也分为从main返回，调用exit等方式 异常终止分为调用abort、接收信号等。当程序获取不到资源比如内存、CPU资源等，会调用abort函数来终止程序 ps命令使用方法：ps [选项] 单独使用ps命令，它只能查看到当前终端既当前shell下面能够查看到的进程状态，并不是真的只有这些进程在运行，如下只查看到两条: 1234[root@iZm5ehzqow4ijp2ya2g2drZ etc]# ps PID TTY TIME CMD27267 pts/0 00:00:00 bash27342 pts/0 00:00:00 ps PID：表示进程在系统中运行的唯一表示，注意进程的名称是可以重复的，但是PID不能重复 TTY：表示执行当前进程的终端，那么当前执行是一个虚拟终端，所以叫 pts/0 TIME：程序的运行时间，此项不具有参考价值，可以不用关注 CMD：命令 ps选项说明 -e 查看所有的进程，这样我们查出来的会非常多，我们可以通过 more 命令来进行分页查看，具体使用为：ps -e | more，这里主要是通过管道符，将管道符左边的输出传递给more，示例如下： 123456789root@iZm5ehzqow4ijp2ya2g2drZ etc]# ps -e | more PID TTY TIME CMD 1 ? 00:00:00 init 2 ? 00:00:00 kthreadd 3 ? 00:00:00 migration/0 4 ? 00:00:01 ksoftirqd/0 5 ? 00:00:00 stopper/0 6 ? 00:00:02 watchdog/0 7 ? 00:01:35 events/0 注意我们看到的1号进程，此进程在CentOS6中叫init，在CentOS7中叫systemd -f 表示显示全格式，既对进程的信息显示更加完善，一般是结合-e选项来使用，ps -ef | more 123456UID PID PPID C STIME TTY TIME CMDroot 1 0 0 Sep14 ? 00:00:00 /sbin/initroot 2 0 0 Sep14 ? 00:00:00 [kthreadd]root 3 2 0 Sep14 ? 00:00:00 [migration/0]root 4 2 0 Sep14 ? 00:00:01 [ksoftirqd/0]root 5 2 0 Sep14 ? 00:00:00 [stopper/0] UID表示此进程是哪一个用户来启动的，但是注意，进程启动的用户是可以修改的，所以它的专业名称叫有效用户ID PPID是父进程，因为我们的程序在启动时都要集成它的父进程的一些信息下来，Linux的第一个进程是1号进程，既init进程 -L 查看更详细的进程情况，既可以查看到当前进程中包含了多少个线程，通过此选项我们可以查看到当前进程运行缓慢是不是因为并发太大及线程太多导致的，一般使用也是结合着-ef，具体：ps -eLf | more 123456UID PID PPID LWP C NLWP STIME TTY TIME CMDroot 1 0 1 0 1 Sep14 ? 00:00:00 /sbin/initroot 2 0 2 0 1 Sep14 ? 00:00:00 [kthreadd]root 3 2 3 0 1 Sep14 ? 00:00:00 [migration/0]root 4 2 4 0 1 Sep14 ? 00:00:01 [ksoftirqd/0]root 5 2 5 0 1 Sep14 ? 00:00:00 [stopper/0] LWP表示的既是线程数量 pstree命令pstree命令是将进程用树形表示出来，上述ps命令中，我们能查看到进程的父进程，在使用此命令时，我们可以看到一个树形结构的进程图，方便我们查看进程的依属关系，示例如下： 123456789root@iZm5ehzqow4ijp2ya2g2drZ etc]# pstree | moreinit-+-AliYunDun---17*[&#123;AliYunDun&#125;] |-AliYunDunUpdate---3*[&#123;AliYunDunUpdat&#125;] |-agetty |-aliyun-service---2*[&#123;aliyun-service&#125;] |-auditd---&#123;auditd&#125; |-crond |-dhclient |-java---28*[&#123;java&#125;] top命令top命令能显示系统的信息及进程信息，类似于Windows的任务管理器，也是一个日常非常实用的命令，可以不带参数，使用具体如下： 12345678910111213[root@iZm5ehzqow4ijp2ya2g2drZ etc]# toptop - 17:38:41 up 22 days, 7:54, 2 users, load average: 0.00, 0.00, 0.00Tasks: 78 total, 1 running, 77 sleeping, 0 stopped, 0 zombieCpu(s): 0.3%us, 0.3%sy, 0.0%ni, 99.3%id, 0.0%wa, 0.0%hi, 0.0%si, 0.0%stMem: 1019980k total, 732792k used, 287188k free, 138988k buffersSwap: 0k total, 0k used, 0k free, 230192k cached PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 1407 root 10 -10 121m 11m 9176 S 0.3 1.2 94:59.64 AliYunDun 27417 root 20 0 15012 1292 1004 R 0.3 0.1 0:00.01 top 1 root 20 0 19228 1508 1232 S 0.0 0.1 0:00.72 init 2 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kthreadd 3 root RT 0 0 0 0 S 0.0 0.0 0:00.00 migration/0 说明： top up 22 days： 当前系统上一次开机到现在运行的时长 users：当前系统有两个用户已经登录了 load average: 0.00, 0.00, 0.00： 平均负载，全都是0.00表示空负载，数值越大负载越高，都是1表示满负载运行，平均负载是一分钟进行一次汇总的结果，第一个数字是1分钟的数据，中间数据时5分钟的数据，最后一个是15分钟的统计数据，此数据是查看系统繁忙程度的指标数据 Tasks: 78 tota：系统中有多少个任务正在运行，这里系统将进程表示为任务 1 running, 77 sleeping, 0 stopped, 0 zombie：一个进程在运行中，77个在休眠状态中。。 Cpu(s): 0.3%us： 0.3%的资源用于用户状态的计算 0.3%sy： 进程的状态交互占用的资源 99.3%id：空闲的CPU资源 0.0%wa：磁盘IO占用的资源 Cpu(s)是说统计的是一个整体情况，如果我们是多核的，可以按下数字键1来分别查看每一个CPU的运行状况，再次按下数字1即可恢复成整体模式 123456789101112top - 17:54:45 up 1 min, 0 users, load average: 0.52, 0.58, 0.59Tasks: 4 total, 1 running, 3 sleeping, 0 stopped, 0 zombie%Cpu0 : 5.4 us, 8.0 sy, 0.0 ni, 84.0 id, 0.0 wa, 2.6 hi, 0.0 si, 0.0 st%Cpu1 : 2.0 us, 3.0 sy, 0.0 ni, 95.1 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu2 : 5.6 us, 10.8 sy, 0.0 ni, 83.6 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu3 : 3.0 us, 3.0 sy, 0.0 ni, 94.1 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu4 : 4.6 us, 3.0 sy, 0.0 ni, 92.4 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu5 : 2.3 us, 0.3 sy, 0.0 ni, 97.4 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu6 : 1.6 us, 2.0 sy, 0.0 ni, 96.4 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu7 : 1.6 us, 14.8 sy, 0.0 ni, 83.6 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 stKiB Mem : 16670136 total, 9322736 free, 7118048 used, 229352 buff/cacheKiB Swap: 15518328 total, 15430616 free, 87712 used. 9418356 avail Mem Mem： 1019980k total：总共有多少内存 732792k used：已经使用了的内存 287188k free：空闲的内存 138988k buffers：读写缓存使用的内存 Swap：交换分区，当内存不够用的时候，需要使用交换分区的内存 0k used：这里只需要关注此选项即可，因为在内存占用比较大的时候才会与系统进行交换分区内存，这里有占用说明程序占用内存很大了 进程信息： 这里的进程信息我们可以看到还显示了每个进程当前的CPU占用率，以及内存占用情况，默认是3秒已刷新，我们还可以修改刷新时间，使用按键s，即可输入你需要的刷新间隔时间，然后回车，注意单位是秒，这样既可以按照你输入的时间间隔来刷新 进程信息中PR表示进程的系统优先级，NI表示Nice值，可以理解为此进程占用了多少系统资源，%CPU表示进程占用的CPU资源百分比 参数说明 -p 使用-p参数然后指定进程id可以只查看指定id的进程信息，使用示例： 123456789[root@iZm5ehzqow4ijp2ya2g2drZ ~]# top -p 35top - 16:33:23 up 29 days, 6:49, 2 users, load average: 0.00, 0.00, 0.00Tasks: 1 total, 0 running, 1 sleeping, 0 stopped, 0 zombieCpu(s): 0.0%us, 0.0%sy, 0.0%ni,100.0%id, 0.0%wa, 0.0%hi, 0.0%si, 0.0%stMem: 1019980k total, 758240k used, 261740k free, 139084k buffersSwap: 0k total, 0k used, 0k free, 239196k cached PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 35 root 25 5 0 0 0 S 0.0 0.0 0:00.00 ksmd 进程的优先级调整进程的优先级我们可以通过查看进程的信息来具体查看，进程信息的NI选项就表示进程的优先级，NI的值在 -20 ~ 19 之间，值越小，优先级越高，抢占资源就越多，一般我们启动的程序默认的优先级是0 使用nice命令修改启动进程的优先级我们首先启动一个程序，查看它的进程信息如下： 1234567891011121314# 第一个终端启动此自定义进程[root@iZm5ehzqow4ijp2ya2g2drZ home]# ./test.sh2946# 重新打开一个终端，查看此进程的信息[root@iZm5ehzqow4ijp2ya2g2drZ ~]# top -p 2946top - 17:14:15 up 29 days, 7:29, 3 users, load average: 0.89, 0.85, 0.55Tasks: 1 total, 1 running, 0 sleeping, 0 stopped, 0 zombieCpu(s):100.0%us, 0.0%sy, 0.0%ni, 0.0%id, 0.0%wa, 0.0%hi, 0.0%si, 0.0%stMem: 1019980k total, 760396k used, 259584k free, 139088k buffersSwap: 0k total, 0k used, 0k free, 239332k cachedPID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 2946 root 20 0 103m 1332 1152 R 99.9 0.1 0:53.76 test.sh 我们看到此进程的NI值为0，CPU的占用率达到了100%，因为我们这个程序一直在循环执行中，然后我们停止此程序，然后使用nice命令指定优先级 nice命令使用方法：nice -n [优先级值] ./应用程序 使用示例： 1234567891011121314# 使用第一个终端启动自定义的应用程序并指定进程优先级为15[root@iZm5ehzqow4ijp2ya2g2drZ home]# nice -n 15 ./test.sh2953# 使用第二个终端查看此进程信息[root@iZm5ehzqow4ijp2ya2g2drZ ~]# top -p 2953top - 17:12:54 up 29 days, 7:28, 3 users, load average: 0.92, 0.84, 0.52Tasks: 1 total, 1 running, 0 sleeping, 0 stopped, 0 zombieCpu(s): 0.0%us, 0.0%sy,100.0%ni, 0.0%id, 0.0%wa, 0.0%hi, 0.0%si, 0.0%stMem: 1019980k total, 760396k used, 259584k free, 139088k buffersSwap: 0k total, 0k used, 0k free, 239332k cached PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 2953 root 35 15 103m 1332 1152 R 99.6 0.1 1:42.75 test.sh 通过更改程序的优先级来启动程序，我们发现更改后的此进程NI值就变成了我们设置的值，并且很明显的区别就是CPU占用率，我们将优先级值调大之后，CPU占用率在0.0% - 0.3%摆动，表示资源占用急剧下降，所以我们指定程序的优先级是很有效果的一个操作 使用renice命令修改进程的优先级nice命令有一个问题，我们一般程序在运行中不会终止，上述更改优先级需要将程序停止然后重新指定优先级后启动，这个问题怎么解决呢？ 使用renice命令就可以解决，可以在程序运行中直接修改，无需重启 使用方法：renice -n [优先级值] ./应用程序 使用示例： 1234567891011121314151617181920212223# 第一个终端启动此自定义进程[root@iZm5ehzqow4ijp2ya2g2drZ home]# ./test.sh2966# 使用第二个终端查看此进程的信息[root@iZm5ehzqow4ijp2ya2g2drZ ~]# top -p 2966...Cpu(s):100.0%us, 0.0%sy, 0.0%ni, 0.0%id, 0.0%wa, 0.0%hi, 0.0%si, 0.0%st PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 2966 root 20 0 103m 1332 1152 R 99.7 0.1 0:47.87 test.sh # 使用第三个终端使用renice修改此进程的优先级值为18[root@iZm5ehzqow4ijp2ya2g2drZ ~]# renice -n 18 29662966: old priority 0, new priority 18# 切换回第二个终端查看此进程信息，我们发现进程的优先级已经被修改，且程序并没有停止[root@iZm5ehzqow4ijp2ya2g2drZ ~]# top -p 2966...Cpu(s): 0.0%us, 0.0%sy,100.0%ni, 0.0%id, 0.0%wa, 0.0%hi, 0.0%si, 0.0%st PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 2966 root 38 18 103m 1332 1152 R 99.6 0.1 5:07.68 test.sh 进程的启动前台后台切换程序后台启动我们上述启动程序发现程序一直在终端显示，无法输入其他命令，此终端不能进行其他操作，这种启动的方式叫做前台启动，后台启动就是程序是后台运行的，不影响我们在终端进行操作 后台启动程序的方式是在启动程序命令后 加 &amp; ，使用示例： 123456789[root@iZm5ehzqow4ijp2ya2g2drZ home]# ./test.sh &amp;[3] 3019[root@iZm5ehzqow4ijp2ya2g2drZ home]# 3019lstest.sh[root@iZm5ehzqow4ijp2ya2g2drZ home]# top -p 3019... PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 3019 root 20 0 103m 1332 1152 R 49.9 0.1 0:14.74 test.sh 通过示例我们发现，启动程序后终端返回了程序的进程ID，然后我们就可以在此终端上进行任意其他操作 后台运行程序切换回前台运行有时候我们需要将后台运行的程序切换回前台运行，可以使用 jobs命令查询出所有的后台程序，然后根据后台运行编号使用fg命令切换回来，使用如下： 1234[root@iZm5ehzqow4ijp2ya2g2drZ home]# jobs[3]+ Running ./test.sh &amp;[root@iZm5ehzqow4ijp2ya2g2drZ home]# fg 3./test.sh 我们发现程序就恢复前台运行了，此时可以通过 CTRL + C 来终止此程序 前台运行程序切换到后台运行使用 CTRL + Z 可以将前台运行程序切换为后台运行，但是使用此命令切换到后台运行，程序就不是运行的状态了，而是一个暂停运行的状态，它保存在了内存中 使用示例： 12345# 首先前台启动进程，然后使用 CTRL + Z 将程序转为后台运行，并且提示你程序为Stopped状态，既停止运行的状态[root@iZm5ehzqow4ijp2ya2g2drZ home]# ./test.sh3043^Z[4]+ Stopped ./test.sh 上述示例我们发现程序进入后台运行但是是停止状态，我们需要让程序继续运行怎么办？使用jobs命令，然后使用 fg 将程序切换为前台运行或者使用 bg 将程序切换为后台运行 切换为前台运行我们上面已经有过示例了，现在我们示例切换为后台运行，完整示例如下： 12345678910111213# 前台运行程序然后切换为后台暂停运行[root@iZm5ehzqow4ijp2ya2g2drZ home]# ./test.sh3050^Z[5]+ Stopped ./test.sh# 将程序切换为后台运行[root@iZm5ehzqow4ijp2ya2g2drZ home]# jobs[5]+ Stopped ./test.sh[root@iZm5ehzqow4ijp2ya2g2drZ home]# bg 5[5]+ ./test.sh &amp;[root@iZm5ehzqow4ijp2ya2g2drZ home]# jobs[5] Running ./test.sh 上述后，我们发现程序就为后台运行了 进程的通信方式与信号进程之间的通信就是两个进程之间可以有一些消息进行交互，还有就是两个进程之间可以互相进行控制。进程通信有很多种的方式，比如管道，信号，这里我们主要学习信号 信号：终端用户通过快捷键或者命令来输入信号，通过信号的机制可以让程序停止运行，经常使用的有 CTRL + C、kill等 kill命令我们可以使用kill命令的 -l 参数来查看我们系统支持的所有信号，示例如下： 1234567891011121314[root@iZm5ehzqow4ijp2ya2g2drZ ~]# kill -l 1) SIGHUP 2) SIGINT 3) SIGQUIT 4) SIGILL 5) SIGTRAP 6) SIGABRT 7) SIGBUS 8) SIGFPE 9) SIGKILL 10) SIGUSR111) SIGSEGV 12) SIGUSR2 13) SIGPIPE 14) SIGALRM 15) SIGTERM16) SIGSTKFLT 17) SIGCHLD 18) SIGCONT 19) SIGSTOP 20) SIGTSTP21) SIGTTIN 22) SIGTTOU 23) SIGURG 24) SIGXCPU 25) SIGXFSZ26) SIGVTALRM 27) SIGPROF 28) SIGWINCH 29) SIGIO 30) SIGPWR31) SIGSYS 34) SIGRTMIN 35) SIGRTMIN+1 36) SIGRTMIN+2 37) SIGRTMIN+338) SIGRTMIN+4 39) SIGRTMIN+5 40) SIGRTMIN+6 41) SIGRTMIN+7 42) SIGRTMIN+843) SIGRTMIN+9 44) SIGRTMIN+10 45) SIGRTMIN+11 46) SIGRTMIN+12 47) SIGRTMIN+1348) SIGRTMIN+14 49) SIGRTMIN+15 50) SIGRTMAX-14 51) SIGRTMAX-13 52) SIGRTMAX-1253) SIGRTMAX-11 54) SIGRTMAX-10 55) SIGRTMAX-9 56) SIGRTMAX-8 57) SIGRTMAX-758) SIGRTMAX-6 59) SIGRTMAX-5 60) SIGRTMAX-4 61) SIGRTMAX-3 62) SIGRTMAX-263) SIGRTMAX-1 64) SIGRTMAX 以上就是我们系统中所有的信号，平时我们使用的CTRL + C对应的就是2号信号，SIGINT kill命令具体使用方法：kill [-信号编号] 进程ID 比如我们平时使用的更多的是 kill -9 9号命令，它是用于强制停止进程，直接杀掉，一般我们在生产中直接使用 kill 命令来结束程序，可以达到优雅下线的效果 守护进程很多时候我们希望我们有些进程在系统启动的时候就启动，或者有些我们在终端启动的进程在关闭终端之后还继续运行，Linux提供了实现这种需求的方法，就是使用守护进程，英文叫 daemon，就是精灵的意思，守护进程实现的就是我们不需要使用终端就可以把进程启动起来，另外启动的时候它的输出也会打印出来，并且这个程序使用的目录是根目录，避免占用其他一些移动硬盘的目录，导致此移动硬盘无法卸载的情况 nohup启动进程在讲守护进程之前我们先讲另外一个进程，叫nohup启动进程，以此来对比守护进程 nohup启动进程会使进程忽略掉 hangup 挂起信号，使用此进程我们可以实现守护进程的效果，比如关掉终端之后进程还可以继续运行，但它还是有一些不同，首先这里示例一下使用nohup进程的效果 123456789101112131415# 首先我们使用第一个终端然后运行 tail 进程[root@iZm5ehzqow4ijp2ya2g2drZ ~]# tail -1000f /balyu/logs/platformrun.log 2019-10-19 01:02:12.606 [http-nio-80-exec-16] INFO com.sparrow.portal.IndexController - access index...2019-10-19 01:18:06.548 [http-nio-80-exec-18] INFO com.sparrow.manage.monitor.AccessMonitor - 123.126.113.160...# 然后打开第二个终端查看此进程 这里是可以查看到的[root@iZm5ehzqow4ijp2ya2g2drZ ~]# ps -ef | grep tailroot 12218 12129 0 13:46 pts/2 00:00:00 tail -1000f /balyu/logs/platformrun.logroot 12237 12221 0 13:47 pts/3 00:00:00 grep tail# 然后第三步是直接关闭终端，不退出tail直接关闭终端窗口# 然后第四步我们继续到另一个终端查看此进程 -&gt; 发现tail进程也不存在了[root@iZm5ehzqow4ijp2ya2g2drZ ~]# ps -ef | grep tailroot 12241 12221 0 13:49 pts/3 00:00:00 grep tail 下面示例使用nohup来是进程在终端关闭后继续运行 12345678910111213# 第一步使用nohup启动tail进程，启动后提示将此进程的输出比如tail的查看内容输出放在了 nohup.out 文件下[root@iZm5ehzqow4ijp2ya2g2drZ ~]# nohup tail - 100f /balyu/logs/platformrun.log nohup: ignoring input and appending output to `nohup.out&apos;# 第二步启动另外一个终端查看此进程，这里我们查看到此进程的父进程是 pts/3[root@iZm5ehzqow4ijp2ya2g2drZ ~]# ps -ef | grep tailroot 12251 12221 0 13:54 pts/3 00:00:00 tail -100f /balyu/logs/platformrun.logroot 12270 12254 0 13:55 pts/2 00:00:00 grep tail# 第三步关闭此终端，然后使用另一个终端查看tail进程，我们发现进程还在存活，但是父进程变成了?，这是因为我们的进程在终端关闭之后此进程就成了孤儿进程，孤儿进程一定要被其它进程所收留，那么这里它就被 1 号进程所收留，这里显示了一个 ?，但其实是 1 号进程，init进程[root@iZm5ehzqow4ijp2ya2g2drZ ~]# ps -ef | grep tailroot 12251 1 0 13:54 ? 00:00:00 tail -100f /balyu/logs/platformrun.logroot 12272 12254 0 13:56 pts/2 00:00:00 grep tail 以上就是nohup的使用示例，这里我们发现虽然可以将进程一直运行，但是启动程序的时候还是要通过终端启动，还有一个特点就是我们的进程输出会放在我们执行命令的当前文件夹下的nohup.out文件，它会占用我们当前磁盘的空间，name我们可不可以像windows一样，设置开机自启动呢？并且有一个合理的日志文件或者输出内容的文件所在的位置呢？请看下面的内容 screen命令Screen是一款由GNU计划开发的用于命令行终端切换的自由软件。用户可以通过该软件同时连接多个本地或远程的命令行会话，并在其间自由切换。GNU Screen可以看作是窗口管理器的命令行界面版本。它提供了统一的管理多个会话的界面和相应的功能 在Screen环境下，所有的会话都独立的运行，并拥有各自的编号、输入、输出和窗口缓存。用户可以通过快捷键在不同的窗口下切换，并可以自由的重定向各个窗口的输入和输出 总的来说个人理解就是使用screen启动的程序我们在退出screen之后，程序还会继续运行，退出终端也会如此，所以直接将启动的程序作为了守护进程 使用方法： 使用 screen 命令直接进入screen环境 操作完成后或者启动程序完成后，使用 CTRL + A D，退出（detached）screen环境 我们可以使用 screen -ls 查看所有screen的会话 可以使用 screen -r sessionid 恢复会话，注意这里的sessionid是上述使用-ls查询出来的信息 注意：我们可以在screen模式下结束我们的进程，退出此环境使用 exit 退出此环境 以下是使用示例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859# 1.首先使用screen命令进入此环境[root@iZm5ehzqow4ijp2ya2g2drZ ~]# screen-bash: screen: command not found# 2.这里提示找不到这个命令，是因为我们没有安装，需要使用yum命令进行安装[root@iZm5ehzqow4ijp2ya2g2drZ ~]# yum install screenLoaded plugins: fastestmirrorSetting up Install Process...Installed: screen.x86_64 0:4.0.3-19.el6Complete!# 3.安装成功后再次使用此命令进入Screen环境，我们发现直接就进入了此环境，并没有任何提示和不一样的地方[root@iZm5ehzqow4ijp2ya2g2drZ ~]# screen[root@iZm5ehzqow4ijp2ya2g2drZ ~]# # 4.再此环境下执行命令，还是之前使用的tail命令来让它后台运行[root@iZm5ehzqow4ijp2ya2g2drZ ~]# tail -1000f /balyu/logs/platformrun.log 2019-10-26 00:15:58.351 [http-nio-80-exec-9] INFO com.sparrow.portal.IndexController - access index...2019-10-26 00:51:58.660 [http-nio-80-exec-7] ERROR org.apache.catalina.core.ContainerBase.[Tomcat].[localhost] - Exception Processing ErrorPage[errorCode=0, location=/error]org.apache.catalina.connector.ClientAbortException: java.io.IOException: Connection reset by peer# 5.使用另外一个客户端，查看此启动的进程，我们发现实可以查询到的[root@iZm5ehzqow4ijp2ya2g2drZ ~]# ps -ef | grep tailroot 20513 20484 0 12:02 pts/1 00:00:00 tail -1000f /balyu/logs/platformrun.logroot 20532 20516 0 12:04 pts/3 00:00:00 grep tail# 6.我们使用CTRL + A D退出screen环境，退出后发现终端并没有什么变化[root@iZm5ehzqow4ijp2ya2g2drZ ~]# screen[detached][root@iZm5ehzqow4ijp2ya2g2drZ ~]# # 7.我们再次用第二个客户端查看在screen环境中启动的tail进程发现是可以查询到的，即使将第一个终端直接关闭掉，也是可以查询到此进程[root@iZm5ehzqow4ijp2ya2g2drZ ~]# ps -ef | grep tailroot 20513 20484 0 12:02 pts/1 00:00:00 tail -1000f /balyu/logs/platformrun.logroot 20538 20516 0 12:09 pts/3 00:00:00 grep tail# 8.使用第二个终端查询当前系统上运行的screen环境， screen -ls 命令，查询发现启动的有一个，并且sessionid是20483 [root@iZm5ehzqow4ijp2ya2g2drZ ~]# screen -lsThere is a screen on: 20483.pts-0.iZm5ehzqow4ijp2ya2g2drZ (Detached)1 Socket in /var/run/screen/S-root.# 9.使用 screen -r sessionid恢复此screen环境，发现是恢复了的[root@iZm5ehzqow4ijp2ya2g2drZ ~]# screen -r 20483 at org.apache.catalina.core.ApplicationDispatcher.invoke(ApplicationDispatcher.java:726) at org.apache.catalina.core.ApplicationDispatcher.processRequest(ApplicationDispatcher.java:471) ... # 10.使用CTRL + C 退出此环境下前台运行的程序（tail 程序），然后使用exit退出screen环境... 这里不做演示# 11.再次使用screen -ls 查询运行的screen环境，发现已经查询不到了，因为我们已经退出了[root@iZm5ehzqow4ijp2ya2g2drZ ~]# screen -lsNo Sockets found in /var/run/screen/S-root. 系统日志这里只是一个补充说明，我们可以进入 /var/log 文件夹，这里有大量的日志文件，这些文件叫做系统日志，我们系统运行的状态都记录在这些文件中，重点关注以下文件就行： messages文件，系统的常规日志，也可以理解为当前系统运行实时产生的日志 dmesg文件，内核日志信息，内核日志一般在我们启动系统的时候启动内核所打印出来的日志，一般我们在系统启动时可能查看的不够详细，这样我们就可以直接查看此文件来详细查看内核启动运行的一些日志信息 secure文件，这个文件是我们系统的安全日志，此文件可以查看系统有没有产生一些安全的问题 cron文件，这个日志是我们系统执行计划任务，定时任务等产生的日志，查看这种任务的日志可以在此文件中查看 服务管理工具这里服务指的是提供常见功能的守护进程，是系统本身所提供的服务。服务管理工具说的是我们之前在网络管理和配置文件章节讲述过，有两种，CentOS7以前的版本是用的是service工具，之后默认使用的是systemctl工具，但是我们可以切换回service工具来管理 我们之前讲述过service的基本启动脚本在 /etc/init.d 文件夹中，这里有我们service管理工具所管理的所有服务，每个服务都有一个文件，此文件中便是服务的启动关闭重启等等的操作的命令脚本，这些脚本也可以我们自己来编写，就比如之前我们操作过的网卡服务，network文件中便有一堆关于操作网卡的脚本，每个操作我们可以理解为一个函数，函数中又具体的后台的逻辑。我们可以看到，service管理的服务脚本都很复杂。而systemctl管理工具基本的脚本在 /usr/lib/systemd/system 文件夹下，里面也是各种文件，文件所管理的就是服务，比如我们打开sshd.service文件，这个里面就是封装的sshd服务的一些操作脚本，我们明显可以看到这里的脚本比service管理的服务脚本要简单很多，这是因为脚本中具体的逻辑都已经有systemctl来管理了，不需要我们手动自己来写这些复杂的脚本，所有相对看着比较简单，我们在Linux系统的迭代中，会逐渐的将所有的service管理的服务都交给systenctl来管理。 之前我们说过service管理的服务都有级别，分为6个级别，这6个级别分别代表程序在哪个级别是启动的，在哪个级别的关闭的，我们可以通过service提供的chkconfig命令来查看及修改服务在各种级别运行的状态，而systemctl管理工具不是用过数字来代表启动级别了，而是直接通过英语单词来代表 systemctl管理工具怎么操作服务，我们列举一下常见的操作： start、stop、restart、reload、enable、disable、status 使用的方法就是：systemctl 操作命令 服务名称，例如：systemctl start sshd.service 具体有哪些服务呢？我们可以直接查看 /usr/lib/systemd/system 文件夹，里面的内容中有很多扩展名为 .service 和 .target 的文件，.service的文件就是我们管理的服务，我们就可以通过systemctl命令来操作这些服务，这些.target的文件，表示的就是服务表示的就是不同的级别，runleavel0.target 到 runleavel6.target 就表示我们之前描述的 0 - 6 的系统级别，我们可以通过命令 ls -l runleavel*.target 来查看这些文件的具体映射，这些查看出来的文件就映射到了具体的英文单词表示的级别 我们还可以通过 systemctl get-default 来查看我们当前系统的默认级别，字符级别还是图形界面级别。还可以通过 systemctl set-default 级别英文单词表示 来修改我们设置的默认级别，这样在下次启动系统的时候就切换了默认的级别，例如： systemctl set-default multy-user.target 就将默认的启动级别就切换成多用户的启动级别了，也就是字符界面级别 以上具体可以查看 网络管理和配置文件 章节","categories":[{"name":"Linux","slug":"Linux","permalink":"https://jjw-story.github.io/categories/Linux/"}],"tags":[{"name":"command","slug":"command","permalink":"https://jjw-story.github.io/tags/command/"},{"name":"进程管理","slug":"进程管理","permalink":"https://jjw-story.github.io/tags/进程管理/"}],"author":"JJW"},{"title":"网络故障排除命令","slug":"网络故障排除命令","date":"2019-09-03T12:02:04.000Z","updated":"2019-09-03T11:45:01.715Z","comments":true,"path":"2019/09/03/网络故障排除命令/","link":"","permalink":"https://jjw-story.github.io/2019/09/03/网络故障排除命令/","excerpt":"","text":"网络故障排查命令ping命令Linux系统的ping命令是常用的网络命令，它通常用来测试与目标主机的连通性 使用方法：ping [参数] 主机IP或域名 参数详解： -q 不显示任何传送封包的信息，只显示最后的结果 -n 只输出数值 -R 记录路由过程 -c count 总次数 -i 时间间隔 -t 存活数值：设置存活数值TTL的大小 使用示例： 123456789wangjia3@CHJ-20190520VPS:~$ ping -c 3 192.168.1.1PING 192.168.1.1 (192.168.1.1) 56(84) bytes of data.64 bytes from 192.168.1.1: icmp_seq=1 ttl=64 time=3.18 ms64 bytes from 192.168.1.1: icmp_seq=2 ttl=64 time=3.14 ms64 bytes from 192.168.1.1: icmp_seq=3 ttl=64 time=10.0 ms--- 192.168.1.1 ping statistics ---3 packets transmitted, 3 received, 0% packet loss, time 2002msrtt min/avg/max/mdev = 3.147/5.445/10.007/3.226 ms traceroute命令命令用于显示数据包到主机间的路径，traceroute指令让你追踪网络数据包的路由途径，预设数据包大小是40Bytes，用户可另行设置 使用方法：traceroute [参数] 主机IP或域名 参数详解： -m &lt;存活数值&gt; 设置检测数据包的最大存活数值TTL的大小 -n 直接使用IP地址而非主机名称 -v 详细显示指令的执行过程 -w &lt;超时秒数&gt; 设置等待远端主机回报的时间 12345678910traceroute to www.baidu.com (180.101.49.12), 30 hops max, 60 byte packets 1 * * * 2 11.219.5.13 (11.219.5.13) 6.841 ms 11.219.5.85 (11.219.5.85) 7.559 ms 11.219.4.85 (11.219.4.85) 6.439 ms 3 * * * 4 11.219.68.42 (11.219.68.42) 0.427 ms 0.436 ms 11.219.68.26 (11.219.68.26) 0.679 ms 5 103.41.143.69 (103.41.143.69) 1.187 ms 103.52.86.106 (103.52.86.106) 1.045 ms 103.52.86.138 (103.52.86.138) 0.956 ms 6 116.251.113.33 (116.251.113.33) 1.145 ms 116.251.113.37 (116.251.113.37) 1.447 ms 116.251.113.53 (116.251.113.53) 0.856 ms 7 150.138.130.121 (150.138.130.121) 1.377 ms 150.138.132.129 (150.138.132.129) 0.939 ms 150.138.130.133 (150.138.130.133) 1.184 ms 8 150.138.128.65 (150.138.128.65) 12.132 ms 150.138.128.173 (150.138.128.173) 17.526 ms 17.970 ms 9 202.97.46.49 (202.97.46.49) 22.672 ms 显示的访问此主机中间经过的路由，中间路由对应的IP地址及它的延时是多长时间等等，注意如果不支持traceroute方式追踪，会以 * * * 的方式展示出来 mtr命令在Linux中有一个更好的网络连通性判断工具，它可以结合ping nslookup tracert 来判断网络的相关特性,这个命令就是mtr 此命令要比上述traceroute命令展示的信息更加详细，所以使用的更多 使用方法：mtr [参数] [主机IP或域名] 参数详解： -r 已报告模式显示 使用示例： 123456789101112131415161718[root@iZm5ehzqow4ijp2ya2g2drZ ~]# mtr -r www.baidu.comHOST: iZm5ehzqow4ijp2ya2g2drZ Loss% Snt Last Avg Best Wrst StDev 1. ??? 100.0 10 0.0 0.0 0.0 0.0 0.0 2. 11.219.4.13 0.0% 10 2.3 4.5 1.6 12.9 3.7 3. ??? 100.0 10 0.0 0.0 0.0 0.0 0.0 4. 11.219.68.58 0.0% 10 0.4 1.8 0.4 12.5 3.8 5. 116.251.117.198 0.0% 10 0.7 0.8 0.7 1.1 0.2 6. 140.205.26.217 0.0% 10 1.2 1.5 1.2 3.0 0.5 7. 150.138.132.149 0.0% 10 1.6 1.5 1.4 1.6 0.1 8. 150.138.128.157 0.0% 10 18.6 20.8 18.6 27.0 3.5 9. 202.97.46.61 20.0% 10 24.5 23.1 22.9 24.5 0.6 10. 58.213.94.6 0.0% 10 18.2 18.4 18.0 20.4 0.7 11. 58.213.94.122 90.0% 10 24.1 24.1 24.1 24.1 0.0 12. 58.213.96.90 0.0% 10 21.4 21.6 21.2 23.7 0.7 13. ??? 100.0 10 0.0 0.0 0.0 0.0 0.0 14. ??? 100.0 10 0.0 0.0 0.0 0.0 0.0 15. ??? 100.0 10 0.0 0.0 0.0 0.0 0.0 16. 180.101.49.12 0.0% 10 18.0 18.0 17.9 18.0 0.0 注意此命令可以不带任何参数及IP单独使用，My traceroute 报告解释： 第一列:显示的是IP地址和本机域名，这点和tracert很像 第二列:snt:10 设置每秒发送数据包的数量，默认值是10 可以通过参数 -c来指定 第三列:是显示的每个对应IP的丢包率 第四列:显示的最近一次的返回时延 第五列:是平均值 这个应该是发送ping包的平均时延 第六列:是最好或者说时延最短的 第七列:是最差或者说时延最常的 第八列:是标准偏差 nslookup命令查看哪台DNS服务器进行的域名解析，并解析出域名对应的IP地址 使用方法：nslookup 域名 使用示例： 12345678910wangjia3@CHJ-20190520VPS:~$ nslookup www.baidu.comServer: 192.168.1.1Address: 192.168.1.1#53Non-authoritative answer:www.baidu.com canonical name = www.a.shifen.com.Name: www.a.shifen.comAddress: 61.135.169.121Name: www.a.shifen.comAddress: 61.135.169.125 以上查询第一行显示的是DNS服务器的地址，这里百度是有对应的别名的：www.baidu.com canonical name = www.a.shifen.com. 别名下有对应的两个地址 telnet命令telnet命令通常用来远程登录，它为用户提供了在本地计算机上完成远程主机工作的 能力。在终端使用者的电脑上使用telnet程序，用它连接到服务器。终端使用者可以在telnet程序中输入命令，这些命令会在服务器上运行，就像直接在服务器的控制台上输入一样。可以在本地就能控制服务器。要开始一个 telnet会话，必须输入用户名和密码来登录服务器。Telnet是常用的远程控制Web服务器的方法。 但是，telnet因为采用明文传送报文，安全性不好，很多Linux服务器都不开放telnet服务，而改用更安全的ssh方式了。但仍然有很多别的系统可能采用了telnet方式来提供远程登录，因此弄清楚telnet客户端的使用方式仍是很有必要的。 telnet命令还可做别的用途，比如确定远程服务的状态，比如确定远程服务器的某个端口是否能访问，这里我们说明的主要使用就是确认端口是否能够访问 畅通 使用方法：telnet [参数] 主机 端口 使用示例： 1234567891011121314# 端口可达wangjia3@CHJ-20190520VPS:~$ telnet www.baidu.com 80Trying 61.135.169.121...Connected to www.a.shifen.com.Escape character is &apos;^]&apos;.^]telnet&gt; quit# 端口不可达wangjia3@CHJ-20190520VPS:~$ telnet www.baidu.com 8900Trying 61.135.169.121...Trying 61.135.169.125...telnet: Unable to connect to remote host: Resource temporarily unavailable 注意我们需要通过 CTRl + 右侧方括号 来退出此查看，然后使用 CTRL + C 或者 quit命令，退出 telnet tcpdump命令很多时候我们的系统部署在Linux系统上面，在一些情况下定位问题就需要查看各个系统之间发送数据报文是否正常，下面我就简单讲解一下如何使用tcpdump抓包。tcpdump是Linux下面的一个开源的抓包工具，和Windows下面的wireshark抓包工具一样， 支持抓取指定网口、指定目的地址、指定源地址、指定端口、指定协议的数据。 用简单的话来定义tcpdump，就是：dump the traffic on a network，根据使用者的定义对网络上的数据包进行截获的包分析工具。 tcpdump可以将网络中传送的数据包的“头”完全截获下来提供分析。它支 持针对网络层、协议、主机、网络或端口的过滤，并提供and、or、not等逻辑语句来帮助你去掉无用的信息 使用说明： 监视所有网卡接口的数据包： tcpdump -i any 监视指定网络接口的数据包： tcpdump -i eth1 如果不指定网卡，默认tcpdump只会监视第一个网络接口，一般是eth0，下面的例子都没有指定网络接口 捕获所有网卡发往80端口的数据包，并且如果包含域名，将域名解析成IP，主要使用 -n 参数 tcpdump -i any -n port 80 监视指定主机收到的和发出的所有的数据包： tcpdump -i any -n host 210.27.48.1 监视指定主机和端口的数据包： tcpdump -i any -n port 23 and host 210.27.48.1 netstat命令Linux netstat命令用于显示网络状态，利用netstat指令可让你得知整个Linux系统的网络情况，查看服务的监听地址 使用方法：netstat [参数] 常用参数说明： -n 直接使用IP地址，而不通过域名服务器 -t 显示TCP传输协议的连线状况 -u 显示UDP传输协议的连线状况 -p 显示正在使用Socket的程序识别码和程序名称 -l 显示监控中的服务器的Socket -v 显示指令执行过程 使用示例： 12345[root@iZm5ehzqow4ijp2ya2g2drZ ~]# netstat -ntplActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program nametcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1260/sshdtcp 0 0 127.0.0.1:25 0.0.0.0:* LISTEN 1427/master ss命令ss是Socket Statistics的缩写。顾名思义，ss命令可以用来获取socket统计信息，它可以显示和netstat类似的内容。ss的优势在于它能够显示更多更详细的有关TCP和连接状态的信息，而且比netstat更快速更高效 当服务器的socket连接数量变得非常大时，无论是使用netstat命令还是直接cat /proc/net/tcp，执行速度都会很慢 ss快的秘诀在于，它利用到了TCP协议栈中tcp_diag。tcp_diag是一个用于分析统计的模块，可以获得Linux 内核中第一手的信息，这就确保了ss的快捷高效 使用方法：ss [参数] 常用参数说明： -n 直接使用IP地址，而不通过域名服务器 -t 显示TCP传输协议的连线状况 -u 显示UDP传输协议的连线状况 -p 显示正在使用Socket的程序识别码和程序名称 -l 显示监控中的服务器的Socket -m 显示套接字的内存使用信息 -p 显示使用套接字的进程 使用示例： 1234[root@iZm5ehzqow4ijp2ya2g2drZ ~]# ss -ntplState Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 128 *:22 *:* users:((&quot;sshd&quot;,1260,3))LISTEN 0 100 127.0.0.1:25 *:* users:((&quot;master&quot;,1427,12))","categories":[],"tags":[{"name":"command","slug":"command","permalink":"https://jjw-story.github.io/tags/command/"},{"name":"网络管理","slug":"网络管理","permalink":"https://jjw-story.github.io/tags/网络管理/"}]},{"title":"网络管理和配置文件","slug":"网络管理和配置文件","date":"2019-08-30T05:18:53.000Z","updated":"2019-11-02T09:50:48.312Z","comments":true,"path":"2019/08/30/网络管理和配置文件/","link":"","permalink":"https://jjw-story.github.io/2019/08/30/网络管理和配置文件/","excerpt":"","text":"网络服务管理概述当我们需要将网络的配置固化下来，既重启服务也能保持我们的配置状态，就需要修改Linux的配置文件，将配置文件中的配置修改后，就能将我们的配置固化下来 管理配置文件我们一般是使用一些管理程序，网络服务管理程序分为两种，分别是SysV和systemd，systemd是 CentOS 7.0 版本新添加的管理程序 配置文件一般是如下两类： 网卡配置文件：ifcfg-etho 注意：etho是根据网卡名称的不同不一样的，它会随着你的真实网卡名称变化， 主机名相关配置文件，控制网络常用参数：/etc/hosts 注意在CentOS7版本中，有两套服务管理的脚本，一套是 network (任何版本都支持)，一套是 NetworkManager，在工作当中我们一般只使用其中一套，不推荐两套都使用，可以使用以下命令查看当前机器是否支持使用 NetworkManager： 1systemctl list-unit-files NetworkManager.service 当我们想要关闭 network 服务管理只使用 NetworkManager 时就需要使用chkconfig命令来解决了，具体是 –level 参数 NetworkManager的作用： 一般应用于个人的主机，比如插入网线之后可以识别网卡的激活状态，自动进行网络的激活，或者比如我们连接到熟悉的无线网络连接当中，它会自动激活无线的连接。但是应用于服务器上这些功能都有些鸡肋，所以服务器上我们一般还是沿用network脚本 启用/禁用 NetworkManager 脚本命令： 12345# 启用systemctl disable NetworkManager禁用systemctl enable NetworkManager 配置文件说明网卡配置文件： 网卡配置文件在 /etc/sysconfig/network-scripts/目录下，在此目录下会有很多以 ifcfg 开头的文件，这些文件每一个对应着我们的一个网络接口，我们可以打开其中一个进行查看： 12345678910[root@iZm5ehzqow4ijp2ya2g2drZ /]# cd /etc/sysconfig/network-scripts/[root@iZm5ehzqow4ijp2ya2g2drZ network-scripts]# ls ifcfg-*ifcfg-eth0 ifcfg-lovim ifcfg-eth0NAME=ethoDEVICE=eth0BOOTPROTO=dhcpONBOOT=yes 网卡配置文件内容说明： 我们打开ifcfg-eth0文件，发现其中设置内容还是有一些的，基本格式都是前边是设置项，后面是设置值，这些设置有一些是它的关键设置，有些是IPV6它的初始化设置，我们只需要关注其中几项即可 BOOTPROTO=dhcp，表示我们的机器它的IP地址是动态分配的，我们可以把它的值修改为 none ，表示IP地址是静态分配的，静态分配具体配置将在下面专门描述 NAMR=etho，DEVICE=eth0，表示的是网卡的名称设置 ONBOOT=yes，表示网卡是否开机启用，如果是 yes 表示开机启用，如果是 no 表示开机不启用 网卡IP静态分配配置： 配置示例如下： 12345678910vim ifcfg-eth0NAME=ethoDEVICE=eth0BOOTPROTO=noneONBOOT=yesIPADDR=192.168.1.28NETMASK=255.255.255.0GATEWAY=192.168.1.1DNS1=114.114.114.114 注意：配置静态IP需要修改BOOTPROTO设置项，然后添加IP地址、子网掩码、网关、默认DNS的地址 设置完成需要使用命令来让它生效，使用命令有两种，分别如下，命令具体使用在后边分析描述： service network restart systemctl restart NetworkManager.service 如上操作完成之后，就可以使用命令 ipconfig etho 来查看IP及子网掩码配置是否生效，使用 route -n 查看网关是否配置生效，使用 nslookup 查看默认的DNS设置是否生效 chkconfigchkconfig命令主要用来更新（启动或停止）和查询系统服务的运行级信息。谨记chkconfig不是立即自动禁止或激活一个服务，它只是简单的改变了符号连接 使用方法：chkconfig 参数 系统服务 参数详解： –list 列出所有的系统服务及状态，使用示例如下： 12[root@iZm5ehzqow4ijp2ya2g2drZ ~]# chkconfig --list networknetwork 0:off 1:off 2:on 3:on 4:on 5:on 6:off 上述示例中，数字表示不同的级别，及不同的级别服务的运行情况，级别表示如下： 等级0表示：表示关机 等级1表示：单用户模式 等级2表示：无网络连接的多用户命令行模式 等级3表示：有网络连接的多用户命令行模式 等级4表示：不可用 等级5表示：带图形界面的多用户模式 等级6表示：重新启动 –level 指定读系统服务要在哪一个执行等级中开启或关毕，使用时需要指定等级 使用示例，将当前开启的服务全部关闭 2 3 4 5 等级都关闭： 1234[root@iZm5ehzqow4ijp2ya2g2drZ ~]# chkconfig --level 2345 network off[root@iZm5ehzqow4ijp2ya2g2drZ ~]# chkconfig --list networknetwork 0:off 1:off 2:off 3:off 4:off 5:off 6:off 注意：当我们在CentOS7及以上版本中如此操作时，就相当与关闭了 network 服务管理工具，改为使用 NetworkManager 查看网络状态service network status 命令 使用示例： 12345[root@iZm5ehzqow4ijp2ya2g2drZ ~]# service network statusConfigured devices:lo eth0Currently active devices:lo eth0 如上查询结果中，第一表示我们已配置的网卡设备，第二表示当前活跃的设备 还原网卡默认配置 service network restart 将我们使用ifconfig、route等命令自己配置的内容恢复到默认的状态 使用示例： 1234567[root@iZm5ehzqow4ijp2ya2g2drZ ~]# service network restartShutting down interface eth0: [ OK ]Shutting down loopback interface: [ OK ]Bringing up loopback interface: [ OK ]Bringing up interface eth0: Determining IP information for eth0... done. [ OK ] systemctl restart NetworkManager.service 如果在 CentOS7 及以上版本中开启了 NetworkManager 脚本，还可以使用此命令来还原配置 配置主机名称查看主机名称查看主机名称使用 hostname 命令，使用示例如下： 12wangjia3@CHJ-20190520VPS:~$ hostnameCHJ-20190520VPS 临时设置主机名称临时设置就是当前修改过来，但是主机重启之后还是恢复成默认的 使用命令：hostname 自定义主机名称 如下示例： 1234567wangjia3@CHJ-20190520VPS:~$ hostname CHJhostname: you must be root to change the host namewangjia3@CHJ-20190520VPS:~$ sudo hostname CHJ[sudo] password for wangjia3:wangjia3@CHJ-20190520VPS:~$ hostnameCHJ 永久修改主机名称使用命令：hostnamectl set-hostname 自定义主机名称 这样设置之后即使重启之后也会使用新的主机名，但是要注意，如果我们更改主机名之后，很多服务是要依赖主机名进行工作，这里我们必须一个配置文件中将新的主机名写在127.0.0.1的对应关系当中，如果不写可能会出现在启动系统的时候，在某个服务上卡住，在等待它超时，这个文件是 /etc/hosts，如下： 12345678910 2 # %WINDIR%\\System32\\drivers\\etc\\hosts. Modifications to this file will be overwritten. 3 127.0.0.1 localhost 4 127.0.1.1 CHJ-20190520VPS.localdomain CHJ-20190520VPS # 修改此行内容 5 6 # The following lines are desirable for IPv6 capable hosts 7 ::1 ip6-localhost ip6-loopback 8 fe00::0 ip6-localnet 9 ff00::0 ip6-mcastprefix10 ff02::1 ip6-allnodes11 ff02::2 ip6-allrouters","categories":[],"tags":[{"name":"command","slug":"command","permalink":"https://jjw-story.github.io/tags/command/"},{"name":"网络管理","slug":"网络管理","permalink":"https://jjw-story.github.io/tags/网络管理/"}]},{"title":"软件包管理器和内核升级","slug":"软件包管理器","date":"2019-08-25T03:17:20.000Z","updated":"2019-10-06T08:22:48.743Z","comments":true,"path":"2019/08/25/软件包管理器/","link":"","permalink":"https://jjw-story.github.io/2019/08/25/软件包管理器/","excerpt":"","text":"介绍包管理器是方便软件安装、卸载、解决软件依赖关系的重要工具 CentOS、RedHat使用yum包管理器，软件安装包格式为rpm Debian、Ubuntu使用apt包管理器，软件安装包格式为deb rpmrpm包格式： vim-common-7.4.10.5.el7.x86_64.rpm 分别对应着软件名称、软件版本、系统版本、平台，然后以.rpm作为结尾。注意系统版本 el7 表示支持7版本的Linux系统，x86_64表示64位的平台系统 rpm命令使用方法：rpm [参数] 常用参数： -a： 查询所有套件 -c： 只列出组态配置文件，本参数需配合”-l”参数使用 -d： 只列出文本文件，本参数需配合”-l”参数使用 -e&lt;软件包&gt;： 删除指定的软件 -f&lt;文件&gt;+： 查询拥有指定文件的套件 -i&lt;软件包&gt;： 安装指定的软件包 -l： 显示套件的文件列表 -p&lt;软件包&gt;+： 查询指定的RPM套件档 -q： 使用询问模式，当遇到任何问题时，rpm指令会先询问用户 查询安装的软件包使用示例： 123456789101112131415# 查询所有安装的软件包[root@iZm5ehzqow4ijp2ya2g2drZ ~]# rpm -qavim-common-7.4.629-5.el6_8.1.x86_64setup-2.8.14-23.el6.noarchtcpdump-4.0.0-11.20090921gitdf3cb4.2.el6.x86_64basesystem-10.0-4.el6.noarch...# 显示内容太多还可以分页显示，命令如下：rpm -qa | more使用管道符加 more 即可实现 more 命令的翻页效果# 查询是否安装指定的软件包：使用-q参数，后面跟上要查询的软件包名称[root@iZm5ehzqow4ijp2ya2g2drZ ~]# rpm -q vim-commonvim-common-7.4.629-5.el6_8.1.x86_64 安装软件包使用示例： 1234# 主要是使用 -i 参数[root@iZm5ehzqow4ijp2ya2g2drZ ~]# rpm -i vim-enhanced-7.4.160-5.el7.x86_64.rpm# 注意很多时候我们安装软件包的时候回安装失败，错误信息为安装此安装包需要依赖另一个软件，这时我们需要先安装依赖的软件包 卸载已安装的软件包使用示例： 1234567# 主要是使用 -e 参数[root@iZm5ehzqow4ijp2ya2g2drZ ~]# rpm -e vim-enhanced注意：在删除安装的软件包时不需要指定软件包的全限定名称，只需要指定名称即可# 删除多个软件包[root@iZm5ehzqow4ijp2ya2g2drZ ~]# rpm -e vim-enhanced vim—common使用空格分开继续追加软件即可 yumyum概述及配置yum包管理器或yum仓库，它的出现是为了解决 rpm 包存在的问题： 需要自己解决依赖关系 如果我们要使用光盘中的rpm包，需要将整个光盘挂载到Linux当中，甚至如果没有光盘需要将整个光盘的iso镜像下载回来，以及软件包来源不可靠 CentOS yum源地址： http://mirror.centos.org/centos/7/ 国内镜像： https://opsx.alibaba.com/mirror 使用国内镜像有两种配置方式，第一种，需要修改yum的配置文件，修改文件如下： /etc/yum.repos.d/CentOS-Base.repo 1234567[base]name=CentOS-$releaseverenabled=1failovermethod=prioritybaseurl=http://mirrors.cloud.aliyuncs.com/centos/$releasever/os/$basearch/gpgcheck=1gpgkey=http://mirrors.cloud.aliyuncs.com/centos/RPM-GPG-KEY-CentOS-6 base表示基础应用的包，baseurl表示基础应用的rpm包放在哪一个源路径下，gpgcheck检测yum源软件包有没有被人恶意修改，是否为最开始发布的软件包的内容，防止被添加入木马 第二种方式，备份我们系统中yum配置文件，然后至镜像网站查询对应的OS版本的配置文件下载的地址 wget 命令，执行此 wget 命令后，就将原来的配置文件覆盖掉，之后运行 yum makecache 命令，生成缓存，让软件包指向我们要指向的开源的镜像站 使用 yum makecache 命令，可以把之前的缓存清空，然后通过网络把新的版本的软件包，配置等下载回来，然后更新，注意更新的过程不要中断 yum命令安装软件包使用yum安装软件可以自动检测软件包的依赖，并将依赖也下载安装，使用示例如下： 123456789101112131415161718192021# 首先卸载 vim-enhanced 和 vim-common 这两个软件包[root@iZm5ehzqow4ijp2ya2g2drZ yum.repos.d]# rpm -e vim-enhanced[root@iZm5ehzqow4ijp2ya2g2drZ yum.repos.d]# rpm -e vim-common# 然后使用 yum install 命令安装 vim-enhanced 软件包# 安装时我们发现它自动检测的安装 vim-enhanced 包的依赖关系，并将两个软件包同时进行安装[root@iZm5ehzqow4ijp2ya2g2drZ yum.repos.d]# yum install vim-enhanced...Dependencies Resolved=============================================================================================================================================================================== Package Arch Version Repository Size===============================================================================================================================================================================Installing: vim-enhanced x86_64 2:7.4.629-5.el6_10.2 updates 1.0 MInstalling for dependencies: vim-common x86_64 2:7.4.629-5.el6_10.2 updates 6.7 MTransaction Summary===============================================================================================================================================================================Install 2 Package(s) 卸载软件包卸载软件包使用的是 yum remove 命令，使用如下： 123456789101112131415# 删除与 vim 相关的软件包[root@iZm5ehzqow4ijp2ya2g2drZ yum.repos.d]# yum remove vim# 会提示有哪些与vim相关的软件包Dependencies Resolved=============================================================================================================================================================================== Package Arch Version Repository Size===============================================================================================================================================================================Removing: vim-enhanced x86_64 2:7.4.629-5.el6_10.2 @updates 2.2 MTransaction Summary===============================================================================================================================================================================Remove 1 Package(s) 查看软件包可以使用 yum list 命令来查看我们已经安装了哪些软件包，使用如下： 1234567[root@iZm5ehzqow4ijp2ya2g2drZ yum.repos.d]# yum list...zvbi.i686 0.2.35-1.el6 epelzvbi.x86_64 0.2.35-1.el6 epelzvbi-devel.i686 0.2.35-1.el6 epelzvbi-devel.x86_64 0.2.35-1.el6 epelzvbi-fonts.noarch 0.2.35-1.el6 epel 还可以使用 yum list package1 查看指定的软件包的安装情况，使用如下: 12345[root@iZm5ehzqow4ijp2ya2g2drZ yum.repos.d]# yum list vim-commonLoaded plugins: fastestmirrorLoading mirror speeds from cached hostfileInstalled Packagesvim-common.x86_64 2:7.4.629-5.el6_10.2 @updates 升级软件包升级软件包是一个非常重要的命令，因为我们在生产环境中安装的软件可能多多少少会出现一些bug或安全漏洞，这就需要我们定期的给软件进行一定的升级，那么如何升级呢，我们就需要使用 yum update 软件包名 命令来升级指定的软件包，如果我们不加软件包名，就会对当前所有的安装的软件包进行升级，注意：并不是直接升级，是会有提示的 使用如下： 1234567891011121314151617181920212223242526272829303132333435363738# 检查所有需要升级的软件并选择是否升级Dependencies Resolved=============================================================================================================================================================================== Package Arch Version Repository Size===============================================================================================================================================================================Installing: kernel x86_64 2.6.32-754.18.2.el6 updates 32 MUpdating: binutils x86_64 2.20.51.0.2-5.48.el6_10.1 updates 2.8 M ca-certificates noarch 2018.2.22-65.1.el6 base 930 kTransaction Summary===============================================================================================================================================================================Install 1 Package(s)Upgrade 57 Package(s)Total download size: 113 MIs this ok [y/N]: # 这里提示有57个软件包需要进行升级，我们出入 y 之后，既开始升级# 升级指定的软件包[root@iZm5ehzqow4ijp2ya2g2drZ yum.repos.d]# yum update vim-filesystemDependencies Resolved=============================================================================================================================================================================== Package Arch Version Repository Size===============================================================================================================================================================================Updating: vim-filesystem x86_64 2:7.4.629-5.el6_10.2 updates 15 kTransaction Summary===============================================================================================================================================================================Upgrade 1 Package(s)Total download size: 15 kIs this ok [y/N]: 通过源代码编译安装软件包有些时候我们在安装或升级软件包时，发现官网并没有直接可以安装的软件包，既不可以通过 yum 命令直接安装，只提供了压缩源代码软件包，这时我们就需要自己来编译此源代码来进行安装 注意，此种情况比较少，且安装比较麻烦，如果 yum 或 rpm 可以直接安装的话，尽量不要通过此种方式 安装示例我们将通过安装一个 openresty 源代码包来作为示例，具体步骤如下： 下载源代码包 使用命令 wget https://openresty.org/download/openresty-1.15.8.1.tar.gz 1234567root@iZm5ehzqow4ijp2ya2g2drZ ~]# wget https://openresty.org/download/openresty-1.15.8.1.tar.gz--2019-09-07 17:03:16-- https://openresty.org/download/openresty-1.15.8.1.tar.gz...2019-09-07 17:03:17 (34.3 MB/s) - “openresty-1.15.8.1.tar.gz” saved [4904182/4904182][root@iZm5ehzqow4ijp2ya2g2drZ ~]# ll-rw-r--r-- 1 root root 4904182 May 17 05:34 openresty-1.15.8.1.tar.gz 解压此源代码包 tar -zxvf openresty-VENSION.tar.gz 123456[root@iZm5ehzqow4ijp2ya2g2drZ ~]# tar -zxvf openresty-1.15.8.1.tar.gz [root@iZm5ehzqow4ijp2ya2g2drZ ~]# ls -lhtotal 53Mdrwxrwxr-x 5 1000 1003 4.0K May 17 05:27 openresty-1.15.8.1-rw-r--r-- 1 root root 4.7M May 17 05:34 openresty-1.15.8.1.tar.gz 进入解压好的文件夹，然后进行编译源代码 123456789[root@iZm5ehzqow4ijp2ya2g2drZ openresty-1.15.8.1]# ls -lhtotal 108Kdrwxrwxr-x 46 1000 1003 4.0K May 17 05:27 bundle-rwxrwxr-x 1 1000 1003 52K May 17 05:27 configure-rw-rw-r-- 1 1000 1003 23K May 17 05:27 COPYRIGHTdrwxrwxr-x 2 1000 1003 4.0K May 17 05:27 patches-rw-rw-r-- 1 1000 1003 4.6K May 17 05:27 README.markdown-rw-rw-r-- 1 1000 1003 8.8K May 17 05:27 README-windows.txtdrwxrwxr-x 2 1000 1003 4.0K May 17 05:27 util 我们发现 configure 是一个绿色的文件，并且是一个可执行的文件，一般情况下我们下载下源代码编译好后，都是通过 make 和 make install 命令来安装源代码，所以在我们解压源代码后就进入目录看看是否有类似于此示例中 configure 这样的可执行文件，如果没有的话，可以阅读源码包中的README文件，来查看具体的安装编译方法 接下来就是执行此可执行文件，注意：一般在执行此可执行程序时，我们都会指定它的安装目录，使用 –prefix 参数执行即可，指定完目录之后就意味着之后安装程序全都是在这个指定的目录下 12345678[root@iZm5ehzqow4ijp2ya2g2drZ openresty-1.15.8.1]# ./configure --prefix=/usr/local/openresty==== Building LuaJIT 2.1.0-beta3 ====gmake -C srcgmake[1]: cc: Command not found...gmake: *** [default] Error 2ERROR: failed to run command: gmake TARGET_STRIP=@: CCDEBUG=-g XCFLAGS=&apos;-DLUAJIT_ENABLE_LUA52COMPAT -DLUAJIT_ENABLE_GC64&apos; CC=cc PREFIX=/usr/local/openresty/luajit 执行之后我们发现有报错信息，这时候我们就需要解决此报错，此报错说 cc 命令找不到，既没有安装 gcc 软件包，那我们使用 yum 命令安装即可 1234[root@iZm5ehzqow4ijp2ya2g2drZ openresty-1.15.8.1]# yum install gccLoaded plugins: fastestmirrorSetting up Install Process... 安装完成之后我们发现再次执行发现可以执行了，但是还是执行失败，失败报错缺少 PCRE 这个库，这时候我们还需要安装这个库 12345678910[root@iZm5ehzqow4ijp2ya2g2drZ openresty-1.15.8.1]# ./configure --prefix=/usr/local/openrestyplatform: linux (linux)cp -rp bundle/ build..../configure: error: the HTTP rewrite module requires the PCRE library.You can either disable the module by using --without-http_rewrite_moduleoption, or install the PCRE library into the system, or build the PCRE librarystatically from the source with nginx by using --with-pcre=&lt;path&gt; option.ERROR: failed to run command: sh ./configure --prefix=/usr/local/openresty/nginx \\... 通过 yum 安装 PCRE 这个库，安装示例： 1234[root@iZm5ehzqow4ijp2ya2g2drZ openresty-1.15.8.1]# yum install pcre-develLoaded plugins: fastestmirrorSetting up Install Process... 安装完成后再次执行此可执行文件，发现还是报错，说缺少 OpenSSL这个库： 12345678[root@iZm5ehzqow4ijp2ya2g2drZ openresty-1.15.8.1]# ./configure --prefix=/usr/local/openresty..../configure: error: SSL modules require the OpenSSL library.You can either do not enable the modules, or install the OpenSSL libraryinto the system, or build the OpenSSL library statically from the sourcewith nginx by using --with-openssl=&lt;path&gt; option.ERROR: failed to run command: sh ./configure --prefix=/usr/local/openresty/nginx \\... 通过 yum 安装 OpenSSL 这个库 12345[root@iZm5ehzqow4ijp2ya2g2drZ openresty-1.15.8.1]# yum install openssl-develLoaded plugins: fastestmirrorSetting up Install ProcessLoading mirror speeds from cached hostfile... 上述示例中：-devel表示的都是开发库 安装完成后再次执行此文件，发现终于可以执行成功了 12345678root@iZm5ehzqow4ijp2ya2g2drZ openresty-1.15.8.1]# ./configure --prefix=/usr/local/openrestyplatform: linux (linux)cp -rp bundle/ build...cd ../..Type the following commands to build and install: gmake gmake install 执行完成后我们发现终于给了提示，说可以使用 gmake 和 gmake install 进行编译安装此软件包 通常我们都是使用 make 和 make install 进行编译安装，这是提示使用 gmake 和 gmake install，gmake 和 gmake install 是方便我们跨平台的进行编译安装的命令，所以我们这里使用 gmake 和 gmake install 这两个命令进行编译安装，此两种命令都可以使用 编译 首先使用 gmake 编译此源码包，可以使用 -j2 参数进行指定使用两个cpu进行编译，效率会更快 1234567[root@iZm5ehzqow4ijp2ya2g2drZ openresty-1.15.8.1]# gmake -j2...gmake[2]: Leaving directory `/root/openresty-1.15.8.1/build/nginx-1.15.8&apos;gmake[1]: Leaving directory `/root/openresty-1.15.8.1/build/nginx-1.15.8&apos;[root@iZm5ehzqow4ijp2ya2g2drZ openresty-1.15.8.1]# lsbuild bundle configure COPYRIGHT Makefile patches README.markdown README-windows.txt util 编译完成之后，我们发现源代码目录文件中多了一个 build 文件夹，这里面就存放了编译之后的文件及配置文件 安装 使用 gmake install 命令，将 build 文件中的所有文件都安装到我们之前指定的目录中 注意还是在原来的目录中，不需要进去其他目录 12345[root@iZm5ehzqow4ijp2ya2g2drZ openresty-1.15.8.1]# gmake installcd /root/openresty-1.15.8.1/build/LuaJIT-2.1-20190507 &amp;&amp; gmake TARGET_STRIP=@: CCDEBUG=-g XCFLAGS=&apos;-std=gnu99 -DLUAJIT_ENABLE_LUA52COMPAT -DLUAJIT_ENABLE_GC64 -msse4.2&apos; CC=cc PREFIX=/usr/local/openresty/luajit...mkdir -p /usr/local/openresty/site/lualib /usr/local/openresty/site/pod /usr/local/openresty/site/manifestln -sf /usr/local/openresty/nginx/sbin/nginx /usr/local/openresty/bin/openresty 执行完成后，就已经安装完成了，可以查看我们之前的指定目录，查看安装后的文件内容 12345678910root@iZm5ehzqow4ijp2ya2g2drZ openresty-1.15.8.1]# ll /usr/local/openresty/total 272drwxr-xr-x 2 root root 4096 Sep 7 18:20 bin-rw-r--r-- 1 root root 22924 Sep 7 18:20 COPYRIGHTdrwxr-xr-x 6 root root 4096 Sep 7 18:20 luajitdrwxr-xr-x 6 root root 4096 Sep 7 18:20 lualibdrwxr-xr-x 6 root root 4096 Sep 7 18:20 nginxdrwxr-xr-x 47 root root 4096 Sep 7 18:20 pod-rw-r--r-- 1 root root 226376 Sep 7 18:20 resty.indexdrwxr-xr-x 5 root root 4096 Sep 7 18:20 site 只有再安装完成后，才可以看到此目录及文件，这样就完成了通过源代码安装软件啦 内核升级uname命令Linux uname命令用于显示系统信息，uname可显示电脑以及操作系统的相关信息 使用方式：uname [选项] 参数说明 -a 显示全部的信息 -m 显示电脑类型 -n 显示在网络上的主机名称 -r 显示操作系统的发行编号 -s 显示操作系统名称 -v 显示操作系统的版本 使用示例： 12[root@iZm5ehzqow4ijp2ya2g2drZ balyu]# uname -aLinux iZm5ehzqow4ijp2ya2g2drZ 2.6.32-696.16.1.el6.x86_64 #1 SMP Wed Nov 15 16:51:15 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux df命令Linux df命令用于显示目前在Linux系统上的文件系统的磁盘使用情况统计 使用方法： df [选项] 参数说明 -h -human-readable 使用人类可读的格式(预设值是不加这个选项的…) -t -type=TYPE 限制列出文件系统的 TYPE -i 输出显示inode信息而非块使用量 使用示例： 1234[root@iZm5ehzqow4ijp2ya2g2drZ boot]# df -hFilesystem Size Used Avail Use% Mounted on/dev/vda1 40G 2.4G 35G 7% /tmpfs 499M 0 499M 0% /dev/shm lscpu命令查看当前主机CPU状况的命令，使用示例： 123456789101112131415161718192021222324[root@iZm5ehzqow4ijp2ya2g2drZ balyu]# lscpuArchitecture: x86_64CPU op-mode(s): 32-bit, 64-bitByte Order: Little EndianCPU(s): 1On-line CPU(s) list: 0Thread(s) per core: 1Core(s) per socket: 1Socket(s): 1NUMA node(s): 1Vendor ID: GenuineIntelCPU family: 6Model: 85Model name: Intel(R) Xeon(R) Platinum 8163 CPU @ 2.50GHzStepping: 4CPU MHz: 2500.006BogoMIPS: 5000.01Hypervisor vendor: KVMVirtualization type: fullL1d cache: 32KL1i cache: 32KL2 cache: 1024KL3 cache: 33792KNUMA node0 CPU(s): 0 top命令类似于Windows的任务管理器，使用示例： 12345678910111213[root@iZm5ehzqow4ijp2ya2g2drZ balyu]# toptop - 15:03:02 up 7 days, 5:18, 2 users, load average: 0.00, 0.00, 0.00Tasks: 79 total, 1 running, 78 sleeping, 0 stopped, 0 zombieCpu(s): 0.3%us, 0.3%sy, 0.0%ni, 99.0%id, 0.3%wa, 0.0%hi, 0.0%si, 0.0%stMem: 1019980k total, 705416k used, 314564k free, 131904k buffersSwap: 0k total, 0k used, 0k free, 209692k cached PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 1407 root 10 -10 121m 11m 9176 S 0.3 1.2 30:52.20 AliYunDun 1 root 20 0 19228 1500 1232 S 0.0 0.1 0:00.71 init 2 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kthreadd 3 root RT 0 0 0 0 S 0.0 0.0 0:00.00 migration/0 4 root 20 0 0 0 0 S 0.0 0.0 0:00.62 ksoftirqd/0 可以看到能查询到CPU及内存等的使用状态，以及当前进程等 扩展软件仓库很多时候我们发现CentOS默认提供的软件仓库中并没有我们需要的软件，或者软件版本没有一些最新的，比如下面我们要说的内核，这时候我们就需要去别的仓库去找，所以这里我们介绍扩展软件仓库 一般比较流行的软件仓库是 epel 仓库，我们只需要通过命令来安装这个仓库即可，命令如下： 1yum install epel-release -y 升级内核以上我们已经知道了如何查看自己主机当前的内核版本，现在我们就可以对它进行升级了 使用yum命令升级第一种方式是指定内核的版本进行升级，我们可以去内核的官网查看我们需要升级的内核版本，然后使用yum命令进行升级，具体命令如下： 1yum install kernel-3.10.0 注意上面我们只使用 yum install kernel 命令，不指定具体的版本号的时候，yum就会去仓库寻找最新的 kernel 版本来进行安装 第二种方式是自动进行升级，它可以直接对我们所有安装的软件及内核进行版本检测，检测到有最新版本的话就会自动升级，具体使用如下： 1yum update 使用源代码编译方式安装升级 源代码编译的方式比较复杂，上面我们已经说过了，需要解决各种各样的依赖，以下是大神总结出来的所有的依赖： 12安装依赖包yum install gcc gcc-c++ make ncurses-devel openssl-devel elfutils-libelf-devel 接下来需要下载并解压缩内核软件包，下载地址：www.kernel.org，选择好我们要安装的内核版本并下载，然后解压缩就可以安装了 配置内核编译参数 配置内核编译参数和我们上述介绍的./configure不一样，需要进入到内核的软件包指定目录中，然后使用 make 命令来配置。具体如下： 12cd /usr/src/kernals/linux-5.1.1.0/make menuconfig | allyelsconfig | allnoconfig 上述介绍的 ./configure 是有很多的自动化配置在里面，但是我们在安装内核的时候，这些配置都需要我们自己手动来完成，所以这里需要使用 make – 命令来进行配置： make menuconfig 我们自己来根据弹出的菜单选项来进行配置 make allyelconfig 无脑设置，既有的功能全部都配置上 make allnoconfig 无脑设置，既什么功能都不配置，这样有可能会出现什么都不安装，导致安装后启动都启动不了 我们还可以使用当前的系统配置来进行配置，这里只需要将我们原先内核的配置文件拷贝到软件包的指定目录下，并且重命名为 .config 就可以使用原来内核的配置，这样就可以减少我们配置的复杂度，具体命令如下： 1cp /boot/config-kernelversion.platfrom /uer/src/kernels/linux-5.1.10/.config 注意上述命令示例中 kernelversion.platfrom 是需要替换成我们本地的文件，形式：config-2.6.32-696.16.1.el6.x86_64 编译 编译软件包与上述源代码编译一样，使用make命令直接编译即可，如下： 1make -j2 all 安装 安装与上述源代码安装不一样，多了一个步骤，我们在安装内核的时候需要先安装内核所支持的模块，然后再安装内核，具体命令如下： 123make modules_installmake install 这里我们就将内核安装升级完成了 grub配置文件升级完内核时我们需要设置启动引导软件来设置默认的内核，CentOS7使用的是gurb2版本，CentOS使用的是一版本，在一版本中，我们什么样的配置都需要自己手动去编辑，而且需要向设置网卡一样，记住每一项的功能，而二版本给我们提供了很多方便的工具，我们需要修改配置的时候只需要通过命令修改即可。所以grub2版本就不需要我们去背每一个设置项及内容了。 配置文件具体说明配置文件所在的位置：/boot/grub2/grub.cfg，由于grub2程序的特性，我们一般不要去直接编辑此文件，因为此文件可以说是一个内存级的配置文件，如果我们再通过一些其他的手段去修改了默认的配置，那么我们的的编辑就会丢失及消失 所以我们通常如果想要修改配置，会去修改：/etc/default/grub 这个文件，这个是一些基本的配置的配置文件，如果我们想修改更为详细的配置，我们可以去：/etc/grud.d/ 此文件目录下的一些其他的配置文件，此文件是从 00、01 … 等一直向后排序的 当我们修改完成后，通过命令：grub2-mkconfig-o /boot/gurb2/grub.cfg 就可以产生新的配置文件了 /etc/default/grub这个文件是修改默认的一些设置，这里面一般我们只需要关注两个配置项即可： GRUB_DEFAULT=saved GRUB_CMDLINE_LINUX=”rd.lvm.lv=centos/root rd.lvm.lv=centos/swap rhgb quiet biosde vname=0 net.ifnames=0” 修改默认启动引导内核当我们需要修改默认的启动引导内核，就需要依赖上述第一项，我们需要通过命令：grub2-editenv list 能查看到当前系统启动的引导内核是什么版本的， 然后我们需要通过命令：grub2 ^menu /boot/default/grub 来查看当前我们系统中安装了哪些内核版本及顺序，我们找到所有以 menuentry 开头的行，它后边包含的内容就是我们安装的内核版本信息，我们需要找到我们需要修改的内核的顺序，第一个从0开始，然后记录。然后我们通过命令：grub2-set-default 顺序编号 来设置我们默认的系统引导内核。 当修改完成后，我们再来通过 grub2-editenv list 命令查看当前系统启动引导内核时，发现就成为了我们设置的内核（saved_entry=顺序编号），这时我们重新启动电脑，发现重启后默认的启动内核就变成了我们所设置的内核 启动项配置上述描述中第二项就是我们需要关注的，修改网卡名称所要用到的一项，此项中我们经常需要修改的是两个项： 1GRUB_CMDLINE_LINUX=&quot;rd.lvm.lv=centos/root rd.lvm.lv=centos/swap rhgb quiet biosde vname=0 net.ifnames=0&quot; 上述中rhgb：此项表示引导的时候使用一个图形界面，我们看到启动时的进度条，也是当启动出现问题的将此项去掉已查看启动时更为详细的信息 上述中quiet：此项为静默模式，表示引导的时候只是打印一些必要的消息，当我们发现启动出现异常的时候，我们会将此项去掉，已打印更为全面的消息来定位问题","categories":[{"name":"Linux","slug":"Linux","permalink":"https://jjw-story.github.io/categories/Linux/"}],"tags":[{"name":"command","slug":"command","permalink":"https://jjw-story.github.io/tags/command/"},{"name":"软件包管理器和内核升级","slug":"软件包管理器和内核升级","permalink":"https://jjw-story.github.io/tags/软件包管理器和内核升级/"}],"author":"JJW"},{"title":"网络配置","slug":"网络配置","date":"2019-08-12T12:00:00.000Z","updated":"2019-08-20T12:06:13.128Z","comments":true,"path":"2019/08/12/网络配置/","link":"","permalink":"https://jjw-story.github.io/2019/08/12/网络配置/","excerpt":"","text":"网络配置命令设置网卡IP地址ifconfig命令我们可以使用ifconfig命令来设置网卡的ip地址，使用方法: ifconfig 接口 IP地址 [netmask 子网掩码] 使用示例： 123456789101112131415161718192021222324root@CHJ-20190520VPS:/# ifconfigeth3: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 172.31.34.113 netmask 255.255.255.240 broadcast 172.31.34.127 inet6 fe80::4c47:3429:b72c:5130 prefixlen 64 scopeid 0x0&lt;global&gt; ether 7e:15:d8:27:73:38 (Ethernet) ...# 修改iproot@CHJ-20190520VPS:/# ifconfig eth3 172.31.34.118root@CHJ-20190520VPS:/# ifconfigeth3: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 172.31.34.113 netmask 255.255.255.240 broadcast 172.31.34.127 inet6 fe80::4c47:3429:b72c:5130 prefixlen 64 scopeid 0x0&lt;global&gt; ether 7e:15:d8:27:73:38 (Ethernet) ...# 修改ip并指定子网掩码root@CHJ-20190520VPS:/# ifconfig eth3 172.31.34.118 netmask 255.255.255.0root@CHJ-20190520VPS:/# ifconfigeth3: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 172.31.34.118 netmask 255.255.255.0 broadcast 172.31.34.127 inet6 fe80::4c47:3429:b72c:5130 prefixlen 64 scopeid 0x0&lt;global&gt; ether 7e:15:d8:27:73:38 (Ethernet) ... 启动和关闭网卡启动和关闭网卡动作和我们Windows中的是一样的，这两个操作其实是在一些特殊情况来使用网卡操作的命令，一般是网卡的配置被改乱了，我们希望恢复到默认的配置，可能需要这两个命令，一般情况下我们是不需要使用这两个命令的 启动命令以下都分别对用两种工具包的命令，使用哪一种都可以 ifconfig 接口 up ifup 接口 关闭命令ipconfig 接口 down ifdown 接口 网关配置命令添加网关网段使用route add命令，使用方法： route add [-net | -host] 目的网络或主机 gw 网关ip route add [-net | -host] dev 网卡接口 route add -net 指定网段 netmask 子网掩码 eth0 route add -net 指定网段 netmask 子网掩码 gw 网关ip -net是指定网段，-host是指定ip 使用示例： 12345678910111213141516171819202122232425262728293031323334353637383940[root@iZm5ehzqow4ijp2ya2g2drZ etc]# routeKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface172.31.240.0 * 255.255.240.0 U 0 0 0 eth0link-local * 255.255.0.0 U 1002 0 0 eth0default 172.31.255.253 0.0.0.0 UG 0 0 0 eth0# 添加主机路由[root@iZm5ehzqow4ijp2ya2g2drZ etc]# route add -host 192.168.1.2 dev eth0[root@iZm5ehzqow4ijp2ya2g2drZ etc]# routeKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface192.168.1.2 * 255.255.255.255 UH 0 0 0 eth0172.31.240.0 * 255.255.240.0 U 0 0 0 eth0link-local * 255.255.0.0 U 1002 0 0 eth0default 172.31.255.253 0.0.0.0 UG 0 0 0 eth0# 添加网络路由 10.20.30.40 ~ 255.255.255.248[root@iZm5ehzqow4ijp2ya2g2drZ etc]# route add -net 10.20.30.40 netmask 255.255.255.248 eth0[root@iZm5ehzqow4ijp2ya2g2drZ etc]# routeKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface192.168.1.2 * 255.255.255.255 UH 0 0 0 eth010.20.30.40 * 255.255.255.248 U 0 0 0 eth0172.31.240.0 * 255.255.240.0 U 0 0 0 eth0link-local * 255.255.0.0 U 1002 0 0 eth0default 172.31.255.253 0.0.0.0 UG 0 0 0 eth0# 添加默认路由 default ~ 192.168.1.2[root@iZm5ehzqow4ijp2ya2g2drZ etc]# route add default gw 192.168.1.2[root@iZm5ehzqow4ijp2ya2g2drZ etc]# routeKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface192.168.1.2 * 255.255.255.255 UH 0 0 0 eth010.20.30.40 * 255.255.255.248 U 0 0 0 eth0172.31.240.0 * 255.255.240.0 U 0 0 0 eth0link-local * 255.255.0.0 U 1002 0 0 eth0default 192.168.1.2 0.0.0.0 UG 0 0 0 eth0default 172.31.255.253 0.0.0.0 UG 0 0 0 eth0 删除网关网段使用route del命令，使用方法： route del [-net | -host] 目的网络或主机 gw 网关ip route del [-net | -host] dev 网卡接口 route del -net 指定网段 netmask 子网掩码 eth0 route del -net 指定网段 netmask 子网掩码 gw 网关ip 使用示例： 123456789101112131415161718192021222324252627282930313233343536373839[root@iZm5ehzqow4ijp2ya2g2drZ etc]# routeKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface192.168.1.2 * 255.255.255.255 UH 0 0 0 eth010.20.30.40 * 255.255.255.248 U 0 0 0 eth0172.31.240.0 * 255.255.240.0 U 0 0 0 eth0link-local * 255.255.0.0 U 1002 0 0 eth0default 192.168.1.2 0.0.0.0 UG 0 0 0 eth0default 172.31.255.253 0.0.0.0 UG 0 0 0 eth0# 删除主机路由[root@iZm5ehzqow4ijp2ya2g2drZ etc]# route del -host 192.168.1.2 dev eth0[root@iZm5ehzqow4ijp2ya2g2drZ etc]# routeKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface10.20.30.40 * 255.255.255.248 U 0 0 0 eth0172.31.240.0 * 255.255.240.0 U 0 0 0 eth0link-local * 255.255.0.0 U 1002 0 0 eth0default 192.168.1.2 0.0.0.0 UG 0 0 0 eth0default 172.31.255.253 0.0.0.0 UG 0 0 0 eth0# 删除默认路由[root@iZm5ehzqow4ijp2ya2g2drZ etc]# route del -net default gw 192.168.1.2[root@iZm5ehzqow4ijp2ya2g2drZ etc]# routeKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface10.20.30.40 * 255.255.255.248 U 0 0 0 eth0172.31.240.0 * 255.255.240.0 U 0 0 0 eth0link-local * 255.255.0.0 U 1002 0 0 eth0default 172.31.255.253 0.0.0.0 UG 0 0 0 eth0# 删除网络路由[root@iZm5ehzqow4ijp2ya2g2drZ etc]# route del -net 10.20.30.40 netmask 255.255.255.248 eth0[root@iZm5ehzqow4ijp2ya2g2drZ etc]# routeKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface172.31.240.0 * 255.255.240.0 U 0 0 0 eth0link-local * 255.255.0.0 U 1002 0 0 eth0default 172.31.255.253 0.0.0.0 UG 0 0 0 eth0 修改网关地址如果我们要修改默认网关，需要先把网关删除，然后再进行添加 使用示例： 将 169.254.0.0 的默认网关修改为 192.168.1.2 1234567891011121314151617181920212223[root@iZm5ehzqow4ijp2ya2g2drZ etc]# route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface192.168.1.2 0.0.0.0 255.255.255.255 UH 0 0 0 eth0172.31.240.0 0.0.0.0 255.255.240.0 U 0 0 0 eth0169.254.0.0 0.0.0.0 255.255.0.0 U 1002 0 0 eth00.0.0.0 169.254.0.0 0.0.0.0 UG 0 0 0 eth00.0.0.0 172.31.255.253 0.0.0.0 UG 0 0 0 eth0# 先删除[root@iZm5ehzqow4ijp2ya2g2drZ etc]# route del -net default gw 169.254.0.0# 然后添加[root@iZm5ehzqow4ijp2ya2g2drZ etc]# route add default gw 192.168.1.2[root@iZm5ehzqow4ijp2ya2g2drZ etc]# route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface192.168.1.2 0.0.0.0 255.255.255.255 UH 0 0 0 eth0172.31.240.0 0.0.0.0 255.255.240.0 U 0 0 0 eth0169.254.0.0 0.0.0.0 255.255.0.0 U 1002 0 0 eth00.0.0.0 192.168.1.2 0.0.0.0 UG 0 0 0 eth00.0.0.0 172.31.255.253 0.0.0.0 UG 0 0 0 eth0","categories":[{"name":"Linux","slug":"Linux","permalink":"https://jjw-story.github.io/categories/Linux/"}],"tags":[{"name":"command","slug":"command","permalink":"https://jjw-story.github.io/tags/command/"},{"name":"网络管理","slug":"网络管理","permalink":"https://jjw-story.github.io/tags/网络管理/"}],"author":"JJW"},{"title":"Djongo-03","slug":"Djongo-03","date":"2019-08-11T05:30:43.000Z","updated":"2019-08-11T12:01:02.866Z","comments":true,"path":"2019/08/11/Djongo-03/","link":"","permalink":"https://jjw-story.github.io/2019/08/11/Djongo-03/","excerpt":"","text":"通用视图通用视图介绍通用视图把视图开发中常用的写法和模式抽象出来，让你编写少量代码就能快速实现常见的数据视图。显示对象列表就是这样一种任务。 有了通用视图，可以把模型作为额外的参数传给 URL 配置。Django 自带的通用视图能实现下述功能： 列出对象并显示单个对象的详细信息。如果创建一个管理会议的应用程序，那么TalkListView 和RegisteredUserListView就是列表视图。某一个演讲的页面就是详细信息视图。 呈现基于日期的对象，显示为年月日归档页面（带有详细信息），以及“最新”页面。 让用户创建、更新和删除对象——需不需要授权都行。 具体使用示例及说明示例展示的是一个查询出所有厂家及根据URl中传入的厂家名称查询出此厂家生产的所有商品的示例： 视图函数如下(在项目view.py下定义)： 12345678910111213141516171819202122232425262728293031323334353637from cerealsOils.models import Manufacturers, Productfrom django.views.generic import ListViewfrom django.shortcuts import get_object_or_404# Create your views here.# 定义通用视图class ManufacturersList(ListView): # 注意此行代码表示：其实是queryset = Publisher.objects.all() 的简洁形式。 # model = Manufacturers # 动态过滤 # 根据 URL 中指定的键过滤列表页面中的对象 # 我们可以覆盖ListView 的 get_queryset() 方法。它的默认实现是返回queryset 属性的值，不过我们可以添加更多逻辑 # 这里根据url中传入的厂家名称，过滤出指定厂家生产的产品 def get_queryset(self): # 获取到GET请求捕获到的参数 self.manu = get_object_or_404(Manufacturers, name=self.args[0]) # 过滤 return Product.objects.filter(manufacturers=self.manu) # 提供“友好的”模板上下文，如果我们不自已定义模板上下文名称，默认会将上述查询结果存储在名为 object_list 的变量中 # 现在我们将它存储在 manu_list 变量中 context_object_name = &quot;product_list&quot; # 自定义了模板名称，既指定使用的模板 # 如果没明确指定，Django 将从对象的名称中推知。这里，推知的模板是cerealsOils/manufacturers_list.html template_name = &apos;manu_list.html&apos; # 提供额外的上下文变量 # 就是扩展DetailView，自己实现get_context_data 方法，然后在此方法提供额外的数据 # 这里查询出所有的厂家返回给页面 def get_context_data(self, **kwargs): # 先调用原来的实现，获取上下文 context = super(ManufacturersList, self).get_context_data(**kwargs) # 查询出所有的产品 context[&apos;manu_list&apos;] = Manufacturers.objects.all() return context url定义如下： 1234urlpatterns = [ # 注意 as_view() 函数 url(r&apos;^manulist/([\\w-]+)$&apos;, views.ManufacturersList.as_view())] 模板代码如下： 1234567891011121314151617181920&lt;!DOCTYPE HTML PUBLIC &quot;-//W3C//DTD HTML 4.01//EN&quot;&gt;&lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;meta charset=&apos;UTF-8&apos;&gt; &lt;title&gt;通用视图测试&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;厂家名称&lt;/h1&gt; &#123;% for manu in manu_list %&#125; &lt;li&gt;&#123;&#123; manu.name &#125;&#125;&lt;/li&gt; &#123;% endfor %&#125; &lt;hr&gt; &lt;h1&gt;产品名称&lt;/h1&gt; &#123;% for prod in product_list %&#125; &lt;li&gt;&#123;&#123; prod.title &#125;&#125;&lt;/li&gt; &#123;% endfor %&#125; &lt;hr&gt; &lt;p&gt;谢谢光临&lt;/p&gt; &lt;/body&gt;&lt;/html&gt; 以上便是通用视图的实现，是不是很方便呢！","categories":[{"name":"Python","slug":"Python","permalink":"https://jjw-story.github.io/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://jjw-story.github.io/tags/Python/"},{"name":"Django","slug":"Django","permalink":"https://jjw-story.github.io/tags/Django/"}],"author":"JJW"},{"title":"网络状态查看","slug":"网络状态查看","date":"2019-08-08T12:20:20.000Z","updated":"2019-08-03T11:13:31.476Z","comments":true,"path":"2019/08/08/网络状态查看/","link":"","permalink":"https://jjw-story.github.io/2019/08/08/网络状态查看/","excerpt":"","text":"网络状态查看网络状态查看我们列举两套工具包，一套是net-tools，一套是iproute或者有时候也叫iproute2 使用两套工具的作用是，在CentOS7以前，我们一般使用的都是net-tools工具包，而在CentOS7以后，主推的使用iproute工具包 ifconfig查看网络状态既网卡状态，使用方法：ifconfig [网卡名称] 注意网卡名称是可选的，管理用户直接输入命令，普通用户需要 /sbin/ifconfig(注意普通用户需要加上命令的完整路径) 一般使用此命令查询出来的结果中，会显示etho，第一块网卡的状态信息，这个名字是默认的，但是有可能我们查询出来不叫这个名字，这是因为在CentOS7中使用了一致性网络设备命名，它会先去检测我们的网卡，检测后具体命名如下： en01 板载网卡 ens33 PCI-E网卡 enp0s3 无法获取物理信息的PCI-E网卡 eth0 如果以上都获取不到，会使用此命名 使用示例： 123456789101112131415161718wangjia3@CHJ-20190520VPS:~$ ifconfigeth3: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 172.31.34.113 netmask 255.255.255.240 broadcast 172.31.34.127 inet6 fe80::4c47:3429:b72c:5130 prefixlen 64 scopeid 0x0&lt;global&gt; ether 7e:15:d8:27:73:38 (Ethernet) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt; mtu 1500 inet 127.0.0.1 netmask 255.0.0.0 inet6 ::1 prefixlen 128 scopeid 0x0&lt;global&gt; loop (Local Loopback) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 我们还可以使用命令：ifconfig 网卡名称 来查看指定网卡，例如我们只查看lo网卡的信息： 以上查询结果我们需要关注的是： etho信息中的 inet选项，第一个参数addr是IP信息，Mask参数对应的是子网掩码，还要注意 有个 ether参数，它显示的是mac地址，RX、TX：发送数据包的个数及多少 lo网卡信息中：lo网卡表示的是本地环回，它的地址永远是127.0.0.1，这个网卡的作用就是我们在自己本地搭建了一个服务，在我们访问自己主机服务的时候，就使用这个IP 123456789wangjia3@CHJ-20190520VPS:~$ ifconfig lolo: flags=73&lt;UP,LOOPBACK,RUNNING&gt; mtu 1500 inet 127.0.0.1 netmask 255.0.0.0 inet6 ::1 prefixlen 128 scopeid 0x0&lt;global&gt; loop (Local Loopback) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 修改网卡名称有时候我们在管理Linux网卡的时候，可能会有很多机器，我们需要写一个通用的脚本来修改，但是我们多个机器的网卡名称不一样，那么我们就需要手动的修改网卡的名称，来保证多个机器的网卡名称保持一致，这样能便于管理，下面我们介绍的就是修改网卡名称的方法，分为两步： 第一步： 网卡命名规则受 biosdevname和net.ifnames两个参数影响，这两个参数我们需要编辑 /etc/defult/grub 文件来修改，为此文件增加如下两个参数： biosdevname=0 net.ifnames=0 第二步： 更新grup，上述编辑好的文件并不会在系统启动的时候被读取到，所以我们需要将上述文件转化为系统启动可读取的文件，使用命令： grub2-mkconfig -o /boot/grup2/grup.cfg 第三步： 重启，重启命令是reboot，重启完成之后，网卡名称就变成了 eth0 biosdevname和net.ifnames组合明细： 序列 biosdevname net.ifnames 网卡名 默认 0 1 ens33 组合1 1 0 em1 组合2 0 0 eth0 查看网卡物理连接情况查看网卡物理连接情况，比如查看网线是否连接好，Windows可以直接通过图形界面来查看，Linux需要用过命令来查看 mii-tool命令 使用方法：mii-tool [网卡名称] 注意CentOS7及以上使用此命令，网卡名称是必须要有的 12345678910111213141516root@CHJ-20190520VPS:/# mii-toolNo interface specifiedusage: mii-tool [-VvRrwl] [-A media,... | -F media] [-p addr] &lt;interface ...&gt; -V, --version display version information -v, --verbose more verbose output -R, --reset reset MII to poweron state -r, --restart restart autonegotiation -w, --watch monitor for link status changes -l, --log with -w, write events to syslog -A, --advertise=media,... advertise only specified media -F, --force=media force specified media technology -p, --phy=addr set PHY (MII address) to reportmedia: 1000baseTx-HD, 1000baseTx-FD, 100baseT4, 100baseTx-FD, 100baseTx-HD, 10baseT-FD, 10baseT-HD, (to advertise both HD and FD) 1000baseTx, 100baseTx, 10base 也可以使用：ethtool命令 使用方法：ethtool 网卡名称 123[root@iZm5ehzqow4ijp2ya2g2drZ etc]# ethtool eth0Settings for eth0: Link detected: ye 查看网关命令当我们机器需要网络通信的时候，需要连接其它的网络地址范围的时候，我们就需要配置网关，也叫配置路由 使用route命令来查看网关，使用方法：route [参数] 参数：-n 如果我们单独只用route命令时，默认使用时每一个IP都会反解成主机名，这个过程很慢，所以可以使用此参数可以不解析主机名 使用示例： 12345678910111213[root@iZm5ehzqow4ijp2ya2g2drZ etc]# routeKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface172.31.240.0 * 255.255.240.0 U 0 0 0 eth0link-local * 255.255.0.0 U 1002 0 0 eth0default 172.31.255.253 0.0.0.0 UG 0 0 0 eth0[root@iZm5ehzqow4ijp2ya2g2drZ etc]# route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface172.31.240.0 0.0.0.0 255.255.240.0 U 0 0 0 eth0169.254.0.0 0.0.0.0 255.255.0.0 U 1002 0 0 eth00.0.0.0 172.31.255.253 0.0.0.0 UG 0 0 0 eth0 输出项说明： 输出项 说明 Destination 目标网段或者主机 Gateway 网关地址，”*” 表示目标是本主机所属的网络，不需要路由 Genmask 网络掩码 Flags 标记。一些可能的标记如下： - U — 路由是活动的 - H — 目标是一个主机 - G — 路由指向默认网关 - R — 恢复动态路由产生的表项 - D — 由路由的后台程序动态地安装 - M — 由路由的后台程序修改 - ! — 拒绝路由 Metric 路由距离，到达指定网络所需的中转数（linux 内核中没有使用） Ref 路由项引用次数（linux 内核中没有使用） Use 此路由项被路由软件查找的次数 Iface 该路由表项对应的输出接口 主机路由：主机路由是路由选择表中指向单个IP地址或主机名的路由记录。主机路由的Flags字段为H。例如，在下面的示例中，本地主机通过IP地址192.168.1.1的路由器到达IP地址为10.0.0.10的主机 12Destination Gateway Genmask Flags Metric Ref Use Iface10.0.0.10 192.168.1.1 255.255.240.0 UH 0 0 0 eth0 网络路由：网络路由是代表主机可以到达的网络。网络路由的Flags字段为N。例如，在下面的示例中，本地主机将发送到网络192.19.12.20的数据包转发到IP地址为192.168.1.1的路由器 12Destination Gateway Genmask Flags Metric Ref Use Iface192.19.12.20 192.168.1.1 255.255.240.0 UN 0 0 0 eth0 默认路由：当主机不能在路由表中查找到目标主机的IP地址或网络路由时，数据包就被发送到默认路由（默认网关）上。默认路由的Flags字段为G。例如，在下面的示例中，默认路由是IP地址为192.168.1.1的路由器 12Destination Gateway Genmask Flags Metric Ref Use Ifacedefault 192.168.1.1 0.0.0.0 UG 0 0 0 eth0","categories":[{"name":"Linux","slug":"Linux","permalink":"https://jjw-story.github.io/categories/Linux/"}],"tags":[{"name":"command","slug":"command","permalink":"https://jjw-story.github.io/tags/command/"},{"name":"网络管理","slug":"网络管理","permalink":"https://jjw-story.github.io/tags/网络管理/"}],"author":"JJW"},{"title":"Django-01","slug":"Django-01","date":"2019-08-04T02:31:02.000Z","updated":"2019-08-05T09:23:05.959Z","comments":true,"path":"2019/08/04/Django-01/","link":"","permalink":"https://jjw-story.github.io/2019/08/04/Django-01/","excerpt":"","text":"Djongo入门Djongo介绍Django是一个开放源代码的Web应用框架，由Python写成。采用了MTV的框架模式，即模型M，视图V和模版T。它最初是被开发来用于管理劳伦斯出版集团旗下的一些以新闻内容为主的网站的，即是CMS（内容管理系统）软件。并于2005年7月在BSD许可证下发布。这套框架是以比利时的吉普赛爵士吉他手Django Reinhardt来命名的。 Django是一个基于MVC构造的框架。但是在Django中，控制器接受用户输入的部分由框架自行处理，所以 Django 里更关注的是模型（Model）、模板(Template)和视图（Views），称为 MTV模式，各自职责如下： 层次 职责 模型（Model），即数据存取层 处理与数据相关的所有事务： 如何存取、如何验证有效性、包含哪些行为以及数据之间的关系等。 模板(Template)，即表现层 处理与表现相关的决定： 如何在页面或其他类型文档中进行显示。 视图（View），即业务逻辑层 存取模型及调取恰当模板的相关逻辑。模型与模板的桥梁 Django 框架的核心组件及设计哲学： 对象关系映射 (ORM,object-relational mapping)：以Python类形式定义你的数据模型，ORM将模型与关系数据库连接起来，你将得到一个非常容易使用的数据库API，同时你也可以在Django中使用原始的SQL语句。 URL 分派：使用正则表达式匹配URL，你可以设计任意的URL，没有框架的特定限定。像你喜欢的一样灵活。 模版系统：使用Django强大而可扩展的模板语言，可以分隔设计、内容和Python代码。并且具有可继承性。 表单处理：你可以方便的生成各种表单模型，实现表单的有效性检验。可以方便的从你定义的模型实例生成相应的表单。 Cache系统：可以挂在内存缓冲或其它的框架实现超级缓冲 －－ 实现你所需要的粒度。 会话(session)，用户登录与权限检查，快速开发用户会话功能。 国际化：内置国际化系统，方便开发出多种语言的网站。 自动化的管理界面：不需要你花大量的工作来创建人员管理和更新内容。Django自带一个ADMIN site,类似于内容管理系统 Djongo安装Djongo安装分为三步： 安装 Python 安装 Python 虚拟环境 安装 Django 第一步不在赘述，注意使用Python3及以上版本 第二步安装虚拟环境的目的是为了解决电脑中的软件相互依赖，每个程序都要依赖某些其他程序，而且要找到运行其他软件的设置（环境变量），编写新软件程序时，可能（经常）要修改其他软件所需的依赖或环境变量，这一步可能会导致各种问题，因此要避免。 Python 虚拟环境能解决这个问题。它把软件所需的全部依赖和环境变量包装到一个文件系统中，与电脑中的其他软件隔离开。 直接使用命令：pip install virtualenv 即可安装完成。 安装完成后执行命令：virtualenv env_mysite为我们自己的项目创建虚拟环境，注意env_mysite可以自定义，执行完成后我们发现在我们电脑家目录下就创建好了一个 \\env_mysite 的文件夹，virtualenv 创建了一个完整的 Python 安装，它与其他软件是隔离开的，因此开发项目时不会影响系统中的其他软件。 我们需要激活此虚拟环境，使用命令：env_mysite\\scripts\\activate，激活后我们就可以使用此虚拟环境。 第三步安装Djongo，直接在虚拟环境下执行命令：pip install django==1.8.13，即可安装Djongo1.8.13版本完成 新建Djongo项目在虚拟环境中执行django-admin startproject mysite，如果不使用虚拟环境，也可以自己找到项目位置，执行此命令创建项目。命令执行完成后我们看到Djongo为我们创建了如下文件： 1234567mysite/ manage.py mysite/ __init__.py settings.py urls.py wsgi.py 外层的mysite/ 根目录是项目的容器。这个目录的名称对 Django 没有什么作用，你可以根据喜好重命名。 manage.py 是一个命令行实用脚本，可以通过不同的方式与 Django 项目交互。 内部的mysite/ 目录是项目的 Python 包。导入这里面的内容时要使用目录的名称（如mysite.urls）。 mysite/init.py 是一个空文件，目的是让 Python 把这个目录识别为 Python 包。 mysite/settings.py 是 Django 项目的设置/配置。 mysite/urls.py 是 Django 项目的 URL 声明，即 Django 驱动的网站的“目录”。 mysite/wsgi.py 是兼容 WSGI 的 Web 服务器的入口点，用于伺服项目。 这里说明一下settings文件，这是整个项目的配置和设置，我们发现Djongo框架本身已经帮我们创建好了一些项目，这是为常见场景所做的约定，具体看INSTALLED_APPS的配置（这里打开项目为大家讲解一下此文件的配置内容）： 1234567891011# Application definition# 注意：此处添加自己开发的应用INSTALLED_APPS = ( &apos;django.contrib.admin&apos;, # 管理后天 &apos;django.contrib.auth&apos;, # 身份验证系统 &apos;django.contrib.contenttypes&apos;, # 内容类型框架 &apos;django.contrib.sessions&apos;, # 会话框架 &apos;django.contrib.messages&apos;, # 消息框架 &apos;django.contrib.staticfiles&apos;, # 管理静态文件的框架 &apos;cerealsOils&apos;, # 自己开发的应用) 使用这些项目我们需要在数据库中创建这些项目所需的表，执行命令即可自动创建：python manage.py migratehibernate框架，通过实体类上使用注解，自动创建表。 这样我们的项目就创建完成了，使用命令：python manage.py runserver 就可以启动项目啦，默认端口为8000，我们访问就可以看到主页了。 视图和URl配置创建视图函数创建视图需要在项目目录下新创建一个view.py文件，此文件中我们定义函数，返回给视图我们要展示的内容，如下： 12345678910111213141516171819202122232425# 从django.http 模块中导入HttpResponse 类。导入这个类是因为后面的代码要使用from django.http import HttpResponse# 视图函数，传入参数：jango.http.HttpRequest对象实例，注意此参数是视图函数必须的且是第一位的参数# 静态内容def hello(request): # 返回 Hello World 给response return HttpResponse(&quot;Hello World&quot;)# 动态内容def currentDatetime(request): now = datetime.datetime.now() html = &quot;现在时间： % now return HttpResponse(html)# 动态urldef timeAhead(request, offset): try: offset = int(offset) except ValueError: # 如果传给int() 函数的值不能转换成整数（如字符串&quot;foo&quot;），Python 会抛出ValueError 异常 raise Http404() dt = datetime.datetime.now() + datetime.timedelta(hours=offset) html = &quot;In %s hour(s), it will be %s.&quot; % (offset, dt) return HttpResponse(html) 配置URl若想把视图函数与特定的 URL 对应起来，要使用 URL 配置（URLconf）。URL 配置相当于 Django 驱动的网站的目录。简单来说，URL 配置把 URL 映射到相应的视图函数上，具体配置及说明如下： 12345678910111213141516171819# 从django.conf.urls 模块中导入两个函数：include，用于导入另一个 URL 配置模块；url，使用正则表达式模式匹配浏览器中的 URL，把它映射到 Django 项目中的某个模块上。from django.conf.urls import include, url# 从django.contrib 模块中导入admin 函数。这个函数传给include 函数，加载 Django 管理后台的 URLfrom django.contrib import admin# url实例列表urlpatterns = [ # 注意：正则表达式字符串前面的&apos;r&apos; 字符。它的目的是告诉 Python，那是“原始字符串”，不要解释里面的反斜线 # 第一个参数是模式匹配字符串（一个正则表达式，稍后说明），第二个参数是模式使用的视图函数 # url(r&apos;^$&apos;, index), # 为根地址指定一个 URL 模式 url(r&apos;^admin/&apos;, include(admin.site.urls)), # 静态类容 url(r&apos;^hello/$&apos;, hello), # ^ 和 $ 开头和结尾匹配模式 去掉hello就可以作为根地址 # 动态内容 url(r&apos;^nowTime/$&apos;, currentDatetime), # 动态URl，Django 的核心哲学之一是，URL 应该美观，既符合REST风格，这里能匹配time/plus/2 time/plus/20 url(r&apos;^time/plus/(\\d&#123;1,2&#125;)/$&apos;, timeAhead), # 正则匹配] 处理请求过程运行python manage.py runserver 命令时，manage.py 脚本在内层mysite 目录中寻找名为settings.py 的文件。这个文件中保存着当前 Django 项目的全部配置，各个配置的名称都是大写的，然后找到如下配置： 12# 指向URl配置文件，寻找URl详细配置ROOT_URLCONF = &apos;mysite.urls&apos; 找到匹配的模式之后，调用对应的视图函数，并把一个HttpRequest 对象作为第一个参数传给视图,视图函数必须返回一个HttpResponse 对象。 随后，余下的工作交给 Django 处理：把那个 Python 对象转换成正确的 Web 响应，并且提供合适的 HTTP 首部和主体（即网页的内容）。综上： 请求/hello/。 Django 查看ROOT_URLCONF 设置，找到根 URL 配置。 Django 比较 URL 配置中的各个 URL 模式，找到与/hello/ 匹配的那个。 如果找到匹配的模式，调用对应的视图函数。 视图函数返回一个HttpResponse 对象。 Django 把HttpResponse 对象转换成正确的 HTTP 响应，得到网页。 Djongo模板Django 模板是一些文本字符串，作用是把文档的表现与数据区分开。模板定义一些占位符和基本的逻辑（模板标签），规定如何显示文档。通常，模板用于生成 HTML，不过 Django 模板可以生成任何基于文本的格式。 变量和模板标签123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141* &#123;&#123; xxx &#125;&#125; 指定变量的值插入这里* &#123;% xxx %&#125; 模板标签，基本模板标签有如下 # 逻辑判断标签 # 注意，此示例中使用了 if elif else and not or 等逻辑判断语句，与python保持一致 # if标签中不能包含括号，如果需要使用括号判断，必须写成嵌套 if 标签语句 &#123;% if a1 and a2 %&#125; &lt;p&gt;a1为真并且a2为真，显示此内容&lt;/p&gt; &#123;% elif not a3 %&#125; &lt;p&gt; else if a3 为假，显示此内容，注意elif是可选标签&lt;/p&gt; &#123;% elif a4 or not a5 %&#125; &lt;p&gt; else if a4 为真，或者 a5 为假，显示此内容，注意elif是可选标签&lt;/p&gt; &#123;% else %&#125; &lt;p&gt; else显示此内容，注意else是可选标签&lt;/p&gt; &#123;% endif %&#125; # 迭代元素标签 # 正向迭代 &#123;% for item in item_list %&#125; &lt;li&gt;&#123;&#123; item &#125;&#125;&lt;/li&gt; &#123;% endfor %&#125; # 反向迭代 &#123;% for item in item_list reversed %&#125; &lt;li&gt;&#123;&#123; item &#125;&#125;&lt;/li&gt; &#123;% endfor %&#125; # 定义迭代列表为空的行为 &#123;% for item in item_list %&#125; &lt;p&gt;&#123;&#123; item &#125;&#125;&lt;/p&gt; &#123;% empty %&#125; &lt;p&gt;此处定义要迭代的元素为空的行为&lt;/p&gt; &#123;% endfor %&#125; # 获取迭代当前元素索引 &#123;% for item in item_list %&#125; &lt;p&gt;&#123;&#123; forloop.counter &#125;&#125;: forloop.counter表示当前元素索引&lt;/p&gt; &lt;p&gt;&#123;&#123; forloop.revcounter &#125;&#125;: forloop.revcounter表示剩余元素数量&lt;/p&gt; &#123;% if forloop.first %&#125; &lt;p&gt;forloop.first返回的是boolean，表示是否第一个元素&lt;/p&gt; &#123;% elif forloop.last %&#125; &lt;p&gt;forloop.last返回的也是boolean，表示是否最后一个元素&lt;/p&gt; &#123;% endif %&#125; &#123;% endfor %&#125; # 比较值相等标签 &#123;% ifequal A B %&#125; &lt;h1&gt;A 的值和 B 的值相等!&lt;/h1&gt; &#123;% else %&#125; &lt;h1&gt;A 的值和 B 的值不相等!&lt;/h1&gt; &#123;% endifequal %&#125; # 比较值不相等标签 &#123;% ifnotequal A &apos;JJW&apos; %&#125; &lt;h1&gt;A 的值不等于JJW!&lt;/h1&gt; &#123;% else %&#125; &lt;h1&gt;A 的值等于JJW!&lt;/h1&gt; &#123;% endifnotequal %&#125; # 模板注释 # 单行注释 &#123;# 这里是一个注释 #&#125; # 多行注释，comment标签 &#123;% comment %&#125; 第一行注释 第二行注释 &#123;% endcomment %&#125; # 过滤器 # 模板过滤器是在显示变量之前调整变量值的简单方式 # 把文本转换成小写，然后再显示 &#123;&#123; name|lower &#125;&#125; # 获取列表中的第一个元素，然后将其转换成大写 &#123;&#123; my_list|first|upper &#125;&#125; # 显示bio 变量的前 30 个词 &#123;&#123; bio|truncatewords:&quot;30&quot; &#125;&#125; # 在反斜线、单引号和双引号前面添加一个反斜线。可用于转义字符串 &#123;&#123; value|addslashes &#125;&#125; # 返回值长度，如果是列表，返回列表元素个数 &#123;&#123; name|length &#125;&#125; # include 模板标签 这个标签的作用是引入另一个模板的内容。它的参数是要引入的模板的名称，可以是变量，也可以是硬编码的字符串（放在引号里，单双引号都行） &#123;% include &apos;nav.html&apos; %&#125; &#123;% include &quot;nav.html&quot; %&#125; # 以下是使用示例 &lt;html&gt; &lt;body&gt; &#123;% include &quot;includes/nav.html&quot; %&#125; &lt;h1&gt;&#123;&#123; title &#125;&#125;&lt;/h1&gt; &lt;/body&gt; &lt;/html&gt; # includes/nav.html &lt;div id=&quot;nav&quot;&gt; You are in: &#123;&#123; current_section &#125;&#125; &lt;/div&gt; # 模板继承 # 模板继承是指创建一个基底“骨架”模板，包含网站的所有通用部分，并且定义一些“块”，让子模板覆盖。 # 首先定义一个基地模板 # &#123;% block xxx %&#125;&#123;% endblock %&#125; 表示此标签内容可以被子模板重写 &lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;title&gt;&#123;% block title %&#125;&#123;% endblock %&#125;&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;My helpful timestamp site&lt;/h1&gt; &#123;% block content %&#125;&#123;% endblock %&#125; &#123;% block footer %&#125; &lt;hr&gt; &lt;p&gt;Thanks for visiting my site.&lt;/p&gt; &#123;% endblock %&#125; &lt;/body&gt; &lt;/html&gt; # 然后定义子模板 # 子模板需要继承父模板 &#123;% extends &quot;base.html&quot; %&#125; # 重写依然要使用 &#123;% block xxx %&#125;&#123;% endblock %&#125; 标签 &#123;% extends &quot;base.html&quot; %&#125; &#123;% block title %&#125;Future time&#123;% endblock %&#125; &#123;% block content %&#125; &lt;p&gt; In &#123;&#123; hour_offset &#125;&#125; hour(s), it will be &#123;&#123; next_time &#125;&#125;. &lt;/p&gt; &#123;% endblock %&#125; 使用模板系统Django 系统经过配置后可以使用一个或多个模板引擎（如果不用模板，那就不用配置）。Django 自带了一个内置的后端，用于支持自身的模板引擎，即 Django Template Language（DTL），若想在 Python 代码中使用 Django 的模板系统，基本方式如下： 以字符串形式提供原始的模板代码，创建Template 对象。 在Template 对象上调用render() 方法，传入一系列变量（上下文）。返回的是完全渲染模板后得到的字符串，模板中的变量和模板标签已经根据上下文求出值了。 以上步骤我们都可以使用一个函数来完成，那就是render()函数，render() 的第一个参数是请求对象，第二个参数是模板名称，第三个参数可选，是一个字段，用于创建传给模板的上下文。如果不指定第三个参数，render() 使用一个空字典，具体使用如下介绍。 模板目录及模板加载为了从文件系统中加载模板，Django 提供了便利而强大的 API，力求去掉模板加载调用和模板自身的冗余。若想使用这个模板加载 API，首先要告诉框架模板的存储位置。这个位置在设置文件中配置，打开settings.py 文件，找到TEMPLATES 设置。它的值是一个列表，分别针对各个模板引擎： 123456789101112131415161718192021222324TEMPLATES = [ &#123; # BACKEND 的值是一个点分 Python 路径，指向实现 Django 模板后端 API 的模板引擎类 &apos;BACKEND&apos;: &apos;django.template.backends.django.DjangoTemplates&apos;, # DIRS 定义一个目录列表，模板引擎按顺序在里面查找模板源文件。 # 当前设置表示在项目根目录中放一些主模板，模板目录不一定非得叫&apos;templates&apos;，可以自定义 &apos;DIRS&apos;: [os.path.join(BASE_DIR, &apos;templates&apos;)], # 去应用所在位置查找模板，APPS_DIRS 设为True 时，DjangoTemplates 会在INSTALLED_APPS 中的各个应用里查找名为“templates”的子目录。这样，即使DIRS 为空，模板引擎还能查找应用模板。 &apos;APP_DIRS&apos;: True, # OPTIONS 是一些针对后端的设置 &apos;OPTIONS&apos;: &#123; # 默认的处理器上下文 &apos;context_processors&apos;: [ &apos;django.template.context_processors.debug&apos;, &apos;django.template.context_processors.request&apos;, &apos;django.contrib.auth.context_processors.auth&apos;, &apos;django.contrib.messages.context_processors.messages&apos;, ], &#125;, &#125;,] 查找模板逻辑 如果APP_DIRS 的值是True，而且使用 DTL，在当前应用中查找“templates”目录。 如果在当前应用中没找到模板，把传给它的模板名称添加到DIRS 中的各个目录后面，按顺序在各个目录中查找。假如DIRS 的第一个元素是’/home/django/mysite/templates’，调用查找的模板是/home/django/mysite/templates/current_datetime.html。 找不到指定名称对应的模板，抛出TemplateDoesNotExist 异常。 使用示例及说明视图函数如下定义： 123456from django.shortcuts import renderimport datetimedef currentDatetime(request): now = datetime.datetime.now() return render(request, &apos;test/current_datetime.html&apos;, &#123;&apos;current_date&apos;: now&#125;) 通过以上示例我们发现： 不用再导入get_template、Template、Context 或HttpResponse 了，而要导入django.shortcuts.render import datetime 不变。 在current_datetime 函数中，仍然要计算now，不过加载模板、创建上下文、渲染模板和创建HttpResponse对象全由render() 调用代替了。render() 的返回值是一个HttpResponse 对象，因此在视图中可以直接返回那个值。 注意上述我们还使用了模板子目录：test/current_datetime.html，表示去根目录下寻找templates目录下的test目录，找到模板。 Djongo模型Django 非常适合构建数据库驱动型网站，它提供了简单而强大的工具，易于使用 Python 执行数据库查询，本章就说明这个功能，即 Django 的数据库层。 配置数据库数据库连接的配置也在settings文件中，具体如下： 1234567891011121314151617181920# 数据库配置，这里使用集成的sqllite3，我们配置自己的数据库，类似于我们Java项目中的配置文件中配置即可DATABASES = &#123; &apos;default&apos;: &#123; &apos;ENGINE&apos;: &apos;django.db.backends.sqlite3&apos;, # ENGINE 告诉 Django 使用哪个数据库引擎。 &apos;NAME&apos;: os.path.join(BASE_DIR, &apos;db.sqlite3&apos;), # NAME 告诉 Django 数据库的名称。 &#125;&#125;# 配置MySQL数据库# DATABASES = &#123;# &apos;default&apos;: &#123;# &apos;ENGINE&apos;: &apos;django.db.backends.mysql&apos;, # 或者使用 mysql.connector.django# &apos;NAME&apos;: &apos;test&apos;,# &apos;USER&apos;: &apos;test&apos;,# &apos;PASSWORD&apos;: &apos;test123&apos;,# &apos;HOST&apos;:&apos;localhost&apos;,# &apos;PORT&apos;:&apos;3306&apos;,# &#125;# &#125; 创建应用下面说明项目和应用的区别： 一个项目是一系列 Django 应用的实例，外加那些应用的配置。严格来说，一个项目唯一需要的是一个设定文件，定义数据库连接信息、安装的应用列表、DIRS，等等。 一个应用是一系列便携的 Django 功能，通常包含模型和视图。打包在一个 Python 包里。Django 自带了一些应用，例如管理后台。这些应用的独特之处是便携，可以在多个项目中复用。 在项目目录，注意是项目目录，使用如下命令创建新的应用，并指定自定义应用名称：python manage.py startapp 应用名称。 Django 通过模型在背后执行 SQL，返回便利的 Python 数据结构，表示数据库表中的行。Django 还通过模型表示 SQL 无法处理的高层级概念，这么做的好处如下： 内省（introspection）有开销，而且不完美。为了提供便利的数据访问 API，Django 需要以某种方式知晓数据库布局，而这一需求有两种实现方式。第一种是使用Python 明确描述数据，第二种是在运行时内省数据库，推知数据模型。第二种方式在一个地方存储表的元数据，看似更简单，其实会导致几个问题。首先，运行时内省数据库肯定有消耗。如果每次执行请求，或者只是初始化 Web 服务器都要内省数据库，那带来的消耗是无法接受的，其次，有些数据库，尤其是旧版 MySQL，存储的元数据不足以完成内省。 Python 编写起来让人心情舒畅，而且使用 Python 编写所有代码无需频繁让大脑切换情境。在一个编程环境（思维）中待久了，有助于提升效率。在 SQL 和 Python 之间换来换去容易打断状态。 把数据模型保存在代码中比保存在数据库中易于做版本控制，易于跟踪数据布局的变化。 SQL 对数据布局的元数据只有部分支持。例如，多数数据库系统没有提供专门表示电子邮件地址或URL 的数据类型。而 Django 模型有。高层级的数据结构有助于提升效率，让代码更便于复用。 不同数据库平台使用的 SQL 不一致。 分发 Web 应用程序时，更务实的做法是分发一个描述数据布局的 Python 模块，而不是分别针对MySQL、PostgreSQL 和 SQLite 的CREATE TABLE 语句。 创建自己的模型在我们新创建的应用的models.py文件中，添加自己定义的模型，如下： 让 Django 具有基本的数据访问能力只需编写这些代码。一般，一个模型对应于一个数据库表，模型中的各个属性分别对应于数据库表中的一列。属性的名称对应于列的名称，字段的类型（如CharField）对应于数据库列的类型(如varchar) 123456789101112131415161718192021222324252627282930313233343536# 厂家class Manufacturers(models.Model): name = models.CharField(max_length=30) address = models.CharField(max_length=50) city = models.CharField(max_length=60) province = models.CharField(max_length=30) website = models.URLField(blank=True, null=True, verbose_name=&apos;网址&apos;) # 表单允许为空 修改数据库结构，表示字段可为空 def __str__(self): return u&apos;%s&apos; % (self.name)# 经销商class Vender(models.Model): name = models.CharField(max_length=30) address = models.CharField(max_length=50) city = models.CharField(max_length=60) province = models.CharField(max_length=30) telephone = models.CharField(max_length=20) def __str__(self): return u&apos;%s %s %s %s %s&apos; % (self.name, self.address, self.city, self.province, self.telephone)# 产品class Product(models.Model): title = models.CharField(max_length=100) vender = models.ManyToManyField(Vender) # 多对多关系 manufacturers = models.ForeignKey(Manufacturers) # 一对多 product_date = models.DateField() # fields = (&apos;title&apos;, &apos;product_date&apos;, &apos;vender&apos;, &apos;manufacturers&apos;) def __str__(self): return u&apos;%s %s&apos; % (self.title, self.product_date) # 任何模型都可以使用Meta 类指定多个针对所在模型的选项。 class Meta: ordering = [&apos;product_date&apos;] 注意：多对多关系，在上述示例模型中，Django 会创建一个额外的表，一个多对多联结表（join table），处理Product与Vender之间的对应关系。 安装模型在settings文件中注册上我们自己创建的应用，注册位置已经在之前描述过，如下： 123456789101112# Application definition# 注意：此处添加自己开发的应用INSTALLED_APPS = ( &apos;django.contrib.admin&apos;, # 管理后台 &apos;django.contrib.auth&apos;, # 身份验证系统 &apos;django.contrib.contenttypes&apos;, # 内容类型框架 &apos;django.contrib.sessions&apos;, # 会话框架 &apos;django.contrib.messages&apos;, # 消息框架 &apos;django.contrib.staticfiles&apos;, # 管理静态文件的框架 &apos;cerealsOils&apos;, # 自己开发的应用) 注册好后就可以验证和安装模型： 验证模型使用命令：python manage.py check check 命令运行 Django 系统检查框架，即验证 Django 项目的一系列静态检查。如果一切正常，你将看到这个消息：System check identified no issues (0 silenced)，不然会抛出出错位置的异常 安装模型使用命令：python manage.py makemigrations cerealsOils，这样我们就安装好了模型，并根据模型定义创建好了数据库表 查看建表语句可以执行命令：python manage.py sqlmigrate cerealsOils 0001，这样建表语句就会输出出来 Djongo后台管理对多数现代的网站而言，管理界面是基础设施的重要组成部分。这是一个 Web 界面，限制只让授信的网站管理员访问，用于添加、编辑和删除网站内容。常见的示例有：发布博客的界面，网站管理人员审核用户评论的后端，客户用来更新新闻稿的工具。不过，管理界面有个问题：构建起来繁琐。构建面向公众的功能时，Web 开发是有趣的，但是管理界面一成不变，要验证用户身份、显示并处理表单、验证输入，等等。这个过程无趣、乏味。在 Django 中，构建管理界面不算个事， Django 为我们自动生成的管理界面，了解它为模型提供的便利界面，以及可以使用的其他功能。 使用管理后台之前创建项目时我们执行了django-admin startproject mysite命令时，Django 为我们创建并配置了默认的管理后台。我们只需创建一个管理员用户（超级用户），就可以登录管理后台。 创建管理用户：python manage.py createsuperuser 输入要创建的用户：Username: admin 输入邮箱地址：Email address: admin@example.com 输入用户密码，需要输入两次确认：Password: ** 启动服务器，访问ttp://127.0.0.1:8000/admin/就可以进入登录页面，登录后具体操作就可以被看懂了，这里不再赘述，可以启动项目为大家演示一下。 将我们创建的模型添加至后台管理在我们新创建的项目目录下创建admin.py文件，并添加如下代码，这样就将我们创建的模型添加至了后天管理系统： 1234567from django.contrib import adminfrom .models import Manufacturers, Vender, Product# 注册我们创建的模型admin.site.register(Manufacturers, ManufacturersAdmin)admin.site.register(Vender, VenderAdmin)admin.site.register(Product, ProductAdmin) 将字段定义为可选（非必填）及自定义字段标注默认我们创建的模型在后台管理页面都是必填字段，及显示的名称都是字段的英文名称，我们可以修改model，添加一下属性，来设置字段为非必填及显示的名称为可以看懂的名称，如下示例： 1234567891011# 厂家class Manufacturers(models.Model): name = models.CharField(max_length=30, verbose_name=&apos;厂家名称&apos;) address = models.CharField(max_length=50, verbose_name=&apos;具体地址&apos;) city = models.CharField(max_length=60, verbose_name=&apos;所在地市&apos;) province = models.CharField(max_length=30, verbose_name=&apos;所在省份&apos;) website = models.URLField(blank=True, null=True, verbose_name=&apos;网址&apos;) # 表单允许为空 修改数据库结构，表示字段可为空 def __str__(self): return u&apos;%s&apos; % (self.name)... 注：上述示例中：blank=True表示表单输入可为空， null=True表示数据库存值是如果是空也存为空，而不是字符”NULL”,verbose_name=’网址’表示自定义名称 自定义ModelAdmin类具体使用及属性设置明细见如下示例（此处可以打开后台管理界面给大家演示一下）： 123456789101112131415161718192021222324252627from django.contrib import adminfrom .models import Manufacturers, Vender, Product# Register your models here.class ProductAdmin(admin.ModelAdmin): list_display = (&apos;title&apos;, &apos;product_date&apos;, &apos;manufacturers&apos;) # 注意 此处不能包含多对多字段 search_fields = (&apos;title&apos;, &apos;product_date&apos;) # 添加列表搜索框内容，注意只有一个框，但输入内容后悔搜索多个字段，类似于ES的机制 list_filter = (&apos;product_date&apos;,) # 右侧的过滤条 可以是日期 布尔 一对一外键类型 date_hierarchy = &apos;product_date&apos; # 显示日期导航，注意只能添加一个导航 ordering = (&apos;-product_date&apos;,) # 列表根据日期降序排序 fields = (&apos;product_date&apos;, &apos;title&apos;, &apos;manufacturers&apos;, &apos;vender&apos;) # 自定义编辑表单，修改卡片页面排序，还可以排除字段，排除的字段将不能编辑 raw_id_fields = (&apos;manufacturers&apos;,) # 针对一对一内容太多而做的界面优化，一般为下拉框内容太多的优化 filter_horizontal = (&apos;vender&apos;,) # 针对一对多内容太多而做的通过弹出框筛选class VenderAdmin(admin.ModelAdmin): list_display = (&apos;name&apos;, &apos;address&apos;) search_fields = (&apos;name&apos;, &apos;address&apos;)class ManufacturersAdmin(admin.ModelAdmin): list_display = (&apos;name&apos;, &apos;address&apos;) search_fields = (&apos;name&apos;, &apos;address&apos;) # 将自定义的ModelAdmin注册到后台管理admin.site.register(Manufacturers, ManufacturersAdmin)admin.site.register(Vender, VenderAdmin)admin.site.register(Product, ProductAdmin)","categories":[{"name":"Python","slug":"Python","permalink":"https://jjw-story.github.io/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://jjw-story.github.io/tags/Python/"},{"name":"Django","slug":"Django","permalink":"https://jjw-story.github.io/tags/Django/"}],"author":"JJW"},{"title":"Django-02","slug":"Django-02","date":"2019-08-04T02:31:02.000Z","updated":"2019-08-11T05:40:34.779Z","comments":true,"path":"2019/08/04/Django-02/","link":"","permalink":"https://jjw-story.github.io/2019/08/04/Django-02/","excerpt":"","text":"Djongo表单从请求对象中获取数据 属性 方法说明 示例 request.path 完整的路径，不含域名，但是含前导斜线 “/hello/” request.get_host() 主机名（即通常所说的“域名”） “127.0.0.1:8000”或“www.example.com” request.get_full_path() 包含查询字符串（如果有的话）的路径 “/hello/?print=true” request.is_secure() 通过 HTTPS 访问时为True，否则为False True 或False request.META[‘HTTP_USER_AGENT’] 入站前的 URL（可能没有） request.META[‘HTTP_USER_AGENT’] 浏览器的用户代理（可能没有），请求头信息 “Mozilla/5.0 (X11; U; Linux i686; fr-FR; rv:1.8.1.17) Gecko/20080829 Firefox/2.0.0.17” request.META[‘REMOTE_ADDR’] 客户端的 IP 地址 “12.345.67.89”。（如果请求经由代理，这个首部的值可能是一组 IP 地址，以逗号分隔） 简单的表单使用示例这里可以打开页面及项目代码为大家演示 视图函数如下： 123456789101112131415161718192021222324from django.shortcuts import renderfrom django.http import HttpResponsefrom cerealsOils.models import Product# Create your views here.def product_search(request): return render(request, &apos;product_search.html&apos;)def search(request): errors = [] if &apos;q&apos; in request.GET : # 通过request对象直接获取传统get请求的参数： q=xxx if ( request.GET[&apos;q&apos;]) : # 判断表单q参数是否为空 q = request.GET[&apos;q&apos;] if len(q) &gt; 5 : errors.append(&quot;查询关键字不能超过五个字符&quot;) else : products = Product.objects.filter(title__contains=q) # 过滤查询 # name = products[0].vender[0] return render(request, &apos;product_search.html&apos;, &#123;&apos;products&apos;: products, &apos;query&apos;: q&#125;) else : # products = Product.objects.all() # 查询所有 errors.append(&quot;查询关键字不能为空&quot;) return render(request, &apos;product_search.html&apos;, &#123;&apos;errors&apos;:errors&#125;) URL配置如下： 12url(r&apos;^product_search/$&apos;, views.product_search), # 查询页面跳转url(r&apos;^search/$&apos;, views.search), # 查询控制层 product_search模板如下： 1234567891011121314151617181920212223242526272829303132&lt;html&gt; &lt;head&gt; &lt;title&gt;产品查询&lt;/title&gt; &lt;meta charset=&apos;UTF-8&apos;&gt; &lt;/head&gt; &lt;body&gt; &#123;% if errors %&#125; &lt;ul&gt; &#123;% for error in errors %&#125; &lt;li&gt;&#123;&#123; error &#125;&#125;&lt;/li&gt; &#123;% endfor %&#125; &lt;/ul&gt; &#123;% endif %&#125; &lt;!-- &lt;form action=&quot;/search/&quot; method=&quot;get&quot;&gt; --&gt; &lt;form action=&quot;/search/&quot; method=&quot;get&quot;&gt; &lt;input type=&quot;text&quot; name=&quot;q&quot;&gt; &lt;input type=&quot;submit&quot; value=&quot;Search&quot;&gt; &lt;/form&gt; &lt;p&gt;查询关键字: &lt;strong&gt;&#123;&#123; query &#125;&#125;&lt;/strong&gt;&lt;/p&gt; &#123;% if products %&#125; &lt;p&gt;产品总数 &#123;&#123; products|length &#125;&#125; 产品&#123;&#123; books|pluralize &#125;&#125;&lt;/p&gt; &lt;ul&gt; &#123;% for product in products %&#125; &lt;li&gt;产品名称：&#123;&#123; product.title &#125;&#125; 生产日期：&#123;&#123; product.product_date &#125;&#125;&lt;/li&gt; &#123;% endfor %&#125; &lt;/ul&gt; &#123;% else %&#125; &lt;p&gt;没有查询到商品&lt;/p&gt; &#123;% endif %&#125; &lt;/body&gt;&lt;/html&gt; 这样就完成了一个表单的使用示例 联系表单Django 自带了一个表单库，django.forms，它能处理从显示 HTML 表单到验证。 这个表单框架的主要用法是为要处理的每个 HTML 表单定义一个Form 类，这个类可以放在任意位置，例如直接放在views.py 文件中，不过社区的约定是，把Form 类放在单独的forms.py 文件中。 下面对表单框架的各部分功能以及自定义校验规则等进行示例： 在views.py 文件所在的目录（mysite）中创建这个文件，然后输入下述内容： 12345678910111213141516# 引入框架的表单库from django import formsclass ContactForm(forms.Form): subject = forms.CharField(max_length=20, min_length=2) # 校验长度 email = forms.EmailField(required=False) # 选项表示表单内容非必填 message = forms.CharField(widget=forms.Textarea) # 可以直接设置表单样式，注意表单样式设置也可以很灵活，使用时具体查看资料 # 自定义校验规则 # 注意校验方法名，需要以clean_开头，字段名称为结尾 # 再检查此规则前定义字段时设置的校验规则已经校验完毕 def clean_message(self): message = self.cleaned_data[&apos;message&apos;] if &quot;香港&quot; in message: raise forms.ValidationError(&quot;消息内容不能包含敏感词&quot;) return message # 一定要显式的返回清理后的值，cleaned_data是清理值 定义视图函数： 1234567891011121314151617def contact(request): if request.method == &apos;POST&apos;: form = ContactForm(request.POST) # Post请求体接受为form表单对象，这点类似于mvc if form.is_valid(): # 校验表单输入是否符合定义的校验规则 cd = form.cleaned_data send_mail( cd[&apos;subject&apos;], cd[&apos;message&apos;], cd.get(&apos;email&apos;, &apos;noreply@example.com&apos;), [&apos;siteowner@example.com&apos;], ) return HttpResponseRedirect(&apos;/contact/thanks/&apos;) else: form = ContactForm( initial=&#123;&apos;subject&apos;: &apos;默认值&apos;&#125; # 设置form表单默认值 ) return render(request, &apos;test/contact_form.html&apos;, &#123;&apos;form&apos;: form&#125;) 定义模板文件： 123456789101112131415161718192021222324252627282930313233&lt;html&gt; &lt;head&gt; &lt;title&gt;联系表单&lt;/title&gt; &lt;meta charset=&apos;UTF-8&apos;&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;表单测试&lt;/h1&gt; &#123;% if form.errors %&#125; &lt;!-- 接受表单对象数据 --&gt; &lt;p style=&quot;color: red;&quot;&gt; 请处理表单错误内容&#123;&#123; form.errors|pluralize &#125;&#125; &lt;/p&gt; &#123;% endif %&#125; &lt;form action=&quot;&quot; method=&quot;post&quot;&gt; &lt;div class=&quot;field&quot;&gt; &#123;&#123; form.subject.errors &#125;&#125; &lt;label for=&quot;id_subject&quot;&gt;科目:&lt;/label&gt; &#123;&#123; form.subject &#125;&#125; &lt;/div&gt; &lt;div class=&quot;field&quot;&gt; &#123;&#123; form.email.errors &#125;&#125; &lt;label for=&quot;id_email&quot;&gt;输入您的邮箱:&lt;/label&gt; &#123;&#123; form.email &#125;&#125; &lt;/div&gt; &lt;div class=&quot;field&quot;&gt; &#123;&#123; form.message.errors &#125;&#125; &lt;label for=&quot;id_message&quot;&gt;消息内容:&lt;/label&gt; &#123;&#123; form.message &#125;&#125; &lt;/div&gt; &#123;% csrf_token %&#125; &lt;!-- 跨域处理 --&gt; &lt;input type=&quot;submit&quot; value=&quot;提交&quot;&gt; &lt;/form&gt; &lt;/body&gt;&lt;/html&gt; 至此一个联系表单就创建完成了 高级视图和URL简化导入函数方式简化导入函数方式就是说我们直接导入views 模块自身，如下示例： 123456# 直接导入viewfrom cerealsOils import viewsurlpatterns = [ url(r&apos;^product_search/$&apos;, views.product_search), # 查询页面跳转 url(r&apos;^search/$&apos;, views.search), # 查询控制层 具名分组（Python具名函数的使用）正则表达式分组（通过括号实现）捕获 URL 中的片段， 123456urlpatterns = [ url(r&apos;^reviews/2003/$&apos;, views.special_case_2003), url(r&apos;^reviews/([0-9]&#123;4&#125;)/$&apos;, views.year_archive), url(r&apos;^reviews/([0-9]&#123;4&#125;)/([0-9]&#123;2&#125;)/$&apos;, views.month_archive), url(r&apos;^reviews/([0-9]&#123;4&#125;)/([0-9]&#123;2&#125;)/([0-9]+)/$&apos;, views.review_detail),] 如上捕获参数时，我们可以通过具名分组，为参数赋予名称： 123456urlpatterns = [ url(r&apos;^reviews/2003/$&apos;, views.special_case_2003), url(r&apos;^reviews/(?P&lt;year&gt;[0-9]&#123;4&#125;)/$&apos;, views.year_archive), url(r&apos;^reviews/(?P&lt;year&gt;[0-9]&#123;4&#125;)/(?P&lt;month&gt;[0-9]&#123;2&#125;)/$&apos;, views.month_archive), url(r&apos;^reviews/(?P&lt;year&gt;[0-9]&#123;4&#125;)/(?P&lt;month&gt;[0-9]&#123;2&#125;)/(?P&lt;day&gt;[0-9]&#123;2&#125;)/$&apos;,views.review_detail),] 如上示例含义如下： 对/reviews/2005/03/ 的请求调用views.month_archive(request, year=’2005’, month=’03’) 函数，而不是views.month_archive(request,’2005’,’03’)。 对/reviews/2003/03/03/ 的请求调用views.review_detail(request, year=’2003’, month=’03’,day=’03’) 函数。 匹配/分组算法URL 配置解析器解析正则表达式中具名分组和非具名分组所采用的算法如下： 如果有具名分组，使用具名分组，忽略非具名分组。 否则，以位置参数传递所有非具名分组。 不论如何，额外的关键字参数都会传给视图。 URL及视图一些特性 注意url的匹配规则，它不区分请求的类型，例如GET POST等，只要url一样，都交给同一个视图函数处理。 不管正则表达式匹配的是什么类型，捕获的每个参数都以普通的 Python 字符串传给视图。 例如： 1url(r&apos;^reviews/(?P&lt;year&gt;[0-9]&#123;4&#125;)/$&apos;, views.year_archive) 虽然[0-9]{4} 只匹配字符串中的整数，但是传给views.year_archive() 视图函数的year 参数是字符串，而不是整数。 可以为视图函数的参数指定默认值(利用的也是Python函数的特性) 例如： 12345678urlpatterns = [ url(r&apos;^reviews/$&apos;, views.page), # 使用默认参数 url(r&apos;^reviews/page(?P&lt;num&gt;[0-9]+)/$&apos;, views.page), # 这里有传值，不使用默认参数]# 视图（在 reviews/views.py 文件中）def page(request, num=&quot;1&quot;):# 输出指定数量的书评 性能问题：urlpatterns 中的每个正则表达式在首次访问时编译，因此系统的速度异常得快。 引入其他URl配置urlpatterns 在任何位置都可以“引入”其他 URL 配置模块。通过这一行为可以把一些 URL 放在另一些名下。 例如： 123456urlpatterns = [ # ... url(r&apos;^community/&apos;, include(&apos;django_website.aggregator.urls&apos;)), url(r&apos;^contact/&apos;, include(&apos;django_website.contact.urls&apos;)), # ...] 注意，这里的正则表达式没有$（匹配字符串末尾的符号），但是末尾有斜线。Django 遇到include() 时，会把截至那一位置匹配的 URL 截断，把余下的字符串传给引入它的 URL 配置，做进一步处理。 可以利用这一点将公共的路径提取出来，示例如下： 1234567891011注意，url的配置可以抽取共性配置urlpatterns = [ url(r&apos;^chehejia/&apos;, include([ # 引入 ，引入可以引入其他URL配置模块，这里是写死的，还可以写成引入 xxx，其中xxx指的是 .py 文件，此文件中也有urlpatterns变量定义了url映射。 可以根据url的全路径匹配到引入模块的映射函数 url(r&apos;^add/$&apos;, views.add), url(r&apos;^edit/$&apos;, views.edit), url(r&apos;^delete/$&apos;, views.delete), url(r&apos;^save/$&apos;, views.save), ]) ),] 注意：通过此方式引入的URl配置，我们在父URl中使用正则捕获到的参数，是可以传递给子URl视图函数的，所以可以放心使用 传递额外参数URL 配置允许向视图函数传递额外的参数，这些参数放在一个 Python 字典中。django.conf.urls.url() 函数的第三个参数是可选的，如果指定，应该是一个字典，指定要传给视图函数的额外关键字参数及其值。 例如： 12345urlpatterns = [ url(r&apos;^reviews/(?P&lt;year&gt;[0-9]&#123;4&#125;)/$&apos;, views.year_archive, &#123;&apos;foo&apos;: &apos;bar&apos;&#125; # 具名分组及设置默认参数 ),] 同样include()也同样适用此特性： 1234567891011# main.pyfrom django.conf.urls import include, url urlpatterns = [ url(r&apos;^reviews/&apos;, include(&apos;inner&apos;), &#123;&apos;reviewid&apos;: 3&#125;),]# inner.pyurlpatterns = [ url(r&apos;^archive/$&apos;, views.archive), url(r&apos;^about/$&apos;, views.about),] 反向解析URl这个不太明白，我认为就是转发请求的时候使用，注意讨论一下 Django 提供了一种方案，只需在 URL 映射中设计 URL。我们为其提供 URL 配置，然后可以双向使用： 从用户（浏览器）请求的 URL 开始，这个方案能调用正确的 Django 视图，并从 URL 中提取可能需要的参数及其值，传给视图。 从 Django 视图对应的标识以及可能传入的参数值开始，获取相应的 URL。 第一点就是我们目前所讨论的处理方式。第二点称为反向解析 URL、反向匹配 URL、反向查找 URL 或 URL反转。 Django 在不同的层中提供了执行 URL 反转所需的工具： 在模板中，使用url 模板标签。 在 Python 代码中，使用django.core.urlresolvers.reverse() 函数。 在处理 Django 模型实例 URL 相关的高层代码中，使用get_absolute_url() 方法。 示例： 123456789101112131415161718192021# URl描述urlpatterns = [ url(r&apos;^reviews/([0-9]&#123;4&#125;)/$&apos;, views.year_archive, name=&apos;reviews-year-archive&apos;),]# 模板中如下描述&lt;ul&gt; &#123;% for yearvar in year_list %&#125; &lt;li&gt;&lt;a href=&quot;&#123;% url &apos;reviews-year-archive&apos; yearvar %&#125;&quot;&gt;&#123;&#123; yearvar &#125;&#125; Archive&lt;/a&gt;&lt;/li&gt; &#123;% endfor %&#125;&lt;/ul&gt;# 视图函数如下from django.core.urlresolvers import reversefrom django.http import HttpResponseRedirectdef redirect_to_year(request): # ... year = 2012 # ... return HttpResponseRedirect(reverse(&apos;reviews-year-archive&apos;, args=(year,))) URl命名空间URL 命名空间在反转具名 URL 模式时具有唯一确定性，即便不同的应用使用相同的名称也不怕。 正确使用 URL 命名空间的 Django 应用程序可以在同一个网站中多次部署。例如，django.contrib.admin 中有个AdminSite 类，可以轻易部署多个管理后台。URL 命名空间分为两部分，而且都是字符串： 应用命名空间。指明应用的名称。一个应用的每个实例都具有相同的应用命名空间。例如，你可能猜到了，Django 管理后台的应用命名空间是admin。 实例命名空间。标识具体的应用程序实例。实例命名空间在整个项目范围内应该是唯一的。不过，实例命名空间可以与应用命名空间相同，供应用的默认实例使用。例如，Django 管理后台实例的默认实例命名空间是admin 命名空间中的 URL 使用: 运算符指定。例如，管理后台的主页使用 admin:index 引用。其中，admin 是命名空间，index 是 URL 的名称。 命名空间还可以嵌套。members:reviews:index 在命名空间members 中查找命名空间reviews，再在里面查找index URL。 反转命名空间的URl的步骤 首先，Django 查找有没有匹配的应用命名空间（这里的reviews）。为此，会产出那个应用的实例列表。 如果有这么一个应用实例，Django 返回它的 URL 解析程序。当前应用可以通过请求的一个属性指定。预期有多个部署实例的应用应该在处理的请求上设定current_app 属性。 当前应用也可以手动指定，方法是作为参数传给reverse() 函数。 如果没有当前应用，Django 查找默认的应用实例。默认应用实例是指实例命名空间与应用命名空间匹配的实例（在这里是指名为reviews 的reviews 实例）。 如果没有默认的应用实例，Django 选中最后部署的应用实例，而不管实例的名称。 如果第 1 步找不到匹配的应用命名空间，Django 直接把它视作实例命名空间查找。 URL 命名空间和引入的 URL 配置示例把引入的 URL 配置放入命名空间中有两种方式。 第一种，在 URL 模式中为include() 提供应用和实例命名空间： 1url(r&apos;^reviews/&apos;, include(&apos;reviews.urls&apos;, namespace=&apos;author-reviews&apos;, app_name=&apos;reviews&apos;)) 上述示例把reviews.urls 中定义的 URL 放在应用命名空间reviews 中，放在实例命名空间author-reviews中。 第二种，引入包含命名空间数据的对象。如果使用include() 引入一组url() 实例，那个对象中的 URL 都添加到全局命名空间中。然而，include() 的参数还可以是一个三元素元组： 123456reviews_patterns = [ url(r&apos;^$&apos;, views.IndexView.as_view(), name=&apos;index&apos;), url(r&apos;^(?P&lt;pk&gt;\\d+)/$&apos;, views.DetailView.as_view(), name=&apos;detail&apos;),]url(r&apos;^reviews/&apos;, include((reviews_patterns, &apos;reviews&apos;, &apos;author-reviews&apos;))), 上述示例把指定的 URL 模式引入指定的应用和实例命名空间中。 记得要把一个元组传给include()。如果直接传入三个参数，例如include(reviews_patterns, ‘reviews’,’author-reviews’)，Django 不会抛出错误，但是根据include() 的签名，’reviews’ 是实例命名空间，’author-reviews’ 是应用命名空间，而正确的顺序应该反过来。 高级模板技术RequestContext和上下文处理器模板要在上下文中渲染。上下文是django.template.Context 的实例，不过 Django 还提供了一个子类，django.template.RequestContext，其行为稍有不同。 RequestContext 默认为模板上下文添加很多变量，例如HttpRequest 对象或当前登录用户的信息，例如我们在视图函数中获取到的request对象，它就是Djongo为我们提供的上下文处理器，我们可以在此处理器中获取很多参数: 示例： 12345def view_1(request): # ... t = loader.get_template(&apos;template1.html&apos;) c = RequestContext(request, &#123;&apos;message&apos;: &apos;I am view 1.&apos;&#125;, processors=[custom_proc]) return t.render(c) 上下文处理器使用示例，提供公共的上下文处理器： 12345678910111213141516171819202122232425262728# 定义一个上下文处理器，提供 &apos;app&apos;、&apos;user&apos; 和 &apos;ip_address&apos;，可以在处理器中为多个请求提供共同的必要的上下文# 注意：上下文处理器必须返回一个字典# 自定义上下文处理器一般放在单独项目或者项目下的context_processors.py中def custom_proc(request): return &#123; &apos;app&apos;: &apos;我的上下文测试&apos;, &apos;user&apos;: request.user, &apos;ip_address&apos;: request.META[&apos;REMOTE_ADDR&apos;] &#125;# 引用上下文处理器直接返回给模板进行渲染# 注意processors函数的参数，第一个必须是request对象，第二个是可选的上下文处理器列表或元组def view_1(request): return render(request, &apos;template1.html&apos;, &#123;&apos;message&apos;: &apos;消息1&apos;&#125;, context_instance=RequestContext( request, processors=[custom_proc] ) )# 与上述一致，公用上下文处理器def view_2(request): return render(request, &apos;template2.html&apos;, &#123;&apos;message&apos;: &apos;消息2&apos;&#125;, context_instance=RequestContext( request, processors=[custom_proc] ) ) Djongo提供的上下文处理器在settings文件中，我们来逐一说明Djongo提供的上下文处理器 123456789101112131415161718192021222324252627282930313233343536&apos;OPTIONS&apos;: &#123; # 默认的处理器上下文 &apos;context_processors&apos;: [ # 启用这个处理器后，RequestContext 中将包含下面两个变量 # debug：True。可以在模板中测试是否在DEBUG 模式中。 # sql_queries：&#123;&apos;sql&apos;: …, &apos;time&apos;: …&#125; 字典构成的列表，表示处理请求的过程中执行的 SQL 查询及其用时。列表中的值按查询的执行顺序排列，在访问时惰性生成 &apos;django.template.context_processors.debug&apos;, # 启用这个处理器后，RequestContext 中将包含request 变量，它的值是当前的HttpRequest 对象 &apos;django.template.context_processors.request&apos;, # 启用此处理器后将包含： # user：auth.User 的实例，表示当前登录的用户（如未登录，是AnonymousUser 实例）。 # perms：django.contrib.auth.context_processors.PermWrapper 实例，表示当前登录用户拥有的权限。 &apos;django.contrib.auth.context_processors.auth&apos;, # 启用这个处理器后，RequestContext 中将包含下面两个变量： # messages：消息框架设定的消息列表（里面的值是字符串） # DEFAULT_MESSAGE_LEVELS：消息等级名称到数字值的映射 &apos;django.contrib.messages.context_processors.messages&apos;, # 非默认，启用后将包含： # LANGUAGES：LANGUAGES 设置的值 # LANGUAGE_CODE：如果request.LANGUAGE_CODE 存在，返回它的值；否则返回LANGUAGE_CODE 设置的值 # django.template.context_processors.i18n # 非默认，启用这个处理器后，RequestContext 中将包含MEDIA_URL 变量，提供MEDIA_URL 设置的值 # django.template.context_processors.media # 非默认，启用这个处理程序后，RequestContext 中将包含STATIC_URL 变量，提供STATIC_URL 设置的值 # jango.template.context_processors.static # 非默认，这个处理器添加一个令牌，供csrf_token 模板标签使用，用于防范跨站请求伪造，（暂时不清楚具体意思） # django.template.context_processors.csrf ],&#125;, 模板加载内部机制DIRS 选项告诉 Django 模板目录有哪些的方法是使用设置文件中TEMPLATES 设置的DIRS 选项，或者是Engine 的dirs 参数。这个选项的值是一个字符串列表，包含指向模板目录的完整路径： 123456789TEMPLATES = [ &#123; &apos;BACKEND&apos;: &apos;django.template.backends.django.DjangoTemplates&apos;, &apos;DIRS&apos;: [ &apos;/home/html/templates/lawrence.com&apos;, &apos;/home/html/templates/default&apos;, ], &#125;,] 模板可以放在任何位置，只要 Web 服务器有权限读取目录及里面的模板即可。模板的扩展名不限，可以是.html 或.txt，甚至可以没有。注意，这里的路径应该使用 Unix 风格的正斜线，即便在 Windows 中也是如此。 加载器类型说明123456789101112# 加载器# 默认使用 ilesystem.Loader 文件系统加载器，如果不设定DIRS 选项，这个加载器找不到任何模板。# DIRS 定义一个目录列表，模板引擎按顺序在里面查找模板源文件。# 当前设置表示在项目根目录中放一些主模板，模板目录不一定非得叫&apos;templates&apos;，可以自定义&apos;DIRS&apos;: [os.path.join(BASE_DIR, &apos;templates&apos;)],# 还有应用目录加载器 pp_directories.Loader# INSTALLED_APPS = [&apos;myproject.reviews&apos;, &apos;myproject.music&apos;]# 从文件系统中的 Django 应用里加载模板。这个加载器在INSTALLED_APPS 列出的各个应用中查找templates 子目录。如果找到，Django 在其中查找模板。# 这意味着，应用可以自带模板。通过这一行为，便于分发带默认模板的 Django 应用。例此加载器会在设置的文件夹中顺序的加载模板，最先找到的被加载，所以设置顺序很重要# 还有一些其他加载器，默认是禁用的，自行了解 Django模型的高级用法新增和修改对象save和create方法，如下： 12345678910111213141516m01 = Manufacturers(name=&apos;金龙鱼&apos;，address=&apos;铁岭&apos;, city=&apos;大连&apos;, province=&apos;沈阳&apos;, website=&apos;www.xmy.com&apos;)# save方法保存m01.save()# create方法保存m02 = Manufacturers.objects.create(name=&apos;金龙鱼&apos;，address=&apos;铁岭&apos;, city=&apos;大连&apos;, province=&apos;沈阳&apos;, website=&apos;www.xmy.com&apos;)# 当数据被保存后，及对象ID值是有的，直接再次调用save方法，就是修改对象，注意这里是全字段修改m02.name = &apos;鲁花&apos;m02.save()# 一个语句更新一个对象Manufacturers.objects.get(name=&apos;金龙鱼&apos;).save(city=&apos;黑龙江&apos;)# 一个语句中更新多条数据Manufacturers.objects.filter(name=&apos;金龙鱼&apos;).update(city=&apos;黑龙江&apos;) 查询数据all、filter、get方法等，如下： 1234567891011121314# 获取所有数据Manufacturers.objects.all()# 根据条件获取部分数据Manufacturers.objects.filter(name=&apos;金龙鱼&apos;)# 根据多个条件获取部分数据Manufacturers.objects.filter(name=&apos;金龙鱼&apos;, address=&apos;铁岭&apos;)# 类似SQL使用like语句过滤获取部分数据，字段加两个下划线，接containsManufacturers.objects.filter(name__contains=&apos;金&apos;)# 获取单个数据，此方法返回的就不是列表了，而是单条数据，如果查询出多条数据或者没有查询出数据，会抛出异常Manufacturers.objects.get(website=&apos;www.xmy.com&apos;) 排序数据order_by方法，具体如下： 12345678# 根据name排序，正向Manufacturers.objects.order_by(&apos;name&apos;)# 根据多个字段排序Manufacturers.objects.order_by(&apos;name&apos;, &apos;province&apos;)# 反向排序，方法是在字段名称前面加上“-”（减号）Manufacturers.objects.order_by(&apos;-name&apos;) 链式查找既过滤加排序，如下： 1Manufacturers.objects.filter(name=&apos;金龙鱼&apos;).order_by(&apos;-name&apos;) 切片数据及传统上理解的分页查找，如下： 12345# 返回查询出的第一条数据Manufacturers.objects.filter(name=&apos;金龙鱼&apos;)[0]# 分页查询，底层使用的是Mysql的Limit函数Manufacturers.objects.filter(name=&apos;金龙鱼&apos;)[0, 10] 删除数据delete方法，如下： 12345678# 删除一条数据Manufacturers.objects.get(name=&apos;金龙鱼&apos;).delete()# 删除多条数据Manufacturers.objects.filter(name=&apos;金龙鱼&apos;).delete()# 删除全部数据Manufacturers.objects.all().delete() 访问外键数据根据外键查询出关联的对象，如下： 123# 一对一关联manufacturers = Product.objects.get(title=&apos;小米&apos;).manufacturersmanufacturersName = Product.objects.get(title=&apos;小米&apos;).manufacturers.name 访问多对多数据多对多关联数据获取如下： 12345678910# 获取所有关联vender = Product.objects.get(title=&apos;小米&apos;).vender.all()# 过滤多对多数据vender = Product.objects.get(title=&apos;小米&apos;).vender.filter(name=&apos;供应商&apos;)# 反过来，查看经销商经销的所有产品，字段加 _setVender.objects.get(name=&apos;供应商&apos;).product_set.all()count = Product.vender.count() 管理器在Book.objects.all() 语句中，objects 是个特殊的属性，我们通过它查询数据库，这是模型的管理器（manager）。现在，我们要深入说明管理器的作用和用法。 添加额外的自定义管理器，修改模型如下： 123456789101112131415161718192021222324# 自定义模型管理器class MyProductManager(models.Manager): # 覆盖的get_queryset() 返回的是一个QuerySet 对象，它对应着我们管理器的all()方法 def get_queryset(self): return super(MyProductManager, self).get_queryset().filter(name=&apos;大米&apos;)# 产品class Product(models.Model): title = models.CharField(max_length=100, verbose_name=&apos;产品名称&apos;) vender = models.ManyToManyField(Vender, verbose_name=&apos;经销商&apos;) manufacturers = models.ForeignKey(Manufacturers, verbose_name=&apos;厂家&apos;) product_date = models.DateField(verbose_name=&apos;生产日期&apos;) # fields = (&apos;title&apos;, &apos;product_date&apos;, &apos;vender&apos;, &apos;manufacturers&apos;) # 我们明确地把objects 设为一个普通的Manager 示例，如若不然，唯一可用的管理器将是dahl_objects objects = models.Manager() # 默认的管理器 my_objects = MyProductManager() # 专门查询 产品名称为大米 的管理器 def __str__(self): return u&apos;%s %s&apos; % (self.title, self.product_date) # 任何模型都可以使用Meta 类指定多个针对所在模型的选项。 class Meta: ordering = [&apos;product_date&apos;] 下面是使用上述自定义管理器示例： 1234# get_queryset() 返回的是一个QuerySet 对象，因此可以在其上调用filter()、exclude() 和其他所有QuerySet 支持的方法Product.my_objects.all()Product.my_objects.filter(title=&apos;Matilda&apos;)Product.my_objects.count() 如果需要，我们可以在同一个模型上使用多个管理器。 模型方法模型方法就是为Model提供一些方法，我们调用这些方法的时候能处理一些我们想要的逻辑。 模型为我们自动提供的常用方法有如下： str()。这是 Python 的一个“魔法方法”，返回对象的 Unicode 表示形式。需要以普通的字符串显示模型实例时，Python 和 Django 会调用这个方法。尤其要注意，在交互式控制台或管理后台中显示对象调用的都是这个方法。这个方法一定要自定义，因为默认的实现没什么用。 get_absolute_url()。这个方法告诉 Django 如何计算一个对象的 URL。Django 在管理后台和需要生成对象的 URL 时调用这个方法。具有唯一标识的 URL 的对象都要定义这个方法。 模型方法大多可以被直接覆盖，最常见的就是覆盖str()方法 一下演示覆盖预定义的模型方法，是针对数据库执行行为来覆盖的，例如： 1234567891011# 定义Blog模型，覆盖它的save方法，如下定义某些情况下不允许保存class Blog(models.Model): name = models.CharField(max_length=100) tagline = models.TextField() def save(self, *args, **kwargs): if self.name == &quot;Yoko Ono&apos;s blog&quot;: return # Yoko 肯定不会开博客的！ else: super(Blog, self).save(*args, **kwargs) # 调用“真正的”save () 方法 执行原始SQL模型的查询 API 不够用时，可以编写原始 SQL。Django 为执行原始 SQL 查询提供了两种方式：使用Manager.raw() 执行，返回模型实例集合；或者完全不用模型层，直接执行自定义SQL 第一种方式执行示例： 123456789101112131415161718# 基本查询分页Product.objects.raw(&apos;SELECT * FROM CEREALSOILS_PRODUCT LIMIT 0, 5&apos;)# 当我们定义的模型字段名称与数据库字段名称不一致时，可以通过AS将字段对应起来Product.objects.raw(&apos;SELECT product_name as name FROM CEREALSOILS_PRODUCT&apos;)# 延期模型字段# 注意：指定查询字段的时候，必须要包含主键字段p = Product.objects.raw(&apos;SELECT id, title FROM CEREALSOILS_PRODUCT&apos;)title = p.title # 上述执行取出的数product_date = p.product_date # 又执行了一次SQL来取出的此字段的值# 为raw传递参数，注意，这里是防注入的用法，参数写在raw方法内才有防注入的作用# 注意：Djongo中的占位符是 %s ，而不是 ?# 查询中有 % ，则需要写两个 %title = &apos;大米&apos;pa = Product.objects.raw(&apos;SELECT * FROM CEREALSOILS_PRODUCT where title = %s&apos;, title)p9 = Product.objects.raw(&apos;SELECT * FROM cerealsOils_product where title like %s LIMIT 0, 5&apos;, [&apos;%米%&apos;]) 第二种方式执行示例： django.db.connection 对象表示默认的数据库连接。若想使用这个数据库连接，调用connection.cursor()，然后，调用cursor.execute(sql, [params]) 执行 SQL，再调用cursor.fetchone() 或cursor.fetchall() 返回所得的行。 12345678910111213141516171819202122232425262728293031323334353637from django.db import connectiondef my_custom_sql(self): cursor = connection.cursor() cursor.execute(&quot;UPDATE bar SET foo = 1 WHERE baz = %s&quot;, [self.baz]) cursor.execute(&quot;SELECT foo FROM bar WHERE baz = %s&quot;, [self.baz]) row = cursor.fetchone() return row# 当需要连接多个数据库时，可以获取指定的数据库连接cursor = connections[&apos;my_db_alias&apos;].cursor()# 连接和游标（类似于Java中 Try-with-resouce）with connection.cursor() as c: c.execute(...)等效于：c = connection.cursor()try: c.execute(...)finally: c.close()# 查询数据，只返回结果没有字段名称映射cursor = connection.cursor()cursor.execute(&quot;SELECT id, title FROM cerealsOils_product&quot;)row01 = cursor.fetchone()row02 = cursor.fetchone()print(row01)print(row02)# 查询数据，有字段名称映射cursor01 = connection.cursor()cursor01.execute(&quot;SELECT id, title FROM cerealsOils_product&quot;)desc = cursor01.descriptiondict(zip([col[0] for col in desc], row))for row in cursor01.fetchall(): print(row)","categories":[{"name":"Python","slug":"Python","permalink":"https://jjw-story.github.io/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://jjw-story.github.io/tags/Python/"},{"name":"Django","slug":"Django","permalink":"https://jjw-story.github.io/tags/Django/"}],"author":"JJW"},{"title":"文件及目录权限","slug":"文件及目录权限","date":"2019-08-03T12:20:20.000Z","updated":"2019-08-03T06:13:49.717Z","comments":true,"path":"2019/08/03/文件及目录权限/","link":"","permalink":"https://jjw-story.github.io/2019/08/03/文件及目录权限/","excerpt":"","text":"文件及目录权限的表示方法当我们使用 ls -l 命令查看详细文件内容时，可以看到查询出的内容如下： 123456789root@CHJ-20190520VPS:/usr/lib# ls -ltotal 920drwxr-xr-x 1 root root 4096 May 21 22:39 kerneldrwxr-xr-x 1 root root 4096 May 21 22:39 klibcdrwxr-xr-x 1 root root 4096 May 21 22:40 language-selectorlrwxrwxrwx 1 root root 21 Feb 12 16:55 libDeployPkg.so.0 -&gt; libDeployPkg.so.0.0.0-rw-r--r-- 1 root root 31280 Feb 12 16:55 libDeployPkg.so.0.0.0lrwxrwxrwx 1 root root 20 Feb 12 16:55 libguestlib.so.0 -&gt; libguestlib.so.0.0.0-rw-r--r-- 1 root root 22656 Feb 12 16:55 libguestlib.so.0.0.0 一共查询出七列内容，分别表示： 文件属性(占10个字符空间)、拥有的文件数量、文件的创建者、所属的group、文件大小、建档日期、文件名 文件属性Linux的文件基本上分为三个属性：可读（r），可写（w），可执行（x） 但是这里有十个格子可以填（具体程序实现时，实际上是十个bit位） 文件类型第一个小格是特殊表示格，表示目录或连结文件等等 d 表示目录，这个是在创建下来文件的类型就固定了下来，不可以人为进行更改 l 表示链接文件，类似于快捷方式 - 表示这是普通文件 b 块特殊文件，其实是指的是设备，比如我们插入一个移动硬盘，插入一个硬盘之后，Linux系统就会把他当成一个特出文件块文件来表示 c 字符特殊文件，就是终端 f 命名管道 s 套接字文件 文件权限表示方法字符权限表示方法： r 读 w 写 x 执行 数字权限的表示方法（8进制数字表示）： r=4 w=2 x=1 其余剩下的格子就以每3格为一个单位，因为Linux是多用户多任务系统，所以一个文件可能同时被许多人使用，所以我们一定要设好每个文件的权限，其文件的权限位置排列顺序是（以-rwxr-xr-x为例）： rwx(Owner)r-x(Group)r-x(Other) 这个例子表示的权限是：使用者自己可读，可写，可执行；同一组的用户可读，不可写，可执行；其它用户可读，不可写，可执行。 另外，有一些程序属性的执行部分不是X,而是S,这表示执行这个程序的使用者，临时可以有和拥有者一样权力的身份来执行该程序。一般出现在系统管理之类的指令或程序，让使用者执行时，拥有root身份。 文件权限的修改修改权限命令chown命令修改属主或数组命令，使用方法： 修改属主：chown 用户名称 文件名称 修改属组：chown :用户组名称 文件名称 修改文件、目录权限。Linux/Unix 的文件调用权限分为三级 : 文件拥有者、群组、其他。利用 chmod 可以藉以控制文件如何被他人所调用 首先我们新创建一个目录，查看root用户新创建目录的默认权限，如下： 12root@CHJ-20190520VPS:/tmp# ls -ld testdir/drwxr-xr-x 1 root root 4096 Jul 27 15:05 testdir/ 表示文件的属主是root用户，root用户可以读写删除等，所属用户组不能删除，其他其他用户不能删除 这里我们需要了解，Linux权限限制是非root用户的，这里既是我们将文件或目录的权限给root修改了，但是root用户还是不受限制的 所以为了方便测试我们不要用root用户来操作，命令使用示例如下： 123456789101112131415# 修改属主root@CHJ-20190520VPS:/tmp# chown wangjia3 testdirroot@CHJ-20190520VPS:/tmp# ls -ld testdirdrwxr-xr-x 1 wangjia3 root 4096 Jul 27 15:05 testdir# 修改属组root@CHJ-20190520VPS:/tmp# groupadd group01root@CHJ-20190520VPS:/tmp# chown :group01 testdirroot@CHJ-20190520VPS:/tmp# ls -ld testdirdrwxr-xr-x 1 wangjia3 group01 4096 Jul 27 15:05 testdir# 属主属组一起修改root@CHJ-20190520VPS:/tmp# chown wangjia3:group01 testdir/root@CHJ-20190520VPS:/tmp# ls -ld testdir/drwxr-xr-x 1 wangjia3 group01 4096 Aug 3 12:35 testdir/ 可以看到文件的属主和属组已经改变 chgrp命令修改属组命令，使用方法：chgrp 用户组名称 文件名称 使用示例： 123root@CHJ-20190520VPS:/tmp# chgrp root testdirroot@CHJ-20190520VPS:/tmp# ls -ld testdirdrwxr-xr-x 1 wangjia3 root 4096 Jul 27 15:05 testdir 可以看到文件的属组已经被修改回为root分组 创建文件的默认权限我们创建一个新的文件，默认的权限如下所示： 123root@CHJ-20190520VPS:/tmp/testdir# ls -ltotal 0-rw-r--r-- 1 root root 0 Aug 3 12:35 demoFile 那它是怎么来的呢？其实创建新的文件默认的权限是数字表示法：666，表示属主属组其他都是拥有读写权限，但它会根据数字权限表示减去一个uumask，umask表示如下： 12root@CHJ-20190520VPS:/tmp/testdir# umask0022 所以这就是我们创建文件的默认权限的由来，是使用 666 减去 umask 得到的默认权限 chmod命令chmod是Linux/Unix中修改文件或者目录权限的命令，通过修改权限可以让指定的人对文件可读、可写、可运行，极大地保证了数据的安全性 使用方法：chmod [修改内容 修改符号 权限] 文件 修改字符权限参数详解修改内容 u 修改文件属主的权限 g 修改文件属组的权限 r 修改其他以外的权限 a 以上三者都修改 具体权限修改 + 增加权限 - 取消权限 = 直接设定权限 此三条具体设置的权限就是我们之前了解的：r、w、x 使用示例： 123456789101112131415161718192021222324252627root@CHJ-20190520VPS:/tmp/testdir# ls -ltotal 0-rw-r--r-- 1 root root 0 Aug 3 12:35 demoFile# 属主增加执行权限root@CHJ-20190520VPS:/tmp/testdir# chmod u+x demoFileroot@CHJ-20190520VPS:/tmp/testdir# ls -ltotal 0-rwxr--r-- 1 root root 0 Aug 3 12:35 demoFile# 属组取消读权限root@CHJ-20190520VPS:/tmp/testdir# chmod o-r demoFileroot@CHJ-20190520VPS:/tmp/testdir# ls -ltotal 0-rwxr----- 1 root root 0 Aug 3 12:35 demoFile# 其他设置执行和读权限root@CHJ-20190520VPS:/tmp/testdir# chmod o=xr demoFileroot@CHJ-20190520VPS:/tmp/testdir# ls -ltotal 0-rwxr--r-x 1 root root 0 Aug 3 12:35 demoFile# 所有设置读写执行权限root@CHJ-20190520VPS:/tmp/testdir# chmod a=xwr demoFileroot@CHJ-20190520VPS:/tmp/testdir# ls -ltotal 0-rwxrwxrwx 1 root root 0 Aug 3 12:35 demoFile 修改数字权限修改方法：chmod [数字] 文件 注意：以上参数中数字为3位数 参数详解三位数字第一位代表属主权限，第二位代表属组权限，第三位代表其他权限 数字则分别用 1、2、4 来分别表示 执行、写、读 使用示例： 123456789101112131415root@CHJ-20190520VPS:/tmp/testdir# ls -ltotal 0-rwxrwxrwx 1 root root 0 Aug 3 12:35 demoFile# 设置取消所有权限root@CHJ-20190520VPS:/tmp/testdir# chmod 000 demoFileroot@CHJ-20190520VPS:/tmp/testdir# ls -ltotal 0---------- 1 root root 0 Aug 3 12:35 demoFile# 设置属主读写权限，属组和其他读权限root@CHJ-20190520VPS:/tmp/testdir# chmod 644 demoFileroot@CHJ-20190520VPS:/tmp/testdir# ls -ltotal 0-rw-r--r-- 1 root root 0 Aug 3 12:35 demoFile 特殊权限SUID用于二进制可执行文件，执行命令时取得文件的属主权限，例如 /usr/bin/password 12wangjia3@CHJ-20190520VPS:/tmp/testdir$ ls -l /usr/bin/passwd-rwsr-xr-x 1 root root 59640 Mar 23 03:05 /usr/bin/passwd 如上示例中：属主权限是 ws，s 之前是我们没有解释过的，它表示的是不管是root用户还是普通用户，它在执行这条命令时，它都会以文件的属主的这种身份来进行操作 它的作用就是，我们有些文件用户是没有任何权限的，例如保存用户账户密码的文件，/etc/shadow: 12wangjia3@CHJ-20190520VPS:/tmp/testdir$ ls -l /etc/shadow-rw-r----- 1 root shadow 1153 Jul 27 13:38 /etc/shadow 我们当前登录的用户是没有此文件的任何权限的，而root用户有此文件的权限，那我们普通用户为什么能修改密码呢，就是我们在修改密码例如passwd文件的时候，它能以root用户的身份来执行，这样就避免了我们需要主动去切换用户的修改密码的问题。 SGID用于目录，在该目录下创建新的文件和目录，权限自动更改为该目录的数组，一般是我们在文件共享的时候，一般会用到SET GID SBIT用于目录，该目录下新建的文件和目录，仅root和自己可以删除，如/tmp 12wangjia3@CHJ-20190520VPS:/$ ls -ld /tmpdrwxrwxrwt 1 root root 4096 Aug 3 13:50 /tmp 注意在其他位有一个t，这样就可以防止自己创建的文件被其他的普通用户修改或删除 设置特殊权限使用的也是 chmod命令，用法与上述修改权限用法一致，只不过多了由三位数变为了四位数，第一位为特殊权限的表示数字 特殊权限数字表示： 4 SET UID 123456789root@CHJ-20190520VPS:/tmp/testdir# ls -ltotal 0----rw---- 1 wangjia3 wangjia3 0 Aug 3 12:35 demoFileroot@CHJ-20190520VPS:/tmp/testdir# chmod 4644 demoFileroot@CHJ-20190520VPS:/tmp/testdir# ls -ltotal 0-rwSr--r-- 1 wangjia3 wangjia3 0 Aug 3 12:35 demoFile 1 SET BIT 1234root@CHJ-20190520VPS:/tmp/testdir# chmod 1644 demoFileroot@CHJ-20190520VPS:/tmp/testdir# ls -ltotal 0-rw-r--r-T 1 wangjia3 wangjia3 0 Aug 3 12:35 demoFile 2 SET GID 1234root@CHJ-20190520VPS:/tmp/testdir# chmod 2644 demoFileroot@CHJ-20190520VPS:/tmp/testdir# ls -ltotal 0-rw-r-Sr-- 1 wangjia3 wangjia3 0 Aug 3 12:35 demoFile 注意特殊权限一般不要去自己随便指定，使用系统默认就行","categories":[{"name":"Linux","slug":"Linux","permalink":"https://jjw-story.github.io/categories/Linux/"}],"tags":[{"name":"command","slug":"command","permalink":"https://jjw-story.github.io/tags/command/"},{"name":"文件及目录权限","slug":"文件及目录权限","permalink":"https://jjw-story.github.io/tags/文件及目录权限/"}],"author":"JJW"},{"title":"su-sudo命令","slug":"su-sudo命令","date":"2019-07-27T01:07:11.000Z","updated":"2019-07-27T04:15:12.298Z","comments":true,"path":"2019/07/27/su-sudo命令/","link":"","permalink":"https://jjw-story.github.io/2019/07/27/su-sudo命令/","excerpt":"","text":"su命令Linux su命令用于变更为其他使用者的身份，除 root 外，需要键入该使用者的密码 使用方法：su [选项] [用户名称] 选项说明 -f 不必读启动档（如 csh.cshrc 等），仅用于 csh 或 tcsh -c 既command，变更为帐号为指定账号的使用者并执行指定指令（command）后再变回原来使用者，使用方法：su -c [指定命令] 用户名称 -m -p 既preserve、environment，执行 su 时不改变环变量 - -l login这个参数加了之后，就好像是重新login为该使用者一样，大部份环境变数（HOME SHELL USER等等）都是以该指定用户为主，并且工作目录也会改变，如果没有指定用户，内定是 root -s 指定要执行的shell （bash csh tcsh 等），预设值为 /etc/passwd 内的指定用户shell 使用示例： 1234567891011121314wangjia3@CHJ-20190520VPS:~$ pwd/home/wangjia3wangjia3@CHJ-20190520VPS:~$ su rootPassword:root@CHJ-20190520VPS:/home/wangjia3# pwd/home/wangjia3root@CHJ-20190520VPS:~# su - wangjia3wangjia3@CHJ-20190520VPS:~$ pwd/home/wangjia3wangjia3@CHJ-20190520VPS:~$ su - rootPassword:root@CHJ-20190520VPS:~# pwd/root 注意 su 与 su - 的区别 sudo命令sudo 表示 “superuser do”。 它允许已验证的用户以其他用户的身份来运行命令。其他用户可以是普通用户或者超级用户。然而，大部分时候我们用它来以提升的权限来运行命令 以系统管理者的身份执行指令，也就是说，经由 sudo 所执行的指令就好像是 root 亲自执行 使用方法：su [参数] 参数说明 -V 显示版本编号 -h 显示版本编号及指令的使用方式说明你 -l 显示出当前用户的权限 -v 因为 sudo 在第一次执行时或是在 N 分钟内没有执行（N 预设为五）会问密码，这个参数是重新做一次确认，如果超过 N 分钟，也会问密码 -k 将会强迫使用者在下一次执行 sudo 时问密码（不论有没有超过 N 分钟） -b 将要执行的指令放在背景执行 -s 执行环境变数中的 SHELL 所指定的 shell ，或是 /etc/passwd 里所指定的 shell -i Linux终端命令下改变用户对命令使用权限的命令，加载用户变量，并跳转到目标用户home目录 经常使用参数示例： 1234567wangjia3@CHJ-20190520VPS:/$ sudo -l[sudo] password for wangjia3:Matching Defaults entries for wangjia3 on CHJ-20190520VPS: env_reset, mail_badpass, secure_path=/usr/local/sbin\\:/usr/local/bin\\:/usr/sbin\\:/usr/bin\\:/sbin\\:/bin\\:/snap/binUser wangjia3 may run the following commands on CHJ-20190520VPS: (ALL : ALL) ALL 12345678wangjia3@CHJ-20190520VPS:~$ pwd/home/wangjia3wangjia3@CHJ-20190520VPS:~$ sudo -sroot@CHJ-20190520VPS:~# pwd/home/wangjia3root@CHJ-20190520VPS:~# sudo -iroot@CHJ-20190520VPS:~# pwd/root 注意 -s 和 -i 的区别 sudo命令使用补充通常我们使用普通用户使用一些命令是没有权限的，在使用这些没有权限的命令时需要切换到root用户，这样就需要告知普通用户root用户的密码，这样做是不安全的 例如我们执行shutdown命令时： 12[frog@iZm5ehzqow4ijp2ya2g2drZ ~]$ shutdown -h 60shutdown: Need to be root 显示需要使用root用户来操作此命令 这时我们可以使用visudo来修改sudo的配置文件，将此命令的使用权限赋给普通用户，来让普通用户有权限使用此命令，就可以不将root用户的密码告知与普通用户，安全的使用系统 visudo的使用时以vi开头的，其实就类似于使用 vi 打开了一个文件，使用操作与 vi 一致 1234567891011121314151617181920212223242526272829303132[root@iZm5ehzqow4ijp2ya2g2drZ /]# visudo## Sudoers allows particular users to run various commands as## the root user, without needing the root password.#### Examples are provided at the bottom of the file for collections...## user MACHINE=COMMANDS#### The COMMANDS section may have other options added to it.#### Allow root to run any commands anywhereroot ALL=(ALL) ALL## Allows members of the &apos;sys&apos; group to run networking, software,## service management apps and more.# %sys ALL = NETWORKING, SOFTWARE, SERVICES, STORAGE, DELEGATING, PROCESSES, LOCATE, DRIVERS## Allows people in group wheel to run all commands# %wheel ALL=(ALL) ALL## Same thing without a password# %wheel ALL=(ALL) NOPASSWD: ALL## Allows members of the users group to mount and unmount the## cdrom as root# %users ALL=/sbin/mount /mnt/cdrom, /sbin/umount /mnt/cdrom## Allows members of the users group to shutdown this system# %users localhost=/sbin/shutdown -h now## Read drop-in files from /etc/sudoers.d (the # here does not mean a comment) 注意此文件最下方有几段关于使用sudo的设置说明，下面是设置说明： 12345## Allows people in group wheel to run all commands# %wheel ALL=(ALL) ALL## Same thing without a password# %wheel ALL=(ALL) NOPASSWD: ALL %wheel 表示的是如果我们要设置的是用户组，则需要用 % 加上用户组名称，如果只是单个用户，就直接写用户名即可 ALL=(ALL) 表示在哪台主机上可以执行哪些命令，哪来主机指的是我们登陆的主机，Linux可以在本地登陆，也可以远程登陆，如果在本地登陆那么主机就是localhost，locachost是字符端登陆，如果是字符或远程都去登陆，就赋予 ALL 的权限。 如果只赋予一些命令，如上述中：# %users localhost=/sbin/shutdown -h now，意思是赋予了用户shutdown -h now 的命令的使用权限 如果有多条命令，就将命令用 “,” 隔开，例如上述段落中示例：%users ALL=/sbin/mount /mnt/cdrom, /sbin/umount /mnt/cdrom，表示赋予了用户mount、unmount命令 NOPASSWD: ALL 表示普通用户在使用管理员账户赋予它的这些命令时是否需要输入密码，这里 NOPASSWD: ALL 表示不需要输入密码，但是这种是不安全的，所以我们不建议此种设置类型 使用示例我们现在配置普通用户 frog 被赋予使用 shutdown -h 60 的权限，使用visudo来设置，修改如下： 123## Read drop-in files from /etc/sudoers.d (the # here does not mean a comment)#includedir /etc/sudoers.dforg ALL=/sbin/shutdown -h 60 修改完成然后切换到frog用户执行此命令： 12345678910[root@iZm5ehzqow4ijp2ya2g2drZ /]# su -l frog[frog@iZm5ehzqow4ijp2ya2g2drZ ~]$ shutdown -h 60shutdown: Need to be root[frog@iZm5ehzqow4ijp2ya2g2drZ ~]$ sudo /sbin/shutdown -h 60[sudo] password for frog:Broadcast message from root@iZm5ehzqow4ijp2ya2g2drZ (/dev/pts/1) at 12:14 ...The system is going down for halt in 60 minutes! 注意：直接执行还是会告诉你没有权限，我们需要使用sudo命令来执行root赋予权限的命令，需要使用命令的全路径，然后提示输入密码之后就执行成功啦","categories":[{"name":"Linux","slug":"Linux","permalink":"https://jjw-story.github.io/categories/Linux/"}],"tags":[{"name":"command","slug":"command","permalink":"https://jjw-story.github.io/tags/command/"},{"name":"su-sudo","slug":"su-sudo","permalink":"https://jjw-story.github.io/tags/su-sudo/"}],"author":"JJW"},{"title":"用户和权限管理","slug":"用户和用户组管理","date":"2019-07-25T12:00:00.000Z","updated":"2019-07-27T06:08:31.650Z","comments":true,"path":"2019/07/25/用户和用户组管理/","link":"","permalink":"https://jjw-story.github.io/2019/07/25/用户和用户组管理/","excerpt":"","text":"用户管理Linux系统是一个多用户多任务的分时操作系统，任何一个要使用系统资源的用户，都必须首先向系统管理员申请一个账号，然后以这个账号的身份进入系统。 用户的账号一方面可以帮助系统管理员对使用系统的用户进行跟踪，并控制他们对系统资源的访问；另一方面也可以帮助用户组织文件，并为用户提供安全性保护。 每个用户账号都拥有一个惟一的用户名和各自的口令，用户在登录时键入正确的用户名和口令后，就能够进入系统和自己的主目录。 实现用户账号的管理，要完成的工作主要有如下几个方面： 用户账号的添加、删除与修改 用户口令的管理 用户组的管理 用户管理常用命令当前使用的Linux系统中已经有了两个用户，一个是root用户，一个是自己创建的用户，root用户是超级管理员，我们自己创建的用户是普通用户。LInux多用户其实就是将用户分成了两类用户，一类是root用户，一类是普通用户 root用户的权限比较大，它可以访问自己的家目录，访问系统的配置文件，例如之前我们修改的vim的配置文件，还有就是root用户还可以访问普通用户的家目录，但是普通用户的权限就受到了下去限制，它只能访问自己的家目录，以及root用户开放给它的一些没有危害到系统安全的目录文件 普通用户和普通用户之间是没有权限互相访问他们对方的家目录的，Linux就是通过这两种用户的区别，来做了最基本的权限隔离 用户添加命令用户添加命令实际使用的是 useradd命令，使用方法：useradd [选项] 用户名称 在添加用户完成后，我们可以使用 id 命令来验证是否添加成功，通过 id 命令，我们可以查看系统中有哪些已经存在的用户 1234567root@CHJ-20190520VPS:/# useradd wangjiasroot@CHJ-20190520VPS:/# id rootuid=0(root) gid=0(root) groups=0(root)root@CHJ-20190520VPS:/# id wangjiasuid=1001(wangjias) gid=1001(wangjias) groups=1001(wangjias)root@CHJ-20190520VPS:/# id abcid: ‘abc’: no such user 下面分析我们添加用户的时候Linux都做了哪些操作： 首先第一是为新添加的用户创建了它的家目录，创建完成我们访问的时候发现家目录是空的，但其实用户的家目录是存放了很多与用户相关的隐藏配置文件 第二步就是将我们创建的用户记录在 /etc/passwd 文件中，只要包含了如下所示内容，就说明我们系统中存在这样的一个用户 123root@CHJ-20190520VPS:/# cat /etc/passwd...wangjias:x:1001:1001::/home/wangjias:/bin/sh 第三步还会在 etc/shadow 文件中添加我们创建的用户信息，这个文件是用户密码相关的文件 还有就是我们每创建一个用户，都会创建一个独立的用户id，叫uid，如上述我们通过id命令查询出来的内容。注意root用户的id是0，如果我们把普通用户的id也修改为0，那么系统就会把此用户也当成root用户 第四就是还会为用户创建用户所属的组，如果我们没有明确指定所属的组，系统就会创建一个与用户同名的组作为新创建用户所属的组。如果我们希望有一组用户他们使用同样的资源的时候，就可以建立一个这样的用户组，然后把他们都加入到这个组里面，如果我们对这个组进行修改，就相当于对一组的用户全都进行修改 注意创建用户只有root用户有这样的权限，普通用户没有创建用户的权限 上面的创建我们没有指定选项，下面介绍一些选项： -c comment 指定一段注释性描述 -d 目录 指定用户主目录，如果此目录不存在，则同时使用-m选项，可以创建主目录 -g 用户组 指定用户所属的用户组 -G 用户组，用户组 指定用户所属的附加组 -s Shell文件 指定用户的登录Shell -u 用户号 指定用户的用户号，如果同时有-o选项，则可以重复使用其他用户的标识号 为用户设置密码用户登录是需要登录密码的，为用户设置密码的命令使用的是 passwd命令，使用方法：passwd [用户名] 注意用户名选项是可选的，如果不指定要修改密码的用户名，那就是修改当前用户的密码 1234root@CHJ-20190520VPS:/# passwd wangjiasEnter new UNIX password:Retype new UNIX password:passwd: password updated successfully 删除用户删除用户使用的是userdel命令，使用方法： userdel [选项] 用户名 注意我们一般删除用户的时候会添加上 “-r” 选项，如果我们直接使用用户删除命令删除用户，则此用户的家目录会被保留下来，当我们确认用户的家目录中的数据都可以被直接删除的时候，就可以添加 -r 这个选项，直接删除彻底。 如果执行的是彻底删除的命令，那么 /etc/passed 和 /etc/shadow 中的用户信息也会被删除 修改账号修改用户账号就是根据实际情况更改用户的有关属性，如用户号、主目录、用户组、登录Shell等。 修改已有用户的信息使用usermod命令，使用方法：usermod 选项 用户名 常用的选项包括-c, -d, -m, -g, -G, -s, -u以及-o等，这些选项的意义与useradd命令中的选项一样，可以为用户指定新的资源值 经常使用的选项是 -d 选项，既指定用户新的家目录，使用方法：usermod -d 新的家目录 用户名 如果我们修改了用户的家目录，那么我们重新登录此用户的时候，它的默认目录就会成为我们修改的目录，并且关于此用户的配置文件也会放在新的家目录中 用户组管理每个用户都有一个用户组，系统可以对一个用户组中的所有用户进行集中管理。不同Linux 系统对用户组的规定有所不同，如Linux下的用户属于与它同名的用户组，这个用户组在创建用户时同时创建 用户组的管理涉及用户组的添加、删除和修改。组的增加、删除和修改实际上就是对/etc/group文件的更新 用户组管理命令新建用户组新建用户组使用groupadd命令，使用方法：groupadd [选项] 用户组 选项一般使用 -g 选项，此选项用于指定用户组的组标识号 新建好组之后，有两种方式将用户添加至先建好的组，第一种是使用 usermod 命令： 12345root@CHJ-20190520VPS:/# groupadd -g 1001 group1root@CHJ-20190520VPS:/# useradd user1root@CHJ-20190520VPS:/# usermod -g group1 user1root@CHJ-20190520VPS:/# id user1uid=1001(user1) gid=1001(group1) groups=1001(group1) 可以看到我们已经将user1用户添加到了group1组中 第二种就是在新建用户的时候直接将用户添加至指定用户组中: 123root@CHJ-20190520VPS:/# useradd -g group1 user2root@CHJ-20190520VPS:/# id user2uid=1002(user2) gid=1001(group1) groups=1001(group1 修改用户组修改用户组的属性使用groupmod命令，使用方法：groupmod [选项] 用户组 常用选项如下： -g GID 为用户组指定新的组标识号 -o 与-g选项同时使用，用户组的新GID可以与系统已有用户组的GID相同 -n 新用户组 将用户组的名字改为新名字 使用示例： 123root@CHJ-20190520VPS:/# groupmod -n group2 group1root@CHJ-20190520VPS:/# id user2uid=1002(user2) gid=1001(group2) groups=1001(group2) 删除用户组如果要删除一个已有的用户组，使用groupdel命令，使用方法：groupdel 用户组 1root@CHJ-20190520VPS:/# groupdel group2 用户和用户组配置文件用户和用户组相关的配置文件主要有三个，/etc/passwd、/ect/shadow、/etc/group passwd文件内容如下： 12345671 root:x:0:0:root:/root:/bin/bash2 daemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologin3 bin:x:2:2:bin:/bin:/usr/sbin/nologin4 sys:x:3:3:sys:/dev:/usr/sbin/nologin...30 wangjia3:x:1000:1000:,,,:/home/wangjia3:/bin/bash31 user01:x:1001:1001::/home/user01:/bin/sh 我们发现此文件被分成了七个字段，下面分别解释每个字段的含义： 用户名称字段，表示用户的名称，可以看到此文件最后的两行是我们之前新创建的用户 第二个字段表示此用户登录需要不需要密码验证，如果把这个 “x” 删除之后，我们发现登录用户将不需要验证 1234wangjia3@CHJ-20190520VPS:~$ su -l wangjia3Password:wangjia3@CHJ-20190520VPS:~$ su -l user01user01@CHJ-20190520VPS:/$ 第三个字段是用户的uid字段，Linux并不是通过用户的名称来识别用户的，它是通过用户的id来识别用户，如果id重复了就会用最小id的用户使用 第四个字段是gid，是当前用户属于哪一个组的标识字段 第五个字段是注释 第六个字段表示用户的家目录的位置 用户登录后使用的命令解释器，现在所通用的命令解释器都是bash命令解释器。我们发现有很多第七个字段显示的是 /usr/sbin/nologin， 这里表示的是此用户是不能登录终端的，例如我们将user01用户的此字段修改为nologin： 123456 30 wangjia3:x:1000:1000:,,,:/home/wangjia3:/bin/bash 31 user01:x:1001:1001::/home/user01:/usr/sbin/nologinroot@CHJ-20190520VPS:~# su -l user01This account is currently not available.root@CHJ-20190520VPS:~# 切换用户失败，提示此账户不能登录 我们可以直接在这里添加一行数据，来添加用户 shadowshadow文件是保存用户和用户密码相关信息的，我们需要了解它的前两个字段 1234528 sshd:*:18037:0:99999:7:::29 pollinate:*:18037:0:99999:7:::30 wangjia3:$6$486gKZ88$cobO1oh/kuz4HwAmnpnb.OQtszzD78m0e.KvbbxcEbNfIA9/4cSKvU78iTMOgFL8FstKrk0hIQ/S16P/R5o6t.:18080:0: 99999:7:::31 user01:$6$Pe7lIEqi$28CGKQAIa3E4JvTvAZKeymjFgVY5HvGZXVg0RuUWetl2YTlgU5sLcMzRs6FZmJbnIvad3IeJO4bPXs082KqL10:18104:0:99 999:7::: 第一个字段是用户名称字段，用来和passwd字段来进行对应 是用户加密过的密码，加密的密码是以$开头，然后一串字符，这样主要是为了保护用户的密码，及时用户的密码是相同的，但是在此文件中的显示也是不同的，防止被破解 group和用户组相关的配置文件，里面包含四个字段： 第一个字段是组的名称 第二个字段这个组是否需要密码验证 第三个字段表示这个组的gid 第四个字段，表示其他组字段，表示哪些用户属于其他组，这个其他组里面又包含了用户名称","categories":[{"name":"Linux","slug":"Linux","permalink":"https://jjw-story.github.io/categories/Linux/"}],"tags":[{"name":"command","slug":"command","permalink":"https://jjw-story.github.io/tags/command/"},{"name":"用户和权限管理","slug":"用户和权限管理","permalink":"https://jjw-story.github.io/tags/用户和权限管理/"}],"author":"JJW"},{"title":"Python","slug":"Python","date":"2019-07-20T12:00:00.000Z","updated":"2019-07-24T09:40:11.920Z","comments":true,"path":"2019/07/20/Python/","link":"","permalink":"https://jjw-story.github.io/2019/07/20/Python/","excerpt":"","text":"Python基础Python语法注释注释的三种方式如下： 123456789# 注释&apos;&apos;&apos;注释&apos;&apos;&apos;&quot;&quot;&quot;这也是注释&quot;&quot;&quot; 缩进python不需要 {} 都是使用缩进表示代码块 字符串字符串可以 ‘ ‘， “ “, “”” “”” 123456&apos;字符串&apos;&quot;字符串&quot;&quot;&quot;&quot;多行字符串&quot;&quot;&quot; 空行函数之间或类方法之间用空行分开 ; 符号同一行可以显示多条语句，使用 ; 隔开 导入 在 python 用 import 或者 from…import 来导入相应的模块 将整个模块(somemodule)导入，格式为： import somemodule 从某个模块中导入某个函数,格式为： from somemodule import somefunction 从某个模块中导入多个函数,格式为： from somemodule import firstfunc, secondfunc, thirdfunc 将某个模块中的全部函数导入，格式为： from somemodule import * end关键字关键字end可以用于将结果输出到同一行，或者在输出的末尾添加不同的字符 123while b &lt; 1000: print(b, end=&apos;,&apos;) b += 1 条件控制123456789101112if 表达式1: 语句 if 表达式2: 语句 elif 表达式3: 语句 else: 语句elif 表达式4: 语句else: 语句 循环while循环: 123456count = 0while count &lt; 5:print (count, &quot; 小于 5&quot;)count = count + 1else:print (count, &quot; 大于或等于 5&quot;) for循环： 12345678sites = [&quot;Baidu&quot;, &quot;Google&quot;,&quot;Runoob&quot;,&quot;Taobao&quot;]for site in sites: if site == &quot;Runoob&quot;: print(&quot;菜鸟教程!&quot;) break print(&quot;循环数据 &quot; + site)else: print(&quot;没有循环数据!&quot;) 注意：以上循环中，else为跳出循环后执行的逻辑，且只执行一次，可以不存在else range()函数： 12345for i in range(103) : print(i)for i in range(0, 10, 3) : print(i) 参数最多可以有三个，第一个为开始限定，第二个为结束限定，第三个为步长 123a = [&apos;Google&apos;, &apos;Baidu&apos;, &apos;Runoob&apos;, &apos;Taobao&apos;, &apos;QQ&apos;]for i in range(len(a)): print(i, a[i]) break、continue break 语句可以跳出 for 和 while 的循环体。如果你从 for 或 while 循环中终止，任何对应的循环 else 块将不执行 continue语句被用来告诉Python跳过当前循环块中的剩余语句，然后继续进行下一轮循环 pass 语句： 12while True: pass 遍历技巧： 在序列中遍历时，索引位置和对应值可以使用 enumerate() 函数同时得到： 1234567for i, v in enumerate([&apos;tic&apos;, &apos;tac&apos;, &apos;toe&apos;]): print(i, v)# 结果0 tic1 tac2 toe 反向遍历： 12for i in reversed(range(1, 10, 2)): print(i) 迭代器迭代器有两个基本的方法：iter( 和 next() 字符串，列表或元组对象都可用于创建迭代器 示例： 123456789101112list=[1,2,3,4]it = iter(list) # 创建迭代器对象for x in it: print (x, end=&quot; &quot;)list=[1,2,3,4]it = iter(list) # 创建迭代器对象while True: try: print (next(it)) except StopIteration: sys.exit() StopIteration 异常用于标识迭代的完成，防止出现无限循环的情况，在 next() 方法中我们可以设置在完成指定循环次数后触发 StopIteration 异常来结束迭代。 函数1.语法12def 函数名（参数列表）: 函数体 可更改(mutable)与不可更改(immutable)对象： 不可变类型：变量赋值 a = 5 后再赋值 a = 10，这里实际是新生成一个 int 值对象 10，再让 a 指向它，而 5 被丢弃，不是改变a的值，相当于新生成了a 可变类型：变量赋值 la=[1,2,3,4] 后再赋值 la[2]=5 则是将 list la 的第三个元素值更改，本身la没有动，只是其内部的一部分值被修改了 python 函数的参数传递： 不可变类型：类似 c++ 的值传递，如 整数、字符串、元组。如fun(a)，传递的只是a的值，没有影响a对象本身。比如在 fun(a)内部修改 a 的值，只是修改另一个复制的对象，不会影响 a 本身 可变类型：类似 c++ 的引用传递，如 列表，字典。如 fun(la)，则是将 la 真正的传过去，修改后fun外部的la也会受影响 2.参数必需参数： 必需参数须以正确的顺序传入函数。调用时的数量必须和声明时的一样，既只要声明了参数，调用时就必须传递 关键字参数：使用关键字参数允许函数调用时参数的顺序与声明时不一致，因为 Python 解释器能够用参数名匹配参数值。 例如： 1234567def printme( name, age ): &quot;打印任何传入的字符串&quot; print (str) return#调用printme函数printme( age = 10, name = &quot;菜鸟教程&quot;) 默认参数：调用函数时，如果没有传递参数，则会使用默认参数,与Kotlin一样 不定长参数：就是可变参数，python的可变参数可以有多种类型，任意指定 例如： 123456789# 可写函数说明def printinfo( arg1, **vardict ):&quot;打印任何传入的参数&quot;print (&quot;输出: &quot;)print (arg1)print (vardict)# 调用printinfo 函数printinfo(1, a=2,b=3) 3.匿名函数语法：lambda [arg1 [,arg2,…..argn]]:expression 示例： 12345# 可写函数说明sum = lambda arg1, arg2: arg1 + arg2# 调用sum函数print (&quot;相加后的值为 : &quot;, sum( 10, 20 )) 4.return语句return [表达式] 语句用于退出函数，选择性地向调用方返回一个表达式，不带参数值的return语句返回None 示例： 1234567def sum( arg1, arg2 ):total = arg1 + arg2print (&quot;函数内 : &quot;, total)return total# 调用sum函数total = sum( 10, 20 ) 变量作用域1.Python的作用域一共有4种 L： （Local） 局部作用域 E： （Enclosing） 闭包函数外的函数中 G： （Global） 全局作用域 B： （Built-in） 内置作用域（内置函数所在模块的范围） 以 L –&gt; E –&gt; G –&gt;B 的规则查找，即：在局部找不到，便会去局部外的局部找（例如闭包），再找不到就会去全局找，再者去内置中找。 示例： 12345g_count = 0 # 全局作用域def outer(): o_count = 1 # 闭包函数外的函数中 def inner(): i_count = 2 # 局部作用域 全局变量和局部变量，与Java类似 2.global 和 nonlocal 关键字当内部作用域想修改外部作用域的变量时，就要用到global和nonlocal关键字: 示例： 1234567891011num = 1 # 外部作用域定义变量def fun1(): global num # 需要使用 global 关键字声明 print(num) # 注意这两想要打印成功，一方面可思议使用global关键字，如果不适用此关键词声明，可以将num放在方法中传递进来使用，否则将会报错，这里跟Java不同，这是因为 fun1 函数中的 num 使用的是局部，未定义，无法修改。 num = 123 print(num)fun1() # 输出: 1 123print(num) # 输出： 123 如果要修改嵌套作用域（enclosing 作用域，外层非全局作用域）中的变量则需要 nonlocal 关键字: 示例： 123456789def outer(): num = 10 # 嵌套作用域 def inner(): nonlocal num # nonlocal关键字声明 num = 100 print(num) inner() print(num)outer() 输出 100 100 模块和包1.模块模块是一个包含所有你定义的函数和变量的文件，其后缀名是.py。模块可以被别的程序引入，以使用该模块中的函数等功能，这也是使用 python 标准库的方法import 语句 想使用 Python 源文件，只需在另一个源文件里执行 import 语句，语法如下： import module1, module2,... moduleNfrom … import 语句 Python 的 from 语句让你从模块中导入一个指定的部分到当前命名空间中，语法如下： from modname import name1, name2, ... nameNfrom … import * 语句 把一个模块的所有内容全都导入到当前的命名空间也是可行的，只需使用如下声明： from modname import *dir() 函数 内置的函数 dir() 可以找到模块内定义的所有名称，以一个字符串列表的形式返回2.包包是一种管理 Python 模块命名空间的形式，采用”点模块名称” 比如一个模块的名称是 A.B， 那么他表示一个包 A 中的子模块 B 用户可以每次只导入一个包里面的特定模块，比如: 123import sound.effects.echo这将会导入子模块:sound.effects.echo 它必须使用全名去访问:sound.effects.echo.echofilter(input, output, delay=0.7, atten=4) 还有一种导入子模块的方法是: 123from sound.effects import echo这同样会导入子模块: echo，并且他不需要那些冗长的前缀，所以他可以这样使用:echo.echofilter(input, output, delay=0.7, atten=4) 还有一种变化就是直接导入一个函数或者变量: 123from sound.effects.echo import echofilter同样的，这种方法会导入子模块: echo，并且可以直接使用他的 echofilter() 函数:echofilter(input, output, delay=0.7, atten=4) 基本数据类型变量不需要声明，直接赋值，且赋值后才能使用 1234counter = 1000name = &quot;wangjia&quot;a = b = c = 100 python基本类型 Number（数字） String（字符串） Tuple（元组） List（列表） Set（集合） Dictionary（字典） 注意：前三类是不可变类型 1.python数字类型 Numberint、bool、float、complex（复数） 可以删除对象引用 del var, (del var_a, var_b) 有很多数学函数可以直接调用，比如Java中Math函数中的很多计算函数，在python中直接用就可以，例如 ：abs(-1)，还有一些随机数函数，用的时候查就可以 2.字符串python中没有字符类型，单个字符当做字符串处理 字符串截取：变量[头下标:尾下标] 支持负数，负数代表从后往前截取 使用 “/“ 转义特殊字符，可以在字符串前加 “r” 表示原始字符，例如 r”abc/nvc” 注意字符串格式化： 一般用于日志输出，print (“我叫 %s 今年 %d 岁!” % (‘小明’, 10)) 注意字符串中有四十多个功能内建函数，我们在操作判断关于字符串时查看以后函数是否支持 3.list 列表可以直接初始化: list = [‘12321’, 299, 12.80] 也支持截取，截取方法特性与字符串一样 list是可变的，可以更改元素，list[0] = ‘45654’, 或者批量修改：list[1:3] = [‘45654’, 300, 11.20] 删除元素：list[0] = [], list[0:2] = [] 合并列表，直接 + ，例如： list1 + list2。 list * 2 表示列表元素复制两倍 列表函数： 123456781. 获取长度函数：len(list)2. max(list)：返回列表元素最大值3. min(list)：返回列表元素最小值4. ist(seq)：将元组转换为列表5. list.append(obj)：在列表末尾添加新的对象6. list.index(obj)：从列表中找出某个值第一个匹配项的索引位置7. list.insert(index, obj)：将对象插入列表8. list.remove(obj)：移除列表中某个值的第一个匹配项 del可以根据索引来删除列表元素，例如： del list[2:4] 可以使用append和pop方法将列表作为堆栈使用，等等 4.tuple元组与list类似，但是元素不可变，也支持截取输出 tuple不可变，但是可以包含可变的对象，或list 创建空元组：tup1 = (); 元组不可以修改，但是可组合： tup3 = tup1 + tup2 元组元素不能删除，可以删除整个元组： del tup1 元组运算符支持与list一致 内置函数有：len、max、min、tuple 5.set集合创建方式： set = {1, 2, 3, 4} 或者，set(1) 创建空set 必须使用 set = set() 可以使用 in 关键字判断元素在不在set中， 例如 bool = 2 in set set支持运算，- 表示差集， | 表示并集， &amp; 交集， ^ 不同时存在的元素 基本内置函数： 12341. 添加元素：set.add(元素)2. 删除元素：set.remove( x )3. 计算元素个数：len(s)4. 清空集合：s.clear() 6.Dictionary字典列表是有序的对象集合，字典是无序的对象集合,字典当中的元素是通过键来存取的，类似于map 使用： dict = {} dict[“jjw”] = “wangjia” 字典键不能重复，值无所谓 可以这样创建：d = {key1 : value1, key2 : value2 } 使用字典取值的时候： dict[key] 如果key不存在于字典中，就会抛出异常 字典修改与 Kotlin修改map值一样 删除元素： del dict[key] 字典的键必须是不可变的，不可以使用列表作为键 基本内置函数： 12345671. len(dict)：计算字典元素个数，即键的总数2. str(dict)：输出字典，以可打印的字符串表示，类似于toString()3. radiansdict.get(key, default=None)：返回指定键的值，如果值不在字典中返回default值4. key in dict：如果键在字典dict里返回true，否则返回false5. radiansdict.items()：以列表返回可遍历的(键, 值) 元组数组6. radiansdict.keys()：返回一个迭代器，可以使用 list() 来转换为列表7. radiansdict.values()：返回一个迭代器，可以使用 list() 来转换为列表 遍历字典技巧： 123knights = &#123;&apos;gallahad&apos;: &apos;the pure&apos;, &apos;robin&apos;: &apos;the brave&apos;&#125;for k, v in knights.items(): print(k, v) 7.数据转换方法：数据类型(数据) 即可。 例如 ： float(“10.00”) Python运算符数值运算符数值运算可以直接运算，运算的结果是精确的 (+、-、、/、%、*、\\) 主要说明：其他运算符于Java一致， /是精确除法，与Java不一样 ** 是幂，返回x的y次幂 // 取整除,向下取接近除数的整数 类似于我们Java中的 “&quot; 注意以上运算符都支持赋值运算，例如： += 、 *=、 //= 类型判断内置的 type() 函数可以用来查询变量所指的对象类型， isinstance()会判断类型是否属于某种类型 位运算与Java一致 逻辑运算符例如：a = 10; b = 20; and： x and y: 布尔”与” - 如果 x 为 False，x and y 返回 False，否则它返回 y 的计算值。 (a and b) 返回 20 or x or y: 布尔”或” - 如果 x 是 True，它返回 x 的值，否则它返回 y 的计算值。 (a or b) 返回 10 not not x: 布尔”非” - 如果 x 为 True，返回 False 。如果 x 为 False，它返回 True。 not(a and b) 返回 False 成员运算符in 如果在指定的序列中找到值返回 True，否则返回 False not in 如果在指定的序列中没有找到值返回 True，否则返回 False 一般用来判断变量在不在集合中，或者指定字符串中包含不包含特定字符串 身份运算符is: 是判断两个标识符是不是引用自一个对象 is not: 是判断两个标识符是不是引用自不同对象 例如：a = 10; b = 20; a is b 返回结果 true is 用于判断两个变量引用对象是否为同一个， == 用于判断引用变量的值是否相等 错误和异常异常即便Python程序的语法是正确的，在运行它的时候，也有可能发生错误。运行期检测到的错误被称为异常，异常的类型有多种，与Java类似 异常处理，使用类似于try-catch语句捕获处理： 12345678for arg in sys.argv[1:]: try: f = open(arg, &apos;r&apos;) except IOError: print(&apos;cannot open&apos;, arg) # 处理异常 else: # else语句表示没有发生任何异常的时候执行的代码块 print(arg, &apos;has&apos;, len(f.readlines()), &apos;lines&apos;) f.close() except就类似于catch，except可以处理多个异常： 12except (RuntimeError, TypeError, NameError): pass 抛出异常Python 使用 raise 语句抛出一个指定的异常，示例： 1raise NameError(&apos;HiThere&apos;) 定义清理行为try 语句还有另外一个可选的子句，它定义了无论在任何情况下都会执行的清理行为，就是finally代码块，具体执行与Java类似： 123456789def divide(x, y): try: result = x / y except ZeroDivisionError: print(&quot;division by zero!&quot;) else: print(&quot;result is&quot;, result) finally: print(&quot;executing finally clause&quot;)","categories":[{"name":"Python","slug":"Python","permalink":"https://jjw-story.github.io/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://jjw-story.github.io/tags/Python/"},{"name":"Python基础","slug":"Python基础","permalink":"https://jjw-story.github.io/tags/Python基础/"}],"author":"JJW"},{"title":"vim","slug":"vim","date":"2019-07-20T04:21:42.000Z","updated":"2019-07-25T02:02:10.245Z","comments":true,"path":"2019/07/20/vim/","link":"","permalink":"https://jjw-story.github.io/2019/07/20/vim/","excerpt":"","text":"vi编辑器vi编辑器是所有Unix及Linux系统下标准的编辑器，它的强大不逊色于任何最新的文本编辑器。 由于对Unix及Linux系统的任何版本，vi编辑器是完全相同的，因此您可以在其他任何介绍vi的地方进一步了解它。Vi也是Linux中最基本的文本编辑器，学会它后，您将在Linux的世界里畅行无阻。 vim vi的多模式 正常模式(Normal-mode) 启动vim后默认处于正常模式，其他模式都可以用ESC键直接转换到正常模式。在这个模式我们键盘所敲的任何按键都是对vim所下的命令，如何进行复制如何进行粘贴都是要在这个模式下进行的。 命令模式(Command-mode) 是指可以在界面最底部的一行输入控制操作命令，主要用来进行一些文字编辑的辅助功能，比如字串搜寻、替代、保存文件，以及退出vim等。在命令行模式下输入”:”，或者是使用”?”和”/”键，就可以进入命令模式了。命令模式下输入的命令都会在最底部的一行中显示，按Enter键vim便会执行命令。 插入模式(Insert-mode) 插入模式用来修改文件内容的，只有在Insert mode下，才可以做文字输入，按「ESC」键可回到命令行模式。 可视模式(Visual-mode) 有一些情况我们要进行一个高级编辑，比如对一块文件进行插入操作，就需要进入此模式。相当于高亮选取文本后的普通模式。在命令模式按下v, V, +v，ctrl+v可以进入可视模式。 vim编辑器所有的 Unix Like 系统都会内建 vi 文书编辑器，其他的文书编辑器则不一定会存在，但是目前我们使用比较多的是 vim 编辑器。 vim 具有程序编辑的能力，可以主动的以字体颜色辨别语法的正确性，方便程序设计。 Vim是从 vi 发展出来的一个文本编辑器。代码补完、编译及错误跳转等方便编程的功能特别丰富，在程序员中被广泛使用。 简单的来说，vi 是老式的字处理器，不过功能已经很齐全了，但是还是有可以进步的地方。 vim 则可以说是程序开发者的一项很好用的工具。 vim正常模式首先使用vim命令进入正常模式，使用方法如下： vim [文件] 文件可以不写，类似于我们Windows记事本一样，可以点击一个文本文档打开，或者直接打开记事本进行编写内容。 正常模式常用命令 在正常模式下可以使用 i、I、a、A、o、O 命令进入到插入模式 i 表示从光标当前位置进入插入模式 I 表示从光标当前所在行的行首进入插入模式 a 表示从光标当前位置的下一位进入插入模式 A 表示从光标当前所在行的行尾进图插入模式 o 表示从当前光标所在行的下一行并插入一行进入插入模式 O 表示从当前光标所在行的上一行并插入一行进入插入模式 v命令 正常模式下输入 v 命令可以进入可视模式 :命令 可以进入命令模式，也称为末行模式 esc命令 在其他模式下可以使用 esc 返回到正常模式 h、j、k、l h 光标向左移动 l 光标向右移动 j 光标向下移动 k 光标向上移动 y复制命令 yy:复制光标所在行到缓冲区 nyy:注意n表示行数，表示复制当前行向下n行的内容 y$:复制当前光标所在位置到行尾的内容 yw:与y$效果一致 ny$:注意n表示字数，表示复制当前光标所在位置后n个字符 d剪切命令 dd:剪切光标所在行到缓冲区 ndd:注意n表示行数，表示剪切当前行向下n行的内容 d$:剪切光标所在位置到行尾的内容 dw:与d$效果一致 p粘贴命令 将复制或剪切的内容粘贴到光标所在位置 u撤销命令 撤销命令，可以将失误的操作进行撤销，如果我们连续失误了很多个命令，就多次使用u命令，一条一条撤销 Ctrl + r 重做撤销命令 就是将使用u命令撤销的命令重做，类似于撤回撤销 x命令 删除光标所在的单个字符 r命令 替换光标所在单个字符，使用时先按r键，再输入新的字符 n + G命令 n表示行数，G是大写，既将光标移动到指定的行 如果不指定 n 则直接将光标跳转到文件的最后一行 ^命令 将光标移动到所在行的行尾 $命令 将光标移动到所在行的行首 vim命令模式下面介绍命令模式常用命令操作 :w [文件名] 如果是新建文件，则使用 :w 文件目录+文件名 来将编辑好的内容保存为指定的文件 如果是修改文件，则直接使用 :w 命令保存文件 :q 使用 :q 退出vim w和q命令可以组合起来使用，直接 :wq 来保存并退出vim 注意：:wq 也可以使用快捷键 shift + z z 来实现 :q! 不保存退出 注意：可以使用快捷键 shift + z + q 来实现 :! 有时候我们在打开vim的时候，需要临时执行一条命令，并查看命令执行的结果，就可以使用 ！ 命令 12345678910111213:!ifconfigroot@CHJ-20190520VPS:/# vim /tmp/test.txteth3: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 172.31.34.113 netmask 255.255.255.240 broadcast 172.31.34.127 inet6 fe80::4c47:3429:b72c:5130 prefixlen 64 scopeid 0x0&lt;global&gt; ether 7e:15:d8:27:73:38 (Ethernet) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 ... / + 字符 向下搜索字符，例如使用 /h 可以在文本中查到h出现的地方，并将光标移动到第一次出现的位置 在查找到的时候，我们还可以使用 “n” 键来将光标移动到下一个此字符出现的位置 还可以使用 “shift + n” 来向上查到此字符出现的位置 ? + 字符 向上搜索字符，例如使用 /h 可以在文本中查到h出现的地方，并将光标移动到第一次出现的位置 在查找到的时候，我们还可以使用 “n” 键来将光标移动到下一个此字符出现的位置 还可以使用 “shift + n” 来向上查到此字符出现的位置 :s/旧的字符/新的字符 此命令的作用是将文本中旧的字符替换成新的字符，模式只是将光标当前所在行的字符替换 我们还可以将文本中每一行第一次出现的指定字符替换，可以使用命令 “:%s/旧的字符/新的字符” 如果我们需要将文本跟中所有的指定的字符替换为新的字符，就需要使用命令 “:%s/旧的字符/新的字符/g” ，命令中的g表示global 1234567891011sdaaaaaaaaaaaaaaaaaaaaaasdfsdaaaaasddsaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaag:%s/a/0/gsd0000000000000000000000sdfsd00000sdds00000000000000000000000000000000000000000000g 有的时候我们需要替换指定的行的特定字符，则需要使用命令 “:3,5/s/旧的字符/新的字符/g”, 表示将第3-5行中的旧的字符替换 :set命令 :set nu: 表示设置显示文本的行号 :set nonu: 表示关闭显示文本的行号 :set hlsearch 在使用查找字符命令时，高亮显示查找到的所有字符 :set nohlsearch 关闭查找字符高亮显示 默认情况下，我们使用set命令设置只在当次vim命令中生效，当我们下次进入vim的时候，set命令设置的东西就又会恢复为默认，这样的话很多时候回造成不必要的麻烦，如果我们需要将set命令设置的内容保存，以便于每次打开都能用，例如 set nu 命令，我们希望每次打开vim编辑文本的时候都能显示行号，这样的话，就需要去修改vim的配置文件，配置文件目录为：/etc/vim/vimrc 我们直接使用 vim /etc/vim/vimrc 命令编辑此配置文件，然后使用 G 命令直接将光标跳转到最后一行，然后使用命令 o 向下插入一行空行，直接编辑我们要设置的内容即可 添加如下： 123456&quot; Source a global configuration file if availableif filereadable(&quot;/etc/vim/vimrc.local&quot;) source /etc/vim/vimrc.localendifset nu 编辑完成之后，使用 esc 退出编辑模式，使用 :wq 保存并退出，这样当我们每次打开文件的时候就都会显示行号 vim插入模式 字符按键以及Shift组合，输入字符 ENTER，回车键，换行 BACK SPACE，退格键，删除光标前一个字符 DEL，删除键，删除光标后一个字符 方向键，在文本中移动光标 HOME/END，移动光标到行首/行尾 Page Up/Page Down，上/下翻页 Insert，切换光标为输入/替换模式，光标将变成竖线/下划线 ESC，退出输入模式，切换到命令模式 vim可视模式可视模式主要是针对于我们对文件的大量操作使用此模式一次性执行完成，通常我们都是配合 “I”, “d” 命令来快捷操作 可以在正常模式下使用 v、V、Ctrl + v三种方式进入: 命令 进入字符可视模式，字符可视模式就是当我们移动光标的时候，它是以字符为单位进行选择的 V 进入行可视模式，当我们移动光标的时候是对行进行选中 Ctrl + v 进入块可视模式，移动光标时选中的是上下对齐的一个块，此命令是使用较多的命令 使用示例如下： 我们要在多个行中同时插入一下字符，就可以使用vim先打开文件，然后使用 “Ctrl + v” 选中要操作的多个行为块，然后输入 “I” 命令进入行首进行编辑，插入我们要插入的字符后，连续按两次 esc 按键，就会发现，之前选中的行都被添加进去了我们新添加的字符 1234567891011 18 tyutyutyutyutyustyukcdefsdf 19 sdfsdf 20 sdf 21 sdf# 操作完成后 18 wangjia3tyutyutyutyutyustyukcdefsdf 19 wangjia3sdfsdf 20 wangjia3sdf 21 wangjia3sdf 也可以使用 “d” 命令，将选中的块或字符直接删除，使用方法同上，在块选择后，直接输入 d 即可完成删除，此命令比较常用","categories":[{"name":"Linux","slug":"Linux","permalink":"https://jjw-story.github.io/categories/Linux/"}],"tags":[{"name":"command","slug":"command","permalink":"https://jjw-story.github.io/tags/command/"},{"name":"vim","slug":"vim","permalink":"https://jjw-story.github.io/tags/vim/"}],"author":"JJW"},{"title":"打包压缩与解压缩","slug":"打包压缩与解压缩","date":"2019-07-17T11:43:36.000Z","updated":"2019-07-18T12:48:43.436Z","comments":true,"path":"2019/07/17/打包压缩与解压缩/","link":"","permalink":"https://jjw-story.github.io/2019/07/17/打包压缩与解压缩/","excerpt":"","text":"打包压缩与解压缩打包与压缩windows常见压缩文件格式：.rar .zip .7z Linux常见压缩文件格式 ：.tar.gz; .tar.bz2; .tgz; tbz2 在linux系统中，文件的格式与后缀名没有关系，一般压缩工具压缩之后会在压缩文件后添加对应压缩工具的后缀名 在Windows中，打包与压缩是一个软件功能，但是在Linux中，它是由两个软件构成的 打包命令Linux早期的打包命令其实是备份命令，备份的介质是磁带，使用的命令是 tar 可以对打包后的磁带文件进行压缩存储，压缩的命令是 gzip 和 bzip2，所以我们可以看到，打包和压缩的命令是分开的 tar命令打包的使用方法：tar [选项] 打包后的文件名 要打包的文件 注意：tar命令 使用tar命令需要了解它的选项，来帮助我们完成打包过程，常用的选项如下： c 建立压缩档案，及打包必须的参数 f 打包成文件并指定文件名称，切记，这个参数是最后一个参数，后面只能接文件名 使用示例： 123root@CHJ-20190520VPS:/# tar cf /tmp/etc-backup.tar /etctar: Removing leading `/&apos; from member namesroot@CHJ-20190520VPS:/# 如上示例中，我们将 /etc 目录打包成文件，放置在 /tmp 目录下，并指定打包后的文件名称为 etc-backup.tar ，执行命令后提示会把根目录开头的斜杠 “/“ 去掉，方便我们在解包的时候可以解压到任何目录 压缩命令单纯的打包的打包后的文件一般都很大，因为他并没有做过压缩，一般我们都会在存储的时候进行压缩，如上述打包文件的大小： 12root@CHJ-20190520VPS:/# ls -lh /tmp/etc-backup.tar-rw-r--r-- 1 root root 2.7M Jul 17 20:11 /tmp/etc-backup.tar 通常使用的压缩命令有 gzip bzip2 使用方法如下： gzip [文件名] bzip2 [文件名] 1234root@CHJ-20190520VPS:/# gzip /tmp/etc-backup.tarroot@CHJ-20190520VPS:/# ls -lh /tmptotal 488K-rw-r--r-- 1 root root 459K Jul 17 20:40 etc-backup.tar.gz 在我们使用tar命令的时候，其实已经把这两个命令集成进去了，只需要使用的时候添加参数就可以完成压缩解压缩，下面介绍使用此两个压缩命令的tar选项： z 打包文件并使用gzip压缩文件 j 打包文件并使用bzip2压缩文件 一般在使用打包和压缩命令时，为了方便人看到压缩文件是使用哪种压缩方式压缩的文件，对压缩后的文件使用双扩展名，例如 “xxx.tar.xx”，具体使用如下： 12345678910tar: Removing leading `/&apos; from member namesroot@CHJ-20190520VPS:/# tar czf /tmp/etc-backup.tar.gz /etctar: Removing leading `/&apos; from member namesroot@CHJ-20190520VPS:/# ls -lh /tmptotal 1.0Mdrwxr-xr-x 1 root root 4.0K Jul 13 18:34 a-rw-r--r-- 1 root root 437K Jul 17 20:35 etc-backup.tar.bz2-rw-r--r-- 1 root root 459K Jul 17 20:35 etc-backup.tar.gz-rw-r--r-- 1 root root 551 Jul 14 14:03 testtextroot@CHJ-20190520VPS:/# 虽然压缩后的文件都不大，但是能感觉到使用 bzip2 压缩用的时间明显能更长一点，但是 bzip2 压缩后的文件更小一些，因为 bzip2 压缩后的比例更高一些 两种压缩方式都可以，如果我们希望压缩后的比例更高一下，就使用bzip2进行压缩 解压缩命令解压缩我们使用的命令还是 tar 命令，但是需要更换选项 使用方法：tar [参数] 压缩文件 [-C] [解压后目录] 常用选项说明： x 与上述 c 命令对应，x 参数是解压缩参数 f 与上述一致 v 显示所有进程，及压缩或解压明细 C 注意：C是大写，此选项是可以指定解压后的目录地址 使用示例： 12345root@CHJ-20190520VPS:/# ls /tmpetc-backup.tar etc-backup.tar.gz testtextroot@CHJ-20190520VPS:/# tar xf /tmp/etc-backup.tar -C /rootroot@CHJ-20190520VPS:/# ls /rootetc 将/tmp/etc-backup.tar压缩文件解压到 /root 目录下 实际我们见到的很多的压缩文件是 .tbz2 .tgz 的文件，这两种其实是 .tar.bz2 .tar.gz 的缩写，为了方便网络上的传播，将双扩展名的文件进行的缩写 解压我们不需要因为压缩软件的不同而使用不同的选项，只使用标准的 tar 解压就可以，如下： 12345678root@CHJ-20190520VPS:/# ls /tmpetc-backup.tar etc-backup.tar.gz testtextroot@CHJ-20190520VPS:/# tar -xvf /tmp/etc-backup.tar.gz -C /rootetc/etc/.pwd.lock...... 解压文件明细root@CHJ-20190520VPS:/# ls /rootetc","categories":[{"name":"Linux","slug":"Linux","permalink":"https://jjw-story.github.io/categories/Linux/"}],"tags":[{"name":"command","slug":"command","permalink":"https://jjw-story.github.io/tags/command/"},{"name":"打包压缩与解压缩","slug":"打包压缩与解压缩","permalink":"https://jjw-story.github.io/tags/打包压缩与解压缩/"}],"author":"JJW"},{"title":"文本查看命令","slug":"文本查看命令","date":"2019-07-15T05:55:16.000Z","updated":"2019-07-14T06:58:51.714Z","comments":true,"path":"2019/07/15/文本查看命令/","link":"","permalink":"https://jjw-story.github.io/2019/07/15/文本查看命令/","excerpt":"","text":"文本查看命令cat命令显示文本文件内容，适用于查看整体内容，文件内容不多的，将所有的文本内容都显示到终端 使用方法：cat [参数] 文件 参数说明-n 显示的文本的行编号 -e 显示行结束符号$ 示例： 123456root@CHJ-20190520VPS:/tmp# cat -n -E testtext 1 sdf$ 2 $ 3 sd$ 4 f$ 5 ds$ head命令查看文件的开头的内容，默认显示文件开头的前十行 使用方法：head [参数] 文件 参数说明-n 注意：n 表示行数，意为查看文件的前n行内容 1234root@CHJ-20190520VPS:/tmp# head -3 testtextsdfsd tail命令查看文件的末尾的内容，默认显示文件末的后十行 使用方法：tail [参数] 文件 参数说明-n 注意：n 表示行数，意为查看文件的后n行内容 -f 循环读取文本信息，此命令一般用于文件内容在不断变化的文本查看，一般在查看服务器日志内容时使用 当我们看到文件在一直滚动循环查看，想要停止的时候，使用 ctrl + c命令，退出循环查看，即可停止来具体查看 wc命令wc(Word Count)命令的功能为统计指定文件中的字节数、字数、行数，并将统计结果显示输出。 参数说明-l 统计文本文件的内容行数，一般我们在使用文本查看命令时，不清粗应该使用哪种命令来查看，可以使用此命令来查看文本的行数，然后选择要使用的文本查看命令 12root@CHJ-20190520VPS:/tmp# wc -l testtext206 testtext -c 统计字节数 -m 统计字符数。这个标志不能与 -c 标志一起使用 -w 统计字数。一个字被定义为由空白、跳格或换行字符分隔的字符串 -L 打印最长行的长度 12root@CHJ-20190520VPS:/tmp# wc -L testtext7 testtext more命令分页显示文件内容，还支持直接跳转行等功能，最大的特点是查看每一页文本内容下方都会显示当前当前查看的文本内容所在位置百分比 使用方法：more 文件名 具体操作 Space：显示文本下一屏内容 Enter：只显示文本下一行内容 b：显示文本上一屏内容 q：退出 less命令分页显示文件内容，操作比more更为详细 使用方法：less [参数] 文件名 参数说明-m 显示类似more命令的百分比 -N 注意这里是大写N，显示每行的行号 具体操作 Space：显示文本下一屏内容 b：显示文本上一屏内容 Enter：前进一行 v：后退一行 d：前进半页 u：后退半页 /字符串 向下搜索 ?字符串 向上搜索 左右方向键 相当于水平滚动条 q键：退出","categories":[{"name":"Linux","slug":"Linux","permalink":"https://jjw-story.github.io/categories/Linux/"}],"tags":[{"name":"command","slug":"command","permalink":"https://jjw-story.github.io/tags/command/"},{"name":"文本查看命令","slug":"文本查看命令","permalink":"https://jjw-story.github.io/tags/文本查看命令/"}],"author":"JJW"},{"title":"文件管理命令","slug":"文件管理命令","date":"2019-07-11T12:32:46.000Z","updated":"2019-07-14T05:53:08.747Z","comments":true,"path":"2019/07/11/文件管理命令/","link":"","permalink":"https://jjw-story.github.io/2019/07/11/文件管理命令/","excerpt":"","text":"文件管理命令mkdir命令创建目录 使用方法：mkdir [参数] [目录…] 省略号代表可以建立多个目录 例如：建立一个 demo 目录 在根目录下建立：mkdir /demo 在当前目录下建立：mkdir ./demo “./“可以省略 建立多个目录：mkdir demo1 demo2 demo3 如果目录已存在，建立会失败 12root@CHJ-20190520VPS:/# mkdir homemkdir: cannot create directory ‘home’: File exists 参数的使用-p 一次创建多级目录，既父目录不存在先创建父目录 123456789101112root@CHJ-20190520VPS:/# mkdir -p a/b/c/droot@CHJ-20190520VPS:/# ls -R /a/a:b/a/b:c/a/b/c:d/a/b/c/d: 相比Windows，我们发现命令行的好处就在于可以一次创建多级目录 -v 显示目录创建的过程 123root@CHJ-20190520VPS:/# mkdir -p -v /e/fmkdir: created directory &apos;/e&apos;mkdir: created directory &apos;/e/f&apos; rmdir命令删除目录 使用方法：rmdir [目录…] 注意：rmdir 只能删除空的目录，删除非空目录会失败，必须逐级删除目录中的文件 12root@CHJ-20190520VPS:/# rmdir armdir: failed to remove &apos;a&apos;: Directory not empty rm命令删除文件或目录 使用方法：rm [参数] [目录…] 参数的使用-i 交互模式，在删除前询问用户是否操作 -r 如果删除的是目录，则需要使用此参数，作用是即使目录是非空的，也能逐级删除，但是每一级都要手动确认 -f 即使原档案属性设为唯读，亦直接删除，无需逐一确认。 特别需要注意这条命令，注意他的目录是可以写多个的，如果我们的命令写成 “rm -r -f / a “，既 不小心在 “/“ 与 “a” 之间多了一个空格，那么系统下所有的文件都会被删除，而且不会有任何提示。 所以我们在使用此项命令时一定要留意检查，避免操作失误 -r -f 可以合并使用： 12345root@CHJ-20190520VPS:/# mkdir -p a/b/c/d/f/eroot@CHJ-20190520VPS:/# rm -rf aroot@CHJ-20190520VPS:/# lsbin boot dev e etc home init lib lib64 media mnt opt proc root run sbin snap srv sys tmp usr varroot@CHJ-20190520VPS:/# cp命令文件复制命令，copy简写 使用方法： cp [参数] [文件…] 目录 cp [参数] [文件] 文件…目录 参数的使用-r 当我们直接使用cp命令复制目录的时候，是会失败的，因为cp命令本身是只复制文件，递归复制，用于目录的复制操作 12345root@CHJ-20190520VPS:/# cp a /tmpcp: -r not specified; omitting directory &apos;a&apos;root@CHJ-20190520VPS:/# cp -r a /tmproot@CHJ-20190520VPS:/# ls /tmpa -v 复制时显示复制信息，类似进度条，直接复制文件的时候不会有任何提示 12root@CHJ-20190520VPS:/# cp -v /filea /tmp&apos;/filea&apos; -&gt; &apos;/tmp/filea&apos; -p 与文件的属性一起复制，而非使用默认属性，例如文件创建更新时间 -a 与文件的属性一起复制，包括文件的属主，权限等 123456root@CHJ-20190520VPS:/# cp -v -a filea /tmp&apos;filea&apos; -&gt; &apos;/tmp/filea&apos;root@CHJ-20190520VPS:/# ls -l /tmp/filea-rw-r--r-- 1 root root 0 Jul 13 18:47 /tmp/filearoot@CHJ-20190520VPS:/# ls -l filea-rw-r--r-- 1 root root 0 Jul 13 18:47 filea -i 若目标文件已存在，在覆盖时会先询问是否真的操作 123root@CHJ-20190520VPS:/# cp -v -a -i filea /tmpcp: overwrite &apos;/tmp/filea&apos;? yes&apos;filea&apos; -&gt; &apos;/tmp/filea&apos; 注意词命令的第二种语法 表示将文件复制并重命令为自定义名称 12345root@CHJ-20190520VPS:/# cp -v -a -i -r filea /tmp/fileb&apos;filea&apos; -&gt; &apos;/tmp/fileb&apos;root@CHJ-20190520VPS:/# ls /tmpa filea filebroot@CHJ-20190520VPS:/# mv命令mv命令有两个功能，一个是文件及文件夹的移动功能，另一个是重命名功能 使用方法： mv [参数] 源文件 目录…文件名 重命名演示： 1234root@CHJ-20190520VPS:/# mv filea filebroot@CHJ-20190520VPS:/# lsa boot e fileb init lib64 mnt proc run snap sys usrbin dev etc home lib media opt root sbin srv tmp var 注意：重命名的本质其实就是将文件移动 移动演示： 123root@CHJ-20190520VPS:/# mv fileb /tmproot@CHJ-20190520VPS:/# ls /tmpa filea fileb 还可以移动并重命名，使用命令： mv filea /tmp/filec 通配符的使用* *号表示匹配当前目录下所有目录及文件 使用示例，例如我们在 /tmp 目录下创建三个文件 filea、filebb、fileccc，然后使用通配符将此三个文件复制到其他目录下 123456root@CHJ-20190520VPS:/tmp# lsa dira dirb dirc filea fileb filecroot@CHJ-20190520VPS:/# cp /tmp/file* /root@CHJ-20190520VPS:/# lsa boot e filea fileccc init lib64 mnt proc run snap sys usrbin dev etc filebb home lib media opt root sbin srv tmp var ? ? 号与 * 作用相同，但是它只匹配一个字符，* 匹配多个字符 1234567891011root@CHJ-20190520VPS:/# lsa boot e home lib media opt root sbin srv tmp varbin dev etc init lib64 mnt proc run snap sys usrroot@CHJ-20190520VPS:/# ls /tmp/file*/tmp/filea /tmp/filebb /tmp/filecccroot@CHJ-20190520VPS:/# cp -v /tmp/file? /&apos;/tmp/filea&apos; -&gt; &apos;/filea&apos;root@CHJ-20190520VPS:/# lsa boot e filea init lib64 mnt proc run snap sys usrbin dev etc home lib media opt root sbin srv tmp var 通过示例我们发现这里只复制过来 filea 目录，所以 ? 表示只匹配一个字符 注意上面我们使用ls命令也是用了通配符，表示通配符可以在很多命令中使用","categories":[{"name":"Linux","slug":"Linux","permalink":"https://jjw-story.github.io/categories/Linux/"}],"tags":[{"name":"command","slug":"command","permalink":"https://jjw-story.github.io/tags/command/"},{"name":"文件管理命令","slug":"文件管理命令","permalink":"https://jjw-story.github.io/tags/文件管理命令/"}],"author":"JJW"},{"title":"文件查看命令","slug":"文件查看命令","date":"2019-07-08T04:55:40.000Z","updated":"2019-07-27T06:23:23.261Z","comments":true,"path":"2019/07/08/文件查看命令/","link":"","permalink":"https://jjw-story.github.io/2019/07/08/文件查看命令/","excerpt":"","text":"文件查看命令文件管理命令是Linux管理的核心，因为Linux中有一个非常重要的概念-一切皆文件。在Windows系统中存在注册表、设备管理器了等等各种各样的组建来管理Windows，但是在Linux中，我们系统的管理控制等通通都是文件，所以文件管理命令是Linux管理中非常重要的内容。 pwd命令显示出完整的当前活动目录名称 注意：目录结构中 “/“ 目录和 “/root” 目录是两个不同的目录，”/“目录是我们的根目录，”/root”是root用户的家目录 ls命令列出目录的内容 使用方法：ls [选项] [文件名称…] 如果不写文件名称，默认代表当前目录 省略号表示支持多个文件或者目录名称，多个文件或目录中间用空格隔开（可以用多个空格） 查询内容有颜色不同，代表着不同的权限。不同的客户端颜色展示可能不同 ls基本选项说明-l使用详细格式列表，此命令可以直接缩写为 ll 命令执行如下及结果说明： 123456789root@CHJ-20190520VPS:/usr/lib# ls -ltotal 920drwxr-xr-x 1 root root 4096 May 21 22:39 kerneldrwxr-xr-x 1 root root 4096 May 21 22:39 klibcdrwxr-xr-x 1 root root 4096 May 21 22:40 language-selectorlrwxrwxrwx 1 root root 21 Feb 12 16:55 libDeployPkg.so.0 -&gt; libDeployPkg.so.0.0.0-rw-r--r-- 1 root root 31280 Feb 12 16:55 libDeployPkg.so.0.0.0lrwxrwxrwx 1 root root 20 Feb 12 16:55 libguestlib.so.0 -&gt; libguestlib.so.0.0.0-rw-r--r-- 1 root root 22656 Feb 12 16:55 libguestlib.so.0.0.0 一共查询出七列内容，分别表示： 文件属性(占10个字符空间)、拥有的文件数量、文件的创建者、所属的group、文件大小、建档日期、文件名 重点说明文件属性代表的内容： Linux的文件基本上分为三个属性：可读（r），可写（w），可执行（x） 但是这里有十个格子可以添（具体程序实现时，实际上是十个bit位） 第一个小格是特殊表示格，表示目录或连结文件等等，d表示目录，例如drwx——;l表示连结文件，如lrwxrwxrwx;如果是以一横“-”表示，则表示这是文件 其余剩下的格子就以每3格为一个单位，因为Linux是多用户多任务系统，所以一个文件可能同时被许多人使用，所以我们一定要设好每个文件的权限，其文件的权限位置排列顺序是（以-rwxr-xr-x为例）： rwx(Owner)r-x(Group)r-x(Other) 这个例子表示的权限是：使用者自己可读，可写，可执行；同一组的用户可读，不可写，可执行；其它用户可读，不可写，可执行。 另外，有一些程序属性的执行部分不是X,而是S,这表示执行这个程序的使用者，临时可以有和拥有者一样权力的身份来执行该程序。一般出现在系统管理之类的指令或程序，让使用者执行时，拥有root身份。 -a显示全部文件包括隐藏的文件 Linux隐藏文件的目的是为了在用户日常操作中不会误操作或修改掉一些不可修改的文件内容 Linux创建隐藏文件的方式很简单，只需要在文件名前面加一个 “.” 即可 -t按照文件创建或最后修改的时间排序，默认是根据文件的名称来逆向排序 -r逆向排序显示文件 一般是配合 -l 来使用，例如： ls -l -r 如果我们需要按照文件的创建/修改时间来进行逆向排序则可以使用命令 “-t”，例如： ls -l -r -t 可以组合命令，多个参数不需要每个都用空格隔开，例如上述命令，可以写为： ls -lrt -R递归显示文件，就是罗列出当前文件中所有的文件及文件夹，还有子文件夹中的文件夹及文件，都罗列出来 -h将文件大小数据显示转化为可以阅读清楚的大小表示单位 –full-time列出文件完整的日期时间 –color={auto,never,always}用颜色来表示不同的文件类型，大括号内是参数选项 never：从不使用颜色表示不同类型 always：总是使用颜色表示不同类型 auto：根据终端属性自动确定是否使用颜色表示不同类型 cd命令cd命令用于切换当前工作目录至 dirName(目录参数) 使用方法： cd /path/to…绝对路径 cd /path/to…相对路径 注意一些特殊参数： 路径缺省，表示切换到当前用户的目录 ~ 也是切换到当前用户的目录 / 切换到根目录 ../ 切换到上一层目录，注意 “/“ 可以省略也可以 “cd ../..” 切换到上两级目录 - 切换到上一次访问的目录 12345wangjia3@CHJ-20190520VPS:/home$ pwd/homewangjia3@CHJ-20190520VPS:/home$ cd -/usr/local/libwangjia3@CHJ-20190520VPS:/usr/local/lib$ 当我们要切换的目录离根目录比较近，那就使用绝对路径 当我们要切换的目录离当前目录比较近，那就使用相对路径","categories":[{"name":"Linux","slug":"Linux","permalink":"https://jjw-story.github.io/categories/Linux/"}],"tags":[{"name":"command","slug":"command","permalink":"https://jjw-story.github.io/tags/command/"},{"name":"文件查看命令","slug":"文件查看命令","permalink":"https://jjw-story.github.io/tags/文件查看命令/"}],"author":"JJW"},{"title":"IDEA快捷键","slug":"IDEA快捷键","date":"2019-07-07T10:00:00.000Z","updated":"2019-11-20T01:37:16.449Z","comments":true,"path":"2019/07/07/IDEA快捷键/","link":"","permalink":"https://jjw-story.github.io/2019/07/07/IDEA快捷键/","excerpt":"","text":"IDEA快捷键 向上箭头 ctrl+i 向上一行选中 ctrl+shfit+i 当前行内容向上移动一行 ctrl+alt+i 当前行内容向上插入复制一行 ctrl+shift+alt+i 向下箭头 ctrl+k 向下选中一行 ctrl+shift+k 当前行内容向下移动一行 ctrl+alt+k 当前行内容向下插入复制一行 ctrl+shift+alt+k END ctrl+o 选中到END ctrl+shift+o HOME ctrl+u 选中到HOME ctrl+shift+u 向左移动一个单词 ctrl+j 向左移动一个字母 ctrl+alt+j 向左选中一个单词 ctrl+shift+j 向左选中一个字母 ctrl+shift+alt+j 向右移动一个单词 ctrl+l 向右移动一个字母 ctrl+alt+l 向右选中一个单词 ctrl+shift+l 向右选中一个字母 ctrl+shift+alt+l 打开行数跳转框 ctrl+g 切换到上一个编辑窗口 ctrl+, 切换到下一个编辑窗口 ctrl+. 关闭当前编辑窗口 ctrl+w 打开查找框 ctrl+f3 向下查找 f3 向上查找 shift+f3 显示意图动作 ctrl+空格，alt+enter project框移动 ctrl+i，ctrl+k 打开关闭：enter 删除一行 ctrl+alt+d 打开各种功能框 alt+功能框框对应数字 打开接口实现类，进入方法内部，获取方法在哪里被调用（类似eclipse的ctrl+alt+h） ctrl+b或者ctrl+shift+F7 RUN shift+f9 DEBUG shift+f10 括号跳转（头-尾） ctrl+m+b 当前文件文本查找 ctrl+f 查找文件（查找类文件） 双击shift project中查找包含指定文本的文件 ctrl+shift+f 查看某个类包含的所有属性方法 ctrl+F12 打开后可以直接输入方法名查找过滤，对应Eclipse ctrl+o","categories":[{"name":"IDEA","slug":"IDEA","permalink":"https://jjw-story.github.io/categories/IDEA/"}],"tags":[{"name":"IDEA","slug":"IDEA","permalink":"https://jjw-story.github.io/tags/IDEA/"}],"author":"JJW"},{"title":"帮助命令","slug":"帮助命令","date":"2019-07-06T12:58:05.000Z","updated":"2019-07-27T05:13:22.166Z","comments":true,"path":"2019/07/06/帮助命令/","link":"","permalink":"https://jjw-story.github.io/2019/07/06/帮助命令/","excerpt":"","text":"man命令man命令 man是manual的缩写（有问题找男人帮忙） 使用方法：man [章数] [命令] 可以查询到要查询的命令具体作用、参数选项、描述等。查看完毕后按 q 退出 man命令本身也是一个命令，所以可以通过 [man man] 命令查看此命令本身的一些帮助文档 man命令帮助内容man命令帮助内容一共可以有九章的帮助内容，分别如下： Commands 用户可从 shell 运行的命令,查询第一章的内容的时候 1 可以省略 System calls 必须由内核完成的功能，系统调用 Library calls 大多数 libs 函数，如 sort(3) 此命令与第三章命令一般是用在我们在编程过程中获取函数的帮助文档使用的 Special files /dev 目录中的文件，第四章和第五章主要是文件的帮助 File formats and conventions /etc/pass 等人类可读的配置文件等格式及说明 Game Macro packages and conveentions 文件系统标准描述，网络协议，ASCII和其他字符集等 System Management commands 类似 mount(8) 等命令，大部分只能由 root 执行 Kernel routes 废弃的章节，原本是想把一些关于核心的文件放在这里 man一共有九个章节的帮助，分为这么多章主要是因为命令和系统调用还有文件有的时候会出现重名的情况，一旦重名，我们只单用一个man不加章节很难区分 例如 passwd 命令，这个命令是进行用户密码设置的命令，但是在我们的 /etc 目录下，还有一个 passwd 的一个配置文件，如果我们只使用 man passwd 的命令，很难区分出到底是对这个命令的帮助文档，还是对这个配置文件的帮助文档，这时，我们就可以通过章节这个参数来进行区分 有的时候我们并不知道要查看的帮助到底是命令还是配置文件等，可以使用 man a [参数] 来详细查看所有的帮助文档，在查看完一条之后，按 q 退出，即会提示有其他条的帮助文档，我们可以选择查看 man命令说明页含义 标头 含义 Name 命令的名称和用途 Synopsis 命令语法 Description 完整描述 Environment 命令使用的环境变量 Author 开发该程序者 Files 对该命令重要的文件列表 See also 相关信息 Diagnostics 可能的错误和警告 Bugs （可能没有） help命令help命令也是帮助命令，它使用分为内部命令使用帮助、外部命令使用帮助 内部命令和外部命令shell（命令解释器）自带的命令成为内部命令，其他的是外部命令 内部命令内部命令实际上是shell程序的一部分，其中包含的是一些比较简单的linux系统命令，这些命令由shell程序识别并在shell程序内部完成运行，通常在linux系统加载运行时shell就被加载并驻留在系统内存中。内部命令是写在bashy源码里面的，其执行速度比外部命令快，因为解析内部命令shell不需要创建子进程。比如：exit，history，cd，echo等。 外部命令外部命令是linux系统中的实用程序部分，因为实用程序的功能通常都比较强大，所以其包含的程序量也会很大，在系统加载时并不随系统一起被加载到内存中，而是在需要时才将其调用内存。通常外部命令的实体并不包含在shell中，但是其命令执行过程是由shell程序控制的。shell程序管理外部命令执行的路径查找、加载存放，并控制命令的执行。外部命令是在bash之外额外安装的，通常放在/bin，/usr/bin，/sbin，/usr/sbin 等等。可通过 “echo $PATH” 命令查看外部命令的存储路径，比如：ls、vi等。 使用type命令区分内外部命令使用方法：type [命令] 1234root@CHJ-20190520VPS:~# type cdcd is a shell builtinroot@CHJ-20190520VPS:~# type mkdirmkdir is /bin/mkdir 内部命令和外部命令最大的区别之处就是性能。内部命令由于构建在shell中而不必创建多余的进程，要比外部命令执行快得多。因此和执行更大的脚本道理一样，执行包含很多外部命令的脚本会损害脚本的性能。 help命令用法 内部命令 help [命令] 外部命令 [命令] --help 帮助命令总结Linux的基本操作方式是命令行，通过命令行的话就需要熟记很多的操作命令，但是海量的命令不适合死记硬背。 当我们使用到陌生的命令的时候，就可以使用 man help 等帮助命令查询它的帮助文档，来帮助我们了解这些命令。 注意：很多内部命令 man 是没有帮助文档的，所以我们使用更多的应该是 help 命令。 which命令查看可执行文件的位置，从全局环境变量PATH里面查找对应的路径，默认是找 bash内所规范的目录，一般用来确认系统中是否安装了指定软件 在PATH变量指定的路径中，搜索某个系统命令的位置，并返回第一个搜索结果 使用方法：which [参数] 命令 -a 打印出PATH中的所有匹配项，而不是仅仅第一个 –skip-dot 跳过PATH中以点开头的目录 –skip-tilde 跳过PATH中以波浪号开头的目录 使用示例： 1234root@CHJ-20190520VPS:~# which shutdown/sbin/shutdownroot@CHJ-20190520VPS:~# which cdroot@CHJ-20190520VPS:~# 注意：我们发现查找 cd 命令竟然没有找到，这是因为 cd 是bash 内建的命令！ 但是 which 默认是找 PATH 内所规范的目录，所以当然一定找不到的","categories":[{"name":"Linux","slug":"Linux","permalink":"https://jjw-story.github.io/categories/Linux/"}],"tags":[{"name":"command","slug":"command","permalink":"https://jjw-story.github.io/tags/command/"},{"name":"帮助命令","slug":"帮助命令","permalink":"https://jjw-story.github.io/tags/帮助命令/"}],"author":"JJW"},{"title":"初识Linux","slug":"什么是Linux","date":"2019-07-06T01:49:19.000Z","updated":"2019-07-07T04:57:08.258Z","comments":true,"path":"2019/07/06/什么是Linux/","link":"","permalink":"https://jjw-story.github.io/2019/07/06/什么是Linux/","excerpt":"","text":"什么是LinuxLinux有两种含义 一种是Linus编写的操作系统的内核 另一种是广义的操作系统 一般我们所说的Linux就是说广义的操作系统 服务端操作系统一般都是使用命令行的方式进行操作,主要因为服务端操作系统与客户端操作系统所做的事情不一样,服务端主要追求稳定 Linux版本内核版本 内核版本分为三个部分,一般使用的是稳定版 稳定版又分为三个版本号，分别是 主版本号 次版本号 末版本号 次版本号为奇数为开发版，偶数为稳定版 发行版本 Red Hat EnterPrise 特点：软件经过专业人员的测试，非常稳定，有大公司支持，但是在技术支持和更新最新的安全漏洞补丁的时候是需要付费的 Fedora 特点：也是Red Hat公司发行的，不同之处是发行方式是组建一个社区，来免费提供操作系统，软件要比上述新，但是没有经过专业的测试，稳定性要差 CentOS 特点：基于Red Hat EnterPrise源代码进行编译的，可以免费试用 Ubuntu 特点：定制了非常华丽的界面，可以直接安装在PC机上进行操作 Debian 特点：与Ubantu一样 终端的使用 图形终端 命令行终端 远程终端（SSH VNC） 通过互联网远程连接终端，实际生产使用较多 Linux常见目录介绍 / 根目录 /root root用户的家目录 /home/username 普通用户的家目录 /etc 配置文件目录 /bin 命令目录 /sbin 管理命令目录 /usr/bin /usr/sbin 系统预装的其他命令","categories":[{"name":"Linux","slug":"Linux","permalink":"https://jjw-story.github.io/categories/Linux/"}],"tags":[{"name":"overview","slug":"overview","permalink":"https://jjw-story.github.io/tags/overview/"}],"author":"JJW"}]}